{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from matplotlib.backend_bases import RendererBase\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from tensorboardX import SummaryWriter\n",
    "from transformers import BertModel, BertTokenizer\n",
    "from transformers import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import BertForSequenceClassification, BertConfig\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of training set: 7934\n",
      "size of validation set: 3393\n",
      "joy        2326\n",
      "sadness    2317\n",
      "anger      2259\n",
      "neutral    2254\n",
      "fear       2171\n",
      "Name: Emotion, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data_train = pd.read_csv('data/data_train.csv', encoding='utf-8')\n",
    "data_test = pd.read_csv('data/data_test.csv', encoding='utf-8')\n",
    "\n",
    "X_train = data_train.Text.tolist()\n",
    "X_test = data_test.Text.tolist()\n",
    "\n",
    "y_train = data_train.Emotion.tolist()\n",
    "y_test = data_test.Emotion.tolist()\n",
    "\n",
    "data = data_train.append(data_test, ignore_index=True)\n",
    "\n",
    "class_names = ['joy', 'sadness', 'fear', 'anger', 'neutral']\n",
    "\n",
    "print('size of training set: %s' % (len(data_train['Text'])))\n",
    "print('size of validation set: %s' % (len(data_test['Text'])))\n",
    "print(data.Emotion.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>There are tons of other paintings that I thin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Yet the dog had grown old and less capable , a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fear</td>\n",
       "      <td>When I get into the tube or the train without ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fear</td>\n",
       "      <td>This last may be a source of considerable disq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>anger</td>\n",
       "      <td>She disliked the intimacy he showed towards so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sadness</td>\n",
       "      <td>When my family heard that my Mother's cousin w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>joy</td>\n",
       "      <td>Finding out I am chosen to collect norms for C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>anger</td>\n",
       "      <td>A spokesperson said : ` Glen is furious that t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Yes .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sadness</td>\n",
       "      <td>When I see people with burns I feel sad, actua...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Emotion                                               Text\n",
       "0  neutral   There are tons of other paintings that I thin...\n",
       "1  sadness  Yet the dog had grown old and less capable , a...\n",
       "2     fear  When I get into the tube or the train without ...\n",
       "3     fear  This last may be a source of considerable disq...\n",
       "4    anger  She disliked the intimacy he showed towards so...\n",
       "5  sadness  When my family heard that my Mother's cousin w...\n",
       "6      joy  Finding out I am chosen to collect norms for C...\n",
       "7    anger  A spokesperson said : ` Glen is furious that t...\n",
       "8  neutral                                             Yes . \n",
       "9  sadness  When I see people with burns I feel sad, actua..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = {\n",
    "    'joy': 0,\n",
    "    'sadness': 1,\n",
    "    'fear': 2,\n",
    "    'anger': 3,\n",
    "    'neutral': 4\n",
    "}\n",
    "\n",
    "# Integer values for each class\n",
    "y_train = [encoding[x] for x in y_train]\n",
    "y_test = [encoding[x] for x in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14bce89e8d244f8cbba8a77d43db9d73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_data_train = tokenizer.batch_encode_plus(\n",
    "    X_train, \n",
    "    add_special_tokens=True, \n",
    "    return_attention_mask=True, \n",
    "    pad_to_max_length=True, \n",
    "    max_length=256, \n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "encoded_data_val = tokenizer.batch_encode_plus(\n",
    "    X_test, \n",
    "    add_special_tokens=True, \n",
    "    return_attention_mask=True, \n",
    "    pad_to_max_length=True, \n",
    "    max_length=256, \n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "\n",
    "input_ids_train = encoded_data_train['input_ids']\n",
    "attention_masks_train = encoded_data_train['attention_mask']\n",
    "labels_train = torch.tensor(y_train)\n",
    "\n",
    "input_ids_val = encoded_data_val['input_ids']\n",
    "attention_masks_val = encoded_data_val['attention_mask']\n",
    "labels_val = torch.tensor(y_test)\n",
    "\n",
    "dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
    "dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 3\n",
    "\n",
    "dataloader_train = DataLoader(dataset_train, \n",
    "                              sampler=RandomSampler(dataset_train), \n",
    "                              batch_size=batch_size)\n",
    "\n",
    "dataloader_validation = DataLoader(dataset_val, \n",
    "                                   sampler=SequentialSampler(dataset_val), \n",
    "                                   batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertForSequenceClassification(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\", \n",
    "    num_labels = len(class_names),   \n",
    "    output_attentions = False,\n",
    "    output_hidden_states = False, \n",
    ")\n",
    "print(model)\n",
    "params = list(model.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 1e-5,\n",
    "                  eps = 1e-8 \n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
    "NUM_EPOCHS=3\n",
    "\n",
    "writer = SummaryWriter(log_dir='./content/')\n",
    "total_steps = len(train_dataset) * NUM_EPOCHS\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0,\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score_func(preds, labels):\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return f1_score(labels_flat, preds_flat, average='weighted')\n",
    "\n",
    "def accuracy_per_class(preds, labels):\n",
    "    label_dict_inverse = {v: k for k, v in label_dict.items()}\n",
    "    \n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "\n",
    "    for label in np.unique(labels_flat):\n",
    "        y_preds = preds_flat[labels_flat==label]\n",
    "        y_true = labels_flat[labels_flat==label]\n",
    "        print(f'Class: {label_dict_inverse[label]}')\n",
    "        print(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checkpoint = torch.load('./model/final.pt')\n",
    "#model.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Epoch 1:   0%|          | 0/2645 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1:   0%|          | 0/2645 [00:00<?, ?it/s, training_loss=0.026]\u001b[A\n",
      "Epoch 1:   0%|          | 1/2645 [00:00<06:43,  6.55it/s, training_loss=0.026]\u001b[A\n",
      "Epoch 1:   0%|          | 1/2645 [00:00<06:43,  6.55it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:   0%|          | 2/2645 [00:00<06:10,  7.14it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:   0%|          | 2/2645 [00:00<06:10,  7.14it/s, training_loss=0.353]\u001b[A\n",
      "Epoch 1:   0%|          | 3/2645 [00:00<05:45,  7.64it/s, training_loss=0.353]\u001b[A\n",
      "Epoch 1:   0%|          | 3/2645 [00:00<05:45,  7.64it/s, training_loss=0.065]\u001b[A\n",
      "Epoch 1:   0%|          | 3/2645 [00:00<05:45,  7.64it/s, training_loss=0.505]\u001b[A\n",
      "Epoch 1:   0%|          | 5/2645 [00:00<05:16,  8.34it/s, training_loss=0.505]\u001b[A\n",
      "Epoch 1:   0%|          | 5/2645 [00:00<05:16,  8.34it/s, training_loss=0.458]\u001b[A\n",
      "Epoch 1:   0%|          | 5/2645 [00:00<05:16,  8.34it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 1:   0%|          | 7/2645 [00:00<04:57,  8.88it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 1:   0%|          | 7/2645 [00:00<04:57,  8.88it/s, training_loss=0.728]\u001b[A\n",
      "Epoch 1:   0%|          | 7/2645 [00:00<04:57,  8.88it/s, training_loss=0.034]\u001b[A\n",
      "Epoch 1:   0%|          | 9/2645 [00:00<04:44,  9.27it/s, training_loss=0.034]\u001b[A\n",
      "Epoch 1:   0%|          | 9/2645 [00:01<04:44,  9.27it/s, training_loss=0.635]\u001b[A\n",
      "Epoch 1:   0%|          | 9/2645 [00:01<04:44,  9.27it/s, training_loss=0.730]\u001b[A\n",
      "Epoch 1:   0%|          | 11/2645 [00:01<04:34,  9.61it/s, training_loss=0.730]\u001b[A\n",
      "Epoch 1:   0%|          | 11/2645 [00:01<04:34,  9.61it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:   0%|          | 11/2645 [00:01<04:34,  9.61it/s, training_loss=0.566]\u001b[A\n",
      "Epoch 1:   0%|          | 13/2645 [00:01<04:27,  9.85it/s, training_loss=0.566]\u001b[A\n",
      "Epoch 1:   0%|          | 13/2645 [00:01<04:27,  9.85it/s, training_loss=0.428]\u001b[A\n",
      "Epoch 1:   1%|          | 14/2645 [00:01<04:26,  9.87it/s, training_loss=0.428]\u001b[A\n",
      "Epoch 1:   1%|          | 14/2645 [00:01<04:26,  9.87it/s, training_loss=0.763]\u001b[A\n",
      "Epoch 1:   1%|          | 15/2645 [00:01<04:26,  9.87it/s, training_loss=0.763]\u001b[A\n",
      "Epoch 1:   1%|          | 15/2645 [00:01<04:26,  9.87it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 1:   1%|          | 15/2645 [00:01<04:26,  9.87it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:   1%|          | 17/2645 [00:01<04:22, 10.02it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:   1%|          | 17/2645 [00:01<04:22, 10.02it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 1:   1%|          | 18/2645 [00:01<04:22, 10.00it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 1:   1%|          | 18/2645 [00:01<04:22, 10.00it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 1:   1%|          | 18/2645 [00:02<04:22, 10.00it/s, training_loss=0.103]\u001b[A\n",
      "Epoch 1:   1%|          | 20/2645 [00:02<04:20, 10.07it/s, training_loss=0.103]\u001b[A\n",
      "Epoch 1:   1%|          | 20/2645 [00:02<04:20, 10.07it/s, training_loss=0.505]\u001b[A\n",
      "Epoch 1:   1%|          | 20/2645 [00:02<04:20, 10.07it/s, training_loss=0.463]\u001b[A\n",
      "Epoch 1:   1%|          | 22/2645 [00:02<04:20, 10.09it/s, training_loss=0.463]\u001b[A\n",
      "Epoch 1:   1%|          | 22/2645 [00:02<04:20, 10.09it/s, training_loss=0.713]\u001b[A\n",
      "Epoch 1:   1%|          | 22/2645 [00:02<04:20, 10.09it/s, training_loss=0.520]\u001b[A\n",
      "Epoch 1:   1%|          | 24/2645 [00:02<04:26,  9.82it/s, training_loss=0.520]\u001b[A\n",
      "Epoch 1:   1%|          | 24/2645 [00:02<04:26,  9.82it/s, training_loss=0.028]\u001b[A\n",
      "Epoch 1:   1%|          | 25/2645 [00:02<04:25,  9.86it/s, training_loss=0.028]\u001b[A\n",
      "Epoch 1:   1%|          | 25/2645 [00:02<04:25,  9.86it/s, training_loss=0.222]\u001b[A\n",
      "Epoch 1:   1%|          | 25/2645 [00:02<04:25,  9.86it/s, training_loss=0.249]\u001b[A\n",
      "Epoch 1:   1%|          | 27/2645 [00:02<04:23,  9.95it/s, training_loss=0.249]\u001b[A\n",
      "Epoch 1:   1%|          | 27/2645 [00:02<04:23,  9.95it/s, training_loss=0.195]\u001b[A\n",
      "Epoch 1:   1%|          | 28/2645 [00:02<04:22,  9.96it/s, training_loss=0.195]\u001b[A\n",
      "Epoch 1:   1%|          | 28/2645 [00:02<04:22,  9.96it/s, training_loss=0.811]\u001b[A\n",
      "Epoch 1:   1%|          | 29/2645 [00:02<04:24,  9.90it/s, training_loss=0.811]\u001b[A\n",
      "Epoch 1:   1%|          | 29/2645 [00:03<04:24,  9.90it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:   1%|          | 29/2645 [00:03<04:24,  9.90it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:   1%|          | 31/2645 [00:03<04:20, 10.05it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:   1%|          | 31/2645 [00:03<04:20, 10.05it/s, training_loss=0.505]\u001b[A\n",
      "Epoch 1:   1%|          | 31/2645 [00:03<04:20, 10.05it/s, training_loss=0.582]\u001b[A\n",
      "Epoch 1:   1%|          | 33/2645 [00:03<04:20, 10.01it/s, training_loss=0.582]\u001b[A\n",
      "Epoch 1:   1%|          | 33/2645 [00:03<04:20, 10.01it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:   1%|          | 33/2645 [00:03<04:20, 10.01it/s, training_loss=0.549]\u001b[A\n",
      "Epoch 1:   1%|▏         | 35/2645 [00:03<04:18, 10.12it/s, training_loss=0.549]\u001b[A\n",
      "Epoch 1:   1%|▏         | 35/2645 [00:03<04:18, 10.12it/s, training_loss=0.635]\u001b[A\n",
      "Epoch 1:   1%|▏         | 35/2645 [00:03<04:18, 10.12it/s, training_loss=0.517]\u001b[A\n",
      "Epoch 1:   1%|▏         | 37/2645 [00:03<04:15, 10.22it/s, training_loss=0.517]\u001b[A\n",
      "Epoch 1:   1%|▏         | 37/2645 [00:03<04:15, 10.22it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 1:   1%|▏         | 37/2645 [00:03<04:15, 10.22it/s, training_loss=0.013]\u001b[A\n",
      "Epoch 1:   1%|▏         | 39/2645 [00:03<04:12, 10.34it/s, training_loss=0.013]\u001b[A\n",
      "Epoch 1:   1%|▏         | 39/2645 [00:03<04:12, 10.34it/s, training_loss=0.424]\u001b[A\n",
      "Epoch 1:   1%|▏         | 39/2645 [00:04<04:12, 10.34it/s, training_loss=0.155]\u001b[A\n",
      "Epoch 1:   2%|▏         | 41/2645 [00:04<04:10, 10.40it/s, training_loss=0.155]\u001b[A\n",
      "Epoch 1:   2%|▏         | 41/2645 [00:04<04:10, 10.40it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 1:   2%|▏         | 41/2645 [00:04<04:10, 10.40it/s, training_loss=0.039]\u001b[A\n",
      "Epoch 1:   2%|▏         | 43/2645 [00:04<04:08, 10.46it/s, training_loss=0.039]\u001b[A\n",
      "Epoch 1:   2%|▏         | 43/2645 [00:04<04:08, 10.46it/s, training_loss=0.822]\u001b[A\n",
      "Epoch 1:   2%|▏         | 43/2645 [00:04<04:08, 10.46it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:   2%|▏         | 45/2645 [00:04<04:07, 10.49it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:   2%|▏         | 45/2645 [00:04<04:07, 10.49it/s, training_loss=0.730]\u001b[A\n",
      "Epoch 1:   2%|▏         | 45/2645 [00:04<04:07, 10.49it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 1:   2%|▏         | 47/2645 [00:04<04:09, 10.40it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 1:   2%|▏         | 47/2645 [00:04<04:09, 10.40it/s, training_loss=0.354]\u001b[A\n",
      "Epoch 1:   2%|▏         | 47/2645 [00:04<04:09, 10.40it/s, training_loss=0.043]\u001b[A\n",
      "Epoch 1:   2%|▏         | 49/2645 [00:04<04:14, 10.19it/s, training_loss=0.043]\u001b[A\n",
      "Epoch 1:   2%|▏         | 49/2645 [00:04<04:14, 10.19it/s, training_loss=0.122]\u001b[A\n",
      "Epoch 1:   2%|▏         | 49/2645 [00:05<04:14, 10.19it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:   2%|▏         | 51/2645 [00:05<04:15, 10.15it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:   2%|▏         | 51/2645 [00:05<04:15, 10.15it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:   2%|▏         | 51/2645 [00:05<04:15, 10.15it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 1:   2%|▏         | 53/2645 [00:05<04:16, 10.09it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 1:   2%|▏         | 53/2645 [00:05<04:16, 10.09it/s, training_loss=0.014]\u001b[A\n",
      "Epoch 1:   2%|▏         | 53/2645 [00:05<04:16, 10.09it/s, training_loss=0.223]\u001b[A\n",
      "Epoch 1:   2%|▏         | 55/2645 [00:05<04:18, 10.00it/s, training_loss=0.223]\u001b[A\n",
      "Epoch 1:   2%|▏         | 55/2645 [00:05<04:18, 10.00it/s, training_loss=0.710]\u001b[A\n",
      "Epoch 1:   2%|▏         | 55/2645 [00:05<04:18, 10.00it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:   2%|▏         | 57/2645 [00:05<04:17, 10.04it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:   2%|▏         | 57/2645 [00:05<04:17, 10.04it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 1:   2%|▏         | 57/2645 [00:05<04:17, 10.04it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:   2%|▏         | 59/2645 [00:05<04:17, 10.04it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:   2%|▏         | 59/2645 [00:05<04:17, 10.04it/s, training_loss=0.016]\u001b[A\n",
      "Epoch 1:   2%|▏         | 59/2645 [00:06<04:17, 10.04it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 1:   2%|▏         | 61/2645 [00:06<04:15, 10.12it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 1:   2%|▏         | 61/2645 [00:06<04:15, 10.12it/s, training_loss=0.469]\u001b[A\n",
      "Epoch 1:   2%|▏         | 61/2645 [00:06<04:15, 10.12it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 1:   2%|▏         | 63/2645 [00:06<04:17, 10.02it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 1:   2%|▏         | 63/2645 [00:06<04:17, 10.02it/s, training_loss=0.493]\u001b[A\n",
      "Epoch 1:   2%|▏         | 63/2645 [00:06<04:17, 10.02it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 1:   2%|▏         | 65/2645 [00:06<04:17, 10.01it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 1:   2%|▏         | 65/2645 [00:06<04:17, 10.01it/s, training_loss=0.335]\u001b[A\n",
      "Epoch 1:   2%|▏         | 65/2645 [00:06<04:17, 10.01it/s, training_loss=0.417]\u001b[A\n",
      "Epoch 1:   3%|▎         | 67/2645 [00:06<04:18,  9.96it/s, training_loss=0.417]\u001b[A\n",
      "Epoch 1:   3%|▎         | 67/2645 [00:06<04:18,  9.96it/s, training_loss=0.241]\u001b[A\n",
      "Epoch 1:   3%|▎         | 68/2645 [00:06<04:18,  9.96it/s, training_loss=0.241]\u001b[A\n",
      "Epoch 1:   3%|▎         | 68/2645 [00:06<04:18,  9.96it/s, training_loss=0.099]\u001b[A\n",
      "Epoch 1:   3%|▎         | 69/2645 [00:06<04:19,  9.94it/s, training_loss=0.099]\u001b[A\n",
      "Epoch 1:   3%|▎         | 69/2645 [00:06<04:19,  9.94it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 1:   3%|▎         | 69/2645 [00:07<04:19,  9.94it/s, training_loss=0.077]\u001b[A\n",
      "Epoch 1:   3%|▎         | 71/2645 [00:07<04:16, 10.03it/s, training_loss=0.077]\u001b[A\n",
      "Epoch 1:   3%|▎         | 71/2645 [00:07<04:16, 10.03it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 1:   3%|▎         | 71/2645 [00:07<04:16, 10.03it/s, training_loss=0.092]\u001b[A\n",
      "Epoch 1:   3%|▎         | 73/2645 [00:07<04:15, 10.06it/s, training_loss=0.092]\u001b[A\n",
      "Epoch 1:   3%|▎         | 73/2645 [00:07<04:15, 10.06it/s, training_loss=0.091]\u001b[A\n",
      "Epoch 1:   3%|▎         | 73/2645 [00:07<04:15, 10.06it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 1:   3%|▎         | 75/2645 [00:07<04:16, 10.00it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 1:   3%|▎         | 75/2645 [00:07<04:16, 10.00it/s, training_loss=1.080]\u001b[A\n",
      "Epoch 1:   3%|▎         | 75/2645 [00:07<04:16, 10.00it/s, training_loss=0.530]\u001b[A\n",
      "Epoch 1:   3%|▎         | 77/2645 [00:07<04:17,  9.97it/s, training_loss=0.530]\u001b[A\n",
      "Epoch 1:   3%|▎         | 77/2645 [00:07<04:17,  9.97it/s, training_loss=0.034]\u001b[A\n",
      "Epoch 1:   3%|▎         | 78/2645 [00:07<04:17,  9.97it/s, training_loss=0.034]\u001b[A\n",
      "Epoch 1:   3%|▎         | 78/2645 [00:07<04:17,  9.97it/s, training_loss=0.083]\u001b[A\n",
      "Epoch 1:   3%|▎         | 79/2645 [00:07<04:17,  9.96it/s, training_loss=0.083]\u001b[A\n",
      "Epoch 1:   3%|▎         | 79/2645 [00:07<04:17,  9.96it/s, training_loss=0.431]\u001b[A\n",
      "Epoch 1:   3%|▎         | 80/2645 [00:07<04:17,  9.97it/s, training_loss=0.431]\u001b[A\n",
      "Epoch 1:   3%|▎         | 80/2645 [00:08<04:17,  9.97it/s, training_loss=0.117]\u001b[A\n",
      "Epoch 1:   3%|▎         | 81/2645 [00:08<04:17,  9.97it/s, training_loss=0.117]\u001b[A\n",
      "Epoch 1:   3%|▎         | 81/2645 [00:08<04:17,  9.97it/s, training_loss=0.068]\u001b[A\n",
      "Epoch 1:   3%|▎         | 82/2645 [00:08<04:17,  9.95it/s, training_loss=0.068]\u001b[A\n",
      "Epoch 1:   3%|▎         | 82/2645 [00:08<04:17,  9.95it/s, training_loss=0.010]\u001b[A\n",
      "Epoch 1:   3%|▎         | 83/2645 [00:08<04:17,  9.96it/s, training_loss=0.010]\u001b[A\n",
      "Epoch 1:   3%|▎         | 83/2645 [00:08<04:17,  9.96it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 1:   3%|▎         | 83/2645 [00:08<04:17,  9.96it/s, training_loss=0.022]\u001b[A\n",
      "Epoch 1:   3%|▎         | 85/2645 [00:08<04:15, 10.02it/s, training_loss=0.022]\u001b[A\n",
      "Epoch 1:   3%|▎         | 85/2645 [00:08<04:15, 10.02it/s, training_loss=1.004]\u001b[A\n",
      "Epoch 1:   3%|▎         | 85/2645 [00:08<04:15, 10.02it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 1:   3%|▎         | 87/2645 [00:08<04:14, 10.06it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 1:   3%|▎         | 87/2645 [00:08<04:14, 10.06it/s, training_loss=0.260]\u001b[A\n",
      "Epoch 1:   3%|▎         | 87/2645 [00:08<04:14, 10.06it/s, training_loss=0.115]\u001b[A\n",
      "Epoch 1:   3%|▎         | 89/2645 [00:08<04:15, 10.02it/s, training_loss=0.115]\u001b[A\n",
      "Epoch 1:   3%|▎         | 89/2645 [00:08<04:15, 10.02it/s, training_loss=0.196]\u001b[A\n",
      "Epoch 1:   3%|▎         | 89/2645 [00:09<04:15, 10.02it/s, training_loss=0.183]\u001b[A\n",
      "Epoch 1:   3%|▎         | 91/2645 [00:09<04:15,  9.98it/s, training_loss=0.183]\u001b[A\n",
      "Epoch 1:   3%|▎         | 91/2645 [00:09<04:15,  9.98it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:   3%|▎         | 91/2645 [00:09<04:15,  9.98it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:   4%|▎         | 93/2645 [00:09<04:14, 10.01it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:   4%|▎         | 93/2645 [00:09<04:14, 10.01it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:   4%|▎         | 93/2645 [00:09<04:14, 10.01it/s, training_loss=0.640]\u001b[A\n",
      "Epoch 1:   4%|▎         | 95/2645 [00:09<04:15,  9.98it/s, training_loss=0.640]\u001b[A\n",
      "Epoch 1:   4%|▎         | 95/2645 [00:09<04:15,  9.98it/s, training_loss=0.517]\u001b[A\n",
      "Epoch 1:   4%|▎         | 96/2645 [00:09<04:17,  9.92it/s, training_loss=0.517]\u001b[A\n",
      "Epoch 1:   4%|▎         | 96/2645 [00:09<04:17,  9.92it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 1:   4%|▎         | 96/2645 [00:09<04:17,  9.92it/s, training_loss=0.011]\u001b[A\n",
      "Epoch 1:   4%|▎         | 98/2645 [00:09<04:14, 10.01it/s, training_loss=0.011]\u001b[A\n",
      "Epoch 1:   4%|▎         | 98/2645 [00:09<04:14, 10.01it/s, training_loss=0.390]\u001b[A\n",
      "Epoch 1:   4%|▎         | 98/2645 [00:09<04:14, 10.01it/s, training_loss=0.040]\u001b[A\n",
      "Epoch 1:   4%|▍         | 100/2645 [00:09<04:13, 10.04it/s, training_loss=0.040]\u001b[A\n",
      "Epoch 1:   4%|▍         | 100/2645 [00:10<04:13, 10.04it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 1:   4%|▍         | 100/2645 [00:10<04:13, 10.04it/s, training_loss=0.741]\u001b[A\n",
      "Epoch 1:   4%|▍         | 102/2645 [00:10<04:14, 10.00it/s, training_loss=0.741]\u001b[A\n",
      "Epoch 1:   4%|▍         | 102/2645 [00:10<04:14, 10.00it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:   4%|▍         | 102/2645 [00:10<04:14, 10.00it/s, training_loss=0.234]\u001b[A\n",
      "Epoch 1:   4%|▍         | 104/2645 [00:10<04:12, 10.07it/s, training_loss=0.234]\u001b[A\n",
      "Epoch 1:   4%|▍         | 104/2645 [00:10<04:12, 10.07it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:   4%|▍         | 104/2645 [00:10<04:12, 10.07it/s, training_loss=0.513]\u001b[A\n",
      "Epoch 1:   4%|▍         | 106/2645 [00:10<04:11, 10.08it/s, training_loss=0.513]\u001b[A\n",
      "Epoch 1:   4%|▍         | 106/2645 [00:10<04:11, 10.08it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 1:   4%|▍         | 106/2645 [00:10<04:11, 10.08it/s, training_loss=0.050]\u001b[A\n",
      "Epoch 1:   4%|▍         | 108/2645 [00:10<04:10, 10.11it/s, training_loss=0.050]\u001b[A\n",
      "Epoch 1:   4%|▍         | 108/2645 [00:10<04:10, 10.11it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 1:   4%|▍         | 108/2645 [00:10<04:10, 10.11it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:   4%|▍         | 110/2645 [00:10<04:11, 10.07it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:   4%|▍         | 110/2645 [00:11<04:11, 10.07it/s, training_loss=0.520]\u001b[A\n",
      "Epoch 1:   4%|▍         | 110/2645 [00:11<04:11, 10.07it/s, training_loss=0.350]\u001b[A\n",
      "Epoch 1:   4%|▍         | 112/2645 [00:11<04:11, 10.08it/s, training_loss=0.350]\u001b[A\n",
      "Epoch 1:   4%|▍         | 112/2645 [00:11<04:11, 10.08it/s, training_loss=0.060]\u001b[A\n",
      "Epoch 1:   4%|▍         | 112/2645 [00:11<04:11, 10.08it/s, training_loss=0.084]\u001b[A\n",
      "Epoch 1:   4%|▍         | 114/2645 [00:11<04:11, 10.04it/s, training_loss=0.084]\u001b[A\n",
      "Epoch 1:   4%|▍         | 114/2645 [00:11<04:11, 10.04it/s, training_loss=0.291]\u001b[A\n",
      "Epoch 1:   4%|▍         | 114/2645 [00:11<04:11, 10.04it/s, training_loss=0.013]\u001b[A\n",
      "Epoch 1:   4%|▍         | 116/2645 [00:11<04:13, 10.00it/s, training_loss=0.013]\u001b[A\n",
      "Epoch 1:   4%|▍         | 116/2645 [00:11<04:13, 10.00it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:   4%|▍         | 116/2645 [00:11<04:13, 10.00it/s, training_loss=0.225]\u001b[A\n",
      "Epoch 1:   4%|▍         | 118/2645 [00:11<04:11, 10.04it/s, training_loss=0.225]\u001b[A\n",
      "Epoch 1:   4%|▍         | 118/2645 [00:11<04:11, 10.04it/s, training_loss=0.264]\u001b[A\n",
      "Epoch 1:   4%|▍         | 118/2645 [00:11<04:11, 10.04it/s, training_loss=0.313]\u001b[A\n",
      "Epoch 1:   5%|▍         | 120/2645 [00:11<04:14,  9.93it/s, training_loss=0.313]\u001b[A\n",
      "Epoch 1:   5%|▍         | 120/2645 [00:12<04:14,  9.93it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 1:   5%|▍         | 121/2645 [00:12<04:13,  9.94it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 1:   5%|▍         | 121/2645 [00:12<04:13,  9.94it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:   5%|▍         | 121/2645 [00:12<04:13,  9.94it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 1:   5%|▍         | 123/2645 [00:12<04:12,  9.98it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 1:   5%|▍         | 123/2645 [00:12<04:12,  9.98it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:   5%|▍         | 124/2645 [00:12<04:14,  9.92it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:   5%|▍         | 124/2645 [00:12<04:14,  9.92it/s, training_loss=0.016]\u001b[A\n",
      "Epoch 1:   5%|▍         | 125/2645 [00:12<04:14,  9.89it/s, training_loss=0.016]\u001b[A\n",
      "Epoch 1:   5%|▍         | 125/2645 [00:12<04:14,  9.89it/s, training_loss=0.303]\u001b[A\n",
      "Epoch 1:   5%|▍         | 126/2645 [00:12<04:15,  9.88it/s, training_loss=0.303]\u001b[A\n",
      "Epoch 1:   5%|▍         | 126/2645 [00:12<04:15,  9.88it/s, training_loss=0.034]\u001b[A\n",
      "Epoch 1:   5%|▍         | 127/2645 [00:12<04:14,  9.89it/s, training_loss=0.034]\u001b[A\n",
      "Epoch 1:   5%|▍         | 127/2645 [00:12<04:14,  9.89it/s, training_loss=0.014]\u001b[A\n",
      "Epoch 1:   5%|▍         | 128/2645 [00:12<04:13,  9.92it/s, training_loss=0.014]\u001b[A\n",
      "Epoch 1:   5%|▍         | 128/2645 [00:12<04:13,  9.92it/s, training_loss=0.087]\u001b[A\n",
      "Epoch 1:   5%|▍         | 129/2645 [00:12<04:13,  9.93it/s, training_loss=0.087]\u001b[A\n",
      "Epoch 1:   5%|▍         | 129/2645 [00:12<04:13,  9.93it/s, training_loss=0.022]\u001b[A\n",
      "Epoch 1:   5%|▍         | 130/2645 [00:12<04:13,  9.93it/s, training_loss=0.022]\u001b[A\n",
      "Epoch 1:   5%|▍         | 130/2645 [00:13<04:13,  9.93it/s, training_loss=1.072]\u001b[A\n",
      "Epoch 1:   5%|▍         | 131/2645 [00:13<04:13,  9.92it/s, training_loss=1.072]\u001b[A\n",
      "Epoch 1:   5%|▍         | 131/2645 [00:13<04:13,  9.92it/s, training_loss=0.630]\u001b[A\n",
      "Epoch 1:   5%|▍         | 132/2645 [00:13<04:13,  9.93it/s, training_loss=0.630]\u001b[A\n",
      "Epoch 1:   5%|▍         | 132/2645 [00:13<04:13,  9.93it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:   5%|▍         | 132/2645 [00:13<04:13,  9.93it/s, training_loss=0.024]\u001b[A\n",
      "Epoch 1:   5%|▌         | 134/2645 [00:13<04:10, 10.04it/s, training_loss=0.024]\u001b[A\n",
      "Epoch 1:   5%|▌         | 134/2645 [00:13<04:10, 10.04it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:   5%|▌         | 134/2645 [00:13<04:10, 10.04it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:   5%|▌         | 136/2645 [00:13<04:09, 10.06it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:   5%|▌         | 136/2645 [00:13<04:09, 10.06it/s, training_loss=0.284]\u001b[A\n",
      "Epoch 1:   5%|▌         | 136/2645 [00:13<04:09, 10.06it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:   5%|▌         | 138/2645 [00:13<04:10, 10.00it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:   5%|▌         | 138/2645 [00:13<04:10, 10.00it/s, training_loss=0.094]\u001b[A\n",
      "Epoch 1:   5%|▌         | 139/2645 [00:13<04:11,  9.96it/s, training_loss=0.094]\u001b[A\n",
      "Epoch 1:   5%|▌         | 139/2645 [00:13<04:11,  9.96it/s, training_loss=0.010]\u001b[A\n",
      "Epoch 1:   5%|▌         | 140/2645 [00:13<04:11,  9.95it/s, training_loss=0.010]\u001b[A\n",
      "Epoch 1:   5%|▌         | 140/2645 [00:14<04:11,  9.95it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 1:   5%|▌         | 141/2645 [00:14<04:11,  9.94it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 1:   5%|▌         | 141/2645 [00:14<04:11,  9.94it/s, training_loss=0.298]\u001b[A\n",
      "Epoch 1:   5%|▌         | 142/2645 [00:14<04:12,  9.93it/s, training_loss=0.298]\u001b[A\n",
      "Epoch 1:   5%|▌         | 142/2645 [00:14<04:12,  9.93it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:   5%|▌         | 142/2645 [00:14<04:12,  9.93it/s, training_loss=0.142]\u001b[A\n",
      "Epoch 1:   5%|▌         | 144/2645 [00:14<04:10,  9.99it/s, training_loss=0.142]\u001b[A\n",
      "Epoch 1:   5%|▌         | 144/2645 [00:14<04:10,  9.99it/s, training_loss=0.434]\u001b[A\n",
      "Epoch 1:   5%|▌         | 145/2645 [00:14<04:14,  9.84it/s, training_loss=0.434]\u001b[A\n",
      "Epoch 1:   5%|▌         | 145/2645 [00:14<04:14,  9.84it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 1:   6%|▌         | 146/2645 [00:14<04:13,  9.86it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 1:   6%|▌         | 146/2645 [00:14<04:13,  9.86it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:   6%|▌         | 147/2645 [00:14<04:13,  9.87it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:   6%|▌         | 147/2645 [00:14<04:13,  9.87it/s, training_loss=0.664]\u001b[A\n",
      "Epoch 1:   6%|▌         | 148/2645 [00:14<04:12,  9.89it/s, training_loss=0.664]\u001b[A\n",
      "Epoch 1:   6%|▌         | 148/2645 [00:14<04:12,  9.89it/s, training_loss=0.314]\u001b[A\n",
      "Epoch 1:   6%|▌         | 149/2645 [00:14<04:11,  9.91it/s, training_loss=0.314]\u001b[A\n",
      "Epoch 1:   6%|▌         | 149/2645 [00:14<04:11,  9.91it/s, training_loss=0.019]\u001b[A\n",
      "Epoch 1:   6%|▌         | 150/2645 [00:14<04:11,  9.91it/s, training_loss=0.019]\u001b[A\n",
      "Epoch 1:   6%|▌         | 150/2645 [00:15<04:11,  9.91it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:   6%|▌         | 150/2645 [00:15<04:11,  9.91it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:   6%|▌         | 152/2645 [00:15<04:08, 10.03it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:   6%|▌         | 152/2645 [00:15<04:08, 10.03it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:   6%|▌         | 152/2645 [00:15<04:08, 10.03it/s, training_loss=0.385]\u001b[A\n",
      "Epoch 1:   6%|▌         | 154/2645 [00:15<04:08, 10.04it/s, training_loss=0.385]\u001b[A\n",
      "Epoch 1:   6%|▌         | 154/2645 [00:15<04:08, 10.04it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:   6%|▌         | 154/2645 [00:15<04:08, 10.04it/s, training_loss=0.040]\u001b[A\n",
      "Epoch 1:   6%|▌         | 156/2645 [00:15<04:05, 10.12it/s, training_loss=0.040]\u001b[A\n",
      "Epoch 1:   6%|▌         | 156/2645 [00:15<04:05, 10.12it/s, training_loss=0.130]\u001b[A\n",
      "Epoch 1:   6%|▌         | 156/2645 [00:15<04:05, 10.12it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 1:   6%|▌         | 158/2645 [00:15<04:06, 10.09it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 1:   6%|▌         | 158/2645 [00:15<04:06, 10.09it/s, training_loss=0.191]\u001b[A\n",
      "Epoch 1:   6%|▌         | 158/2645 [00:15<04:06, 10.09it/s, training_loss=0.550]\u001b[A\n",
      "Epoch 1:   6%|▌         | 160/2645 [00:15<04:07, 10.02it/s, training_loss=0.550]\u001b[A\n",
      "Epoch 1:   6%|▌         | 160/2645 [00:16<04:07, 10.02it/s, training_loss=0.195]\u001b[A\n",
      "Epoch 1:   6%|▌         | 160/2645 [00:16<04:07, 10.02it/s, training_loss=0.458]\u001b[A\n",
      "Epoch 1:   6%|▌         | 162/2645 [00:16<04:08, 10.01it/s, training_loss=0.458]\u001b[A\n",
      "Epoch 1:   6%|▌         | 162/2645 [00:16<04:08, 10.01it/s, training_loss=0.030]\u001b[A\n",
      "Epoch 1:   6%|▌         | 162/2645 [00:16<04:08, 10.01it/s, training_loss=0.011]\u001b[A\n",
      "Epoch 1:   6%|▌         | 164/2645 [00:16<04:08,  9.98it/s, training_loss=0.011]\u001b[A\n",
      "Epoch 1:   6%|▌         | 164/2645 [00:16<04:08,  9.98it/s, training_loss=0.018]\u001b[A\n",
      "Epoch 1:   6%|▌         | 165/2645 [00:16<04:08,  9.98it/s, training_loss=0.018]\u001b[A\n",
      "Epoch 1:   6%|▌         | 165/2645 [00:16<04:08,  9.98it/s, training_loss=0.019]\u001b[A\n",
      "Epoch 1:   6%|▋         | 166/2645 [00:16<04:08,  9.97it/s, training_loss=0.019]\u001b[A\n",
      "Epoch 1:   6%|▋         | 166/2645 [00:16<04:08,  9.97it/s, training_loss=0.442]\u001b[A\n",
      "Epoch 1:   6%|▋         | 167/2645 [00:16<04:08,  9.97it/s, training_loss=0.442]\u001b[A\n",
      "Epoch 1:   6%|▋         | 167/2645 [00:16<04:08,  9.97it/s, training_loss=0.739]\u001b[A\n",
      "Epoch 1:   6%|▋         | 168/2645 [00:16<04:09,  9.94it/s, training_loss=0.739]\u001b[A\n",
      "Epoch 1:   6%|▋         | 168/2645 [00:16<04:09,  9.94it/s, training_loss=0.421]\u001b[A\n",
      "Epoch 1:   6%|▋         | 169/2645 [00:16<04:08,  9.95it/s, training_loss=0.421]\u001b[A\n",
      "Epoch 1:   6%|▋         | 169/2645 [00:16<04:08,  9.95it/s, training_loss=0.065]\u001b[A\n",
      "Epoch 1:   6%|▋         | 170/2645 [00:16<04:08,  9.95it/s, training_loss=0.065]\u001b[A\n",
      "Epoch 1:   6%|▋         | 170/2645 [00:17<04:08,  9.95it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 1:   6%|▋         | 171/2645 [00:17<04:09,  9.92it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 1:   6%|▋         | 171/2645 [00:17<04:09,  9.92it/s, training_loss=0.111]\u001b[A\n",
      "Epoch 1:   7%|▋         | 172/2645 [00:17<04:08,  9.94it/s, training_loss=0.111]\u001b[A\n",
      "Epoch 1:   7%|▋         | 172/2645 [00:17<04:08,  9.94it/s, training_loss=0.531]\u001b[A\n",
      "Epoch 1:   7%|▋         | 173/2645 [00:17<04:08,  9.93it/s, training_loss=0.531]\u001b[A\n",
      "Epoch 1:   7%|▋         | 173/2645 [00:17<04:08,  9.93it/s, training_loss=0.681]\u001b[A\n",
      "Epoch 1:   7%|▋         | 174/2645 [00:17<04:08,  9.94it/s, training_loss=0.681]\u001b[A\n",
      "Epoch 1:   7%|▋         | 174/2645 [00:17<04:08,  9.94it/s, training_loss=0.064]\u001b[A\n",
      "Epoch 1:   7%|▋         | 175/2645 [00:17<04:09,  9.91it/s, training_loss=0.064]\u001b[A\n",
      "Epoch 1:   7%|▋         | 175/2645 [00:17<04:09,  9.91it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:   7%|▋         | 175/2645 [00:17<04:09,  9.91it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:   7%|▋         | 177/2645 [00:17<04:05, 10.04it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:   7%|▋         | 177/2645 [00:17<04:05, 10.04it/s, training_loss=0.045]\u001b[A\n",
      "Epoch 1:   7%|▋         | 177/2645 [00:17<04:05, 10.04it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:   7%|▋         | 179/2645 [00:17<04:06, 10.02it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:   7%|▋         | 179/2645 [00:17<04:06, 10.02it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:   7%|▋         | 179/2645 [00:18<04:06, 10.02it/s, training_loss=0.098]\u001b[A\n",
      "Epoch 1:   7%|▋         | 181/2645 [00:18<04:05, 10.02it/s, training_loss=0.098]\u001b[A\n",
      "Epoch 1:   7%|▋         | 181/2645 [00:18<04:05, 10.02it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 1:   7%|▋         | 181/2645 [00:18<04:05, 10.02it/s, training_loss=0.674]\u001b[A\n",
      "Epoch 1:   7%|▋         | 183/2645 [00:18<04:06,  9.98it/s, training_loss=0.674]\u001b[A\n",
      "Epoch 1:   7%|▋         | 183/2645 [00:18<04:06,  9.98it/s, training_loss=0.018]\u001b[A\n",
      "Epoch 1:   7%|▋         | 184/2645 [00:18<04:07,  9.93it/s, training_loss=0.018]\u001b[A\n",
      "Epoch 1:   7%|▋         | 184/2645 [00:18<04:07,  9.93it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:   7%|▋         | 184/2645 [00:18<04:07,  9.93it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 1:   7%|▋         | 186/2645 [00:18<04:04, 10.05it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 1:   7%|▋         | 186/2645 [00:18<04:04, 10.05it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 1:   7%|▋         | 186/2645 [00:18<04:04, 10.05it/s, training_loss=0.313]\u001b[A\n",
      "Epoch 1:   7%|▋         | 188/2645 [00:18<04:04, 10.05it/s, training_loss=0.313]\u001b[A\n",
      "Epoch 1:   7%|▋         | 188/2645 [00:18<04:04, 10.05it/s, training_loss=0.320]\u001b[A\n",
      "Epoch 1:   7%|▋         | 188/2645 [00:18<04:04, 10.05it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 1:   7%|▋         | 190/2645 [00:18<04:05,  9.99it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 1:   7%|▋         | 190/2645 [00:19<04:05,  9.99it/s, training_loss=0.341]\u001b[A\n",
      "Epoch 1:   7%|▋         | 191/2645 [00:19<04:05,  9.98it/s, training_loss=0.341]\u001b[A\n",
      "Epoch 1:   7%|▋         | 191/2645 [00:19<04:05,  9.98it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 1:   7%|▋         | 191/2645 [00:19<04:05,  9.98it/s, training_loss=0.137]\u001b[A\n",
      "Epoch 1:   7%|▋         | 193/2645 [00:19<04:05,  9.98it/s, training_loss=0.137]\u001b[A\n",
      "Epoch 1:   7%|▋         | 193/2645 [00:19<04:05,  9.98it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 1:   7%|▋         | 194/2645 [00:19<04:05,  9.96it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 1:   7%|▋         | 194/2645 [00:19<04:05,  9.96it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:   7%|▋         | 194/2645 [00:19<04:05,  9.96it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 1:   7%|▋         | 196/2645 [00:19<04:04, 10.03it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 1:   7%|▋         | 196/2645 [00:19<04:04, 10.03it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 1:   7%|▋         | 196/2645 [00:19<04:04, 10.03it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:   7%|▋         | 198/2645 [00:19<04:02, 10.10it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:   7%|▋         | 198/2645 [00:19<04:02, 10.10it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:   7%|▋         | 198/2645 [00:19<04:02, 10.10it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:   8%|▊         | 200/2645 [00:19<04:02, 10.10it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:   8%|▊         | 200/2645 [00:20<04:02, 10.10it/s, training_loss=0.018]\u001b[A\n",
      "Epoch 1:   8%|▊         | 200/2645 [00:20<04:02, 10.10it/s, training_loss=0.121]\u001b[A\n",
      "Epoch 1:   8%|▊         | 202/2645 [00:20<04:00, 10.15it/s, training_loss=0.121]\u001b[A\n",
      "Epoch 1:   8%|▊         | 202/2645 [00:20<04:00, 10.15it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:   8%|▊         | 202/2645 [00:20<04:00, 10.15it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:   8%|▊         | 204/2645 [00:20<03:57, 10.26it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:   8%|▊         | 204/2645 [00:20<03:57, 10.26it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:   8%|▊         | 204/2645 [00:20<03:57, 10.26it/s, training_loss=0.399]\u001b[A\n",
      "Epoch 1:   8%|▊         | 206/2645 [00:20<03:58, 10.23it/s, training_loss=0.399]\u001b[A\n",
      "Epoch 1:   8%|▊         | 206/2645 [00:20<03:58, 10.23it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:   8%|▊         | 206/2645 [00:20<03:58, 10.23it/s, training_loss=0.590]\u001b[A\n",
      "Epoch 1:   8%|▊         | 208/2645 [00:20<03:59, 10.18it/s, training_loss=0.590]\u001b[A\n",
      "Epoch 1:   8%|▊         | 208/2645 [00:20<03:59, 10.18it/s, training_loss=0.184]\u001b[A\n",
      "Epoch 1:   8%|▊         | 208/2645 [00:20<03:59, 10.18it/s, training_loss=0.052]\u001b[A\n",
      "Epoch 1:   8%|▊         | 210/2645 [00:20<04:02, 10.05it/s, training_loss=0.052]\u001b[A\n",
      "Epoch 1:   8%|▊         | 210/2645 [00:21<04:02, 10.05it/s, training_loss=0.060]\u001b[A\n",
      "Epoch 1:   8%|▊         | 210/2645 [00:21<04:02, 10.05it/s, training_loss=0.509]\u001b[A\n",
      "Epoch 1:   8%|▊         | 212/2645 [00:21<04:02, 10.02it/s, training_loss=0.509]\u001b[A\n",
      "Epoch 1:   8%|▊         | 212/2645 [00:21<04:02, 10.02it/s, training_loss=0.024]\u001b[A\n",
      "Epoch 1:   8%|▊         | 212/2645 [00:21<04:02, 10.02it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:   8%|▊         | 214/2645 [00:21<04:02, 10.02it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:   8%|▊         | 214/2645 [00:21<04:02, 10.02it/s, training_loss=0.412]\u001b[A\n",
      "Epoch 1:   8%|▊         | 214/2645 [00:21<04:02, 10.02it/s, training_loss=0.017]\u001b[A\n",
      "Epoch 1:   8%|▊         | 216/2645 [00:21<04:02, 10.02it/s, training_loss=0.017]\u001b[A\n",
      "Epoch 1:   8%|▊         | 216/2645 [00:21<04:02, 10.02it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 1:   8%|▊         | 216/2645 [00:21<04:02, 10.02it/s, training_loss=0.400]\u001b[A\n",
      "Epoch 1:   8%|▊         | 218/2645 [00:21<04:04,  9.92it/s, training_loss=0.400]\u001b[A\n",
      "Epoch 1:   8%|▊         | 218/2645 [00:21<04:04,  9.92it/s, training_loss=0.667]\u001b[A\n",
      "Epoch 1:   8%|▊         | 218/2645 [00:21<04:04,  9.92it/s, training_loss=0.050]\u001b[A\n",
      "Epoch 1:   8%|▊         | 220/2645 [00:21<04:04,  9.90it/s, training_loss=0.050]\u001b[A\n",
      "Epoch 1:   8%|▊         | 220/2645 [00:22<04:04,  9.90it/s, training_loss=0.402]\u001b[A\n",
      "Epoch 1:   8%|▊         | 220/2645 [00:22<04:04,  9.90it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 1:   8%|▊         | 222/2645 [00:22<04:03,  9.94it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 1:   8%|▊         | 222/2645 [00:22<04:03,  9.94it/s, training_loss=1.465]\u001b[A\n",
      "Epoch 1:   8%|▊         | 222/2645 [00:22<04:03,  9.94it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:   8%|▊         | 224/2645 [00:22<04:02,  9.98it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:   8%|▊         | 224/2645 [00:22<04:02,  9.98it/s, training_loss=0.472]\u001b[A\n",
      "Epoch 1:   9%|▊         | 225/2645 [00:22<04:04,  9.90it/s, training_loss=0.472]\u001b[A\n",
      "Epoch 1:   9%|▊         | 225/2645 [00:22<04:04,  9.90it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:   9%|▊         | 225/2645 [00:22<04:04,  9.90it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:   9%|▊         | 227/2645 [00:22<04:00, 10.05it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:   9%|▊         | 227/2645 [00:22<04:00, 10.05it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:   9%|▊         | 227/2645 [00:22<04:00, 10.05it/s, training_loss=0.609]\u001b[A\n",
      "Epoch 1:   9%|▊         | 229/2645 [00:22<04:00, 10.03it/s, training_loss=0.609]\u001b[A\n",
      "Epoch 1:   9%|▊         | 229/2645 [00:22<04:00, 10.03it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 1:   9%|▊         | 229/2645 [00:23<04:00, 10.03it/s, training_loss=0.600]\u001b[A\n",
      "Epoch 1:   9%|▊         | 231/2645 [00:23<03:59, 10.09it/s, training_loss=0.600]\u001b[A\n",
      "Epoch 1:   9%|▊         | 231/2645 [00:23<03:59, 10.09it/s, training_loss=0.040]\u001b[A\n",
      "Epoch 1:   9%|▊         | 231/2645 [00:23<03:59, 10.09it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:   9%|▉         | 233/2645 [00:23<03:58, 10.11it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:   9%|▉         | 233/2645 [00:23<03:58, 10.11it/s, training_loss=0.181]\u001b[A\n",
      "Epoch 1:   9%|▉         | 233/2645 [00:23<03:58, 10.11it/s, training_loss=0.054]\u001b[A\n",
      "Epoch 1:   9%|▉         | 235/2645 [00:23<03:58, 10.11it/s, training_loss=0.054]\u001b[A\n",
      "Epoch 1:   9%|▉         | 235/2645 [00:23<03:58, 10.11it/s, training_loss=0.037]\u001b[A\n",
      "Epoch 1:   9%|▉         | 235/2645 [00:23<03:58, 10.11it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:   9%|▉         | 237/2645 [00:23<03:56, 10.20it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:   9%|▉         | 237/2645 [00:23<03:56, 10.20it/s, training_loss=0.435]\u001b[A\n",
      "Epoch 1:   9%|▉         | 237/2645 [00:23<03:56, 10.20it/s, training_loss=0.014]\u001b[A\n",
      "Epoch 1:   9%|▉         | 239/2645 [00:23<03:56, 10.17it/s, training_loss=0.014]\u001b[A\n",
      "Epoch 1:   9%|▉         | 239/2645 [00:23<03:56, 10.17it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:   9%|▉         | 239/2645 [00:24<03:56, 10.17it/s, training_loss=0.438]\u001b[A\n",
      "Epoch 1:   9%|▉         | 241/2645 [00:24<03:54, 10.23it/s, training_loss=0.438]\u001b[A\n",
      "Epoch 1:   9%|▉         | 241/2645 [00:24<03:54, 10.23it/s, training_loss=0.131]\u001b[A\n",
      "Epoch 1:   9%|▉         | 241/2645 [00:24<03:54, 10.23it/s, training_loss=1.023]\u001b[A\n",
      "Epoch 1:   9%|▉         | 243/2645 [00:24<03:55, 10.22it/s, training_loss=1.023]\u001b[A\n",
      "Epoch 1:   9%|▉         | 243/2645 [00:24<03:55, 10.22it/s, training_loss=0.052]\u001b[A\n",
      "Epoch 1:   9%|▉         | 243/2645 [00:24<03:55, 10.22it/s, training_loss=0.638]\u001b[A\n",
      "Epoch 1:   9%|▉         | 245/2645 [00:24<03:57, 10.12it/s, training_loss=0.638]\u001b[A\n",
      "Epoch 1:   9%|▉         | 245/2645 [00:24<03:57, 10.12it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:   9%|▉         | 245/2645 [00:24<03:57, 10.12it/s, training_loss=0.604]\u001b[A\n",
      "Epoch 1:   9%|▉         | 247/2645 [00:24<03:56, 10.14it/s, training_loss=0.604]\u001b[A\n",
      "Epoch 1:   9%|▉         | 247/2645 [00:24<03:56, 10.14it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:   9%|▉         | 247/2645 [00:24<03:56, 10.14it/s, training_loss=0.630]\u001b[A\n",
      "Epoch 1:   9%|▉         | 249/2645 [00:24<03:59, 10.00it/s, training_loss=0.630]\u001b[A\n",
      "Epoch 1:   9%|▉         | 249/2645 [00:24<03:59, 10.00it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:   9%|▉         | 249/2645 [00:25<03:59, 10.00it/s, training_loss=0.013]\u001b[A\n",
      "Epoch 1:   9%|▉         | 251/2645 [00:25<03:57, 10.07it/s, training_loss=0.013]\u001b[A\n",
      "Epoch 1:   9%|▉         | 251/2645 [00:25<03:57, 10.07it/s, training_loss=0.019]\u001b[A\n",
      "Epoch 1:   9%|▉         | 251/2645 [00:25<03:57, 10.07it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  10%|▉         | 253/2645 [00:25<03:56, 10.11it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  10%|▉         | 253/2645 [00:25<03:56, 10.11it/s, training_loss=0.113]\u001b[A\n",
      "Epoch 1:  10%|▉         | 253/2645 [00:25<03:56, 10.11it/s, training_loss=0.067]\u001b[A\n",
      "Epoch 1:  10%|▉         | 255/2645 [00:25<03:58, 10.01it/s, training_loss=0.067]\u001b[A\n",
      "Epoch 1:  10%|▉         | 255/2645 [00:25<03:58, 10.01it/s, training_loss=0.066]\u001b[A\n",
      "Epoch 1:  10%|▉         | 255/2645 [00:25<03:58, 10.01it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  10%|▉         | 257/2645 [00:25<03:58, 10.01it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  10%|▉         | 257/2645 [00:25<03:58, 10.01it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  10%|▉         | 257/2645 [00:25<03:58, 10.01it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  10%|▉         | 259/2645 [00:25<03:56, 10.08it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  10%|▉         | 259/2645 [00:25<03:56, 10.08it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  10%|▉         | 259/2645 [00:26<03:56, 10.08it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  10%|▉         | 261/2645 [00:26<03:55, 10.13it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  10%|▉         | 261/2645 [00:26<03:55, 10.13it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  10%|▉         | 261/2645 [00:26<03:55, 10.13it/s, training_loss=0.012]\u001b[A\n",
      "Epoch 1:  10%|▉         | 263/2645 [00:26<03:57, 10.03it/s, training_loss=0.012]\u001b[A\n",
      "Epoch 1:  10%|▉         | 263/2645 [00:26<03:57, 10.03it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 1:  10%|▉         | 263/2645 [00:26<03:57, 10.03it/s, training_loss=0.120]\u001b[A\n",
      "Epoch 1:  10%|█         | 265/2645 [00:26<03:58,  9.99it/s, training_loss=0.120]\u001b[A\n",
      "Epoch 1:  10%|█         | 265/2645 [00:26<03:58,  9.99it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  10%|█         | 266/2645 [00:26<03:58,  9.99it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  10%|█         | 266/2645 [00:26<03:58,  9.99it/s, training_loss=0.014]\u001b[A\n",
      "Epoch 1:  10%|█         | 267/2645 [00:26<03:58,  9.98it/s, training_loss=0.014]\u001b[A\n",
      "Epoch 1:  10%|█         | 267/2645 [00:26<03:58,  9.98it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  10%|█         | 267/2645 [00:26<03:58,  9.98it/s, training_loss=0.018]\u001b[A\n",
      "Epoch 1:  10%|█         | 269/2645 [00:26<03:57, 10.01it/s, training_loss=0.018]\u001b[A\n",
      "Epoch 1:  10%|█         | 269/2645 [00:26<03:57, 10.01it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  10%|█         | 269/2645 [00:27<03:57, 10.01it/s, training_loss=0.066]\u001b[A\n",
      "Epoch 1:  10%|█         | 271/2645 [00:27<03:59,  9.92it/s, training_loss=0.066]\u001b[A\n",
      "Epoch 1:  10%|█         | 271/2645 [00:27<03:59,  9.92it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  10%|█         | 272/2645 [00:27<03:59,  9.89it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  10%|█         | 272/2645 [00:27<03:59,  9.89it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  10%|█         | 272/2645 [00:27<03:59,  9.89it/s, training_loss=0.023]\u001b[A\n",
      "Epoch 1:  10%|█         | 274/2645 [00:27<03:57,  9.98it/s, training_loss=0.023]\u001b[A\n",
      "Epoch 1:  10%|█         | 274/2645 [00:27<03:57,  9.98it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  10%|█         | 275/2645 [00:27<04:01,  9.82it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  10%|█         | 275/2645 [00:27<04:01,  9.82it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  10%|█         | 275/2645 [00:27<04:01,  9.82it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  10%|█         | 277/2645 [00:27<03:57,  9.98it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  10%|█         | 277/2645 [00:27<03:57,  9.98it/s, training_loss=0.043]\u001b[A\n",
      "Epoch 1:  10%|█         | 277/2645 [00:27<03:57,  9.98it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  11%|█         | 279/2645 [00:27<03:56, 10.00it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  11%|█         | 279/2645 [00:27<03:56, 10.00it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  11%|█         | 279/2645 [00:28<03:56, 10.00it/s, training_loss=0.055]\u001b[A\n",
      "Epoch 1:  11%|█         | 281/2645 [00:28<03:54, 10.07it/s, training_loss=0.055]\u001b[A\n",
      "Epoch 1:  11%|█         | 281/2645 [00:28<03:54, 10.07it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  11%|█         | 281/2645 [00:28<03:54, 10.07it/s, training_loss=0.466]\u001b[A\n",
      "Epoch 1:  11%|█         | 283/2645 [00:28<03:54, 10.07it/s, training_loss=0.466]\u001b[A\n",
      "Epoch 1:  11%|█         | 283/2645 [00:28<03:54, 10.07it/s, training_loss=0.022]\u001b[A\n",
      "Epoch 1:  11%|█         | 283/2645 [00:28<03:54, 10.07it/s, training_loss=0.018]\u001b[A\n",
      "Epoch 1:  11%|█         | 285/2645 [00:28<03:55, 10.04it/s, training_loss=0.018]\u001b[A\n",
      "Epoch 1:  11%|█         | 285/2645 [00:28<03:55, 10.04it/s, training_loss=0.438]\u001b[A\n",
      "Epoch 1:  11%|█         | 285/2645 [00:28<03:55, 10.04it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  11%|█         | 287/2645 [00:28<03:53, 10.09it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  11%|█         | 287/2645 [00:28<03:53, 10.09it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  11%|█         | 287/2645 [00:28<03:53, 10.09it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  11%|█         | 289/2645 [00:28<03:51, 10.18it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  11%|█         | 289/2645 [00:28<03:51, 10.18it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 1:  11%|█         | 289/2645 [00:28<03:51, 10.18it/s, training_loss=0.033]\u001b[A\n",
      "Epoch 1:  11%|█         | 291/2645 [00:28<03:50, 10.20it/s, training_loss=0.033]\u001b[A\n",
      "Epoch 1:  11%|█         | 291/2645 [00:29<03:50, 10.20it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  11%|█         | 291/2645 [00:29<03:50, 10.20it/s, training_loss=0.554]\u001b[A\n",
      "Epoch 1:  11%|█         | 293/2645 [00:29<03:50, 10.19it/s, training_loss=0.554]\u001b[A\n",
      "Epoch 1:  11%|█         | 293/2645 [00:29<03:50, 10.19it/s, training_loss=0.014]\u001b[A\n",
      "Epoch 1:  11%|█         | 293/2645 [00:29<03:50, 10.19it/s, training_loss=0.031]\u001b[A\n",
      "Epoch 1:  11%|█         | 295/2645 [00:29<03:51, 10.16it/s, training_loss=0.031]\u001b[A\n",
      "Epoch 1:  11%|█         | 295/2645 [00:29<03:51, 10.16it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  11%|█         | 295/2645 [00:29<03:51, 10.16it/s, training_loss=0.018]\u001b[A\n",
      "Epoch 1:  11%|█         | 297/2645 [00:29<03:49, 10.22it/s, training_loss=0.018]\u001b[A\n",
      "Epoch 1:  11%|█         | 297/2645 [00:29<03:49, 10.22it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 1:  11%|█         | 297/2645 [00:29<03:49, 10.22it/s, training_loss=0.347]\u001b[A\n",
      "Epoch 1:  11%|█▏        | 299/2645 [00:29<03:51, 10.13it/s, training_loss=0.347]\u001b[A\n",
      "Epoch 1:  11%|█▏        | 299/2645 [00:29<03:51, 10.13it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  11%|█▏        | 299/2645 [00:29<03:51, 10.13it/s, training_loss=0.597]\u001b[A\n",
      "Epoch 1:  11%|█▏        | 301/2645 [00:29<03:49, 10.19it/s, training_loss=0.597]\u001b[A\n",
      "Epoch 1:  11%|█▏        | 301/2645 [00:30<03:49, 10.19it/s, training_loss=0.403]\u001b[A\n",
      "Epoch 1:  11%|█▏        | 301/2645 [00:30<03:49, 10.19it/s, training_loss=0.340]\u001b[A\n",
      "Epoch 1:  11%|█▏        | 303/2645 [00:30<03:47, 10.27it/s, training_loss=0.340]\u001b[A\n",
      "Epoch 1:  11%|█▏        | 303/2645 [00:30<03:47, 10.27it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  11%|█▏        | 303/2645 [00:30<03:47, 10.27it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 305/2645 [00:30<03:45, 10.40it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 305/2645 [00:30<03:45, 10.40it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 305/2645 [00:30<03:45, 10.40it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 307/2645 [00:30<03:43, 10.46it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 307/2645 [00:30<03:43, 10.46it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 307/2645 [00:30<03:43, 10.46it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 309/2645 [00:30<03:42, 10.50it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 309/2645 [00:30<03:42, 10.50it/s, training_loss=0.676]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 309/2645 [00:30<03:42, 10.50it/s, training_loss=0.255]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 311/2645 [00:30<03:43, 10.42it/s, training_loss=0.255]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 311/2645 [00:31<03:43, 10.42it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 311/2645 [00:31<03:43, 10.42it/s, training_loss=0.442]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 313/2645 [00:31<03:45, 10.32it/s, training_loss=0.442]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 313/2645 [00:31<03:45, 10.32it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 313/2645 [00:31<03:45, 10.32it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 315/2645 [00:31<03:45, 10.35it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 315/2645 [00:31<03:45, 10.35it/s, training_loss=0.356]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 315/2645 [00:31<03:45, 10.35it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 317/2645 [00:31<03:46, 10.29it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 317/2645 [00:31<03:46, 10.29it/s, training_loss=0.311]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 317/2645 [00:31<03:46, 10.29it/s, training_loss=0.404]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 319/2645 [00:31<03:46, 10.25it/s, training_loss=0.404]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 319/2645 [00:31<03:46, 10.25it/s, training_loss=0.136]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 319/2645 [00:31<03:46, 10.25it/s, training_loss=0.176]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 321/2645 [00:31<03:46, 10.28it/s, training_loss=0.176]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 321/2645 [00:31<03:46, 10.28it/s, training_loss=0.057]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 321/2645 [00:32<03:46, 10.28it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 323/2645 [00:32<03:44, 10.32it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 323/2645 [00:32<03:44, 10.32it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 323/2645 [00:32<03:44, 10.32it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 325/2645 [00:32<03:48, 10.14it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 325/2645 [00:32<03:48, 10.14it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 325/2645 [00:32<03:48, 10.14it/s, training_loss=0.083]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 327/2645 [00:32<03:48, 10.13it/s, training_loss=0.083]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 327/2645 [00:32<03:48, 10.13it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 327/2645 [00:32<03:48, 10.13it/s, training_loss=0.339]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 329/2645 [00:32<03:48, 10.12it/s, training_loss=0.339]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 329/2645 [00:32<03:48, 10.12it/s, training_loss=0.166]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 329/2645 [00:32<03:48, 10.12it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 331/2645 [00:32<03:49, 10.09it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 331/2645 [00:32<03:49, 10.09it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 331/2645 [00:33<03:49, 10.09it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 333/2645 [00:33<03:48, 10.13it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 333/2645 [00:33<03:48, 10.13it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 333/2645 [00:33<03:48, 10.13it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 335/2645 [00:33<03:46, 10.19it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 335/2645 [00:33<03:46, 10.19it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 335/2645 [00:33<03:46, 10.19it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 337/2645 [00:33<03:44, 10.30it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 337/2645 [00:33<03:44, 10.30it/s, training_loss=0.120]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 337/2645 [00:33<03:44, 10.30it/s, training_loss=0.502]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 339/2645 [00:33<03:43, 10.32it/s, training_loss=0.502]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 339/2645 [00:33<03:43, 10.32it/s, training_loss=0.117]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 339/2645 [00:33<03:43, 10.32it/s, training_loss=0.252]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 341/2645 [00:33<03:43, 10.33it/s, training_loss=0.252]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 341/2645 [00:33<03:43, 10.33it/s, training_loss=0.609]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 341/2645 [00:34<03:43, 10.33it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 343/2645 [00:34<03:41, 10.38it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 343/2645 [00:34<03:41, 10.38it/s, training_loss=0.046]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 343/2645 [00:34<03:41, 10.38it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 345/2645 [00:34<03:40, 10.44it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 345/2645 [00:34<03:40, 10.44it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 345/2645 [00:34<03:40, 10.44it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 347/2645 [00:34<03:39, 10.47it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 347/2645 [00:34<03:39, 10.47it/s, training_loss=0.694]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 347/2645 [00:34<03:39, 10.47it/s, training_loss=0.433]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 349/2645 [00:34<03:40, 10.39it/s, training_loss=0.433]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 349/2645 [00:34<03:40, 10.39it/s, training_loss=0.239]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 349/2645 [00:34<03:40, 10.39it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 351/2645 [00:34<03:41, 10.35it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 351/2645 [00:34<03:41, 10.35it/s, training_loss=0.888]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 351/2645 [00:35<03:41, 10.35it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 353/2645 [00:35<03:43, 10.28it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 353/2645 [00:35<03:43, 10.28it/s, training_loss=0.368]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 353/2645 [00:35<03:43, 10.28it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 355/2645 [00:35<03:42, 10.30it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 355/2645 [00:35<03:42, 10.30it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 355/2645 [00:35<03:42, 10.30it/s, training_loss=0.010]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 357/2645 [00:35<03:41, 10.32it/s, training_loss=0.010]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 357/2645 [00:35<03:41, 10.32it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 357/2645 [00:35<03:41, 10.32it/s, training_loss=0.411]\u001b[A\n",
      "Epoch 1:  14%|█▎        | 359/2645 [00:35<03:44, 10.20it/s, training_loss=0.411]\u001b[A\n",
      "Epoch 1:  14%|█▎        | 359/2645 [00:35<03:44, 10.20it/s, training_loss=0.317]\u001b[A\n",
      "Epoch 1:  14%|█▎        | 359/2645 [00:35<03:44, 10.20it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 1:  14%|█▎        | 361/2645 [00:35<03:43, 10.24it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 1:  14%|█▎        | 361/2645 [00:35<03:43, 10.24it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  14%|█▎        | 361/2645 [00:35<03:43, 10.24it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  14%|█▎        | 363/2645 [00:35<03:43, 10.19it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  14%|█▎        | 363/2645 [00:36<03:43, 10.19it/s, training_loss=0.629]\u001b[A\n",
      "Epoch 1:  14%|█▎        | 363/2645 [00:36<03:43, 10.19it/s, training_loss=0.325]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 365/2645 [00:36<03:43, 10.18it/s, training_loss=0.325]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 365/2645 [00:36<03:43, 10.18it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 365/2645 [00:36<03:43, 10.18it/s, training_loss=0.022]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 367/2645 [00:36<03:42, 10.24it/s, training_loss=0.022]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 367/2645 [00:36<03:42, 10.24it/s, training_loss=0.799]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 367/2645 [00:36<03:42, 10.24it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 369/2645 [00:36<03:40, 10.33it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 369/2645 [00:36<03:40, 10.33it/s, training_loss=0.010]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 369/2645 [00:36<03:40, 10.33it/s, training_loss=0.456]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 371/2645 [00:36<03:41, 10.28it/s, training_loss=0.456]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 371/2645 [00:36<03:41, 10.28it/s, training_loss=0.178]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 371/2645 [00:36<03:41, 10.28it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 373/2645 [00:36<03:41, 10.24it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 373/2645 [00:37<03:41, 10.24it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 373/2645 [00:37<03:41, 10.24it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 375/2645 [00:37<03:38, 10.37it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 375/2645 [00:37<03:38, 10.37it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 375/2645 [00:37<03:38, 10.37it/s, training_loss=0.423]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 377/2645 [00:37<03:39, 10.34it/s, training_loss=0.423]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 377/2645 [00:37<03:39, 10.34it/s, training_loss=0.080]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 377/2645 [00:37<03:39, 10.34it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 379/2645 [00:37<03:38, 10.35it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 379/2645 [00:37<03:38, 10.35it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 379/2645 [00:37<03:38, 10.35it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 381/2645 [00:37<03:38, 10.38it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 381/2645 [00:37<03:38, 10.38it/s, training_loss=0.267]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 381/2645 [00:37<03:38, 10.38it/s, training_loss=0.563]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 383/2645 [00:37<03:41, 10.22it/s, training_loss=0.563]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 383/2645 [00:38<03:41, 10.22it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 383/2645 [00:38<03:41, 10.22it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  15%|█▍        | 385/2645 [00:38<03:39, 10.30it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  15%|█▍        | 385/2645 [00:38<03:39, 10.30it/s, training_loss=0.011]\u001b[A\n",
      "Epoch 1:  15%|█▍        | 385/2645 [00:38<03:39, 10.30it/s, training_loss=0.015]\u001b[A\n",
      "Epoch 1:  15%|█▍        | 387/2645 [00:38<03:40, 10.24it/s, training_loss=0.015]\u001b[A\n",
      "Epoch 1:  15%|█▍        | 387/2645 [00:38<03:40, 10.24it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  15%|█▍        | 387/2645 [00:38<03:40, 10.24it/s, training_loss=0.015]\u001b[A\n",
      "Epoch 1:  15%|█▍        | 389/2645 [00:38<03:43, 10.08it/s, training_loss=0.015]\u001b[A\n",
      "Epoch 1:  15%|█▍        | 389/2645 [00:38<03:43, 10.08it/s, training_loss=0.012]\u001b[A\n",
      "Epoch 1:  15%|█▍        | 389/2645 [00:38<03:43, 10.08it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  15%|█▍        | 391/2645 [00:38<03:44, 10.05it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  15%|█▍        | 391/2645 [00:38<03:44, 10.05it/s, training_loss=0.037]\u001b[A\n",
      "Epoch 1:  15%|█▍        | 391/2645 [00:38<03:44, 10.05it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  15%|█▍        | 393/2645 [00:38<03:44, 10.03it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  15%|█▍        | 393/2645 [00:39<03:44, 10.03it/s, training_loss=0.024]\u001b[A\n",
      "Epoch 1:  15%|█▍        | 393/2645 [00:39<03:44, 10.03it/s, training_loss=0.022]\u001b[A\n",
      "Epoch 1:  15%|█▍        | 395/2645 [00:39<03:43, 10.05it/s, training_loss=0.022]\u001b[A\n",
      "Epoch 1:  15%|█▍        | 395/2645 [00:39<03:43, 10.05it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  15%|█▍        | 395/2645 [00:39<03:43, 10.05it/s, training_loss=0.579]\u001b[A\n",
      "Epoch 1:  15%|█▌        | 397/2645 [00:39<03:43, 10.08it/s, training_loss=0.579]\u001b[A\n",
      "Epoch 1:  15%|█▌        | 397/2645 [00:39<03:43, 10.08it/s, training_loss=0.019]\u001b[A\n",
      "Epoch 1:  15%|█▌        | 397/2645 [00:39<03:43, 10.08it/s, training_loss=0.625]\u001b[A\n",
      "Epoch 1:  15%|█▌        | 399/2645 [00:39<03:42, 10.09it/s, training_loss=0.625]\u001b[A\n",
      "Epoch 1:  15%|█▌        | 399/2645 [00:39<03:42, 10.09it/s, training_loss=0.077]\u001b[A\n",
      "Epoch 1:  15%|█▌        | 399/2645 [00:39<03:42, 10.09it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  15%|█▌        | 401/2645 [00:39<03:40, 10.16it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  15%|█▌        | 401/2645 [00:39<03:40, 10.16it/s, training_loss=0.721]\u001b[A\n",
      "Epoch 1:  15%|█▌        | 401/2645 [00:39<03:40, 10.16it/s, training_loss=0.048]\u001b[A\n",
      "Epoch 1:  15%|█▌        | 403/2645 [00:39<03:41, 10.11it/s, training_loss=0.048]\u001b[A\n",
      "Epoch 1:  15%|█▌        | 403/2645 [00:40<03:41, 10.11it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  15%|█▌        | 403/2645 [00:40<03:41, 10.11it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  15%|█▌        | 405/2645 [00:40<03:38, 10.23it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  15%|█▌        | 405/2645 [00:40<03:38, 10.23it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  15%|█▌        | 405/2645 [00:40<03:38, 10.23it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  15%|█▌        | 407/2645 [00:40<03:38, 10.27it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  15%|█▌        | 407/2645 [00:40<03:38, 10.27it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  15%|█▌        | 407/2645 [00:40<03:38, 10.27it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  15%|█▌        | 409/2645 [00:40<03:37, 10.30it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  15%|█▌        | 409/2645 [00:40<03:37, 10.30it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  15%|█▌        | 409/2645 [00:40<03:37, 10.30it/s, training_loss=0.089]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 411/2645 [00:40<03:39, 10.17it/s, training_loss=0.089]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 411/2645 [00:40<03:39, 10.17it/s, training_loss=0.071]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 411/2645 [00:40<03:39, 10.17it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 413/2645 [00:40<03:41, 10.06it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 413/2645 [00:40<03:41, 10.06it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 413/2645 [00:41<03:41, 10.06it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 415/2645 [00:41<03:39, 10.18it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 415/2645 [00:41<03:39, 10.18it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 415/2645 [00:41<03:39, 10.18it/s, training_loss=0.488]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 417/2645 [00:41<03:39, 10.17it/s, training_loss=0.488]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 417/2645 [00:41<03:39, 10.17it/s, training_loss=0.791]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 417/2645 [00:41<03:39, 10.17it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 419/2645 [00:41<03:40, 10.08it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 419/2645 [00:41<03:40, 10.08it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 419/2645 [00:41<03:40, 10.08it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 421/2645 [00:41<03:39, 10.14it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 421/2645 [00:41<03:39, 10.14it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 421/2645 [00:41<03:39, 10.14it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 423/2645 [00:41<03:37, 10.20it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 423/2645 [00:41<03:37, 10.20it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 423/2645 [00:42<03:37, 10.20it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 425/2645 [00:42<03:34, 10.33it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 425/2645 [00:42<03:34, 10.33it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 425/2645 [00:42<03:34, 10.33it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 427/2645 [00:42<03:34, 10.35it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 427/2645 [00:42<03:34, 10.35it/s, training_loss=0.035]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 427/2645 [00:42<03:34, 10.35it/s, training_loss=0.011]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 429/2645 [00:42<03:36, 10.23it/s, training_loss=0.011]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 429/2645 [00:42<03:36, 10.23it/s, training_loss=0.173]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 429/2645 [00:42<03:36, 10.23it/s, training_loss=0.616]\u001b[A\n",
      "Epoch 1:  16%|█▋        | 431/2645 [00:42<03:36, 10.23it/s, training_loss=0.616]\u001b[A\n",
      "Epoch 1:  16%|█▋        | 431/2645 [00:42<03:36, 10.23it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  16%|█▋        | 431/2645 [00:42<03:36, 10.23it/s, training_loss=0.848]\u001b[A\n",
      "Epoch 1:  16%|█▋        | 433/2645 [00:42<03:35, 10.25it/s, training_loss=0.848]\u001b[A\n",
      "Epoch 1:  16%|█▋        | 433/2645 [00:42<03:35, 10.25it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  16%|█▋        | 433/2645 [00:43<03:35, 10.25it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  16%|█▋        | 435/2645 [00:43<03:36, 10.22it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  16%|█▋        | 435/2645 [00:43<03:36, 10.22it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  16%|█▋        | 435/2645 [00:43<03:36, 10.22it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 437/2645 [00:43<03:36, 10.20it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 437/2645 [00:43<03:36, 10.20it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 437/2645 [00:43<03:36, 10.20it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 439/2645 [00:43<03:33, 10.32it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 439/2645 [00:43<03:33, 10.32it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 439/2645 [00:43<03:33, 10.32it/s, training_loss=0.701]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 441/2645 [00:43<03:33, 10.31it/s, training_loss=0.701]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 441/2645 [00:43<03:33, 10.31it/s, training_loss=0.228]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 441/2645 [00:43<03:33, 10.31it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 443/2645 [00:43<03:33, 10.31it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 443/2645 [00:43<03:33, 10.31it/s, training_loss=0.153]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 443/2645 [00:44<03:33, 10.31it/s, training_loss=0.033]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 445/2645 [00:44<03:33, 10.29it/s, training_loss=0.033]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 445/2645 [00:44<03:33, 10.29it/s, training_loss=0.380]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 445/2645 [00:44<03:33, 10.29it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 447/2645 [00:44<03:33, 10.30it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 447/2645 [00:44<03:33, 10.30it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 447/2645 [00:44<03:33, 10.30it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 449/2645 [00:44<03:33, 10.27it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 449/2645 [00:44<03:33, 10.27it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 449/2645 [00:44<03:33, 10.27it/s, training_loss=0.103]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 451/2645 [00:44<03:33, 10.26it/s, training_loss=0.103]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 451/2645 [00:44<03:33, 10.26it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 451/2645 [00:44<03:33, 10.26it/s, training_loss=0.127]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 453/2645 [00:44<03:36, 10.13it/s, training_loss=0.127]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 453/2645 [00:44<03:36, 10.13it/s, training_loss=0.042]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 453/2645 [00:44<03:36, 10.13it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 455/2645 [00:44<03:35, 10.18it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 455/2645 [00:45<03:35, 10.18it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 455/2645 [00:45<03:35, 10.18it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 457/2645 [00:45<03:33, 10.26it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 457/2645 [00:45<03:33, 10.26it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 457/2645 [00:45<03:33, 10.26it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 459/2645 [00:45<03:33, 10.24it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 459/2645 [00:45<03:33, 10.24it/s, training_loss=0.112]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 459/2645 [00:45<03:33, 10.24it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 461/2645 [00:45<03:35, 10.13it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 461/2645 [00:45<03:35, 10.13it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 461/2645 [00:45<03:35, 10.13it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 463/2645 [00:45<03:34, 10.16it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 463/2645 [00:45<03:34, 10.16it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 463/2645 [00:45<03:34, 10.16it/s, training_loss=0.370]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 465/2645 [00:45<03:32, 10.24it/s, training_loss=0.370]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 465/2645 [00:46<03:32, 10.24it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 465/2645 [00:46<03:32, 10.24it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 467/2645 [00:46<03:30, 10.37it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 467/2645 [00:46<03:30, 10.37it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 467/2645 [00:46<03:30, 10.37it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 469/2645 [00:46<03:28, 10.45it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 469/2645 [00:46<03:28, 10.45it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 469/2645 [00:46<03:28, 10.45it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 471/2645 [00:46<03:27, 10.48it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 471/2645 [00:46<03:27, 10.48it/s, training_loss=0.567]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 471/2645 [00:46<03:27, 10.48it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 473/2645 [00:46<03:28, 10.39it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 473/2645 [00:46<03:28, 10.39it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 473/2645 [00:46<03:28, 10.39it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 475/2645 [00:46<03:27, 10.44it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 475/2645 [00:47<03:27, 10.44it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 475/2645 [00:47<03:27, 10.44it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 477/2645 [00:47<03:26, 10.49it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 477/2645 [00:47<03:26, 10.49it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 477/2645 [00:47<03:26, 10.49it/s, training_loss=0.356]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 479/2645 [00:47<03:26, 10.48it/s, training_loss=0.356]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 479/2645 [00:47<03:26, 10.48it/s, training_loss=0.879]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 479/2645 [00:47<03:26, 10.48it/s, training_loss=0.073]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 481/2645 [00:47<03:27, 10.44it/s, training_loss=0.073]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 481/2645 [00:47<03:27, 10.44it/s, training_loss=0.031]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 481/2645 [00:47<03:27, 10.44it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 483/2645 [00:47<03:26, 10.46it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 483/2645 [00:47<03:26, 10.46it/s, training_loss=0.010]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 483/2645 [00:47<03:26, 10.46it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 485/2645 [00:47<03:28, 10.38it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 485/2645 [00:47<03:28, 10.38it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 485/2645 [00:48<03:28, 10.38it/s, training_loss=0.133]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 487/2645 [00:48<03:28, 10.36it/s, training_loss=0.133]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 487/2645 [00:48<03:28, 10.36it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 487/2645 [00:48<03:28, 10.36it/s, training_loss=0.022]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 489/2645 [00:48<03:27, 10.37it/s, training_loss=0.022]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 489/2645 [00:48<03:27, 10.37it/s, training_loss=0.738]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 489/2645 [00:48<03:27, 10.37it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  19%|█▊        | 491/2645 [00:48<03:29, 10.29it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  19%|█▊        | 491/2645 [00:48<03:29, 10.29it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  19%|█▊        | 491/2645 [00:48<03:29, 10.29it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  19%|█▊        | 493/2645 [00:48<03:30, 10.22it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  19%|█▊        | 493/2645 [00:48<03:30, 10.22it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  19%|█▊        | 493/2645 [00:48<03:30, 10.22it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  19%|█▊        | 495/2645 [00:48<03:28, 10.31it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  19%|█▊        | 495/2645 [00:48<03:28, 10.31it/s, training_loss=0.375]\u001b[A\n",
      "Epoch 1:  19%|█▊        | 495/2645 [00:49<03:28, 10.31it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 497/2645 [00:49<03:27, 10.33it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 497/2645 [00:49<03:27, 10.33it/s, training_loss=0.221]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 497/2645 [00:49<03:27, 10.33it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 499/2645 [00:49<03:27, 10.33it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 499/2645 [00:49<03:27, 10.33it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 499/2645 [00:49<03:27, 10.33it/s, training_loss=0.334]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 501/2645 [00:49<03:27, 10.31it/s, training_loss=0.334]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 501/2645 [00:49<03:27, 10.31it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 501/2645 [00:49<03:27, 10.31it/s, training_loss=0.802]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 503/2645 [00:49<03:27, 10.30it/s, training_loss=0.802]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 503/2645 [00:49<03:27, 10.30it/s, training_loss=0.797]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 503/2645 [00:49<03:27, 10.30it/s, training_loss=0.103]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 505/2645 [00:49<03:29, 10.20it/s, training_loss=0.103]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 505/2645 [00:49<03:29, 10.20it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 505/2645 [00:50<03:29, 10.20it/s, training_loss=0.596]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 507/2645 [00:50<03:28, 10.24it/s, training_loss=0.596]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 507/2645 [00:50<03:28, 10.24it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 507/2645 [00:50<03:28, 10.24it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 509/2645 [00:50<03:27, 10.31it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 509/2645 [00:50<03:27, 10.31it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 509/2645 [00:50<03:27, 10.31it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 511/2645 [00:50<03:25, 10.37it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 511/2645 [00:50<03:25, 10.37it/s, training_loss=0.901]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 511/2645 [00:50<03:25, 10.37it/s, training_loss=0.544]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 513/2645 [00:50<03:25, 10.40it/s, training_loss=0.544]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 513/2645 [00:50<03:25, 10.40it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 513/2645 [00:50<03:25, 10.40it/s, training_loss=0.020]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 515/2645 [00:50<03:25, 10.37it/s, training_loss=0.020]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 515/2645 [00:50<03:25, 10.37it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 515/2645 [00:50<03:25, 10.37it/s, training_loss=0.432]\u001b[A\n",
      "Epoch 1:  20%|█▉        | 517/2645 [00:50<03:24, 10.39it/s, training_loss=0.432]\u001b[A\n",
      "Epoch 1:  20%|█▉        | 517/2645 [00:51<03:24, 10.39it/s, training_loss=0.546]\u001b[A\n",
      "Epoch 1:  20%|█▉        | 517/2645 [00:51<03:24, 10.39it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  20%|█▉        | 519/2645 [00:51<03:24, 10.37it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  20%|█▉        | 519/2645 [00:51<03:24, 10.37it/s, training_loss=0.043]\u001b[A\n",
      "Epoch 1:  20%|█▉        | 519/2645 [00:51<03:24, 10.37it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  20%|█▉        | 521/2645 [00:51<03:24, 10.36it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  20%|█▉        | 521/2645 [00:51<03:24, 10.36it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  20%|█▉        | 521/2645 [00:51<03:24, 10.36it/s, training_loss=0.543]\u001b[A\n",
      "Epoch 1:  20%|█▉        | 523/2645 [00:51<03:23, 10.41it/s, training_loss=0.543]\u001b[A\n",
      "Epoch 1:  20%|█▉        | 523/2645 [00:51<03:23, 10.41it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 1:  20%|█▉        | 523/2645 [00:51<03:23, 10.41it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  20%|█▉        | 525/2645 [00:51<03:23, 10.40it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  20%|█▉        | 525/2645 [00:51<03:23, 10.40it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  20%|█▉        | 525/2645 [00:51<03:23, 10.40it/s, training_loss=0.010]\u001b[A\n",
      "Epoch 1:  20%|█▉        | 527/2645 [00:51<03:23, 10.42it/s, training_loss=0.010]\u001b[A\n",
      "Epoch 1:  20%|█▉        | 527/2645 [00:52<03:23, 10.42it/s, training_loss=0.087]\u001b[A\n",
      "Epoch 1:  20%|█▉        | 527/2645 [00:52<03:23, 10.42it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  20%|██        | 529/2645 [00:52<03:22, 10.43it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  20%|██        | 529/2645 [00:52<03:22, 10.43it/s, training_loss=0.011]\u001b[A\n",
      "Epoch 1:  20%|██        | 529/2645 [00:52<03:22, 10.43it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  20%|██        | 531/2645 [00:52<03:22, 10.41it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  20%|██        | 531/2645 [00:52<03:22, 10.41it/s, training_loss=0.481]\u001b[A\n",
      "Epoch 1:  20%|██        | 531/2645 [00:52<03:22, 10.41it/s, training_loss=0.011]\u001b[A\n",
      "Epoch 1:  20%|██        | 533/2645 [00:52<03:22, 10.44it/s, training_loss=0.011]\u001b[A\n",
      "Epoch 1:  20%|██        | 533/2645 [00:52<03:22, 10.44it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  20%|██        | 533/2645 [00:52<03:22, 10.44it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  20%|██        | 535/2645 [00:52<03:20, 10.50it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  20%|██        | 535/2645 [00:52<03:20, 10.50it/s, training_loss=0.108]\u001b[A\n",
      "Epoch 1:  20%|██        | 535/2645 [00:52<03:20, 10.50it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  20%|██        | 537/2645 [00:52<03:22, 10.42it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  20%|██        | 537/2645 [00:53<03:22, 10.42it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  20%|██        | 537/2645 [00:53<03:22, 10.42it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  20%|██        | 539/2645 [00:53<03:25, 10.25it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  20%|██        | 539/2645 [00:53<03:25, 10.25it/s, training_loss=0.367]\u001b[A\n",
      "Epoch 1:  20%|██        | 539/2645 [00:53<03:25, 10.25it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  20%|██        | 541/2645 [00:53<03:25, 10.22it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  20%|██        | 541/2645 [00:53<03:25, 10.22it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  20%|██        | 541/2645 [00:53<03:25, 10.22it/s, training_loss=0.530]\u001b[A\n",
      "Epoch 1:  21%|██        | 543/2645 [00:53<03:25, 10.23it/s, training_loss=0.530]\u001b[A\n",
      "Epoch 1:  21%|██        | 543/2645 [00:53<03:25, 10.23it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  21%|██        | 543/2645 [00:53<03:25, 10.23it/s, training_loss=0.031]\u001b[A\n",
      "Epoch 1:  21%|██        | 545/2645 [00:53<03:27, 10.10it/s, training_loss=0.031]\u001b[A\n",
      "Epoch 1:  21%|██        | 545/2645 [00:53<03:27, 10.10it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  21%|██        | 545/2645 [00:53<03:27, 10.10it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  21%|██        | 547/2645 [00:53<03:27, 10.11it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  21%|██        | 547/2645 [00:54<03:27, 10.11it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  21%|██        | 547/2645 [00:54<03:27, 10.11it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  21%|██        | 549/2645 [00:54<03:27, 10.12it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  21%|██        | 549/2645 [00:54<03:27, 10.12it/s, training_loss=0.723]\u001b[A\n",
      "Epoch 1:  21%|██        | 549/2645 [00:54<03:27, 10.12it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  21%|██        | 551/2645 [00:54<03:26, 10.12it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  21%|██        | 551/2645 [00:54<03:26, 10.12it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  21%|██        | 551/2645 [00:54<03:26, 10.12it/s, training_loss=0.604]\u001b[A\n",
      "Epoch 1:  21%|██        | 553/2645 [00:54<03:25, 10.16it/s, training_loss=0.604]\u001b[A\n",
      "Epoch 1:  21%|██        | 553/2645 [00:54<03:25, 10.16it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  21%|██        | 553/2645 [00:54<03:25, 10.16it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 1:  21%|██        | 555/2645 [00:54<03:25, 10.19it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 1:  21%|██        | 555/2645 [00:54<03:25, 10.19it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  21%|██        | 555/2645 [00:54<03:25, 10.19it/s, training_loss=0.232]\u001b[A\n",
      "Epoch 1:  21%|██        | 557/2645 [00:54<03:27, 10.04it/s, training_loss=0.232]\u001b[A\n",
      "Epoch 1:  21%|██        | 557/2645 [00:54<03:27, 10.04it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  21%|██        | 557/2645 [00:55<03:27, 10.04it/s, training_loss=0.609]\u001b[A\n",
      "Epoch 1:  21%|██        | 559/2645 [00:55<03:26, 10.11it/s, training_loss=0.609]\u001b[A\n",
      "Epoch 1:  21%|██        | 559/2645 [00:55<03:26, 10.11it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  21%|██        | 559/2645 [00:55<03:26, 10.11it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  21%|██        | 561/2645 [00:55<03:25, 10.12it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  21%|██        | 561/2645 [00:55<03:25, 10.12it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  21%|██        | 561/2645 [00:55<03:25, 10.12it/s, training_loss=0.019]\u001b[A\n",
      "Epoch 1:  21%|██▏       | 563/2645 [00:55<03:24, 10.19it/s, training_loss=0.019]\u001b[A\n",
      "Epoch 1:  21%|██▏       | 563/2645 [00:55<03:24, 10.19it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  21%|██▏       | 563/2645 [00:55<03:24, 10.19it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  21%|██▏       | 565/2645 [00:55<03:22, 10.25it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  21%|██▏       | 565/2645 [00:55<03:22, 10.25it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  21%|██▏       | 565/2645 [00:55<03:22, 10.25it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  21%|██▏       | 567/2645 [00:55<03:22, 10.27it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  21%|██▏       | 567/2645 [00:55<03:22, 10.27it/s, training_loss=0.886]\u001b[A\n",
      "Epoch 1:  21%|██▏       | 567/2645 [00:56<03:22, 10.27it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 569/2645 [00:56<03:21, 10.29it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 569/2645 [00:56<03:21, 10.29it/s, training_loss=0.105]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 569/2645 [00:56<03:21, 10.29it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 571/2645 [00:56<03:21, 10.29it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 571/2645 [00:56<03:21, 10.29it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 571/2645 [00:56<03:21, 10.29it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 573/2645 [00:56<03:20, 10.32it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 573/2645 [00:56<03:20, 10.32it/s, training_loss=0.271]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 573/2645 [00:56<03:20, 10.32it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 575/2645 [00:56<03:23, 10.18it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 575/2645 [00:56<03:23, 10.18it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 575/2645 [00:56<03:23, 10.18it/s, training_loss=0.202]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 577/2645 [00:56<03:21, 10.24it/s, training_loss=0.202]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 577/2645 [00:56<03:21, 10.24it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 577/2645 [00:57<03:21, 10.24it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 579/2645 [00:57<03:20, 10.29it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 579/2645 [00:57<03:20, 10.29it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 579/2645 [00:57<03:20, 10.29it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 581/2645 [00:57<03:19, 10.34it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 581/2645 [00:57<03:19, 10.34it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 581/2645 [00:57<03:19, 10.34it/s, training_loss=0.306]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 583/2645 [00:57<03:19, 10.33it/s, training_loss=0.306]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 583/2645 [00:57<03:19, 10.33it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 583/2645 [00:57<03:19, 10.33it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 585/2645 [00:57<03:18, 10.37it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 585/2645 [00:57<03:18, 10.37it/s, training_loss=0.046]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 585/2645 [00:57<03:18, 10.37it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 587/2645 [00:57<03:20, 10.29it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 587/2645 [00:57<03:20, 10.29it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 587/2645 [00:58<03:20, 10.29it/s, training_loss=0.073]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 589/2645 [00:58<03:20, 10.23it/s, training_loss=0.073]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 589/2645 [00:58<03:20, 10.23it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 589/2645 [00:58<03:20, 10.23it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 591/2645 [00:58<03:19, 10.28it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 591/2645 [00:58<03:19, 10.28it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 591/2645 [00:58<03:19, 10.28it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 593/2645 [00:58<03:19, 10.26it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 593/2645 [00:58<03:19, 10.26it/s, training_loss=0.313]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 593/2645 [00:58<03:19, 10.26it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 595/2645 [00:58<03:19, 10.28it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 595/2645 [00:58<03:19, 10.28it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 595/2645 [00:58<03:19, 10.28it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 597/2645 [00:58<03:19, 10.26it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 597/2645 [00:58<03:19, 10.26it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 597/2645 [00:58<03:19, 10.26it/s, training_loss=0.857]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 599/2645 [00:58<03:21, 10.15it/s, training_loss=0.857]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 599/2645 [00:59<03:21, 10.15it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 599/2645 [00:59<03:21, 10.15it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 601/2645 [00:59<03:20, 10.20it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 601/2645 [00:59<03:20, 10.20it/s, training_loss=0.042]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 601/2645 [00:59<03:20, 10.20it/s, training_loss=0.208]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 603/2645 [00:59<03:20, 10.17it/s, training_loss=0.208]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 603/2645 [00:59<03:20, 10.17it/s, training_loss=0.011]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 603/2645 [00:59<03:20, 10.17it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 605/2645 [00:59<03:19, 10.24it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 605/2645 [00:59<03:19, 10.24it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 605/2645 [00:59<03:19, 10.24it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 607/2645 [00:59<03:18, 10.26it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 607/2645 [00:59<03:18, 10.26it/s, training_loss=0.583]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 607/2645 [00:59<03:18, 10.26it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 609/2645 [00:59<03:20, 10.14it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 609/2645 [01:00<03:20, 10.14it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 609/2645 [01:00<03:20, 10.14it/s, training_loss=0.421]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 611/2645 [01:00<03:21, 10.08it/s, training_loss=0.421]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 611/2645 [01:00<03:21, 10.08it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 611/2645 [01:00<03:21, 10.08it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 613/2645 [01:00<03:20, 10.13it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 613/2645 [01:00<03:20, 10.13it/s, training_loss=0.068]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 613/2645 [01:00<03:20, 10.13it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 615/2645 [01:00<03:20, 10.12it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 615/2645 [01:00<03:20, 10.12it/s, training_loss=0.151]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 615/2645 [01:00<03:20, 10.12it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 617/2645 [01:00<03:21, 10.08it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 617/2645 [01:00<03:21, 10.08it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 617/2645 [01:00<03:21, 10.08it/s, training_loss=0.107]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 619/2645 [01:00<03:22, 10.00it/s, training_loss=0.107]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 619/2645 [01:01<03:22, 10.00it/s, training_loss=0.012]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 619/2645 [01:01<03:22, 10.00it/s, training_loss=0.406]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 621/2645 [01:01<03:23,  9.97it/s, training_loss=0.406]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 621/2645 [01:01<03:23,  9.97it/s, training_loss=0.312]\u001b[A\n",
      "Epoch 1:  24%|██▎       | 622/2645 [01:01<03:22,  9.97it/s, training_loss=0.312]\u001b[A\n",
      "Epoch 1:  24%|██▎       | 622/2645 [01:01<03:22,  9.97it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  24%|██▎       | 622/2645 [01:01<03:22,  9.97it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  24%|██▎       | 624/2645 [01:01<03:21, 10.02it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  24%|██▎       | 624/2645 [01:01<03:21, 10.02it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  24%|██▎       | 624/2645 [01:01<03:21, 10.02it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  24%|██▎       | 626/2645 [01:01<03:22,  9.98it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  24%|██▎       | 626/2645 [01:01<03:22,  9.98it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  24%|██▎       | 627/2645 [01:01<03:23,  9.90it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  24%|██▎       | 627/2645 [01:01<03:23,  9.90it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  24%|██▎       | 628/2645 [01:01<03:23,  9.90it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  24%|██▎       | 628/2645 [01:01<03:23,  9.90it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 629/2645 [01:01<03:24,  9.84it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 629/2645 [01:02<03:24,  9.84it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 629/2645 [01:02<03:24,  9.84it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 631/2645 [01:02<03:23,  9.89it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 631/2645 [01:02<03:23,  9.89it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 631/2645 [01:02<03:23,  9.89it/s, training_loss=0.621]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 633/2645 [01:02<03:21, 10.00it/s, training_loss=0.621]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 633/2645 [01:02<03:21, 10.00it/s, training_loss=0.256]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 633/2645 [01:02<03:21, 10.00it/s, training_loss=0.070]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 635/2645 [01:02<03:18, 10.11it/s, training_loss=0.070]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 635/2645 [01:02<03:18, 10.11it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 635/2645 [01:02<03:18, 10.11it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 637/2645 [01:02<03:15, 10.27it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 637/2645 [01:02<03:15, 10.27it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 637/2645 [01:02<03:15, 10.27it/s, training_loss=0.227]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 639/2645 [01:02<03:14, 10.30it/s, training_loss=0.227]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 639/2645 [01:03<03:14, 10.30it/s, training_loss=0.463]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 639/2645 [01:03<03:14, 10.30it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 641/2645 [01:03<03:14, 10.31it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 641/2645 [01:03<03:14, 10.31it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 641/2645 [01:03<03:14, 10.31it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 643/2645 [01:03<03:12, 10.40it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 643/2645 [01:03<03:12, 10.40it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 643/2645 [01:03<03:12, 10.40it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 645/2645 [01:03<03:12, 10.39it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 645/2645 [01:03<03:12, 10.39it/s, training_loss=0.242]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 645/2645 [01:03<03:12, 10.39it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 647/2645 [01:03<03:13, 10.34it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 647/2645 [01:03<03:13, 10.34it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 647/2645 [01:03<03:13, 10.34it/s, training_loss=0.890]\u001b[A\n",
      "Epoch 1:  25%|██▍       | 649/2645 [01:03<03:11, 10.40it/s, training_loss=0.890]\u001b[A\n",
      "Epoch 1:  25%|██▍       | 649/2645 [01:03<03:11, 10.40it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  25%|██▍       | 649/2645 [01:04<03:11, 10.40it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  25%|██▍       | 651/2645 [01:04<03:11, 10.44it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  25%|██▍       | 651/2645 [01:04<03:11, 10.44it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  25%|██▍       | 651/2645 [01:04<03:11, 10.44it/s, training_loss=0.061]\u001b[A\n",
      "Epoch 1:  25%|██▍       | 653/2645 [01:04<03:11, 10.42it/s, training_loss=0.061]\u001b[A\n",
      "Epoch 1:  25%|██▍       | 653/2645 [01:04<03:11, 10.42it/s, training_loss=0.659]\u001b[A\n",
      "Epoch 1:  25%|██▍       | 653/2645 [01:04<03:11, 10.42it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  25%|██▍       | 655/2645 [01:04<03:11, 10.37it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  25%|██▍       | 655/2645 [01:04<03:11, 10.37it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  25%|██▍       | 655/2645 [01:04<03:11, 10.37it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  25%|██▍       | 657/2645 [01:04<03:11, 10.40it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  25%|██▍       | 657/2645 [01:04<03:11, 10.40it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  25%|██▍       | 657/2645 [01:04<03:11, 10.40it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 1:  25%|██▍       | 659/2645 [01:04<03:11, 10.38it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 1:  25%|██▍       | 659/2645 [01:04<03:11, 10.38it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  25%|██▍       | 659/2645 [01:05<03:11, 10.38it/s, training_loss=1.044]\u001b[A\n",
      "Epoch 1:  25%|██▍       | 661/2645 [01:05<03:11, 10.35it/s, training_loss=1.044]\u001b[A\n",
      "Epoch 1:  25%|██▍       | 661/2645 [01:05<03:11, 10.35it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  25%|██▍       | 661/2645 [01:05<03:11, 10.35it/s, training_loss=0.118]\u001b[A\n",
      "Epoch 1:  25%|██▌       | 663/2645 [01:05<03:12, 10.32it/s, training_loss=0.118]\u001b[A\n",
      "Epoch 1:  25%|██▌       | 663/2645 [01:05<03:12, 10.32it/s, training_loss=0.596]\u001b[A\n",
      "Epoch 1:  25%|██▌       | 663/2645 [01:05<03:12, 10.32it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  25%|██▌       | 665/2645 [01:05<03:13, 10.25it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  25%|██▌       | 665/2645 [01:05<03:13, 10.25it/s, training_loss=0.511]\u001b[A\n",
      "Epoch 1:  25%|██▌       | 665/2645 [01:05<03:13, 10.25it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  25%|██▌       | 667/2645 [01:05<03:12, 10.26it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  25%|██▌       | 667/2645 [01:05<03:12, 10.26it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  25%|██▌       | 667/2645 [01:05<03:12, 10.26it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  25%|██▌       | 669/2645 [01:05<03:13, 10.21it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  25%|██▌       | 669/2645 [01:05<03:13, 10.21it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  25%|██▌       | 669/2645 [01:06<03:13, 10.21it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  25%|██▌       | 671/2645 [01:06<03:12, 10.26it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  25%|██▌       | 671/2645 [01:06<03:12, 10.26it/s, training_loss=0.478]\u001b[A\n",
      "Epoch 1:  25%|██▌       | 671/2645 [01:06<03:12, 10.26it/s, training_loss=0.481]\u001b[A\n",
      "Epoch 1:  25%|██▌       | 673/2645 [01:06<03:14, 10.13it/s, training_loss=0.481]\u001b[A\n",
      "Epoch 1:  25%|██▌       | 673/2645 [01:06<03:14, 10.13it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  25%|██▌       | 673/2645 [01:06<03:14, 10.13it/s, training_loss=0.141]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 675/2645 [01:06<03:13, 10.17it/s, training_loss=0.141]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 675/2645 [01:06<03:13, 10.17it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 675/2645 [01:06<03:13, 10.17it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 677/2645 [01:06<03:13, 10.18it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 677/2645 [01:06<03:13, 10.18it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 677/2645 [01:06<03:13, 10.18it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 679/2645 [01:06<03:13, 10.18it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 679/2645 [01:06<03:13, 10.18it/s, training_loss=0.623]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 679/2645 [01:07<03:13, 10.18it/s, training_loss=0.158]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 681/2645 [01:07<03:12, 10.21it/s, training_loss=0.158]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 681/2645 [01:07<03:12, 10.21it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 681/2645 [01:07<03:12, 10.21it/s, training_loss=0.879]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 683/2645 [01:07<03:13, 10.16it/s, training_loss=0.879]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 683/2645 [01:07<03:13, 10.16it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 683/2645 [01:07<03:13, 10.16it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 685/2645 [01:07<03:11, 10.25it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 685/2645 [01:07<03:11, 10.25it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 685/2645 [01:07<03:11, 10.25it/s, training_loss=0.310]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 687/2645 [01:07<03:10, 10.30it/s, training_loss=0.310]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 687/2645 [01:07<03:10, 10.30it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 687/2645 [01:07<03:10, 10.30it/s, training_loss=0.084]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 689/2645 [01:07<03:09, 10.33it/s, training_loss=0.084]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 689/2645 [01:07<03:09, 10.33it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 689/2645 [01:07<03:09, 10.33it/s, training_loss=0.374]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 691/2645 [01:07<03:09, 10.32it/s, training_loss=0.374]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 691/2645 [01:08<03:09, 10.32it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 691/2645 [01:08<03:09, 10.32it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 693/2645 [01:08<03:09, 10.30it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 693/2645 [01:08<03:09, 10.30it/s, training_loss=0.024]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 693/2645 [01:08<03:09, 10.30it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  26%|██▋       | 695/2645 [01:08<03:09, 10.30it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  26%|██▋       | 695/2645 [01:08<03:09, 10.30it/s, training_loss=0.012]\u001b[A\n",
      "Epoch 1:  26%|██▋       | 695/2645 [01:08<03:09, 10.30it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  26%|██▋       | 697/2645 [01:08<03:08, 10.32it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  26%|██▋       | 697/2645 [01:08<03:08, 10.32it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  26%|██▋       | 697/2645 [01:08<03:08, 10.32it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  26%|██▋       | 699/2645 [01:08<03:08, 10.35it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  26%|██▋       | 699/2645 [01:08<03:08, 10.35it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  26%|██▋       | 699/2645 [01:08<03:08, 10.35it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 701/2645 [01:08<03:06, 10.40it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 701/2645 [01:09<03:06, 10.40it/s, training_loss=0.079]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 701/2645 [01:09<03:06, 10.40it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 703/2645 [01:09<03:06, 10.44it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 703/2645 [01:09<03:06, 10.44it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 703/2645 [01:09<03:06, 10.44it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 705/2645 [01:09<03:04, 10.52it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 705/2645 [01:09<03:04, 10.52it/s, training_loss=0.336]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 705/2645 [01:09<03:04, 10.52it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 707/2645 [01:09<03:04, 10.51it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 707/2645 [01:09<03:04, 10.51it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 707/2645 [01:09<03:04, 10.51it/s, training_loss=0.223]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 709/2645 [01:09<03:04, 10.48it/s, training_loss=0.223]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 709/2645 [01:09<03:04, 10.48it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 709/2645 [01:09<03:04, 10.48it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 711/2645 [01:09<03:04, 10.48it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 711/2645 [01:09<03:04, 10.48it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 711/2645 [01:10<03:04, 10.48it/s, training_loss=0.804]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 713/2645 [01:10<03:04, 10.46it/s, training_loss=0.804]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 713/2645 [01:10<03:04, 10.46it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 713/2645 [01:10<03:04, 10.46it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 715/2645 [01:10<03:04, 10.45it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 715/2645 [01:10<03:04, 10.45it/s, training_loss=0.024]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 715/2645 [01:10<03:04, 10.45it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 717/2645 [01:10<03:05, 10.42it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 717/2645 [01:10<03:05, 10.42it/s, training_loss=0.734]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 717/2645 [01:10<03:05, 10.42it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 719/2645 [01:10<03:04, 10.44it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 719/2645 [01:10<03:04, 10.44it/s, training_loss=0.092]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 719/2645 [01:10<03:04, 10.44it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 721/2645 [01:10<03:04, 10.43it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 721/2645 [01:10<03:04, 10.43it/s, training_loss=0.025]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 721/2645 [01:11<03:04, 10.43it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 723/2645 [01:11<03:03, 10.48it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 723/2645 [01:11<03:03, 10.48it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 723/2645 [01:11<03:03, 10.48it/s, training_loss=0.409]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 725/2645 [01:11<03:02, 10.50it/s, training_loss=0.409]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 725/2645 [01:11<03:02, 10.50it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 725/2645 [01:11<03:02, 10.50it/s, training_loss=0.035]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 727/2645 [01:11<03:02, 10.50it/s, training_loss=0.035]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 727/2645 [01:11<03:02, 10.50it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 727/2645 [01:11<03:02, 10.50it/s, training_loss=0.031]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 729/2645 [01:11<03:02, 10.51it/s, training_loss=0.031]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 729/2645 [01:11<03:02, 10.51it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 729/2645 [01:11<03:02, 10.51it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 731/2645 [01:11<03:02, 10.49it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 731/2645 [01:11<03:02, 10.49it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 731/2645 [01:12<03:02, 10.49it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 733/2645 [01:12<03:02, 10.47it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 733/2645 [01:12<03:02, 10.47it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 733/2645 [01:12<03:02, 10.47it/s, training_loss=0.633]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 735/2645 [01:12<03:02, 10.48it/s, training_loss=0.633]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 735/2645 [01:12<03:02, 10.48it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 735/2645 [01:12<03:02, 10.48it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 737/2645 [01:12<03:02, 10.44it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 737/2645 [01:12<03:02, 10.44it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 737/2645 [01:12<03:02, 10.44it/s, training_loss=0.841]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 739/2645 [01:12<03:03, 10.37it/s, training_loss=0.841]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 739/2645 [01:12<03:03, 10.37it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 739/2645 [01:12<03:03, 10.37it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 741/2645 [01:12<03:03, 10.37it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 741/2645 [01:12<03:03, 10.37it/s, training_loss=0.085]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 741/2645 [01:12<03:03, 10.37it/s, training_loss=0.302]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 743/2645 [01:12<03:06, 10.18it/s, training_loss=0.302]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 743/2645 [01:13<03:06, 10.18it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 743/2645 [01:13<03:06, 10.18it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 745/2645 [01:13<03:06, 10.21it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 745/2645 [01:13<03:06, 10.21it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 745/2645 [01:13<03:06, 10.21it/s, training_loss=0.010]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 747/2645 [01:13<03:06, 10.20it/s, training_loss=0.010]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 747/2645 [01:13<03:06, 10.20it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 747/2645 [01:13<03:06, 10.20it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 749/2645 [01:13<03:05, 10.23it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 749/2645 [01:13<03:05, 10.23it/s, training_loss=0.129]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 749/2645 [01:13<03:05, 10.23it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 751/2645 [01:13<03:06, 10.14it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 751/2645 [01:13<03:06, 10.14it/s, training_loss=0.445]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 751/2645 [01:13<03:06, 10.14it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 753/2645 [01:13<03:05, 10.18it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 753/2645 [01:14<03:05, 10.18it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 753/2645 [01:14<03:05, 10.18it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  29%|██▊       | 755/2645 [01:14<03:04, 10.27it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  29%|██▊       | 755/2645 [01:14<03:04, 10.27it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  29%|██▊       | 755/2645 [01:14<03:04, 10.27it/s, training_loss=0.315]\u001b[A\n",
      "Epoch 1:  29%|██▊       | 757/2645 [01:14<03:03, 10.29it/s, training_loss=0.315]\u001b[A\n",
      "Epoch 1:  29%|██▊       | 757/2645 [01:14<03:03, 10.29it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  29%|██▊       | 757/2645 [01:14<03:03, 10.29it/s, training_loss=0.661]\u001b[A\n",
      "Epoch 1:  29%|██▊       | 759/2645 [01:14<03:02, 10.32it/s, training_loss=0.661]\u001b[A\n",
      "Epoch 1:  29%|██▊       | 759/2645 [01:14<03:02, 10.32it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  29%|██▊       | 759/2645 [01:14<03:02, 10.32it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 761/2645 [01:14<03:05, 10.14it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 761/2645 [01:14<03:05, 10.14it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 761/2645 [01:14<03:05, 10.14it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 763/2645 [01:14<03:04, 10.19it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 763/2645 [01:15<03:04, 10.19it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 763/2645 [01:15<03:04, 10.19it/s, training_loss=0.012]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 765/2645 [01:15<03:04, 10.20it/s, training_loss=0.012]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 765/2645 [01:15<03:04, 10.20it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 765/2645 [01:15<03:04, 10.20it/s, training_loss=0.066]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 767/2645 [01:15<03:02, 10.27it/s, training_loss=0.066]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 767/2645 [01:15<03:02, 10.27it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 767/2645 [01:15<03:02, 10.27it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 769/2645 [01:15<03:01, 10.34it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 769/2645 [01:15<03:01, 10.34it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 769/2645 [01:15<03:01, 10.34it/s, training_loss=0.385]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 771/2645 [01:15<03:01, 10.32it/s, training_loss=0.385]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 771/2645 [01:15<03:01, 10.32it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 771/2645 [01:15<03:01, 10.32it/s, training_loss=0.394]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 773/2645 [01:15<03:01, 10.33it/s, training_loss=0.394]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 773/2645 [01:16<03:01, 10.33it/s, training_loss=1.107]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 773/2645 [01:16<03:01, 10.33it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 775/2645 [01:16<03:00, 10.38it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 775/2645 [01:16<03:00, 10.38it/s, training_loss=0.656]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 775/2645 [01:16<03:00, 10.38it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 777/2645 [01:16<02:59, 10.40it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 777/2645 [01:16<02:59, 10.40it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 777/2645 [01:16<02:59, 10.40it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 779/2645 [01:16<02:59, 10.41it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 779/2645 [01:16<02:59, 10.41it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 779/2645 [01:16<02:59, 10.41it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  30%|██▉       | 781/2645 [01:16<02:57, 10.48it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  30%|██▉       | 781/2645 [01:16<02:57, 10.48it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  30%|██▉       | 781/2645 [01:16<02:57, 10.48it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  30%|██▉       | 783/2645 [01:16<02:57, 10.48it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  30%|██▉       | 783/2645 [01:16<02:57, 10.48it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  30%|██▉       | 783/2645 [01:17<02:57, 10.48it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  30%|██▉       | 785/2645 [01:17<02:57, 10.46it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  30%|██▉       | 785/2645 [01:17<02:57, 10.46it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  30%|██▉       | 785/2645 [01:17<02:57, 10.46it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  30%|██▉       | 787/2645 [01:17<02:56, 10.50it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  30%|██▉       | 787/2645 [01:17<02:56, 10.50it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  30%|██▉       | 787/2645 [01:17<02:56, 10.50it/s, training_loss=0.117]\u001b[A\n",
      "Epoch 1:  30%|██▉       | 789/2645 [01:17<02:57, 10.45it/s, training_loss=0.117]\u001b[A\n",
      "Epoch 1:  30%|██▉       | 789/2645 [01:17<02:57, 10.45it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  30%|██▉       | 789/2645 [01:17<02:57, 10.45it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  30%|██▉       | 791/2645 [01:17<02:56, 10.49it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  30%|██▉       | 791/2645 [01:17<02:56, 10.49it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  30%|██▉       | 791/2645 [01:17<02:56, 10.49it/s, training_loss=0.364]\u001b[A\n",
      "Epoch 1:  30%|██▉       | 793/2645 [01:17<02:56, 10.48it/s, training_loss=0.364]\u001b[A\n",
      "Epoch 1:  30%|██▉       | 793/2645 [01:17<02:56, 10.48it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  30%|██▉       | 793/2645 [01:18<02:56, 10.48it/s, training_loss=0.365]\u001b[A\n",
      "Epoch 1:  30%|███       | 795/2645 [01:18<02:57, 10.45it/s, training_loss=0.365]\u001b[A\n",
      "Epoch 1:  30%|███       | 795/2645 [01:18<02:57, 10.45it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  30%|███       | 795/2645 [01:18<02:57, 10.45it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  30%|███       | 797/2645 [01:18<02:56, 10.49it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  30%|███       | 797/2645 [01:18<02:56, 10.49it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  30%|███       | 797/2645 [01:18<02:56, 10.49it/s, training_loss=0.858]\u001b[A\n",
      "Epoch 1:  30%|███       | 799/2645 [01:18<02:57, 10.38it/s, training_loss=0.858]\u001b[A\n",
      "Epoch 1:  30%|███       | 799/2645 [01:18<02:57, 10.38it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  30%|███       | 799/2645 [01:18<02:57, 10.38it/s, training_loss=0.744]\u001b[A\n",
      "Epoch 1:  30%|███       | 801/2645 [01:18<02:57, 10.39it/s, training_loss=0.744]\u001b[A\n",
      "Epoch 1:  30%|███       | 801/2645 [01:18<02:57, 10.39it/s, training_loss=0.265]\u001b[A\n",
      "Epoch 1:  30%|███       | 801/2645 [01:18<02:57, 10.39it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  30%|███       | 803/2645 [01:18<02:56, 10.44it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  30%|███       | 803/2645 [01:18<02:56, 10.44it/s, training_loss=0.213]\u001b[A\n",
      "Epoch 1:  30%|███       | 803/2645 [01:18<02:56, 10.44it/s, training_loss=0.491]\u001b[A\n",
      "Epoch 1:  30%|███       | 805/2645 [01:18<02:56, 10.43it/s, training_loss=0.491]\u001b[A\n",
      "Epoch 1:  30%|███       | 805/2645 [01:19<02:56, 10.43it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  30%|███       | 805/2645 [01:19<02:56, 10.43it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  31%|███       | 807/2645 [01:19<02:55, 10.50it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  31%|███       | 807/2645 [01:19<02:55, 10.50it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  31%|███       | 807/2645 [01:19<02:55, 10.50it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  31%|███       | 809/2645 [01:19<02:54, 10.52it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  31%|███       | 809/2645 [01:19<02:54, 10.52it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  31%|███       | 809/2645 [01:19<02:54, 10.52it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  31%|███       | 811/2645 [01:19<02:54, 10.51it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  31%|███       | 811/2645 [01:19<02:54, 10.51it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  31%|███       | 811/2645 [01:19<02:54, 10.51it/s, training_loss=0.202]\u001b[A\n",
      "Epoch 1:  31%|███       | 813/2645 [01:19<02:56, 10.39it/s, training_loss=0.202]\u001b[A\n",
      "Epoch 1:  31%|███       | 813/2645 [01:19<02:56, 10.39it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  31%|███       | 813/2645 [01:19<02:56, 10.39it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  31%|███       | 815/2645 [01:19<02:56, 10.35it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  31%|███       | 815/2645 [01:20<02:56, 10.35it/s, training_loss=0.419]\u001b[A\n",
      "Epoch 1:  31%|███       | 815/2645 [01:20<02:56, 10.35it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  31%|███       | 817/2645 [01:20<02:57, 10.30it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  31%|███       | 817/2645 [01:20<02:57, 10.30it/s, training_loss=0.616]\u001b[A\n",
      "Epoch 1:  31%|███       | 817/2645 [01:20<02:57, 10.30it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  31%|███       | 819/2645 [01:20<03:01, 10.06it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  31%|███       | 819/2645 [01:20<03:01, 10.06it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  31%|███       | 819/2645 [01:20<03:01, 10.06it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  31%|███       | 821/2645 [01:20<02:58, 10.20it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  31%|███       | 821/2645 [01:20<02:58, 10.20it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  31%|███       | 821/2645 [01:20<02:58, 10.20it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  31%|███       | 823/2645 [01:20<02:56, 10.32it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  31%|███       | 823/2645 [01:20<02:56, 10.32it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  31%|███       | 823/2645 [01:20<02:56, 10.32it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  31%|███       | 825/2645 [01:20<02:55, 10.37it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  31%|███       | 825/2645 [01:20<02:55, 10.37it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  31%|███       | 825/2645 [01:21<02:55, 10.37it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  31%|███▏      | 827/2645 [01:21<02:54, 10.42it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  31%|███▏      | 827/2645 [01:21<02:54, 10.42it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  31%|███▏      | 827/2645 [01:21<02:54, 10.42it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  31%|███▏      | 829/2645 [01:21<02:53, 10.45it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  31%|███▏      | 829/2645 [01:21<02:53, 10.45it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  31%|███▏      | 829/2645 [01:21<02:53, 10.45it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  31%|███▏      | 831/2645 [01:21<02:53, 10.47it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  31%|███▏      | 831/2645 [01:21<02:53, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  31%|███▏      | 831/2645 [01:21<02:53, 10.47it/s, training_loss=0.069]\u001b[A\n",
      "Epoch 1:  31%|███▏      | 833/2645 [01:21<02:52, 10.48it/s, training_loss=0.069]\u001b[A\n",
      "Epoch 1:  31%|███▏      | 833/2645 [01:21<02:52, 10.48it/s, training_loss=0.371]\u001b[A\n",
      "Epoch 1:  31%|███▏      | 833/2645 [01:21<02:52, 10.48it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 835/2645 [01:21<02:52, 10.47it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 835/2645 [01:21<02:52, 10.47it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 835/2645 [01:22<02:52, 10.47it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 837/2645 [01:22<02:52, 10.49it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 837/2645 [01:22<02:52, 10.49it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 837/2645 [01:22<02:52, 10.49it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 839/2645 [01:22<02:51, 10.55it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 839/2645 [01:22<02:51, 10.55it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 839/2645 [01:22<02:51, 10.55it/s, training_loss=0.200]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 841/2645 [01:22<02:52, 10.46it/s, training_loss=0.200]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 841/2645 [01:22<02:52, 10.46it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 841/2645 [01:22<02:52, 10.46it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 843/2645 [01:22<02:51, 10.50it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 843/2645 [01:22<02:51, 10.50it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 843/2645 [01:22<02:51, 10.50it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 845/2645 [01:22<02:50, 10.56it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 845/2645 [01:22<02:50, 10.56it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 845/2645 [01:22<02:50, 10.56it/s, training_loss=0.018]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 847/2645 [01:22<02:50, 10.52it/s, training_loss=0.018]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 847/2645 [01:23<02:50, 10.52it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 847/2645 [01:23<02:50, 10.52it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 849/2645 [01:23<02:50, 10.56it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 849/2645 [01:23<02:50, 10.56it/s, training_loss=0.221]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 849/2645 [01:23<02:50, 10.56it/s, training_loss=0.144]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 851/2645 [01:23<02:50, 10.53it/s, training_loss=0.144]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 851/2645 [01:23<02:50, 10.53it/s, training_loss=0.565]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 851/2645 [01:23<02:50, 10.53it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 853/2645 [01:23<02:50, 10.53it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 853/2645 [01:23<02:50, 10.53it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 853/2645 [01:23<02:50, 10.53it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 855/2645 [01:23<02:49, 10.54it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 855/2645 [01:23<02:49, 10.54it/s, training_loss=0.557]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 855/2645 [01:23<02:49, 10.54it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 857/2645 [01:23<02:50, 10.48it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 857/2645 [01:24<02:50, 10.48it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 857/2645 [01:24<02:50, 10.48it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 859/2645 [01:24<02:50, 10.48it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 859/2645 [01:24<02:50, 10.48it/s, training_loss=0.732]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 859/2645 [01:24<02:50, 10.48it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 861/2645 [01:24<02:50, 10.46it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 861/2645 [01:24<02:50, 10.46it/s, training_loss=0.520]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 861/2645 [01:24<02:50, 10.46it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 863/2645 [01:24<02:50, 10.47it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 863/2645 [01:24<02:50, 10.47it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 863/2645 [01:24<02:50, 10.47it/s, training_loss=0.044]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 865/2645 [01:24<02:50, 10.45it/s, training_loss=0.044]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 865/2645 [01:24<02:50, 10.45it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 865/2645 [01:24<02:50, 10.45it/s, training_loss=0.501]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 867/2645 [01:24<02:50, 10.44it/s, training_loss=0.501]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 867/2645 [01:24<02:50, 10.44it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 867/2645 [01:25<02:50, 10.44it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 869/2645 [01:25<02:49, 10.48it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 869/2645 [01:25<02:49, 10.48it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 869/2645 [01:25<02:49, 10.48it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 871/2645 [01:25<02:48, 10.50it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 871/2645 [01:25<02:48, 10.50it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 871/2645 [01:25<02:48, 10.50it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 873/2645 [01:25<02:48, 10.54it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 873/2645 [01:25<02:48, 10.54it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 873/2645 [01:25<02:48, 10.54it/s, training_loss=0.797]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 875/2645 [01:25<02:48, 10.51it/s, training_loss=0.797]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 875/2645 [01:25<02:48, 10.51it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 875/2645 [01:25<02:48, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 877/2645 [01:25<02:48, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 877/2645 [01:25<02:48, 10.49it/s, training_loss=0.116]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 877/2645 [01:26<02:48, 10.49it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 879/2645 [01:26<02:49, 10.43it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 879/2645 [01:26<02:49, 10.43it/s, training_loss=0.149]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 879/2645 [01:26<02:49, 10.43it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 881/2645 [01:26<02:49, 10.41it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 881/2645 [01:26<02:49, 10.41it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 881/2645 [01:26<02:49, 10.41it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 883/2645 [01:26<02:47, 10.49it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 883/2645 [01:26<02:47, 10.49it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 883/2645 [01:26<02:47, 10.49it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 885/2645 [01:26<02:47, 10.52it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 885/2645 [01:26<02:47, 10.52it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 885/2645 [01:26<02:47, 10.52it/s, training_loss=0.817]\u001b[A\n",
      "Epoch 1:  34%|███▎      | 887/2645 [01:26<02:47, 10.49it/s, training_loss=0.817]\u001b[A\n",
      "Epoch 1:  34%|███▎      | 887/2645 [01:26<02:47, 10.49it/s, training_loss=0.164]\u001b[A\n",
      "Epoch 1:  34%|███▎      | 887/2645 [01:26<02:47, 10.49it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  34%|███▎      | 889/2645 [01:26<02:47, 10.46it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  34%|███▎      | 889/2645 [01:27<02:47, 10.46it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  34%|███▎      | 889/2645 [01:27<02:47, 10.46it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  34%|███▎      | 891/2645 [01:27<02:47, 10.50it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  34%|███▎      | 891/2645 [01:27<02:47, 10.50it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  34%|███▎      | 891/2645 [01:27<02:47, 10.50it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 893/2645 [01:27<02:46, 10.52it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 893/2645 [01:27<02:46, 10.52it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 893/2645 [01:27<02:46, 10.52it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 895/2645 [01:27<02:47, 10.46it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 895/2645 [01:27<02:47, 10.46it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 895/2645 [01:27<02:47, 10.46it/s, training_loss=0.629]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 897/2645 [01:27<02:47, 10.46it/s, training_loss=0.629]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 897/2645 [01:27<02:47, 10.46it/s, training_loss=0.439]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 897/2645 [01:27<02:47, 10.46it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 899/2645 [01:27<02:47, 10.41it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 899/2645 [01:28<02:47, 10.41it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 899/2645 [01:28<02:47, 10.41it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 901/2645 [01:28<02:47, 10.42it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 901/2645 [01:28<02:47, 10.42it/s, training_loss=0.371]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 901/2645 [01:28<02:47, 10.42it/s, training_loss=0.099]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 903/2645 [01:28<02:47, 10.38it/s, training_loss=0.099]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 903/2645 [01:28<02:47, 10.38it/s, training_loss=0.327]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 903/2645 [01:28<02:47, 10.38it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 905/2645 [01:28<02:47, 10.39it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 905/2645 [01:28<02:47, 10.39it/s, training_loss=0.025]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 905/2645 [01:28<02:47, 10.39it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 907/2645 [01:28<02:47, 10.40it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 907/2645 [01:28<02:47, 10.40it/s, training_loss=0.877]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 907/2645 [01:28<02:47, 10.40it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 909/2645 [01:28<02:46, 10.45it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 909/2645 [01:29<02:46, 10.45it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 909/2645 [01:29<02:46, 10.45it/s, training_loss=0.782]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 911/2645 [01:29<02:45, 10.46it/s, training_loss=0.782]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 911/2645 [01:29<02:45, 10.46it/s, training_loss=0.024]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 911/2645 [01:29<02:45, 10.46it/s, training_loss=0.017]\u001b[A\n",
      "Epoch 1:  35%|███▍      | 913/2645 [01:29<02:46, 10.40it/s, training_loss=0.017]\u001b[A\n",
      "Epoch 1:  35%|███▍      | 913/2645 [01:29<02:46, 10.40it/s, training_loss=0.011]\u001b[A\n",
      "Epoch 1:  35%|███▍      | 913/2645 [01:29<02:46, 10.40it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  35%|███▍      | 915/2645 [01:29<02:46, 10.40it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  35%|███▍      | 915/2645 [01:29<02:46, 10.40it/s, training_loss=0.065]\u001b[A\n",
      "Epoch 1:  35%|███▍      | 915/2645 [01:29<02:46, 10.40it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  35%|███▍      | 917/2645 [01:29<02:45, 10.44it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  35%|███▍      | 917/2645 [01:29<02:45, 10.44it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  35%|███▍      | 917/2645 [01:29<02:45, 10.44it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  35%|███▍      | 919/2645 [01:29<02:44, 10.50it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  35%|███▍      | 919/2645 [01:29<02:44, 10.50it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  35%|███▍      | 919/2645 [01:30<02:44, 10.50it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  35%|███▍      | 921/2645 [01:30<02:43, 10.53it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  35%|███▍      | 921/2645 [01:30<02:43, 10.53it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  35%|███▍      | 921/2645 [01:30<02:43, 10.53it/s, training_loss=1.700]\u001b[A\n",
      "Epoch 1:  35%|███▍      | 923/2645 [01:30<02:43, 10.51it/s, training_loss=1.700]\u001b[A\n",
      "Epoch 1:  35%|███▍      | 923/2645 [01:30<02:43, 10.51it/s, training_loss=0.201]\u001b[A\n",
      "Epoch 1:  35%|███▍      | 923/2645 [01:30<02:43, 10.51it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  35%|███▍      | 925/2645 [01:30<02:49, 10.13it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  35%|███▍      | 925/2645 [01:30<02:49, 10.13it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  35%|███▍      | 925/2645 [01:30<02:49, 10.13it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  35%|███▌      | 927/2645 [01:30<02:47, 10.25it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  35%|███▌      | 927/2645 [01:30<02:47, 10.25it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  35%|███▌      | 927/2645 [01:30<02:47, 10.25it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  35%|███▌      | 929/2645 [01:30<02:46, 10.32it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  35%|███▌      | 929/2645 [01:30<02:46, 10.32it/s, training_loss=0.645]\u001b[A\n",
      "Epoch 1:  35%|███▌      | 929/2645 [01:31<02:46, 10.32it/s, training_loss=0.790]\u001b[A\n",
      "Epoch 1:  35%|███▌      | 931/2645 [01:31<02:46, 10.29it/s, training_loss=0.790]\u001b[A\n",
      "Epoch 1:  35%|███▌      | 931/2645 [01:31<02:46, 10.29it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  35%|███▌      | 931/2645 [01:31<02:46, 10.29it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  35%|███▌      | 933/2645 [01:31<02:45, 10.36it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  35%|███▌      | 933/2645 [01:31<02:45, 10.36it/s, training_loss=0.990]\u001b[A\n",
      "Epoch 1:  35%|███▌      | 933/2645 [01:31<02:45, 10.36it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  35%|███▌      | 935/2645 [01:31<02:44, 10.40it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  35%|███▌      | 935/2645 [01:31<02:44, 10.40it/s, training_loss=0.072]\u001b[A\n",
      "Epoch 1:  35%|███▌      | 935/2645 [01:31<02:44, 10.40it/s, training_loss=0.747]\u001b[A\n",
      "Epoch 1:  35%|███▌      | 937/2645 [01:31<02:44, 10.40it/s, training_loss=0.747]\u001b[A\n",
      "Epoch 1:  35%|███▌      | 937/2645 [01:31<02:44, 10.40it/s, training_loss=0.047]\u001b[A\n",
      "Epoch 1:  35%|███▌      | 937/2645 [01:31<02:44, 10.40it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 939/2645 [01:31<02:43, 10.42it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 939/2645 [01:31<02:43, 10.42it/s, training_loss=0.027]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 939/2645 [01:31<02:43, 10.42it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 941/2645 [01:31<02:42, 10.46it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 941/2645 [01:32<02:42, 10.46it/s, training_loss=0.020]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 941/2645 [01:32<02:42, 10.46it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 943/2645 [01:32<02:42, 10.45it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 943/2645 [01:32<02:42, 10.45it/s, training_loss=0.590]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 943/2645 [01:32<02:42, 10.45it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 945/2645 [01:32<02:42, 10.47it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 945/2645 [01:32<02:42, 10.47it/s, training_loss=0.455]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 945/2645 [01:32<02:42, 10.47it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 947/2645 [01:32<02:42, 10.43it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 947/2645 [01:32<02:42, 10.43it/s, training_loss=0.034]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 947/2645 [01:32<02:42, 10.43it/s, training_loss=0.015]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 949/2645 [01:32<02:43, 10.40it/s, training_loss=0.015]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 949/2645 [01:32<02:43, 10.40it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 949/2645 [01:32<02:43, 10.40it/s, training_loss=0.725]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 951/2645 [01:32<02:43, 10.37it/s, training_loss=0.725]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 951/2645 [01:33<02:43, 10.37it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 951/2645 [01:33<02:43, 10.37it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 953/2645 [01:33<02:42, 10.41it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 953/2645 [01:33<02:42, 10.41it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 953/2645 [01:33<02:42, 10.41it/s, training_loss=0.168]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 955/2645 [01:33<02:42, 10.42it/s, training_loss=0.168]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 955/2645 [01:33<02:42, 10.42it/s, training_loss=0.474]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 955/2645 [01:33<02:42, 10.42it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 957/2645 [01:33<02:41, 10.43it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 957/2645 [01:33<02:41, 10.43it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 957/2645 [01:33<02:41, 10.43it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  36%|███▋      | 959/2645 [01:33<02:41, 10.45it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  36%|███▋      | 959/2645 [01:33<02:41, 10.45it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  36%|███▋      | 959/2645 [01:33<02:41, 10.45it/s, training_loss=0.374]\u001b[A\n",
      "Epoch 1:  36%|███▋      | 961/2645 [01:33<02:41, 10.45it/s, training_loss=0.374]\u001b[A\n",
      "Epoch 1:  36%|███▋      | 961/2645 [01:34<02:41, 10.45it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  36%|███▋      | 961/2645 [01:34<02:41, 10.45it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  36%|███▋      | 963/2645 [01:34<02:40, 10.51it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  36%|███▋      | 963/2645 [01:34<02:40, 10.51it/s, training_loss=1.205]\u001b[A\n",
      "Epoch 1:  36%|███▋      | 963/2645 [01:34<02:40, 10.51it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  36%|███▋      | 965/2645 [01:34<02:39, 10.51it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  36%|███▋      | 965/2645 [01:34<02:39, 10.51it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  36%|███▋      | 965/2645 [01:34<02:39, 10.51it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 967/2645 [01:34<02:39, 10.51it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 967/2645 [01:34<02:39, 10.51it/s, training_loss=0.259]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 967/2645 [01:34<02:39, 10.51it/s, training_loss=0.541]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 969/2645 [01:34<02:39, 10.49it/s, training_loss=0.541]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 969/2645 [01:34<02:39, 10.49it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 969/2645 [01:34<02:39, 10.49it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 971/2645 [01:34<02:38, 10.53it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 971/2645 [01:34<02:38, 10.53it/s, training_loss=1.484]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 971/2645 [01:35<02:38, 10.53it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 973/2645 [01:35<02:39, 10.51it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 973/2645 [01:35<02:39, 10.51it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 973/2645 [01:35<02:39, 10.51it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 975/2645 [01:35<02:38, 10.54it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 975/2645 [01:35<02:38, 10.54it/s, training_loss=0.178]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 975/2645 [01:35<02:38, 10.54it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 977/2645 [01:35<02:38, 10.51it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 977/2645 [01:35<02:38, 10.51it/s, training_loss=0.034]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 977/2645 [01:35<02:38, 10.51it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 979/2645 [01:35<02:38, 10.54it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 979/2645 [01:35<02:38, 10.54it/s, training_loss=0.233]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 979/2645 [01:35<02:38, 10.54it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 981/2645 [01:35<02:38, 10.49it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 981/2645 [01:35<02:38, 10.49it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 981/2645 [01:35<02:38, 10.49it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 983/2645 [01:36<02:37, 10.53it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 983/2645 [01:36<02:37, 10.53it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 983/2645 [01:36<02:37, 10.53it/s, training_loss=0.018]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 985/2645 [01:36<02:37, 10.52it/s, training_loss=0.018]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 985/2645 [01:36<02:37, 10.52it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 985/2645 [01:36<02:37, 10.52it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 987/2645 [01:36<02:38, 10.47it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 987/2645 [01:36<02:38, 10.47it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 987/2645 [01:36<02:38, 10.47it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 989/2645 [01:36<02:38, 10.45it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 989/2645 [01:36<02:38, 10.45it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 989/2645 [01:36<02:38, 10.45it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 991/2645 [01:36<02:38, 10.46it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 991/2645 [01:36<02:38, 10.46it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 991/2645 [01:36<02:38, 10.46it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 993/2645 [01:36<02:38, 10.41it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 993/2645 [01:37<02:38, 10.41it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 993/2645 [01:37<02:38, 10.41it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 995/2645 [01:37<02:38, 10.44it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 995/2645 [01:37<02:38, 10.44it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 995/2645 [01:37<02:38, 10.44it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 997/2645 [01:37<02:36, 10.50it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 997/2645 [01:37<02:36, 10.50it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 997/2645 [01:37<02:36, 10.50it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 999/2645 [01:37<02:36, 10.53it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 999/2645 [01:37<02:36, 10.53it/s, training_loss=0.801]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 999/2645 [01:37<02:36, 10.53it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 1001/2645 [01:37<02:36, 10.50it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 1001/2645 [01:37<02:36, 10.50it/s, training_loss=0.456]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 1001/2645 [01:37<02:36, 10.50it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 1003/2645 [01:37<02:36, 10.51it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 1003/2645 [01:38<02:36, 10.51it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 1003/2645 [01:38<02:36, 10.51it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 1005/2645 [01:38<02:36, 10.51it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 1005/2645 [01:38<02:36, 10.51it/s, training_loss=0.673]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 1005/2645 [01:38<02:36, 10.51it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 1007/2645 [01:38<02:36, 10.46it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 1007/2645 [01:38<02:36, 10.46it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 1007/2645 [01:38<02:36, 10.46it/s, training_loss=0.015]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 1009/2645 [01:38<02:36, 10.42it/s, training_loss=0.015]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 1009/2645 [01:38<02:36, 10.42it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 1009/2645 [01:38<02:36, 10.42it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 1011/2645 [01:38<02:36, 10.43it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 1011/2645 [01:38<02:36, 10.43it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 1011/2645 [01:38<02:36, 10.43it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 1013/2645 [01:38<02:36, 10.42it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 1013/2645 [01:38<02:36, 10.42it/s, training_loss=0.789]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 1013/2645 [01:39<02:36, 10.42it/s, training_loss=0.599]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 1015/2645 [01:39<02:36, 10.39it/s, training_loss=0.599]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 1015/2645 [01:39<02:36, 10.39it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 1015/2645 [01:39<02:36, 10.39it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 1017/2645 [01:39<02:36, 10.39it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 1017/2645 [01:39<02:36, 10.39it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 1017/2645 [01:39<02:36, 10.39it/s, training_loss=0.025]\u001b[A\n",
      "Epoch 1:  39%|███▊      | 1019/2645 [01:39<02:36, 10.41it/s, training_loss=0.025]\u001b[A\n",
      "Epoch 1:  39%|███▊      | 1019/2645 [01:39<02:36, 10.41it/s, training_loss=0.052]\u001b[A\n",
      "Epoch 1:  39%|███▊      | 1019/2645 [01:39<02:36, 10.41it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  39%|███▊      | 1021/2645 [01:39<02:35, 10.43it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  39%|███▊      | 1021/2645 [01:39<02:35, 10.43it/s, training_loss=0.552]\u001b[A\n",
      "Epoch 1:  39%|███▊      | 1021/2645 [01:39<02:35, 10.43it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  39%|███▊      | 1023/2645 [01:39<02:35, 10.40it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  39%|███▊      | 1023/2645 [01:39<02:35, 10.40it/s, training_loss=0.812]\u001b[A\n",
      "Epoch 1:  39%|███▊      | 1023/2645 [01:40<02:35, 10.40it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 1025/2645 [01:40<02:35, 10.43it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 1025/2645 [01:40<02:35, 10.43it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 1025/2645 [01:40<02:35, 10.43it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 1027/2645 [01:40<02:34, 10.49it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 1027/2645 [01:40<02:34, 10.49it/s, training_loss=0.368]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 1027/2645 [01:40<02:34, 10.49it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 1029/2645 [01:40<02:34, 10.45it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 1029/2645 [01:40<02:34, 10.45it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 1029/2645 [01:40<02:34, 10.45it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 1031/2645 [01:40<02:34, 10.45it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 1031/2645 [01:40<02:34, 10.45it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 1031/2645 [01:40<02:34, 10.45it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 1033/2645 [01:40<02:36, 10.33it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 1033/2645 [01:40<02:36, 10.33it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 1033/2645 [01:40<02:36, 10.33it/s, training_loss=0.016]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 1035/2645 [01:40<02:36, 10.30it/s, training_loss=0.016]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 1035/2645 [01:41<02:36, 10.30it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 1035/2645 [01:41<02:36, 10.30it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 1037/2645 [01:41<02:36, 10.26it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 1037/2645 [01:41<02:36, 10.26it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 1037/2645 [01:41<02:36, 10.26it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 1039/2645 [01:41<02:35, 10.32it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 1039/2645 [01:41<02:35, 10.32it/s, training_loss=0.236]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 1039/2645 [01:41<02:35, 10.32it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 1041/2645 [01:41<02:35, 10.29it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 1041/2645 [01:41<02:35, 10.29it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 1041/2645 [01:41<02:35, 10.29it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 1043/2645 [01:41<02:36, 10.24it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 1043/2645 [01:41<02:36, 10.24it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 1043/2645 [01:41<02:36, 10.24it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  40%|███▉      | 1045/2645 [01:41<02:35, 10.28it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  40%|███▉      | 1045/2645 [01:42<02:35, 10.28it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  40%|███▉      | 1045/2645 [01:42<02:35, 10.28it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  40%|███▉      | 1047/2645 [01:42<02:35, 10.27it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  40%|███▉      | 1047/2645 [01:42<02:35, 10.27it/s, training_loss=0.112]\u001b[A\n",
      "Epoch 1:  40%|███▉      | 1047/2645 [01:42<02:35, 10.27it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  40%|███▉      | 1049/2645 [01:42<02:35, 10.29it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  40%|███▉      | 1049/2645 [01:42<02:35, 10.29it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  40%|███▉      | 1049/2645 [01:42<02:35, 10.29it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  40%|███▉      | 1051/2645 [01:42<02:33, 10.35it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  40%|███▉      | 1051/2645 [01:42<02:33, 10.35it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  40%|███▉      | 1051/2645 [01:42<02:33, 10.35it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  40%|███▉      | 1053/2645 [01:42<02:35, 10.25it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  40%|███▉      | 1053/2645 [01:42<02:35, 10.25it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  40%|███▉      | 1053/2645 [01:42<02:35, 10.25it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  40%|███▉      | 1055/2645 [01:42<02:34, 10.31it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  40%|███▉      | 1055/2645 [01:43<02:34, 10.31it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  40%|███▉      | 1055/2645 [01:43<02:34, 10.31it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  40%|███▉      | 1057/2645 [01:43<02:34, 10.29it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  40%|███▉      | 1057/2645 [01:43<02:34, 10.29it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  40%|███▉      | 1057/2645 [01:43<02:34, 10.29it/s, training_loss=0.823]\u001b[A\n",
      "Epoch 1:  40%|████      | 1059/2645 [01:43<02:33, 10.32it/s, training_loss=0.823]\u001b[A\n",
      "Epoch 1:  40%|████      | 1059/2645 [01:43<02:33, 10.32it/s, training_loss=0.119]\u001b[A\n",
      "Epoch 1:  40%|████      | 1059/2645 [01:43<02:33, 10.32it/s, training_loss=0.086]\u001b[A\n",
      "Epoch 1:  40%|████      | 1061/2645 [01:43<02:33, 10.33it/s, training_loss=0.086]\u001b[A\n",
      "Epoch 1:  40%|████      | 1061/2645 [01:43<02:33, 10.33it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  40%|████      | 1061/2645 [01:43<02:33, 10.33it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  40%|████      | 1063/2645 [01:43<02:33, 10.32it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  40%|████      | 1063/2645 [01:43<02:33, 10.32it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  40%|████      | 1063/2645 [01:43<02:33, 10.32it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  40%|████      | 1065/2645 [01:43<02:34, 10.21it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  40%|████      | 1065/2645 [01:44<02:34, 10.21it/s, training_loss=0.010]\u001b[A\n",
      "Epoch 1:  40%|████      | 1065/2645 [01:44<02:34, 10.21it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  40%|████      | 1067/2645 [01:44<02:35, 10.17it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  40%|████      | 1067/2645 [01:44<02:35, 10.17it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  40%|████      | 1067/2645 [01:44<02:35, 10.17it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  40%|████      | 1069/2645 [01:44<02:35, 10.15it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  40%|████      | 1069/2645 [01:44<02:35, 10.15it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  40%|████      | 1069/2645 [01:44<02:35, 10.15it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  40%|████      | 1071/2645 [01:44<02:34, 10.19it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  40%|████      | 1071/2645 [01:44<02:34, 10.19it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  40%|████      | 1071/2645 [01:44<02:34, 10.19it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  41%|████      | 1073/2645 [01:44<02:34, 10.14it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  41%|████      | 1073/2645 [01:44<02:34, 10.14it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  41%|████      | 1073/2645 [01:44<02:34, 10.14it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  41%|████      | 1075/2645 [01:44<02:35, 10.11it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  41%|████      | 1075/2645 [01:45<02:35, 10.11it/s, training_loss=0.019]\u001b[A\n",
      "Epoch 1:  41%|████      | 1075/2645 [01:45<02:35, 10.11it/s, training_loss=0.028]\u001b[A\n",
      "Epoch 1:  41%|████      | 1077/2645 [01:45<02:37,  9.97it/s, training_loss=0.028]\u001b[A\n",
      "Epoch 1:  41%|████      | 1077/2645 [01:45<02:37,  9.97it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  41%|████      | 1078/2645 [01:45<02:37,  9.97it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  41%|████      | 1078/2645 [01:45<02:37,  9.97it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  41%|████      | 1078/2645 [01:45<02:37,  9.97it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  41%|████      | 1080/2645 [01:45<02:35, 10.09it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  41%|████      | 1080/2645 [01:45<02:35, 10.09it/s, training_loss=0.619]\u001b[A\n",
      "Epoch 1:  41%|████      | 1080/2645 [01:45<02:35, 10.09it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  41%|████      | 1082/2645 [01:45<02:36, 10.01it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  41%|████      | 1082/2645 [01:45<02:36, 10.01it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  41%|████      | 1082/2645 [01:45<02:36, 10.01it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  41%|████      | 1084/2645 [01:45<02:35, 10.05it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  41%|████      | 1084/2645 [01:45<02:35, 10.05it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  41%|████      | 1084/2645 [01:45<02:35, 10.05it/s, training_loss=0.421]\u001b[A\n",
      "Epoch 1:  41%|████      | 1086/2645 [01:45<02:34, 10.06it/s, training_loss=0.421]\u001b[A\n",
      "Epoch 1:  41%|████      | 1086/2645 [01:46<02:34, 10.06it/s, training_loss=0.310]\u001b[A\n",
      "Epoch 1:  41%|████      | 1086/2645 [01:46<02:34, 10.06it/s, training_loss=0.023]\u001b[A\n",
      "Epoch 1:  41%|████      | 1088/2645 [01:46<02:33, 10.11it/s, training_loss=0.023]\u001b[A\n",
      "Epoch 1:  41%|████      | 1088/2645 [01:46<02:33, 10.11it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  41%|████      | 1088/2645 [01:46<02:33, 10.11it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  41%|████      | 1090/2645 [01:46<02:34, 10.07it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  41%|████      | 1090/2645 [01:46<02:34, 10.07it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  41%|████      | 1090/2645 [01:46<02:34, 10.07it/s, training_loss=0.420]\u001b[A\n",
      "Epoch 1:  41%|████▏     | 1092/2645 [01:46<02:34, 10.05it/s, training_loss=0.420]\u001b[A\n",
      "Epoch 1:  41%|████▏     | 1092/2645 [01:46<02:34, 10.05it/s, training_loss=0.642]\u001b[A\n",
      "Epoch 1:  41%|████▏     | 1092/2645 [01:46<02:34, 10.05it/s, training_loss=0.186]\u001b[A\n",
      "Epoch 1:  41%|████▏     | 1094/2645 [01:46<02:34, 10.07it/s, training_loss=0.186]\u001b[A\n",
      "Epoch 1:  41%|████▏     | 1094/2645 [01:46<02:34, 10.07it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  41%|████▏     | 1094/2645 [01:46<02:34, 10.07it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  41%|████▏     | 1096/2645 [01:46<02:33, 10.12it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  41%|████▏     | 1096/2645 [01:47<02:33, 10.12it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  41%|████▏     | 1096/2645 [01:47<02:33, 10.12it/s, training_loss=0.559]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1098/2645 [01:47<02:32, 10.14it/s, training_loss=0.559]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1098/2645 [01:47<02:32, 10.14it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1098/2645 [01:47<02:32, 10.14it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1100/2645 [01:47<02:31, 10.21it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1100/2645 [01:47<02:31, 10.21it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1100/2645 [01:47<02:31, 10.21it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1102/2645 [01:47<02:29, 10.29it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1102/2645 [01:47<02:29, 10.29it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1102/2645 [01:47<02:29, 10.29it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1104/2645 [01:47<02:30, 10.24it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1104/2645 [01:47<02:30, 10.24it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1104/2645 [01:47<02:30, 10.24it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1106/2645 [01:47<02:31, 10.15it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1106/2645 [01:48<02:31, 10.15it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1106/2645 [01:48<02:31, 10.15it/s, training_loss=0.674]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1108/2645 [01:48<02:31, 10.17it/s, training_loss=0.674]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1108/2645 [01:48<02:31, 10.17it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1108/2645 [01:48<02:31, 10.17it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1110/2645 [01:48<02:30, 10.22it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1110/2645 [01:48<02:30, 10.22it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1110/2645 [01:48<02:30, 10.22it/s, training_loss=0.298]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1112/2645 [01:48<02:32, 10.08it/s, training_loss=0.298]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1112/2645 [01:48<02:32, 10.08it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1112/2645 [01:48<02:32, 10.08it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1114/2645 [01:48<02:31, 10.09it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1114/2645 [01:48<02:31, 10.09it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1114/2645 [01:48<02:31, 10.09it/s, training_loss=0.073]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1116/2645 [01:48<02:30, 10.17it/s, training_loss=0.073]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1116/2645 [01:49<02:30, 10.17it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1116/2645 [01:49<02:30, 10.17it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1118/2645 [01:49<02:29, 10.24it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1118/2645 [01:49<02:29, 10.24it/s, training_loss=0.382]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1118/2645 [01:49<02:29, 10.24it/s, training_loss=0.410]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1120/2645 [01:49<02:29, 10.19it/s, training_loss=0.410]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1120/2645 [01:49<02:29, 10.19it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1120/2645 [01:49<02:29, 10.19it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1122/2645 [01:49<02:32,  9.96it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1122/2645 [01:49<02:32,  9.96it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1122/2645 [01:49<02:32,  9.96it/s, training_loss=0.319]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1124/2645 [01:49<02:31, 10.02it/s, training_loss=0.319]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1124/2645 [01:49<02:31, 10.02it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1124/2645 [01:49<02:31, 10.02it/s, training_loss=0.159]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1126/2645 [01:49<02:29, 10.14it/s, training_loss=0.159]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1126/2645 [01:50<02:29, 10.14it/s, training_loss=0.023]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1126/2645 [01:50<02:29, 10.14it/s, training_loss=0.246]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1128/2645 [01:50<02:31,  9.99it/s, training_loss=0.246]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1128/2645 [01:50<02:31,  9.99it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1128/2645 [01:50<02:31,  9.99it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1130/2645 [01:50<02:30, 10.05it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1130/2645 [01:50<02:30, 10.05it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1130/2645 [01:50<02:30, 10.05it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1132/2645 [01:50<02:31,  9.98it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1132/2645 [01:50<02:31,  9.98it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1133/2645 [01:50<02:31,  9.98it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1133/2645 [01:50<02:31,  9.98it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1134/2645 [01:50<02:31,  9.96it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1134/2645 [01:50<02:31,  9.96it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1135/2645 [01:50<02:31,  9.95it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1135/2645 [01:50<02:31,  9.95it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1136/2645 [01:50<02:32,  9.88it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1136/2645 [01:51<02:32,  9.88it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1136/2645 [01:51<02:32,  9.88it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1138/2645 [01:51<02:30,  9.99it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1138/2645 [01:51<02:30,  9.99it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1138/2645 [01:51<02:30,  9.99it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1140/2645 [01:51<02:29, 10.07it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1140/2645 [01:51<02:29, 10.07it/s, training_loss=1.193]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1140/2645 [01:51<02:29, 10.07it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1142/2645 [01:51<02:29, 10.02it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1142/2645 [01:51<02:29, 10.02it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1142/2645 [01:51<02:29, 10.02it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1144/2645 [01:51<02:30,  9.96it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1144/2645 [01:51<02:30,  9.96it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1144/2645 [01:51<02:30,  9.96it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1146/2645 [01:51<02:29, 10.05it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1146/2645 [01:52<02:29, 10.05it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1146/2645 [01:52<02:29, 10.05it/s, training_loss=0.422]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1148/2645 [01:52<02:28, 10.06it/s, training_loss=0.422]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1148/2645 [01:52<02:28, 10.06it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1148/2645 [01:52<02:28, 10.06it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1150/2645 [01:52<02:29, 10.02it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1150/2645 [01:52<02:29, 10.02it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1150/2645 [01:52<02:29, 10.02it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  44%|████▎     | 1152/2645 [01:52<02:28, 10.04it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  44%|████▎     | 1152/2645 [01:52<02:28, 10.04it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  44%|████▎     | 1152/2645 [01:52<02:28, 10.04it/s, training_loss=1.347]\u001b[A\n",
      "Epoch 1:  44%|████▎     | 1154/2645 [01:52<02:28, 10.04it/s, training_loss=1.347]\u001b[A\n",
      "Epoch 1:  44%|████▎     | 1154/2645 [01:52<02:28, 10.04it/s, training_loss=0.890]\u001b[A\n",
      "Epoch 1:  44%|████▎     | 1154/2645 [01:52<02:28, 10.04it/s, training_loss=0.560]\u001b[A\n",
      "Epoch 1:  44%|████▎     | 1156/2645 [01:52<02:28, 10.04it/s, training_loss=0.560]\u001b[A\n",
      "Epoch 1:  44%|████▎     | 1156/2645 [01:53<02:28, 10.04it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  44%|████▎     | 1156/2645 [01:53<02:28, 10.04it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 1158/2645 [01:53<02:28, 10.03it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 1158/2645 [01:53<02:28, 10.03it/s, training_loss=0.248]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 1158/2645 [01:53<02:28, 10.03it/s, training_loss=0.874]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 1160/2645 [01:53<02:28,  9.99it/s, training_loss=0.874]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 1160/2645 [01:53<02:28,  9.99it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 1160/2645 [01:53<02:28,  9.99it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 1162/2645 [01:53<02:27, 10.07it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 1162/2645 [01:53<02:27, 10.07it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 1162/2645 [01:53<02:27, 10.07it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 1164/2645 [01:53<02:26, 10.12it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 1164/2645 [01:53<02:26, 10.12it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 1164/2645 [01:53<02:26, 10.12it/s, training_loss=0.054]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 1166/2645 [01:53<02:26, 10.09it/s, training_loss=0.054]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 1166/2645 [01:54<02:26, 10.09it/s, training_loss=0.632]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 1166/2645 [01:54<02:26, 10.09it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 1168/2645 [01:54<02:28,  9.96it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 1168/2645 [01:54<02:28,  9.96it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 1168/2645 [01:54<02:28,  9.96it/s, training_loss=0.160]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 1170/2645 [01:54<02:27, 10.01it/s, training_loss=0.160]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 1170/2645 [01:54<02:27, 10.01it/s, training_loss=0.796]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 1170/2645 [01:54<02:27, 10.01it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 1172/2645 [01:54<02:28,  9.94it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 1172/2645 [01:54<02:28,  9.94it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 1173/2645 [01:54<02:28,  9.88it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 1173/2645 [01:54<02:28,  9.88it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 1173/2645 [01:54<02:28,  9.88it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 1175/2645 [01:54<02:26, 10.04it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 1175/2645 [01:54<02:26, 10.04it/s, training_loss=0.506]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 1175/2645 [01:55<02:26, 10.04it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 1177/2645 [01:55<02:26, 10.03it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 1177/2645 [01:55<02:26, 10.03it/s, training_loss=1.228]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 1177/2645 [01:55<02:26, 10.03it/s, training_loss=0.037]\u001b[A\n",
      "Epoch 1:  45%|████▍     | 1179/2645 [01:55<02:25, 10.07it/s, training_loss=0.037]\u001b[A\n",
      "Epoch 1:  45%|████▍     | 1179/2645 [01:55<02:25, 10.07it/s, training_loss=1.347]\u001b[A\n",
      "Epoch 1:  45%|████▍     | 1179/2645 [01:55<02:25, 10.07it/s, training_loss=0.609]\u001b[A\n",
      "Epoch 1:  45%|████▍     | 1181/2645 [01:55<02:25, 10.07it/s, training_loss=0.609]\u001b[A\n",
      "Epoch 1:  45%|████▍     | 1181/2645 [01:55<02:25, 10.07it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  45%|████▍     | 1181/2645 [01:55<02:25, 10.07it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  45%|████▍     | 1183/2645 [01:55<02:24, 10.12it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  45%|████▍     | 1183/2645 [01:55<02:24, 10.12it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  45%|████▍     | 1183/2645 [01:55<02:24, 10.12it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  45%|████▍     | 1185/2645 [01:55<02:23, 10.16it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  45%|████▍     | 1185/2645 [01:55<02:23, 10.16it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  45%|████▍     | 1185/2645 [01:56<02:23, 10.16it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  45%|████▍     | 1187/2645 [01:56<02:23, 10.15it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  45%|████▍     | 1187/2645 [01:56<02:23, 10.15it/s, training_loss=0.149]\u001b[A\n",
      "Epoch 1:  45%|████▍     | 1187/2645 [01:56<02:23, 10.15it/s, training_loss=0.462]\u001b[A\n",
      "Epoch 1:  45%|████▍     | 1189/2645 [01:56<02:23, 10.11it/s, training_loss=0.462]\u001b[A\n",
      "Epoch 1:  45%|████▍     | 1189/2645 [01:56<02:23, 10.11it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  45%|████▍     | 1189/2645 [01:56<02:23, 10.11it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  45%|████▌     | 1191/2645 [01:56<02:24, 10.09it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  45%|████▌     | 1191/2645 [01:56<02:24, 10.09it/s, training_loss=0.309]\u001b[A\n",
      "Epoch 1:  45%|████▌     | 1191/2645 [01:56<02:24, 10.09it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  45%|████▌     | 1193/2645 [01:56<02:25,  9.97it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  45%|████▌     | 1193/2645 [01:56<02:25,  9.97it/s, training_loss=0.014]\u001b[A\n",
      "Epoch 1:  45%|████▌     | 1194/2645 [01:56<02:25,  9.96it/s, training_loss=0.014]\u001b[A\n",
      "Epoch 1:  45%|████▌     | 1194/2645 [01:56<02:25,  9.96it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  45%|████▌     | 1195/2645 [01:56<02:29,  9.72it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  45%|████▌     | 1195/2645 [01:56<02:29,  9.72it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  45%|████▌     | 1195/2645 [01:57<02:29,  9.72it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  45%|████▌     | 1197/2645 [01:57<02:25,  9.92it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  45%|████▌     | 1197/2645 [01:57<02:25,  9.92it/s, training_loss=0.527]\u001b[A\n",
      "Epoch 1:  45%|████▌     | 1197/2645 [01:57<02:25,  9.92it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  45%|████▌     | 1199/2645 [01:57<02:24,  9.98it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  45%|████▌     | 1199/2645 [01:57<02:24,  9.98it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  45%|████▌     | 1200/2645 [01:57<02:25,  9.95it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  45%|████▌     | 1200/2645 [01:57<02:25,  9.95it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  45%|████▌     | 1200/2645 [01:57<02:25,  9.95it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  45%|████▌     | 1202/2645 [01:57<02:23, 10.02it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  45%|████▌     | 1202/2645 [01:57<02:23, 10.02it/s, training_loss=0.080]\u001b[A\n",
      "Epoch 1:  45%|████▌     | 1202/2645 [01:57<02:23, 10.02it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 1204/2645 [01:57<02:22, 10.08it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 1204/2645 [01:57<02:22, 10.08it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 1204/2645 [01:57<02:22, 10.08it/s, training_loss=0.698]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 1206/2645 [01:57<02:23, 10.05it/s, training_loss=0.698]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 1206/2645 [01:58<02:23, 10.05it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 1206/2645 [01:58<02:23, 10.05it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 1208/2645 [01:58<02:24,  9.97it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 1208/2645 [01:58<02:24,  9.97it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 1208/2645 [01:58<02:24,  9.97it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 1210/2645 [01:58<02:22, 10.04it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 1210/2645 [01:58<02:22, 10.04it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 1210/2645 [01:58<02:22, 10.04it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 1212/2645 [01:58<02:22, 10.05it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 1212/2645 [01:58<02:22, 10.05it/s, training_loss=0.026]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 1212/2645 [01:58<02:22, 10.05it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 1214/2645 [01:58<02:22, 10.03it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 1214/2645 [01:58<02:22, 10.03it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 1214/2645 [01:58<02:22, 10.03it/s, training_loss=0.069]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 1216/2645 [01:58<02:23,  9.98it/s, training_loss=0.069]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 1216/2645 [01:59<02:23,  9.98it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 1217/2645 [01:59<02:23,  9.98it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 1217/2645 [01:59<02:23,  9.98it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 1218/2645 [01:59<02:23,  9.93it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 1218/2645 [01:59<02:23,  9.93it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 1218/2645 [01:59<02:23,  9.93it/s, training_loss=0.110]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 1220/2645 [01:59<02:22,  9.97it/s, training_loss=0.110]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 1220/2645 [01:59<02:22,  9.97it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 1221/2645 [01:59<02:24,  9.89it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 1221/2645 [01:59<02:24,  9.89it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 1221/2645 [01:59<02:24,  9.89it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 1223/2645 [01:59<02:22,  9.98it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 1223/2645 [01:59<02:22,  9.98it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 1223/2645 [01:59<02:22,  9.98it/s, training_loss=0.783]\u001b[A\n",
      "Epoch 1:  46%|████▋     | 1225/2645 [01:59<02:22,  9.99it/s, training_loss=0.783]\u001b[A\n",
      "Epoch 1:  46%|████▋     | 1225/2645 [01:59<02:22,  9.99it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  46%|████▋     | 1225/2645 [02:00<02:22,  9.99it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  46%|████▋     | 1227/2645 [02:00<02:21, 10.03it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  46%|████▋     | 1227/2645 [02:00<02:21, 10.03it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  46%|████▋     | 1227/2645 [02:00<02:21, 10.03it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  46%|████▋     | 1229/2645 [02:00<02:22,  9.97it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  46%|████▋     | 1229/2645 [02:00<02:22,  9.97it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  46%|████▋     | 1229/2645 [02:00<02:22,  9.97it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1231/2645 [02:00<02:20, 10.08it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1231/2645 [02:00<02:20, 10.08it/s, training_loss=0.013]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1231/2645 [02:00<02:20, 10.08it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1233/2645 [02:00<02:20, 10.07it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1233/2645 [02:00<02:20, 10.07it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1233/2645 [02:00<02:20, 10.07it/s, training_loss=0.528]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1235/2645 [02:00<02:23,  9.84it/s, training_loss=0.528]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1235/2645 [02:00<02:23,  9.84it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1235/2645 [02:01<02:23,  9.84it/s, training_loss=0.014]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1237/2645 [02:01<02:21,  9.95it/s, training_loss=0.014]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1237/2645 [02:01<02:21,  9.95it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1237/2645 [02:01<02:21,  9.95it/s, training_loss=0.014]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1239/2645 [02:01<02:20,  9.97it/s, training_loss=0.014]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1239/2645 [02:01<02:20,  9.97it/s, training_loss=0.700]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1240/2645 [02:01<02:21,  9.95it/s, training_loss=0.700]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1240/2645 [02:01<02:21,  9.95it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1240/2645 [02:01<02:21,  9.95it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1242/2645 [02:01<02:19, 10.04it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1242/2645 [02:01<02:19, 10.04it/s, training_loss=0.204]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1242/2645 [02:01<02:19, 10.04it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1244/2645 [02:01<02:18, 10.13it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1244/2645 [02:01<02:18, 10.13it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1244/2645 [02:01<02:18, 10.13it/s, training_loss=0.643]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1246/2645 [02:01<02:18, 10.13it/s, training_loss=0.643]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1246/2645 [02:02<02:18, 10.13it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1246/2645 [02:02<02:18, 10.13it/s, training_loss=0.072]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1248/2645 [02:02<02:16, 10.20it/s, training_loss=0.072]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1248/2645 [02:02<02:16, 10.20it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1248/2645 [02:02<02:16, 10.20it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1250/2645 [02:02<02:15, 10.26it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1250/2645 [02:02<02:15, 10.26it/s, training_loss=0.015]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1250/2645 [02:02<02:15, 10.26it/s, training_loss=0.718]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1252/2645 [02:02<02:16, 10.23it/s, training_loss=0.718]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1252/2645 [02:02<02:16, 10.23it/s, training_loss=0.226]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1252/2645 [02:02<02:16, 10.23it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1254/2645 [02:02<02:16, 10.17it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1254/2645 [02:02<02:16, 10.17it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1254/2645 [02:02<02:16, 10.17it/s, training_loss=0.328]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1256/2645 [02:02<02:16, 10.18it/s, training_loss=0.328]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1256/2645 [02:02<02:16, 10.18it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1256/2645 [02:03<02:16, 10.18it/s, training_loss=0.107]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1258/2645 [02:03<02:14, 10.28it/s, training_loss=0.107]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1258/2645 [02:03<02:14, 10.28it/s, training_loss=0.245]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1258/2645 [02:03<02:14, 10.28it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1260/2645 [02:03<02:13, 10.37it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1260/2645 [02:03<02:13, 10.37it/s, training_loss=0.022]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1260/2645 [02:03<02:13, 10.37it/s, training_loss=0.626]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1262/2645 [02:03<02:15, 10.17it/s, training_loss=0.626]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1262/2645 [02:03<02:15, 10.17it/s, training_loss=0.274]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1262/2645 [02:03<02:15, 10.17it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1264/2645 [02:03<02:15, 10.22it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1264/2645 [02:03<02:15, 10.22it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1264/2645 [02:03<02:15, 10.22it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1266/2645 [02:03<02:13, 10.31it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1266/2645 [02:03<02:13, 10.31it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1266/2645 [02:04<02:13, 10.31it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1268/2645 [02:04<02:13, 10.34it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1268/2645 [02:04<02:13, 10.34it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1268/2645 [02:04<02:13, 10.34it/s, training_loss=0.695]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1270/2645 [02:04<02:14, 10.26it/s, training_loss=0.695]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1270/2645 [02:04<02:14, 10.26it/s, training_loss=0.536]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1270/2645 [02:04<02:14, 10.26it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1272/2645 [02:04<02:13, 10.28it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1272/2645 [02:04<02:13, 10.28it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1272/2645 [02:04<02:13, 10.28it/s, training_loss=0.606]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1274/2645 [02:04<02:13, 10.29it/s, training_loss=0.606]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1274/2645 [02:04<02:13, 10.29it/s, training_loss=0.033]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1274/2645 [02:04<02:13, 10.29it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1276/2645 [02:04<02:13, 10.29it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1276/2645 [02:04<02:13, 10.29it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1276/2645 [02:05<02:13, 10.29it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1278/2645 [02:05<02:13, 10.25it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1278/2645 [02:05<02:13, 10.25it/s, training_loss=0.815]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1278/2645 [02:05<02:13, 10.25it/s, training_loss=0.181]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1280/2645 [02:05<02:14, 10.19it/s, training_loss=0.181]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1280/2645 [02:05<02:14, 10.19it/s, training_loss=0.552]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1280/2645 [02:05<02:14, 10.19it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1282/2645 [02:05<02:14, 10.14it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1282/2645 [02:05<02:14, 10.14it/s, training_loss=0.598]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1282/2645 [02:05<02:14, 10.14it/s, training_loss=0.490]\u001b[A\n",
      "Epoch 1:  49%|████▊     | 1284/2645 [02:05<02:14, 10.13it/s, training_loss=0.490]\u001b[A\n",
      "Epoch 1:  49%|████▊     | 1284/2645 [02:05<02:14, 10.13it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  49%|████▊     | 1284/2645 [02:05<02:14, 10.13it/s, training_loss=0.271]\u001b[A\n",
      "Epoch 1:  49%|████▊     | 1286/2645 [02:05<02:14, 10.12it/s, training_loss=0.271]\u001b[A\n",
      "Epoch 1:  49%|████▊     | 1286/2645 [02:05<02:14, 10.12it/s, training_loss=0.339]\u001b[A\n",
      "Epoch 1:  49%|████▊     | 1286/2645 [02:06<02:14, 10.12it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  49%|████▊     | 1288/2645 [02:06<02:13, 10.13it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  49%|████▊     | 1288/2645 [02:06<02:13, 10.13it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  49%|████▊     | 1288/2645 [02:06<02:13, 10.13it/s, training_loss=0.385]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 1290/2645 [02:06<02:14, 10.10it/s, training_loss=0.385]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 1290/2645 [02:06<02:14, 10.10it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 1290/2645 [02:06<02:14, 10.10it/s, training_loss=0.029]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 1292/2645 [02:06<02:15,  9.98it/s, training_loss=0.029]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 1292/2645 [02:06<02:15,  9.98it/s, training_loss=0.015]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 1293/2645 [02:06<02:16,  9.93it/s, training_loss=0.015]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 1293/2645 [02:06<02:16,  9.93it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 1293/2645 [02:06<02:16,  9.93it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 1295/2645 [02:06<02:15,  9.96it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 1295/2645 [02:06<02:15,  9.96it/s, training_loss=0.598]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 1296/2645 [02:06<02:15,  9.94it/s, training_loss=0.598]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 1296/2645 [02:06<02:15,  9.94it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 1296/2645 [02:07<02:15,  9.94it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 1298/2645 [02:07<02:14, 10.03it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 1298/2645 [02:07<02:14, 10.03it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 1298/2645 [02:07<02:14, 10.03it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 1300/2645 [02:07<02:12, 10.13it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 1300/2645 [02:07<02:12, 10.13it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 1300/2645 [02:07<02:12, 10.13it/s, training_loss=0.396]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 1302/2645 [02:07<02:12, 10.16it/s, training_loss=0.396]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 1302/2645 [02:07<02:12, 10.16it/s, training_loss=0.060]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 1302/2645 [02:07<02:12, 10.16it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 1304/2645 [02:07<02:12, 10.09it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 1304/2645 [02:07<02:12, 10.09it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 1304/2645 [02:07<02:12, 10.09it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 1306/2645 [02:07<02:12, 10.12it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 1306/2645 [02:07<02:12, 10.12it/s, training_loss=0.377]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 1306/2645 [02:07<02:12, 10.12it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 1308/2645 [02:07<02:12, 10.12it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 1308/2645 [02:08<02:12, 10.12it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 1308/2645 [02:08<02:12, 10.12it/s, training_loss=0.715]\u001b[A\n",
      "Epoch 1:  50%|████▉     | 1310/2645 [02:08<02:11, 10.14it/s, training_loss=0.715]\u001b[A\n",
      "Epoch 1:  50%|████▉     | 1310/2645 [02:08<02:11, 10.14it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  50%|████▉     | 1310/2645 [02:08<02:11, 10.14it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  50%|████▉     | 1312/2645 [02:08<02:09, 10.29it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  50%|████▉     | 1312/2645 [02:08<02:09, 10.29it/s, training_loss=0.529]\u001b[A\n",
      "Epoch 1:  50%|████▉     | 1312/2645 [02:08<02:09, 10.29it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  50%|████▉     | 1314/2645 [02:08<02:10, 10.17it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  50%|████▉     | 1314/2645 [02:08<02:10, 10.17it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  50%|████▉     | 1314/2645 [02:08<02:10, 10.17it/s, training_loss=0.022]\u001b[A\n",
      "Epoch 1:  50%|████▉     | 1316/2645 [02:08<02:10, 10.22it/s, training_loss=0.022]\u001b[A\n",
      "Epoch 1:  50%|████▉     | 1316/2645 [02:08<02:10, 10.22it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  50%|████▉     | 1316/2645 [02:08<02:10, 10.22it/s, training_loss=0.506]\u001b[A\n",
      "Epoch 1:  50%|████▉     | 1318/2645 [02:08<02:09, 10.23it/s, training_loss=0.506]\u001b[A\n",
      "Epoch 1:  50%|████▉     | 1318/2645 [02:09<02:09, 10.23it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  50%|████▉     | 1318/2645 [02:09<02:09, 10.23it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  50%|████▉     | 1320/2645 [02:09<02:09, 10.25it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  50%|████▉     | 1320/2645 [02:09<02:09, 10.25it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  50%|████▉     | 1320/2645 [02:09<02:09, 10.25it/s, training_loss=0.242]\u001b[A\n",
      "Epoch 1:  50%|████▉     | 1322/2645 [02:09<02:10, 10.15it/s, training_loss=0.242]\u001b[A\n",
      "Epoch 1:  50%|████▉     | 1322/2645 [02:09<02:10, 10.15it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  50%|████▉     | 1322/2645 [02:09<02:10, 10.15it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  50%|█████     | 1324/2645 [02:09<02:11, 10.03it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  50%|█████     | 1324/2645 [02:09<02:11, 10.03it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  50%|█████     | 1324/2645 [02:09<02:11, 10.03it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  50%|█████     | 1326/2645 [02:09<02:10, 10.08it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  50%|█████     | 1326/2645 [02:09<02:10, 10.08it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  50%|█████     | 1326/2645 [02:09<02:10, 10.08it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  50%|█████     | 1328/2645 [02:09<02:10, 10.13it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  50%|█████     | 1328/2645 [02:10<02:10, 10.13it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  50%|█████     | 1328/2645 [02:10<02:10, 10.13it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  50%|█████     | 1330/2645 [02:10<02:10, 10.08it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  50%|█████     | 1330/2645 [02:10<02:10, 10.08it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  50%|█████     | 1330/2645 [02:10<02:10, 10.08it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  50%|█████     | 1332/2645 [02:10<02:11, 10.01it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  50%|█████     | 1332/2645 [02:10<02:11, 10.01it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  50%|█████     | 1332/2645 [02:10<02:11, 10.01it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  50%|█████     | 1334/2645 [02:10<02:10, 10.02it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  50%|█████     | 1334/2645 [02:10<02:10, 10.02it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  50%|█████     | 1334/2645 [02:10<02:10, 10.02it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  51%|█████     | 1336/2645 [02:10<02:11,  9.98it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  51%|█████     | 1336/2645 [02:10<02:11,  9.98it/s, training_loss=0.197]\u001b[A\n",
      "Epoch 1:  51%|█████     | 1336/2645 [02:10<02:11,  9.98it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  51%|█████     | 1338/2645 [02:10<02:09, 10.07it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  51%|█████     | 1338/2645 [02:11<02:09, 10.07it/s, training_loss=0.807]\u001b[A\n",
      "Epoch 1:  51%|█████     | 1338/2645 [02:11<02:09, 10.07it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  51%|█████     | 1340/2645 [02:11<02:10, 10.04it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  51%|█████     | 1340/2645 [02:11<02:10, 10.04it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  51%|█████     | 1340/2645 [02:11<02:10, 10.04it/s, training_loss=0.618]\u001b[A\n",
      "Epoch 1:  51%|█████     | 1342/2645 [02:11<02:09, 10.07it/s, training_loss=0.618]\u001b[A\n",
      "Epoch 1:  51%|█████     | 1342/2645 [02:11<02:09, 10.07it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  51%|█████     | 1342/2645 [02:11<02:09, 10.07it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  51%|█████     | 1344/2645 [02:11<02:07, 10.20it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  51%|█████     | 1344/2645 [02:11<02:07, 10.20it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  51%|█████     | 1344/2645 [02:11<02:07, 10.20it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  51%|█████     | 1346/2645 [02:11<02:06, 10.29it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  51%|█████     | 1346/2645 [02:11<02:06, 10.29it/s, training_loss=0.250]\u001b[A\n",
      "Epoch 1:  51%|█████     | 1346/2645 [02:11<02:06, 10.29it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  51%|█████     | 1348/2645 [02:11<02:05, 10.32it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  51%|█████     | 1348/2645 [02:12<02:05, 10.32it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  51%|█████     | 1348/2645 [02:12<02:05, 10.32it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  51%|█████     | 1350/2645 [02:12<02:04, 10.39it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  51%|█████     | 1350/2645 [02:12<02:04, 10.39it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  51%|█████     | 1350/2645 [02:12<02:04, 10.39it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  51%|█████     | 1352/2645 [02:12<02:03, 10.46it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  51%|█████     | 1352/2645 [02:12<02:03, 10.46it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  51%|█████     | 1352/2645 [02:12<02:03, 10.46it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  51%|█████     | 1354/2645 [02:12<02:03, 10.49it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  51%|█████     | 1354/2645 [02:12<02:03, 10.49it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  51%|█████     | 1354/2645 [02:12<02:03, 10.49it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  51%|█████▏    | 1356/2645 [02:12<02:02, 10.53it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  51%|█████▏    | 1356/2645 [02:12<02:02, 10.53it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  51%|█████▏    | 1356/2645 [02:12<02:02, 10.53it/s, training_loss=0.034]\u001b[A\n",
      "Epoch 1:  51%|█████▏    | 1358/2645 [02:12<02:02, 10.47it/s, training_loss=0.034]\u001b[A\n",
      "Epoch 1:  51%|█████▏    | 1358/2645 [02:12<02:02, 10.47it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  51%|█████▏    | 1358/2645 [02:13<02:02, 10.47it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  51%|█████▏    | 1360/2645 [02:13<02:02, 10.49it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  51%|█████▏    | 1360/2645 [02:13<02:02, 10.49it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  51%|█████▏    | 1360/2645 [02:13<02:02, 10.49it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  51%|█████▏    | 1362/2645 [02:13<02:02, 10.50it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  51%|█████▏    | 1362/2645 [02:13<02:02, 10.50it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  51%|█████▏    | 1362/2645 [02:13<02:02, 10.50it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1364/2645 [02:13<02:02, 10.49it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1364/2645 [02:13<02:02, 10.49it/s, training_loss=1.215]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1364/2645 [02:13<02:02, 10.49it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1366/2645 [02:13<02:02, 10.42it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1366/2645 [02:13<02:02, 10.42it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1366/2645 [02:13<02:02, 10.42it/s, training_loss=0.810]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1368/2645 [02:13<02:03, 10.36it/s, training_loss=0.810]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1368/2645 [02:13<02:03, 10.36it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1368/2645 [02:14<02:03, 10.36it/s, training_loss=0.028]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1370/2645 [02:14<02:02, 10.38it/s, training_loss=0.028]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1370/2645 [02:14<02:02, 10.38it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1370/2645 [02:14<02:02, 10.38it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1372/2645 [02:14<02:02, 10.40it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1372/2645 [02:14<02:02, 10.40it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1372/2645 [02:14<02:02, 10.40it/s, training_loss=0.060]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1374/2645 [02:14<02:02, 10.36it/s, training_loss=0.060]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1374/2645 [02:14<02:02, 10.36it/s, training_loss=1.121]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1374/2645 [02:14<02:02, 10.36it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1376/2645 [02:14<02:02, 10.40it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1376/2645 [02:14<02:02, 10.40it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1376/2645 [02:14<02:02, 10.40it/s, training_loss=0.107]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1378/2645 [02:14<02:03, 10.27it/s, training_loss=0.107]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1378/2645 [02:14<02:03, 10.27it/s, training_loss=0.512]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1378/2645 [02:15<02:03, 10.27it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1380/2645 [02:15<02:04, 10.17it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1380/2645 [02:15<02:04, 10.17it/s, training_loss=0.016]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1380/2645 [02:15<02:04, 10.17it/s, training_loss=0.858]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1382/2645 [02:15<02:03, 10.20it/s, training_loss=0.858]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1382/2645 [02:15<02:03, 10.20it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1382/2645 [02:15<02:03, 10.20it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1384/2645 [02:15<02:02, 10.32it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1384/2645 [02:15<02:02, 10.32it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1384/2645 [02:15<02:02, 10.32it/s, training_loss=0.826]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1386/2645 [02:15<02:03, 10.18it/s, training_loss=0.826]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1386/2645 [02:15<02:03, 10.18it/s, training_loss=0.011]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1386/2645 [02:15<02:03, 10.18it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1388/2645 [02:15<02:02, 10.27it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1388/2645 [02:15<02:02, 10.27it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1388/2645 [02:15<02:02, 10.27it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1390/2645 [02:15<02:01, 10.36it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1390/2645 [02:16<02:01, 10.36it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1390/2645 [02:16<02:01, 10.36it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1392/2645 [02:16<02:00, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1392/2645 [02:16<02:00, 10.43it/s, training_loss=0.950]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1392/2645 [02:16<02:00, 10.43it/s, training_loss=0.325]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1394/2645 [02:16<02:00, 10.42it/s, training_loss=0.325]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1394/2645 [02:16<02:00, 10.42it/s, training_loss=0.102]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1394/2645 [02:16<02:00, 10.42it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1396/2645 [02:16<01:59, 10.43it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1396/2645 [02:16<01:59, 10.43it/s, training_loss=0.083]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1396/2645 [02:16<01:59, 10.43it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1398/2645 [02:16<01:59, 10.45it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1398/2645 [02:16<01:59, 10.45it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1398/2645 [02:16<01:59, 10.45it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1400/2645 [02:16<01:58, 10.47it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1400/2645 [02:17<01:58, 10.47it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1400/2645 [02:17<01:58, 10.47it/s, training_loss=0.836]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1402/2645 [02:17<02:00, 10.35it/s, training_loss=0.836]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1402/2645 [02:17<02:00, 10.35it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1402/2645 [02:17<02:00, 10.35it/s, training_loss=0.072]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1404/2645 [02:17<01:59, 10.40it/s, training_loss=0.072]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1404/2645 [02:17<01:59, 10.40it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1404/2645 [02:17<01:59, 10.40it/s, training_loss=0.028]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1406/2645 [02:17<01:58, 10.43it/s, training_loss=0.028]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1406/2645 [02:17<01:58, 10.43it/s, training_loss=0.420]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1406/2645 [02:17<01:58, 10.43it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1408/2645 [02:17<01:58, 10.44it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1408/2645 [02:17<01:58, 10.44it/s, training_loss=0.291]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1408/2645 [02:17<01:58, 10.44it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1410/2645 [02:17<01:58, 10.43it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1410/2645 [02:17<01:58, 10.43it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1410/2645 [02:18<01:58, 10.43it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1412/2645 [02:18<01:57, 10.49it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1412/2645 [02:18<01:57, 10.49it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1412/2645 [02:18<01:57, 10.49it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1414/2645 [02:18<01:57, 10.51it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1414/2645 [02:18<01:57, 10.51it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1414/2645 [02:18<01:57, 10.51it/s, training_loss=0.019]\u001b[A\n",
      "Epoch 1:  54%|█████▎    | 1416/2645 [02:18<01:56, 10.52it/s, training_loss=0.019]\u001b[A\n",
      "Epoch 1:  54%|█████▎    | 1416/2645 [02:18<01:56, 10.52it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  54%|█████▎    | 1416/2645 [02:18<01:56, 10.52it/s, training_loss=0.070]\u001b[A\n",
      "Epoch 1:  54%|█████▎    | 1418/2645 [02:18<01:56, 10.53it/s, training_loss=0.070]\u001b[A\n",
      "Epoch 1:  54%|█████▎    | 1418/2645 [02:18<01:56, 10.53it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  54%|█████▎    | 1418/2645 [02:18<01:56, 10.53it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  54%|█████▎    | 1420/2645 [02:18<01:56, 10.51it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  54%|█████▎    | 1420/2645 [02:18<01:56, 10.51it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  54%|█████▎    | 1420/2645 [02:19<01:56, 10.51it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 1422/2645 [02:19<01:56, 10.54it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 1422/2645 [02:19<01:56, 10.54it/s, training_loss=0.035]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 1422/2645 [02:19<01:56, 10.54it/s, training_loss=0.043]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 1424/2645 [02:19<01:56, 10.50it/s, training_loss=0.043]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 1424/2645 [02:19<01:56, 10.50it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 1424/2645 [02:19<01:56, 10.50it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 1426/2645 [02:19<01:55, 10.53it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 1426/2645 [02:19<01:55, 10.53it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 1426/2645 [02:19<01:55, 10.53it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 1428/2645 [02:19<01:55, 10.55it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 1428/2645 [02:19<01:55, 10.55it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 1428/2645 [02:19<01:55, 10.55it/s, training_loss=0.033]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 1430/2645 [02:19<01:55, 10.53it/s, training_loss=0.033]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 1430/2645 [02:19<01:55, 10.53it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 1430/2645 [02:19<01:55, 10.53it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 1432/2645 [02:19<01:54, 10.56it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 1432/2645 [02:20<01:54, 10.56it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 1432/2645 [02:20<01:54, 10.56it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 1434/2645 [02:20<01:54, 10.58it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 1434/2645 [02:20<01:54, 10.58it/s, training_loss=0.199]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 1434/2645 [02:20<01:54, 10.58it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 1436/2645 [02:20<01:54, 10.55it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 1436/2645 [02:20<01:54, 10.55it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 1436/2645 [02:20<01:54, 10.55it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 1438/2645 [02:20<01:54, 10.58it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 1438/2645 [02:20<01:54, 10.58it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 1438/2645 [02:20<01:54, 10.58it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 1440/2645 [02:20<01:54, 10.54it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 1440/2645 [02:20<01:54, 10.54it/s, training_loss=0.482]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 1440/2645 [02:20<01:54, 10.54it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  55%|█████▍    | 1442/2645 [02:20<01:54, 10.49it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  55%|█████▍    | 1442/2645 [02:21<01:54, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  55%|█████▍    | 1442/2645 [02:21<01:54, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  55%|█████▍    | 1444/2645 [02:21<01:54, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  55%|█████▍    | 1444/2645 [02:21<01:54, 10.52it/s, training_loss=0.081]\u001b[A\n",
      "Epoch 1:  55%|█████▍    | 1444/2645 [02:21<01:54, 10.52it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  55%|█████▍    | 1446/2645 [02:21<01:54, 10.49it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  55%|█████▍    | 1446/2645 [02:21<01:54, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  55%|█████▍    | 1446/2645 [02:21<01:54, 10.49it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  55%|█████▍    | 1448/2645 [02:21<01:53, 10.53it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  55%|█████▍    | 1448/2645 [02:21<01:53, 10.53it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  55%|█████▍    | 1448/2645 [02:21<01:53, 10.53it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  55%|█████▍    | 1450/2645 [02:21<01:53, 10.56it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  55%|█████▍    | 1450/2645 [02:21<01:53, 10.56it/s, training_loss=0.833]\u001b[A\n",
      "Epoch 1:  55%|█████▍    | 1450/2645 [02:21<01:53, 10.56it/s, training_loss=0.044]\u001b[A\n",
      "Epoch 1:  55%|█████▍    | 1452/2645 [02:21<01:53, 10.51it/s, training_loss=0.044]\u001b[A\n",
      "Epoch 1:  55%|█████▍    | 1452/2645 [02:21<01:53, 10.51it/s, training_loss=0.872]\u001b[A\n",
      "Epoch 1:  55%|█████▍    | 1452/2645 [02:22<01:53, 10.51it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  55%|█████▍    | 1454/2645 [02:22<01:53, 10.53it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  55%|█████▍    | 1454/2645 [02:22<01:53, 10.53it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  55%|█████▍    | 1454/2645 [02:22<01:53, 10.53it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  55%|█████▌    | 1456/2645 [02:22<01:52, 10.57it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  55%|█████▌    | 1456/2645 [02:22<01:52, 10.57it/s, training_loss=0.917]\u001b[A\n",
      "Epoch 1:  55%|█████▌    | 1456/2645 [02:22<01:52, 10.57it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  55%|█████▌    | 1458/2645 [02:22<01:52, 10.54it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  55%|█████▌    | 1458/2645 [02:22<01:52, 10.54it/s, training_loss=0.301]\u001b[A\n",
      "Epoch 1:  55%|█████▌    | 1458/2645 [02:22<01:52, 10.54it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  55%|█████▌    | 1460/2645 [02:22<01:52, 10.54it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  55%|█████▌    | 1460/2645 [02:22<01:52, 10.54it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  55%|█████▌    | 1460/2645 [02:22<01:52, 10.54it/s, training_loss=0.332]\u001b[A\n",
      "Epoch 1:  55%|█████▌    | 1462/2645 [02:22<01:52, 10.51it/s, training_loss=0.332]\u001b[A\n",
      "Epoch 1:  55%|█████▌    | 1462/2645 [02:22<01:52, 10.51it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  55%|█████▌    | 1462/2645 [02:23<01:52, 10.51it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  55%|█████▌    | 1464/2645 [02:23<01:51, 10.56it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  55%|█████▌    | 1464/2645 [02:23<01:51, 10.56it/s, training_loss=0.197]\u001b[A\n",
      "Epoch 1:  55%|█████▌    | 1464/2645 [02:23<01:51, 10.56it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  55%|█████▌    | 1466/2645 [02:23<01:52, 10.51it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  55%|█████▌    | 1466/2645 [02:23<01:52, 10.51it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  55%|█████▌    | 1466/2645 [02:23<01:52, 10.51it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 1468/2645 [02:23<01:51, 10.52it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 1468/2645 [02:23<01:51, 10.52it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 1468/2645 [02:23<01:51, 10.52it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 1470/2645 [02:23<01:51, 10.54it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 1470/2645 [02:23<01:51, 10.54it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 1470/2645 [02:23<01:51, 10.54it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 1472/2645 [02:23<01:50, 10.57it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 1472/2645 [02:23<01:50, 10.57it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 1472/2645 [02:23<01:50, 10.57it/s, training_loss=0.219]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 1474/2645 [02:23<01:51, 10.55it/s, training_loss=0.219]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 1474/2645 [02:24<01:51, 10.55it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 1474/2645 [02:24<01:51, 10.55it/s, training_loss=0.098]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 1476/2645 [02:24<01:50, 10.54it/s, training_loss=0.098]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 1476/2645 [02:24<01:50, 10.54it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 1476/2645 [02:24<01:50, 10.54it/s, training_loss=0.721]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 1478/2645 [02:24<01:50, 10.52it/s, training_loss=0.721]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 1478/2645 [02:24<01:50, 10.52it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 1478/2645 [02:24<01:50, 10.52it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 1480/2645 [02:24<01:50, 10.56it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 1480/2645 [02:24<01:50, 10.56it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 1480/2645 [02:24<01:50, 10.56it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 1482/2645 [02:24<01:50, 10.55it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 1482/2645 [02:24<01:50, 10.55it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 1482/2645 [02:24<01:50, 10.55it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 1484/2645 [02:24<01:49, 10.56it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 1484/2645 [02:25<01:49, 10.56it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 1484/2645 [02:25<01:49, 10.56it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 1486/2645 [02:25<01:50, 10.51it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 1486/2645 [02:25<01:50, 10.51it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 1486/2645 [02:25<01:50, 10.51it/s, training_loss=0.699]\u001b[A\n",
      "Epoch 1:  56%|█████▋    | 1488/2645 [02:25<01:49, 10.53it/s, training_loss=0.699]\u001b[A\n",
      "Epoch 1:  56%|█████▋    | 1488/2645 [02:25<01:49, 10.53it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  56%|█████▋    | 1488/2645 [02:25<01:49, 10.53it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  56%|█████▋    | 1490/2645 [02:25<01:49, 10.56it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  56%|█████▋    | 1490/2645 [02:25<01:49, 10.56it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  56%|█████▋    | 1490/2645 [02:25<01:49, 10.56it/s, training_loss=0.088]\u001b[A\n",
      "Epoch 1:  56%|█████▋    | 1492/2645 [02:25<01:49, 10.53it/s, training_loss=0.088]\u001b[A\n",
      "Epoch 1:  56%|█████▋    | 1492/2645 [02:25<01:49, 10.53it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  56%|█████▋    | 1492/2645 [02:25<01:49, 10.53it/s, training_loss=0.384]\u001b[A\n",
      "Epoch 1:  56%|█████▋    | 1494/2645 [02:25<01:49, 10.47it/s, training_loss=0.384]\u001b[A\n",
      "Epoch 1:  56%|█████▋    | 1494/2645 [02:25<01:49, 10.47it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  56%|█████▋    | 1494/2645 [02:26<01:49, 10.47it/s, training_loss=0.547]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 1496/2645 [02:26<01:50, 10.44it/s, training_loss=0.547]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 1496/2645 [02:26<01:50, 10.44it/s, training_loss=0.707]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 1496/2645 [02:26<01:50, 10.44it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 1498/2645 [02:26<01:49, 10.45it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 1498/2645 [02:26<01:49, 10.45it/s, training_loss=0.018]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 1498/2645 [02:26<01:49, 10.45it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 1500/2645 [02:26<01:49, 10.48it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 1500/2645 [02:26<01:49, 10.48it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 1500/2645 [02:26<01:49, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 1502/2645 [02:26<01:48, 10.53it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 1502/2645 [02:26<01:48, 10.53it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 1502/2645 [02:26<01:48, 10.53it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 1504/2645 [02:26<01:48, 10.51it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 1504/2645 [02:26<01:48, 10.51it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 1504/2645 [02:27<01:48, 10.51it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 1506/2645 [02:27<01:48, 10.51it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 1506/2645 [02:27<01:48, 10.51it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 1506/2645 [02:27<01:48, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 1508/2645 [02:27<01:47, 10.54it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 1508/2645 [02:27<01:47, 10.54it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 1508/2645 [02:27<01:47, 10.54it/s, training_loss=0.761]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 1510/2645 [02:27<01:47, 10.52it/s, training_loss=0.761]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 1510/2645 [02:27<01:47, 10.52it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 1510/2645 [02:27<01:47, 10.52it/s, training_loss=0.037]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 1512/2645 [02:27<01:47, 10.53it/s, training_loss=0.037]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 1512/2645 [02:27<01:47, 10.53it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 1512/2645 [02:27<01:47, 10.53it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 1514/2645 [02:27<01:47, 10.55it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 1514/2645 [02:27<01:47, 10.55it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 1514/2645 [02:27<01:47, 10.55it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 1516/2645 [02:27<01:46, 10.58it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 1516/2645 [02:28<01:46, 10.58it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 1516/2645 [02:28<01:46, 10.58it/s, training_loss=0.453]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 1518/2645 [02:28<01:47, 10.52it/s, training_loss=0.453]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 1518/2645 [02:28<01:47, 10.52it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 1518/2645 [02:28<01:47, 10.52it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 1520/2645 [02:28<01:47, 10.46it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 1520/2645 [02:28<01:47, 10.46it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 1520/2645 [02:28<01:47, 10.46it/s, training_loss=0.487]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 1522/2645 [02:28<01:47, 10.46it/s, training_loss=0.487]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 1522/2645 [02:28<01:47, 10.46it/s, training_loss=0.378]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 1522/2645 [02:28<01:47, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 1524/2645 [02:28<01:47, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 1524/2645 [02:28<01:47, 10.47it/s, training_loss=0.838]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 1524/2645 [02:28<01:47, 10.47it/s, training_loss=0.024]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 1526/2645 [02:28<01:47, 10.45it/s, training_loss=0.024]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 1526/2645 [02:29<01:47, 10.45it/s, training_loss=0.872]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 1526/2645 [02:29<01:47, 10.45it/s, training_loss=0.327]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 1528/2645 [02:29<01:47, 10.43it/s, training_loss=0.327]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 1528/2645 [02:29<01:47, 10.43it/s, training_loss=0.432]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 1528/2645 [02:29<01:47, 10.43it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 1530/2645 [02:29<01:46, 10.45it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 1530/2645 [02:29<01:46, 10.45it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 1530/2645 [02:29<01:46, 10.45it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 1532/2645 [02:29<01:45, 10.52it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 1532/2645 [02:29<01:45, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 1532/2645 [02:29<01:45, 10.52it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 1534/2645 [02:29<01:45, 10.53it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 1534/2645 [02:29<01:45, 10.53it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 1534/2645 [02:29<01:45, 10.53it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 1536/2645 [02:29<01:45, 10.56it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 1536/2645 [02:29<01:45, 10.56it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 1536/2645 [02:30<01:45, 10.56it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 1538/2645 [02:30<01:44, 10.59it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 1538/2645 [02:30<01:44, 10.59it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 1538/2645 [02:30<01:44, 10.59it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 1540/2645 [02:30<01:44, 10.60it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 1540/2645 [02:30<01:44, 10.60it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 1540/2645 [02:30<01:44, 10.60it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 1542/2645 [02:30<01:44, 10.59it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 1542/2645 [02:30<01:44, 10.59it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 1542/2645 [02:30<01:44, 10.59it/s, training_loss=0.839]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 1544/2645 [02:30<01:44, 10.58it/s, training_loss=0.839]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 1544/2645 [02:30<01:44, 10.58it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 1544/2645 [02:30<01:44, 10.58it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 1546/2645 [02:30<01:44, 10.51it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 1546/2645 [02:30<01:44, 10.51it/s, training_loss=0.020]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 1546/2645 [02:31<01:44, 10.51it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  59%|█████▊    | 1548/2645 [02:31<01:44, 10.48it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  59%|█████▊    | 1548/2645 [02:31<01:44, 10.48it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  59%|█████▊    | 1548/2645 [02:31<01:44, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  59%|█████▊    | 1550/2645 [02:31<01:45, 10.40it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  59%|█████▊    | 1550/2645 [02:31<01:45, 10.40it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 1:  59%|█████▊    | 1550/2645 [02:31<01:45, 10.40it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  59%|█████▊    | 1552/2645 [02:31<01:46, 10.27it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  59%|█████▊    | 1552/2645 [02:31<01:46, 10.27it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  59%|█████▊    | 1552/2645 [02:31<01:46, 10.27it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 1554/2645 [02:31<01:45, 10.35it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 1554/2645 [02:31<01:45, 10.35it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 1554/2645 [02:31<01:45, 10.35it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 1556/2645 [02:31<01:44, 10.41it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 1556/2645 [02:31<01:44, 10.41it/s, training_loss=0.077]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 1556/2645 [02:31<01:44, 10.41it/s, training_loss=0.846]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 1558/2645 [02:31<01:44, 10.42it/s, training_loss=0.846]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 1558/2645 [02:32<01:44, 10.42it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 1558/2645 [02:32<01:44, 10.42it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 1560/2645 [02:32<01:43, 10.50it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 1560/2645 [02:32<01:43, 10.50it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 1560/2645 [02:32<01:43, 10.50it/s, training_loss=0.051]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 1562/2645 [02:32<01:43, 10.50it/s, training_loss=0.051]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 1562/2645 [02:32<01:43, 10.50it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 1562/2645 [02:32<01:43, 10.50it/s, training_loss=0.051]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 1564/2645 [02:32<01:44, 10.39it/s, training_loss=0.051]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 1564/2645 [02:32<01:44, 10.39it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 1564/2645 [02:32<01:44, 10.39it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 1566/2645 [02:32<01:43, 10.48it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 1566/2645 [02:32<01:43, 10.48it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 1566/2645 [02:32<01:43, 10.48it/s, training_loss=0.318]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 1568/2645 [02:32<01:42, 10.49it/s, training_loss=0.318]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 1568/2645 [02:33<01:42, 10.49it/s, training_loss=0.184]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 1568/2645 [02:33<01:42, 10.49it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 1570/2645 [02:33<01:42, 10.48it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 1570/2645 [02:33<01:42, 10.48it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 1570/2645 [02:33<01:42, 10.48it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 1572/2645 [02:33<01:42, 10.50it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 1572/2645 [02:33<01:42, 10.50it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 1572/2645 [02:33<01:42, 10.50it/s, training_loss=0.040]\u001b[A\n",
      "Epoch 1:  60%|█████▉    | 1574/2645 [02:33<01:42, 10.41it/s, training_loss=0.040]\u001b[A\n",
      "Epoch 1:  60%|█████▉    | 1574/2645 [02:33<01:42, 10.41it/s, training_loss=0.105]\u001b[A\n",
      "Epoch 1:  60%|█████▉    | 1574/2645 [02:33<01:42, 10.41it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  60%|█████▉    | 1576/2645 [02:33<01:42, 10.43it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  60%|█████▉    | 1576/2645 [02:33<01:42, 10.43it/s, training_loss=0.061]\u001b[A\n",
      "Epoch 1:  60%|█████▉    | 1576/2645 [02:33<01:42, 10.43it/s, training_loss=0.342]\u001b[A\n",
      "Epoch 1:  60%|█████▉    | 1578/2645 [02:33<01:42, 10.42it/s, training_loss=0.342]\u001b[A\n",
      "Epoch 1:  60%|█████▉    | 1578/2645 [02:33<01:42, 10.42it/s, training_loss=0.410]\u001b[A\n",
      "Epoch 1:  60%|█████▉    | 1578/2645 [02:34<01:42, 10.42it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  60%|█████▉    | 1580/2645 [02:34<01:42, 10.42it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  60%|█████▉    | 1580/2645 [02:34<01:42, 10.42it/s, training_loss=0.055]\u001b[A\n",
      "Epoch 1:  60%|█████▉    | 1580/2645 [02:34<01:42, 10.42it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  60%|█████▉    | 1582/2645 [02:34<01:41, 10.47it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  60%|█████▉    | 1582/2645 [02:34<01:41, 10.47it/s, training_loss=0.697]\u001b[A\n",
      "Epoch 1:  60%|█████▉    | 1582/2645 [02:34<01:41, 10.47it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  60%|█████▉    | 1584/2645 [02:34<01:41, 10.41it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  60%|█████▉    | 1584/2645 [02:34<01:41, 10.41it/s, training_loss=0.017]\u001b[A\n",
      "Epoch 1:  60%|█████▉    | 1584/2645 [02:34<01:41, 10.41it/s, training_loss=0.640]\u001b[A\n",
      "Epoch 1:  60%|█████▉    | 1586/2645 [02:34<01:41, 10.40it/s, training_loss=0.640]\u001b[A\n",
      "Epoch 1:  60%|█████▉    | 1586/2645 [02:34<01:41, 10.40it/s, training_loss=0.535]\u001b[A\n",
      "Epoch 1:  60%|█████▉    | 1586/2645 [02:34<01:41, 10.40it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  60%|██████    | 1588/2645 [02:34<01:41, 10.43it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  60%|██████    | 1588/2645 [02:34<01:41, 10.43it/s, training_loss=0.039]\u001b[A\n",
      "Epoch 1:  60%|██████    | 1588/2645 [02:35<01:41, 10.43it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  60%|██████    | 1590/2645 [02:35<01:40, 10.47it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  60%|██████    | 1590/2645 [02:35<01:40, 10.47it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  60%|██████    | 1590/2645 [02:35<01:40, 10.47it/s, training_loss=0.210]\u001b[A\n",
      "Epoch 1:  60%|██████    | 1592/2645 [02:35<01:40, 10.48it/s, training_loss=0.210]\u001b[A\n",
      "Epoch 1:  60%|██████    | 1592/2645 [02:35<01:40, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  60%|██████    | 1592/2645 [02:35<01:40, 10.48it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  60%|██████    | 1594/2645 [02:35<01:40, 10.47it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  60%|██████    | 1594/2645 [02:35<01:40, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  60%|██████    | 1594/2645 [02:35<01:40, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  60%|██████    | 1596/2645 [02:35<01:39, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  60%|██████    | 1596/2645 [02:35<01:39, 10.51it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  60%|██████    | 1596/2645 [02:35<01:39, 10.51it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  60%|██████    | 1598/2645 [02:35<01:39, 10.54it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  60%|██████    | 1598/2645 [02:35<01:39, 10.54it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  60%|██████    | 1598/2645 [02:35<01:39, 10.54it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  60%|██████    | 1600/2645 [02:35<01:39, 10.55it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  60%|██████    | 1600/2645 [02:36<01:39, 10.55it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  60%|██████    | 1600/2645 [02:36<01:39, 10.55it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  61%|██████    | 1602/2645 [02:36<01:38, 10.55it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  61%|██████    | 1602/2645 [02:36<01:38, 10.55it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  61%|██████    | 1602/2645 [02:36<01:38, 10.55it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  61%|██████    | 1604/2645 [02:36<01:38, 10.58it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  61%|██████    | 1604/2645 [02:36<01:38, 10.58it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  61%|██████    | 1604/2645 [02:36<01:38, 10.58it/s, training_loss=0.368]\u001b[A\n",
      "Epoch 1:  61%|██████    | 1606/2645 [02:36<01:38, 10.53it/s, training_loss=0.368]\u001b[A\n",
      "Epoch 1:  61%|██████    | 1606/2645 [02:36<01:38, 10.53it/s, training_loss=0.654]\u001b[A\n",
      "Epoch 1:  61%|██████    | 1606/2645 [02:36<01:38, 10.53it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  61%|██████    | 1608/2645 [02:36<01:38, 10.50it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  61%|██████    | 1608/2645 [02:36<01:38, 10.50it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  61%|██████    | 1608/2645 [02:36<01:38, 10.50it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  61%|██████    | 1610/2645 [02:36<01:38, 10.53it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  61%|██████    | 1610/2645 [02:37<01:38, 10.53it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  61%|██████    | 1610/2645 [02:37<01:38, 10.53it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  61%|██████    | 1612/2645 [02:37<01:38, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  61%|██████    | 1612/2645 [02:37<01:38, 10.50it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  61%|██████    | 1612/2645 [02:37<01:38, 10.50it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  61%|██████    | 1614/2645 [02:37<01:38, 10.50it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  61%|██████    | 1614/2645 [02:37<01:38, 10.50it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  61%|██████    | 1614/2645 [02:37<01:38, 10.50it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  61%|██████    | 1616/2645 [02:37<01:38, 10.43it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  61%|██████    | 1616/2645 [02:37<01:38, 10.43it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  61%|██████    | 1616/2645 [02:37<01:38, 10.43it/s, training_loss=0.437]\u001b[A\n",
      "Epoch 1:  61%|██████    | 1618/2645 [02:37<01:38, 10.43it/s, training_loss=0.437]\u001b[A\n",
      "Epoch 1:  61%|██████    | 1618/2645 [02:37<01:38, 10.43it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  61%|██████    | 1618/2645 [02:37<01:38, 10.43it/s, training_loss=0.018]\u001b[A\n",
      "Epoch 1:  61%|██████    | 1620/2645 [02:37<01:37, 10.48it/s, training_loss=0.018]\u001b[A\n",
      "Epoch 1:  61%|██████    | 1620/2645 [02:37<01:37, 10.48it/s, training_loss=0.759]\u001b[A\n",
      "Epoch 1:  61%|██████    | 1620/2645 [02:38<01:37, 10.48it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  61%|██████▏   | 1622/2645 [02:38<01:38, 10.42it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  61%|██████▏   | 1622/2645 [02:38<01:38, 10.42it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  61%|██████▏   | 1622/2645 [02:38<01:38, 10.42it/s, training_loss=0.041]\u001b[A\n",
      "Epoch 1:  61%|██████▏   | 1624/2645 [02:38<01:37, 10.45it/s, training_loss=0.041]\u001b[A\n",
      "Epoch 1:  61%|██████▏   | 1624/2645 [02:38<01:37, 10.45it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  61%|██████▏   | 1624/2645 [02:38<01:37, 10.45it/s, training_loss=0.018]\u001b[A\n",
      "Epoch 1:  61%|██████▏   | 1626/2645 [02:38<01:37, 10.48it/s, training_loss=0.018]\u001b[A\n",
      "Epoch 1:  61%|██████▏   | 1626/2645 [02:38<01:37, 10.48it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  61%|██████▏   | 1626/2645 [02:38<01:37, 10.48it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 1628/2645 [02:38<01:36, 10.50it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 1628/2645 [02:38<01:36, 10.50it/s, training_loss=1.161]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 1628/2645 [02:38<01:36, 10.50it/s, training_loss=0.155]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 1630/2645 [02:38<01:36, 10.48it/s, training_loss=0.155]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 1630/2645 [02:38<01:36, 10.48it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 1630/2645 [02:39<01:36, 10.48it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 1632/2645 [02:39<01:36, 10.51it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 1632/2645 [02:39<01:36, 10.51it/s, training_loss=0.075]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 1632/2645 [02:39<01:36, 10.51it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 1634/2645 [02:39<01:36, 10.52it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 1634/2645 [02:39<01:36, 10.52it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 1634/2645 [02:39<01:36, 10.52it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 1636/2645 [02:39<01:35, 10.53it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 1636/2645 [02:39<01:35, 10.53it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 1636/2645 [02:39<01:35, 10.53it/s, training_loss=0.208]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 1638/2645 [02:39<01:35, 10.51it/s, training_loss=0.208]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 1638/2645 [02:39<01:35, 10.51it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 1638/2645 [02:39<01:35, 10.51it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 1640/2645 [02:39<01:37, 10.31it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 1640/2645 [02:39<01:37, 10.31it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 1640/2645 [02:40<01:37, 10.31it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 1642/2645 [02:40<01:38, 10.23it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 1642/2645 [02:40<01:38, 10.23it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 1642/2645 [02:40<01:38, 10.23it/s, training_loss=0.511]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 1644/2645 [02:40<01:38, 10.20it/s, training_loss=0.511]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 1644/2645 [02:40<01:38, 10.20it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 1644/2645 [02:40<01:38, 10.20it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 1646/2645 [02:40<01:37, 10.26it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 1646/2645 [02:40<01:37, 10.26it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 1646/2645 [02:40<01:37, 10.26it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 1648/2645 [02:40<01:36, 10.37it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 1648/2645 [02:40<01:36, 10.37it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 1648/2645 [02:40<01:36, 10.37it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 1650/2645 [02:40<01:35, 10.40it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 1650/2645 [02:40<01:35, 10.40it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 1650/2645 [02:40<01:35, 10.40it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 1652/2645 [02:40<01:35, 10.45it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 1652/2645 [02:41<01:35, 10.45it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 1652/2645 [02:41<01:35, 10.45it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 1654/2645 [02:41<01:34, 10.50it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 1654/2645 [02:41<01:34, 10.50it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 1654/2645 [02:41<01:34, 10.50it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 1656/2645 [02:41<01:33, 10.55it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 1656/2645 [02:41<01:33, 10.55it/s, training_loss=0.026]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 1656/2645 [02:41<01:33, 10.55it/s, training_loss=0.129]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 1658/2645 [02:41<01:34, 10.49it/s, training_loss=0.129]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 1658/2645 [02:41<01:34, 10.49it/s, training_loss=0.567]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 1658/2645 [02:41<01:34, 10.49it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 1660/2645 [02:41<01:34, 10.40it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 1660/2645 [02:41<01:34, 10.40it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 1660/2645 [02:41<01:34, 10.40it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 1662/2645 [02:41<01:34, 10.40it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 1662/2645 [02:42<01:34, 10.40it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 1662/2645 [02:42<01:34, 10.40it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 1664/2645 [02:42<01:33, 10.48it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 1664/2645 [02:42<01:33, 10.48it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 1664/2645 [02:42<01:33, 10.48it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 1666/2645 [02:42<01:33, 10.51it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 1666/2645 [02:42<01:33, 10.51it/s, training_loss=0.208]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 1666/2645 [02:42<01:33, 10.51it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 1668/2645 [02:42<01:34, 10.29it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 1668/2645 [02:42<01:34, 10.29it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 1668/2645 [02:42<01:34, 10.29it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 1670/2645 [02:42<01:34, 10.29it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 1670/2645 [02:42<01:34, 10.29it/s, training_loss=0.016]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 1670/2645 [02:42<01:34, 10.29it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 1672/2645 [02:42<01:34, 10.27it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 1672/2645 [02:42<01:34, 10.27it/s, training_loss=0.226]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 1672/2645 [02:43<01:34, 10.27it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 1674/2645 [02:43<01:34, 10.33it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 1674/2645 [02:43<01:34, 10.33it/s, training_loss=0.010]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 1674/2645 [02:43<01:34, 10.33it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 1676/2645 [02:43<01:34, 10.27it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 1676/2645 [02:43<01:34, 10.27it/s, training_loss=0.793]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 1676/2645 [02:43<01:34, 10.27it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 1678/2645 [02:43<01:34, 10.19it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 1678/2645 [02:43<01:34, 10.19it/s, training_loss=0.059]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 1678/2645 [02:43<01:34, 10.19it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  64%|██████▎   | 1680/2645 [02:43<01:34, 10.21it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  64%|██████▎   | 1680/2645 [02:43<01:34, 10.21it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  64%|██████▎   | 1680/2645 [02:43<01:34, 10.21it/s, training_loss=0.466]\u001b[A\n",
      "Epoch 1:  64%|██████▎   | 1682/2645 [02:43<01:33, 10.30it/s, training_loss=0.466]\u001b[A\n",
      "Epoch 1:  64%|██████▎   | 1682/2645 [02:43<01:33, 10.30it/s, training_loss=0.845]\u001b[A\n",
      "Epoch 1:  64%|██████▎   | 1682/2645 [02:44<01:33, 10.30it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  64%|██████▎   | 1684/2645 [02:44<01:32, 10.36it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  64%|██████▎   | 1684/2645 [02:44<01:32, 10.36it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  64%|██████▎   | 1684/2645 [02:44<01:32, 10.36it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  64%|██████▎   | 1686/2645 [02:44<01:31, 10.43it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  64%|██████▎   | 1686/2645 [02:44<01:31, 10.43it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  64%|██████▎   | 1686/2645 [02:44<01:31, 10.43it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 1688/2645 [02:44<01:31, 10.48it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 1688/2645 [02:44<01:31, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 1688/2645 [02:44<01:31, 10.48it/s, training_loss=0.710]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 1690/2645 [02:44<01:31, 10.44it/s, training_loss=0.710]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 1690/2645 [02:44<01:31, 10.44it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 1690/2645 [02:44<01:31, 10.44it/s, training_loss=0.024]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 1692/2645 [02:44<01:31, 10.43it/s, training_loss=0.024]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 1692/2645 [02:44<01:31, 10.43it/s, training_loss=0.865]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 1692/2645 [02:45<01:31, 10.43it/s, training_loss=0.993]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 1694/2645 [02:45<01:31, 10.36it/s, training_loss=0.993]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 1694/2645 [02:45<01:31, 10.36it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 1694/2645 [02:45<01:31, 10.36it/s, training_loss=0.354]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 1696/2645 [02:45<01:31, 10.40it/s, training_loss=0.354]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 1696/2645 [02:45<01:31, 10.40it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 1696/2645 [02:45<01:31, 10.40it/s, training_loss=0.071]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 1698/2645 [02:45<01:30, 10.43it/s, training_loss=0.071]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 1698/2645 [02:45<01:30, 10.43it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 1698/2645 [02:45<01:30, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 1700/2645 [02:45<01:30, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 1700/2645 [02:45<01:30, 10.48it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 1700/2645 [02:45<01:30, 10.48it/s, training_loss=0.534]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 1702/2645 [02:45<01:30, 10.40it/s, training_loss=0.534]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 1702/2645 [02:45<01:30, 10.40it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 1702/2645 [02:45<01:30, 10.40it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 1704/2645 [02:45<01:30, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 1704/2645 [02:46<01:30, 10.44it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 1704/2645 [02:46<01:30, 10.44it/s, training_loss=0.302]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 1706/2645 [02:46<01:29, 10.46it/s, training_loss=0.302]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 1706/2645 [02:46<01:29, 10.46it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 1706/2645 [02:46<01:29, 10.46it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  65%|██████▍   | 1708/2645 [02:46<01:29, 10.49it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  65%|██████▍   | 1708/2645 [02:46<01:29, 10.49it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  65%|██████▍   | 1708/2645 [02:46<01:29, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  65%|██████▍   | 1710/2645 [02:46<01:29, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  65%|██████▍   | 1710/2645 [02:46<01:29, 10.47it/s, training_loss=0.033]\u001b[A\n",
      "Epoch 1:  65%|██████▍   | 1710/2645 [02:46<01:29, 10.47it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  65%|██████▍   | 1712/2645 [02:46<01:29, 10.45it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  65%|██████▍   | 1712/2645 [02:46<01:29, 10.45it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  65%|██████▍   | 1712/2645 [02:46<01:29, 10.45it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  65%|██████▍   | 1714/2645 [02:46<01:28, 10.50it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  65%|██████▍   | 1714/2645 [02:47<01:28, 10.50it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  65%|██████▍   | 1714/2645 [02:47<01:28, 10.50it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  65%|██████▍   | 1716/2645 [02:47<01:28, 10.55it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  65%|██████▍   | 1716/2645 [02:47<01:28, 10.55it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  65%|██████▍   | 1716/2645 [02:47<01:28, 10.55it/s, training_loss=0.057]\u001b[A\n",
      "Epoch 1:  65%|██████▍   | 1718/2645 [02:47<01:28, 10.49it/s, training_loss=0.057]\u001b[A\n",
      "Epoch 1:  65%|██████▍   | 1718/2645 [02:47<01:28, 10.49it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  65%|██████▍   | 1718/2645 [02:47<01:28, 10.49it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  65%|██████▌   | 1720/2645 [02:47<01:27, 10.52it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  65%|██████▌   | 1720/2645 [02:47<01:27, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  65%|██████▌   | 1720/2645 [02:47<01:27, 10.52it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  65%|██████▌   | 1722/2645 [02:47<01:27, 10.53it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  65%|██████▌   | 1722/2645 [02:47<01:27, 10.53it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  65%|██████▌   | 1722/2645 [02:47<01:27, 10.53it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  65%|██████▌   | 1724/2645 [02:47<01:28, 10.41it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  65%|██████▌   | 1724/2645 [02:47<01:28, 10.41it/s, training_loss=0.445]\u001b[A\n",
      "Epoch 1:  65%|██████▌   | 1724/2645 [02:48<01:28, 10.41it/s, training_loss=0.647]\u001b[A\n",
      "Epoch 1:  65%|██████▌   | 1726/2645 [02:48<01:28, 10.37it/s, training_loss=0.647]\u001b[A\n",
      "Epoch 1:  65%|██████▌   | 1726/2645 [02:48<01:28, 10.37it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  65%|██████▌   | 1726/2645 [02:48<01:28, 10.37it/s, training_loss=0.056]\u001b[A\n",
      "Epoch 1:  65%|██████▌   | 1728/2645 [02:48<01:27, 10.42it/s, training_loss=0.056]\u001b[A\n",
      "Epoch 1:  65%|██████▌   | 1728/2645 [02:48<01:27, 10.42it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  65%|██████▌   | 1728/2645 [02:48<01:27, 10.42it/s, training_loss=0.079]\u001b[A\n",
      "Epoch 1:  65%|██████▌   | 1730/2645 [02:48<01:27, 10.41it/s, training_loss=0.079]\u001b[A\n",
      "Epoch 1:  65%|██████▌   | 1730/2645 [02:48<01:27, 10.41it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  65%|██████▌   | 1730/2645 [02:48<01:27, 10.41it/s, training_loss=0.810]\u001b[A\n",
      "Epoch 1:  65%|██████▌   | 1732/2645 [02:48<01:27, 10.43it/s, training_loss=0.810]\u001b[A\n",
      "Epoch 1:  65%|██████▌   | 1732/2645 [02:48<01:27, 10.43it/s, training_loss=0.012]\u001b[A\n",
      "Epoch 1:  65%|██████▌   | 1732/2645 [02:48<01:27, 10.43it/s, training_loss=0.031]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 1734/2645 [02:48<01:27, 10.41it/s, training_loss=0.031]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 1734/2645 [02:48<01:27, 10.41it/s, training_loss=0.284]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 1734/2645 [02:49<01:27, 10.41it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 1736/2645 [02:49<01:27, 10.43it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 1736/2645 [02:49<01:27, 10.43it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 1736/2645 [02:49<01:27, 10.43it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 1738/2645 [02:49<01:26, 10.50it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 1738/2645 [02:49<01:26, 10.50it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 1738/2645 [02:49<01:26, 10.50it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 1740/2645 [02:49<01:25, 10.53it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 1740/2645 [02:49<01:25, 10.53it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 1740/2645 [02:49<01:25, 10.53it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 1742/2645 [02:49<01:25, 10.55it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 1742/2645 [02:49<01:25, 10.55it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 1742/2645 [02:49<01:25, 10.55it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 1744/2645 [02:49<01:25, 10.57it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 1744/2645 [02:49<01:25, 10.57it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 1744/2645 [02:49<01:25, 10.57it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 1746/2645 [02:49<01:26, 10.45it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 1746/2645 [02:50<01:26, 10.45it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 1746/2645 [02:50<01:26, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 1748/2645 [02:50<01:25, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 1748/2645 [02:50<01:25, 10.48it/s, training_loss=0.059]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 1748/2645 [02:50<01:25, 10.48it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 1750/2645 [02:50<01:25, 10.49it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 1750/2645 [02:50<01:25, 10.49it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 1750/2645 [02:50<01:25, 10.49it/s, training_loss=0.415]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 1752/2645 [02:50<01:25, 10.43it/s, training_loss=0.415]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 1752/2645 [02:50<01:25, 10.43it/s, training_loss=0.324]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 1752/2645 [02:50<01:25, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  66%|██████▋   | 1754/2645 [02:50<01:25, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  66%|██████▋   | 1754/2645 [02:50<01:25, 10.45it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  66%|██████▋   | 1754/2645 [02:50<01:25, 10.45it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  66%|██████▋   | 1756/2645 [02:50<01:24, 10.47it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  66%|██████▋   | 1756/2645 [02:51<01:24, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  66%|██████▋   | 1756/2645 [02:51<01:24, 10.47it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  66%|██████▋   | 1758/2645 [02:51<01:24, 10.47it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  66%|██████▋   | 1758/2645 [02:51<01:24, 10.47it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  66%|██████▋   | 1758/2645 [02:51<01:24, 10.47it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 1760/2645 [02:51<01:24, 10.50it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 1760/2645 [02:51<01:24, 10.50it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 1760/2645 [02:51<01:24, 10.50it/s, training_loss=0.094]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 1762/2645 [02:51<01:24, 10.51it/s, training_loss=0.094]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 1762/2645 [02:51<01:24, 10.51it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 1762/2645 [02:51<01:24, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 1764/2645 [02:51<01:23, 10.54it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 1764/2645 [02:51<01:23, 10.54it/s, training_loss=0.667]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 1764/2645 [02:51<01:23, 10.54it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 1766/2645 [02:51<01:23, 10.52it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 1766/2645 [02:51<01:23, 10.52it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 1766/2645 [02:52<01:23, 10.52it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 1768/2645 [02:52<01:23, 10.56it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 1768/2645 [02:52<01:23, 10.56it/s, training_loss=0.912]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 1768/2645 [02:52<01:23, 10.56it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 1770/2645 [02:52<01:22, 10.54it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 1770/2645 [02:52<01:22, 10.54it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 1770/2645 [02:52<01:22, 10.54it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 1772/2645 [02:52<01:23, 10.52it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 1772/2645 [02:52<01:23, 10.52it/s, training_loss=0.158]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 1772/2645 [02:52<01:23, 10.52it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 1774/2645 [02:52<01:23, 10.42it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 1774/2645 [02:52<01:23, 10.42it/s, training_loss=0.272]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 1774/2645 [02:52<01:23, 10.42it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 1776/2645 [02:52<01:23, 10.44it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 1776/2645 [02:52<01:23, 10.44it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 1776/2645 [02:53<01:23, 10.44it/s, training_loss=0.379]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 1778/2645 [02:53<01:23, 10.43it/s, training_loss=0.379]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 1778/2645 [02:53<01:23, 10.43it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 1778/2645 [02:53<01:23, 10.43it/s, training_loss=0.011]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 1780/2645 [02:53<01:23, 10.34it/s, training_loss=0.011]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 1780/2645 [02:53<01:23, 10.34it/s, training_loss=0.035]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 1780/2645 [02:53<01:23, 10.34it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 1782/2645 [02:53<01:23, 10.31it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 1782/2645 [02:53<01:23, 10.31it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 1782/2645 [02:53<01:23, 10.31it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 1784/2645 [02:53<01:23, 10.35it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 1784/2645 [02:53<01:23, 10.35it/s, training_loss=0.125]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 1784/2645 [02:53<01:23, 10.35it/s, training_loss=0.014]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 1786/2645 [02:53<01:24, 10.19it/s, training_loss=0.014]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 1786/2645 [02:53<01:24, 10.19it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 1786/2645 [02:54<01:24, 10.19it/s, training_loss=0.130]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 1788/2645 [02:54<01:25, 10.06it/s, training_loss=0.130]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 1788/2645 [02:54<01:25, 10.06it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 1788/2645 [02:54<01:25, 10.06it/s, training_loss=0.516]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 1790/2645 [02:54<01:25, 10.03it/s, training_loss=0.516]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 1790/2645 [02:54<01:25, 10.03it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 1790/2645 [02:54<01:25, 10.03it/s, training_loss=0.407]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 1792/2645 [02:54<01:24, 10.06it/s, training_loss=0.407]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 1792/2645 [02:54<01:24, 10.06it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 1792/2645 [02:54<01:24, 10.06it/s, training_loss=0.744]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 1794/2645 [02:54<01:24, 10.03it/s, training_loss=0.744]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 1794/2645 [02:54<01:24, 10.03it/s, training_loss=0.748]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 1794/2645 [02:54<01:24, 10.03it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 1796/2645 [02:54<01:25,  9.98it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 1796/2645 [02:54<01:25,  9.98it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 1797/2645 [02:54<01:25,  9.97it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 1797/2645 [02:55<01:25,  9.97it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 1798/2645 [02:55<01:25,  9.88it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 1798/2645 [02:55<01:25,  9.88it/s, training_loss=0.012]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 1799/2645 [02:55<01:25,  9.85it/s, training_loss=0.012]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 1799/2645 [02:55<01:25,  9.85it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 1799/2645 [02:55<01:25,  9.85it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 1801/2645 [02:55<01:24,  9.93it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 1801/2645 [02:55<01:24,  9.93it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 1801/2645 [02:55<01:24,  9.93it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 1803/2645 [02:55<01:23, 10.06it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 1803/2645 [02:55<01:23, 10.06it/s, training_loss=0.013]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 1803/2645 [02:55<01:23, 10.06it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 1805/2645 [02:55<01:23, 10.07it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 1805/2645 [02:55<01:23, 10.07it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 1805/2645 [02:55<01:23, 10.07it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 1807/2645 [02:55<01:23, 10.06it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 1807/2645 [02:56<01:23, 10.06it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 1807/2645 [02:56<01:23, 10.06it/s, training_loss=0.610]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 1809/2645 [02:56<01:23, 10.06it/s, training_loss=0.610]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 1809/2645 [02:56<01:23, 10.06it/s, training_loss=0.027]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 1809/2645 [02:56<01:23, 10.06it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 1811/2645 [02:56<01:23, 10.00it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 1811/2645 [02:56<01:23, 10.00it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 1811/2645 [02:56<01:23, 10.00it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  69%|██████▊   | 1813/2645 [02:56<01:23,  9.99it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  69%|██████▊   | 1813/2645 [02:56<01:23,  9.99it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  69%|██████▊   | 1814/2645 [02:56<01:23,  9.90it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  69%|██████▊   | 1814/2645 [02:56<01:23,  9.90it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  69%|██████▊   | 1814/2645 [02:56<01:23,  9.90it/s, training_loss=0.736]\u001b[A\n",
      "Epoch 1:  69%|██████▊   | 1816/2645 [02:56<01:23,  9.97it/s, training_loss=0.736]\u001b[A\n",
      "Epoch 1:  69%|██████▊   | 1816/2645 [02:56<01:23,  9.97it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  69%|██████▊   | 1817/2645 [02:56<01:23,  9.89it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  69%|██████▊   | 1817/2645 [02:57<01:23,  9.89it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  69%|██████▊   | 1818/2645 [02:57<01:24,  9.80it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  69%|██████▊   | 1818/2645 [02:57<01:24,  9.80it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  69%|██████▊   | 1818/2645 [02:57<01:24,  9.80it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  69%|██████▉   | 1820/2645 [02:57<01:23,  9.90it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  69%|██████▉   | 1820/2645 [02:57<01:23,  9.90it/s, training_loss=0.022]\u001b[A\n",
      "Epoch 1:  69%|██████▉   | 1821/2645 [02:57<01:24,  9.71it/s, training_loss=0.022]\u001b[A\n",
      "Epoch 1:  69%|██████▉   | 1821/2645 [02:57<01:24,  9.71it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  69%|██████▉   | 1821/2645 [02:57<01:24,  9.71it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  69%|██████▉   | 1823/2645 [02:57<01:23,  9.86it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  69%|██████▉   | 1823/2645 [02:57<01:23,  9.86it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  69%|██████▉   | 1824/2645 [02:57<01:23,  9.80it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  69%|██████▉   | 1824/2645 [02:57<01:23,  9.80it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  69%|██████▉   | 1825/2645 [02:57<01:23,  9.83it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  69%|██████▉   | 1825/2645 [02:57<01:23,  9.83it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  69%|██████▉   | 1825/2645 [02:57<01:23,  9.83it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  69%|██████▉   | 1827/2645 [02:57<01:22,  9.91it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  69%|██████▉   | 1827/2645 [02:58<01:22,  9.91it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  69%|██████▉   | 1828/2645 [02:58<01:23,  9.84it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  69%|██████▉   | 1828/2645 [02:58<01:23,  9.84it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  69%|██████▉   | 1828/2645 [02:58<01:23,  9.84it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  69%|██████▉   | 1830/2645 [02:58<01:21, 10.00it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  69%|██████▉   | 1830/2645 [02:58<01:21, 10.00it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  69%|██████▉   | 1830/2645 [02:58<01:21, 10.00it/s, training_loss=0.062]\u001b[A\n",
      "Epoch 1:  69%|██████▉   | 1832/2645 [02:58<01:20, 10.08it/s, training_loss=0.062]\u001b[A\n",
      "Epoch 1:  69%|██████▉   | 1832/2645 [02:58<01:20, 10.08it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  69%|██████▉   | 1832/2645 [02:58<01:20, 10.08it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  69%|██████▉   | 1834/2645 [02:58<01:20, 10.10it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  69%|██████▉   | 1834/2645 [02:58<01:20, 10.10it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  69%|██████▉   | 1834/2645 [02:58<01:20, 10.10it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  69%|██████▉   | 1836/2645 [02:58<01:19, 10.15it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  69%|██████▉   | 1836/2645 [02:58<01:19, 10.15it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  69%|██████▉   | 1836/2645 [02:59<01:19, 10.15it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  69%|██████▉   | 1838/2645 [02:59<01:19, 10.13it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  69%|██████▉   | 1838/2645 [02:59<01:19, 10.13it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  69%|██████▉   | 1838/2645 [02:59<01:19, 10.13it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  70%|██████▉   | 1840/2645 [02:59<01:19, 10.17it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  70%|██████▉   | 1840/2645 [02:59<01:19, 10.17it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  70%|██████▉   | 1840/2645 [02:59<01:19, 10.17it/s, training_loss=0.827]\u001b[A\n",
      "Epoch 1:  70%|██████▉   | 1842/2645 [02:59<01:19, 10.11it/s, training_loss=0.827]\u001b[A\n",
      "Epoch 1:  70%|██████▉   | 1842/2645 [02:59<01:19, 10.11it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  70%|██████▉   | 1842/2645 [02:59<01:19, 10.11it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  70%|██████▉   | 1844/2645 [02:59<01:18, 10.16it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  70%|██████▉   | 1844/2645 [02:59<01:18, 10.16it/s, training_loss=0.389]\u001b[A\n",
      "Epoch 1:  70%|██████▉   | 1844/2645 [02:59<01:18, 10.16it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  70%|██████▉   | 1846/2645 [02:59<01:18, 10.18it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  70%|██████▉   | 1846/2645 [02:59<01:18, 10.18it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  70%|██████▉   | 1846/2645 [02:59<01:18, 10.18it/s, training_loss=0.033]\u001b[A\n",
      "Epoch 1:  70%|██████▉   | 1848/2645 [03:00<01:19, 10.09it/s, training_loss=0.033]\u001b[A\n",
      "Epoch 1:  70%|██████▉   | 1848/2645 [03:00<01:19, 10.09it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  70%|██████▉   | 1848/2645 [03:00<01:19, 10.09it/s, training_loss=0.028]\u001b[A\n",
      "Epoch 1:  70%|██████▉   | 1850/2645 [03:00<01:18, 10.08it/s, training_loss=0.028]\u001b[A\n",
      "Epoch 1:  70%|██████▉   | 1850/2645 [03:00<01:18, 10.08it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  70%|██████▉   | 1850/2645 [03:00<01:18, 10.08it/s, training_loss=0.212]\u001b[A\n",
      "Epoch 1:  70%|███████   | 1852/2645 [03:00<01:19,  9.98it/s, training_loss=0.212]\u001b[A\n",
      "Epoch 1:  70%|███████   | 1852/2645 [03:00<01:19,  9.98it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  70%|███████   | 1852/2645 [03:00<01:19,  9.98it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  70%|███████   | 1854/2645 [03:00<01:18, 10.05it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  70%|███████   | 1854/2645 [03:00<01:18, 10.05it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  70%|███████   | 1854/2645 [03:00<01:18, 10.05it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  70%|███████   | 1856/2645 [03:00<01:18, 10.08it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  70%|███████   | 1856/2645 [03:00<01:18, 10.08it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  70%|███████   | 1856/2645 [03:00<01:18, 10.08it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  70%|███████   | 1858/2645 [03:01<01:18, 10.03it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  70%|███████   | 1858/2645 [03:01<01:18, 10.03it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  70%|███████   | 1858/2645 [03:01<01:18, 10.03it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  70%|███████   | 1860/2645 [03:01<01:18, 10.01it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  70%|███████   | 1860/2645 [03:01<01:18, 10.01it/s, training_loss=0.218]\u001b[A\n",
      "Epoch 1:  70%|███████   | 1860/2645 [03:01<01:18, 10.01it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  70%|███████   | 1862/2645 [03:01<01:18,  9.99it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  70%|███████   | 1862/2645 [03:01<01:18,  9.99it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  70%|███████   | 1863/2645 [03:01<01:18,  9.92it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  70%|███████   | 1863/2645 [03:01<01:18,  9.92it/s, training_loss=0.037]\u001b[A\n",
      "Epoch 1:  70%|███████   | 1864/2645 [03:01<01:19,  9.88it/s, training_loss=0.037]\u001b[A\n",
      "Epoch 1:  70%|███████   | 1864/2645 [03:01<01:19,  9.88it/s, training_loss=0.027]\u001b[A\n",
      "Epoch 1:  71%|███████   | 1865/2645 [03:01<01:18,  9.90it/s, training_loss=0.027]\u001b[A\n",
      "Epoch 1:  71%|███████   | 1865/2645 [03:01<01:18,  9.90it/s, training_loss=0.435]\u001b[A\n",
      "Epoch 1:  71%|███████   | 1866/2645 [03:01<01:18,  9.91it/s, training_loss=0.435]\u001b[A\n",
      "Epoch 1:  71%|███████   | 1866/2645 [03:01<01:18,  9.91it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  71%|███████   | 1866/2645 [03:01<01:18,  9.91it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  71%|███████   | 1868/2645 [03:02<01:17, 10.03it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  71%|███████   | 1868/2645 [03:02<01:17, 10.03it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  71%|███████   | 1868/2645 [03:02<01:17, 10.03it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  71%|███████   | 1870/2645 [03:02<01:17, 10.01it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  71%|███████   | 1870/2645 [03:02<01:17, 10.01it/s, training_loss=0.534]\u001b[A\n",
      "Epoch 1:  71%|███████   | 1870/2645 [03:02<01:17, 10.01it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  71%|███████   | 1872/2645 [03:02<01:17, 10.03it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  71%|███████   | 1872/2645 [03:02<01:17, 10.03it/s, training_loss=0.465]\u001b[A\n",
      "Epoch 1:  71%|███████   | 1872/2645 [03:02<01:17, 10.03it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  71%|███████   | 1874/2645 [03:02<01:17,  9.99it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  71%|███████   | 1874/2645 [03:02<01:17,  9.99it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  71%|███████   | 1875/2645 [03:02<01:17,  9.95it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  71%|███████   | 1875/2645 [03:02<01:17,  9.95it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  71%|███████   | 1875/2645 [03:02<01:17,  9.95it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  71%|███████   | 1877/2645 [03:02<01:16, 10.00it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  71%|███████   | 1877/2645 [03:03<01:16, 10.00it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  71%|███████   | 1877/2645 [03:03<01:16, 10.00it/s, training_loss=0.022]\u001b[A\n",
      "Epoch 1:  71%|███████   | 1879/2645 [03:03<01:16,  9.95it/s, training_loss=0.022]\u001b[A\n",
      "Epoch 1:  71%|███████   | 1879/2645 [03:03<01:16,  9.95it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  71%|███████   | 1880/2645 [03:03<01:17,  9.93it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  71%|███████   | 1880/2645 [03:03<01:17,  9.93it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  71%|███████   | 1881/2645 [03:03<01:16,  9.95it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  71%|███████   | 1881/2645 [03:03<01:16,  9.95it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  71%|███████   | 1882/2645 [03:03<01:17,  9.88it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  71%|███████   | 1882/2645 [03:03<01:17,  9.88it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  71%|███████   | 1882/2645 [03:03<01:17,  9.88it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  71%|███████   | 1884/2645 [03:03<01:15, 10.03it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  71%|███████   | 1884/2645 [03:03<01:15, 10.03it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  71%|███████   | 1884/2645 [03:03<01:15, 10.03it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  71%|███████▏  | 1886/2645 [03:03<01:15, 10.10it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  71%|███████▏  | 1886/2645 [03:03<01:15, 10.10it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  71%|███████▏  | 1886/2645 [03:03<01:15, 10.10it/s, training_loss=0.297]\u001b[A\n",
      "Epoch 1:  71%|███████▏  | 1888/2645 [03:03<01:15, 10.09it/s, training_loss=0.297]\u001b[A\n",
      "Epoch 1:  71%|███████▏  | 1888/2645 [03:04<01:15, 10.09it/s, training_loss=0.014]\u001b[A\n",
      "Epoch 1:  71%|███████▏  | 1888/2645 [03:04<01:15, 10.09it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  71%|███████▏  | 1890/2645 [03:04<01:15, 10.05it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  71%|███████▏  | 1890/2645 [03:04<01:15, 10.05it/s, training_loss=0.442]\u001b[A\n",
      "Epoch 1:  71%|███████▏  | 1890/2645 [03:04<01:15, 10.05it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  72%|███████▏  | 1892/2645 [03:04<01:15, 10.01it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  72%|███████▏  | 1892/2645 [03:04<01:15, 10.01it/s, training_loss=0.739]\u001b[A\n",
      "Epoch 1:  72%|███████▏  | 1892/2645 [03:04<01:15, 10.01it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  72%|███████▏  | 1894/2645 [03:04<01:15,  9.97it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  72%|███████▏  | 1894/2645 [03:04<01:15,  9.97it/s, training_loss=0.871]\u001b[A\n",
      "Epoch 1:  72%|███████▏  | 1895/2645 [03:04<01:15,  9.96it/s, training_loss=0.871]\u001b[A\n",
      "Epoch 1:  72%|███████▏  | 1895/2645 [03:04<01:15,  9.96it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  72%|███████▏  | 1895/2645 [03:04<01:15,  9.96it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  72%|███████▏  | 1897/2645 [03:04<01:16,  9.78it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  72%|███████▏  | 1897/2645 [03:05<01:16,  9.78it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  72%|███████▏  | 1897/2645 [03:05<01:16,  9.78it/s, training_loss=0.769]\u001b[A\n",
      "Epoch 1:  72%|███████▏  | 1899/2645 [03:05<01:15,  9.86it/s, training_loss=0.769]\u001b[A\n",
      "Epoch 1:  72%|███████▏  | 1899/2645 [03:05<01:15,  9.86it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  72%|███████▏  | 1900/2645 [03:05<01:15,  9.90it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  72%|███████▏  | 1900/2645 [03:05<01:15,  9.90it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  72%|███████▏  | 1901/2645 [03:05<01:15,  9.86it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  72%|███████▏  | 1901/2645 [03:05<01:15,  9.86it/s, training_loss=0.019]\u001b[A\n",
      "Epoch 1:  72%|███████▏  | 1902/2645 [03:05<01:15,  9.87it/s, training_loss=0.019]\u001b[A\n",
      "Epoch 1:  72%|███████▏  | 1902/2645 [03:05<01:15,  9.87it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  72%|███████▏  | 1902/2645 [03:05<01:15,  9.87it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  72%|███████▏  | 1904/2645 [03:05<01:14,  9.99it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  72%|███████▏  | 1904/2645 [03:05<01:14,  9.99it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  72%|███████▏  | 1904/2645 [03:05<01:14,  9.99it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  72%|███████▏  | 1906/2645 [03:05<01:13, 10.08it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  72%|███████▏  | 1906/2645 [03:05<01:13, 10.08it/s, training_loss=0.022]\u001b[A\n",
      "Epoch 1:  72%|███████▏  | 1906/2645 [03:06<01:13, 10.08it/s, training_loss=0.249]\u001b[A\n",
      "Epoch 1:  72%|███████▏  | 1908/2645 [03:06<01:13, 10.09it/s, training_loss=0.249]\u001b[A\n",
      "Epoch 1:  72%|███████▏  | 1908/2645 [03:06<01:13, 10.09it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  72%|███████▏  | 1908/2645 [03:06<01:13, 10.09it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  72%|███████▏  | 1910/2645 [03:06<01:12, 10.09it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  72%|███████▏  | 1910/2645 [03:06<01:12, 10.09it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  72%|███████▏  | 1910/2645 [03:06<01:12, 10.09it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  72%|███████▏  | 1912/2645 [03:06<01:12, 10.12it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  72%|███████▏  | 1912/2645 [03:06<01:12, 10.12it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  72%|███████▏  | 1912/2645 [03:06<01:12, 10.12it/s, training_loss=1.482]\u001b[A\n",
      "Epoch 1:  72%|███████▏  | 1914/2645 [03:06<01:12, 10.10it/s, training_loss=1.482]\u001b[A\n",
      "Epoch 1:  72%|███████▏  | 1914/2645 [03:06<01:12, 10.10it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  72%|███████▏  | 1914/2645 [03:06<01:12, 10.10it/s, training_loss=1.075]\u001b[A\n",
      "Epoch 1:  72%|███████▏  | 1916/2645 [03:06<01:12, 10.05it/s, training_loss=1.075]\u001b[A\n",
      "Epoch 1:  72%|███████▏  | 1916/2645 [03:06<01:12, 10.05it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  72%|███████▏  | 1916/2645 [03:06<01:12, 10.05it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  73%|███████▎  | 1918/2645 [03:06<01:12, 10.08it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  73%|███████▎  | 1918/2645 [03:07<01:12, 10.08it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  73%|███████▎  | 1918/2645 [03:07<01:12, 10.08it/s, training_loss=0.391]\u001b[A\n",
      "Epoch 1:  73%|███████▎  | 1920/2645 [03:07<01:12,  9.96it/s, training_loss=0.391]\u001b[A\n",
      "Epoch 1:  73%|███████▎  | 1920/2645 [03:07<01:12,  9.96it/s, training_loss=0.111]\u001b[A\n",
      "Epoch 1:  73%|███████▎  | 1921/2645 [03:07<01:12,  9.95it/s, training_loss=0.111]\u001b[A\n",
      "Epoch 1:  73%|███████▎  | 1921/2645 [03:07<01:12,  9.95it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  73%|███████▎  | 1921/2645 [03:07<01:12,  9.95it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  73%|███████▎  | 1923/2645 [03:07<01:12,  9.99it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  73%|███████▎  | 1923/2645 [03:07<01:12,  9.99it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  73%|███████▎  | 1923/2645 [03:07<01:12,  9.99it/s, training_loss=0.331]\u001b[A\n",
      "Epoch 1:  73%|███████▎  | 1925/2645 [03:07<01:11, 10.06it/s, training_loss=0.331]\u001b[A\n",
      "Epoch 1:  73%|███████▎  | 1925/2645 [03:07<01:11, 10.06it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  73%|███████▎  | 1925/2645 [03:07<01:11, 10.06it/s, training_loss=0.475]\u001b[A\n",
      "Epoch 1:  73%|███████▎  | 1927/2645 [03:07<01:11, 10.07it/s, training_loss=0.475]\u001b[A\n",
      "Epoch 1:  73%|███████▎  | 1927/2645 [03:07<01:11, 10.07it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  73%|███████▎  | 1927/2645 [03:08<01:11, 10.07it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  73%|███████▎  | 1929/2645 [03:08<01:11, 10.01it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  73%|███████▎  | 1929/2645 [03:08<01:11, 10.01it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  73%|███████▎  | 1929/2645 [03:08<01:11, 10.01it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  73%|███████▎  | 1931/2645 [03:08<01:10, 10.10it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  73%|███████▎  | 1931/2645 [03:08<01:10, 10.10it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  73%|███████▎  | 1931/2645 [03:08<01:10, 10.10it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  73%|███████▎  | 1933/2645 [03:08<01:10, 10.13it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  73%|███████▎  | 1933/2645 [03:08<01:10, 10.13it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  73%|███████▎  | 1933/2645 [03:08<01:10, 10.13it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  73%|███████▎  | 1935/2645 [03:08<01:10, 10.07it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  73%|███████▎  | 1935/2645 [03:08<01:10, 10.07it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  73%|███████▎  | 1935/2645 [03:08<01:10, 10.07it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  73%|███████▎  | 1937/2645 [03:08<01:11,  9.97it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  73%|███████▎  | 1937/2645 [03:08<01:11,  9.97it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  73%|███████▎  | 1938/2645 [03:08<01:11,  9.94it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  73%|███████▎  | 1938/2645 [03:09<01:11,  9.94it/s, training_loss=0.041]\u001b[A\n",
      "Epoch 1:  73%|███████▎  | 1939/2645 [03:09<01:10,  9.95it/s, training_loss=0.041]\u001b[A\n",
      "Epoch 1:  73%|███████▎  | 1939/2645 [03:09<01:10,  9.95it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  73%|███████▎  | 1939/2645 [03:09<01:10,  9.95it/s, training_loss=0.020]\u001b[A\n",
      "Epoch 1:  73%|███████▎  | 1941/2645 [03:09<01:10, 10.01it/s, training_loss=0.020]\u001b[A\n",
      "Epoch 1:  73%|███████▎  | 1941/2645 [03:09<01:10, 10.01it/s, training_loss=0.065]\u001b[A\n",
      "Epoch 1:  73%|███████▎  | 1941/2645 [03:09<01:10, 10.01it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  73%|███████▎  | 1943/2645 [03:09<01:10, 10.00it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  73%|███████▎  | 1943/2645 [03:09<01:10, 10.00it/s, training_loss=0.075]\u001b[A\n",
      "Epoch 1:  73%|███████▎  | 1943/2645 [03:09<01:10, 10.00it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  74%|███████▎  | 1945/2645 [03:09<01:09, 10.05it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  74%|███████▎  | 1945/2645 [03:09<01:09, 10.05it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  74%|███████▎  | 1945/2645 [03:09<01:09, 10.05it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  74%|███████▎  | 1947/2645 [03:09<01:09, 10.06it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  74%|███████▎  | 1947/2645 [03:09<01:09, 10.06it/s, training_loss=0.311]\u001b[A\n",
      "Epoch 1:  74%|███████▎  | 1947/2645 [03:10<01:09, 10.06it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  74%|███████▎  | 1949/2645 [03:10<01:09,  9.98it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  74%|███████▎  | 1949/2645 [03:10<01:09,  9.98it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  74%|███████▎  | 1949/2645 [03:10<01:09,  9.98it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  74%|███████▍  | 1951/2645 [03:10<01:09, 10.01it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  74%|███████▍  | 1951/2645 [03:10<01:09, 10.01it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  74%|███████▍  | 1951/2645 [03:10<01:09, 10.01it/s, training_loss=0.123]\u001b[A\n",
      "Epoch 1:  74%|███████▍  | 1953/2645 [03:10<01:09,  9.94it/s, training_loss=0.123]\u001b[A\n",
      "Epoch 1:  74%|███████▍  | 1953/2645 [03:10<01:09,  9.94it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  74%|███████▍  | 1953/2645 [03:10<01:09,  9.94it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  74%|███████▍  | 1955/2645 [03:10<01:08, 10.02it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  74%|███████▍  | 1955/2645 [03:10<01:08, 10.02it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  74%|███████▍  | 1955/2645 [03:10<01:08, 10.02it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  74%|███████▍  | 1957/2645 [03:10<01:08, 10.06it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  74%|███████▍  | 1957/2645 [03:10<01:08, 10.06it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  74%|███████▍  | 1957/2645 [03:11<01:08, 10.06it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  74%|███████▍  | 1959/2645 [03:11<01:07, 10.12it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  74%|███████▍  | 1959/2645 [03:11<01:07, 10.12it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  74%|███████▍  | 1959/2645 [03:11<01:07, 10.12it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  74%|███████▍  | 1961/2645 [03:11<01:07, 10.12it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  74%|███████▍  | 1961/2645 [03:11<01:07, 10.12it/s, training_loss=0.121]\u001b[A\n",
      "Epoch 1:  74%|███████▍  | 1961/2645 [03:11<01:07, 10.12it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  74%|███████▍  | 1963/2645 [03:11<01:08,  9.98it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  74%|███████▍  | 1963/2645 [03:11<01:08,  9.98it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  74%|███████▍  | 1963/2645 [03:11<01:08,  9.98it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  74%|███████▍  | 1965/2645 [03:11<01:07, 10.03it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  74%|███████▍  | 1965/2645 [03:11<01:07, 10.03it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  74%|███████▍  | 1965/2645 [03:11<01:07, 10.03it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  74%|███████▍  | 1967/2645 [03:11<01:08,  9.85it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  74%|███████▍  | 1967/2645 [03:11<01:08,  9.85it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  74%|███████▍  | 1967/2645 [03:12<01:08,  9.85it/s, training_loss=0.010]\u001b[A\n",
      "Epoch 1:  74%|███████▍  | 1969/2645 [03:12<01:08,  9.93it/s, training_loss=0.010]\u001b[A\n",
      "Epoch 1:  74%|███████▍  | 1969/2645 [03:12<01:08,  9.93it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  74%|███████▍  | 1969/2645 [03:12<01:08,  9.93it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  75%|███████▍  | 1971/2645 [03:12<01:06, 10.09it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  75%|███████▍  | 1971/2645 [03:12<01:06, 10.09it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  75%|███████▍  | 1971/2645 [03:12<01:06, 10.09it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  75%|███████▍  | 1973/2645 [03:12<01:06, 10.14it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  75%|███████▍  | 1973/2645 [03:12<01:06, 10.14it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  75%|███████▍  | 1973/2645 [03:12<01:06, 10.14it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  75%|███████▍  | 1975/2645 [03:12<01:06, 10.06it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  75%|███████▍  | 1975/2645 [03:12<01:06, 10.06it/s, training_loss=0.314]\u001b[A\n",
      "Epoch 1:  75%|███████▍  | 1975/2645 [03:12<01:06, 10.06it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  75%|███████▍  | 1977/2645 [03:12<01:06, 10.03it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  75%|███████▍  | 1977/2645 [03:12<01:06, 10.03it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  75%|███████▍  | 1977/2645 [03:13<01:06, 10.03it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  75%|███████▍  | 1979/2645 [03:13<01:06,  9.98it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  75%|███████▍  | 1979/2645 [03:13<01:06,  9.98it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  75%|███████▍  | 1980/2645 [03:13<01:06,  9.97it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  75%|███████▍  | 1980/2645 [03:13<01:06,  9.97it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  75%|███████▍  | 1981/2645 [03:13<01:06,  9.93it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  75%|███████▍  | 1981/2645 [03:13<01:06,  9.93it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  75%|███████▍  | 1981/2645 [03:13<01:06,  9.93it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  75%|███████▍  | 1983/2645 [03:13<01:06, 10.02it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  75%|███████▍  | 1983/2645 [03:13<01:06, 10.02it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  75%|███████▍  | 1983/2645 [03:13<01:06, 10.02it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  75%|███████▌  | 1985/2645 [03:13<01:05, 10.06it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  75%|███████▌  | 1985/2645 [03:13<01:05, 10.06it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  75%|███████▌  | 1985/2645 [03:13<01:05, 10.06it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  75%|███████▌  | 1987/2645 [03:13<01:05,  9.99it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  75%|███████▌  | 1987/2645 [03:13<01:05,  9.99it/s, training_loss=0.975]\u001b[A\n",
      "Epoch 1:  75%|███████▌  | 1988/2645 [03:13<01:06,  9.95it/s, training_loss=0.975]\u001b[A\n",
      "Epoch 1:  75%|███████▌  | 1988/2645 [03:14<01:06,  9.95it/s, training_loss=1.015]\u001b[A\n",
      "Epoch 1:  75%|███████▌  | 1989/2645 [03:14<01:06,  9.93it/s, training_loss=1.015]\u001b[A\n",
      "Epoch 1:  75%|███████▌  | 1989/2645 [03:14<01:06,  9.93it/s, training_loss=0.209]\u001b[A\n",
      "Epoch 1:  75%|███████▌  | 1990/2645 [03:14<01:05,  9.93it/s, training_loss=0.209]\u001b[A\n",
      "Epoch 1:  75%|███████▌  | 1990/2645 [03:14<01:05,  9.93it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  75%|███████▌  | 1991/2645 [03:14<01:05,  9.92it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  75%|███████▌  | 1991/2645 [03:14<01:05,  9.92it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  75%|███████▌  | 1991/2645 [03:14<01:05,  9.92it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  75%|███████▌  | 1993/2645 [03:14<01:05, 10.00it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  75%|███████▌  | 1993/2645 [03:14<01:05, 10.00it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  75%|███████▌  | 1993/2645 [03:14<01:05, 10.00it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  75%|███████▌  | 1995/2645 [03:14<01:04, 10.01it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  75%|███████▌  | 1995/2645 [03:14<01:04, 10.01it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  75%|███████▌  | 1995/2645 [03:14<01:04, 10.01it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  76%|███████▌  | 1997/2645 [03:14<01:04, 10.08it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  76%|███████▌  | 1997/2645 [03:14<01:04, 10.08it/s, training_loss=0.612]\u001b[A\n",
      "Epoch 1:  76%|███████▌  | 1997/2645 [03:15<01:04, 10.08it/s, training_loss=0.219]\u001b[A\n",
      "Epoch 1:  76%|███████▌  | 1999/2645 [03:15<01:04,  9.98it/s, training_loss=0.219]\u001b[A\n",
      "Epoch 1:  76%|███████▌  | 1999/2645 [03:15<01:04,  9.98it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  76%|███████▌  | 1999/2645 [03:15<01:04,  9.98it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  76%|███████▌  | 2001/2645 [03:15<01:04, 10.00it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  76%|███████▌  | 2001/2645 [03:15<01:04, 10.00it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  76%|███████▌  | 2001/2645 [03:15<01:04, 10.00it/s, training_loss=0.580]\u001b[A\n",
      "Epoch 1:  76%|███████▌  | 2003/2645 [03:15<01:04, 10.00it/s, training_loss=0.580]\u001b[A\n",
      "Epoch 1:  76%|███████▌  | 2003/2645 [03:15<01:04, 10.00it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  76%|███████▌  | 2003/2645 [03:15<01:04, 10.00it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  76%|███████▌  | 2005/2645 [03:15<01:04,  9.97it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  76%|███████▌  | 2005/2645 [03:15<01:04,  9.97it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  76%|███████▌  | 2006/2645 [03:15<01:04,  9.88it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  76%|███████▌  | 2006/2645 [03:15<01:04,  9.88it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  76%|███████▌  | 2006/2645 [03:15<01:04,  9.88it/s, training_loss=0.205]\u001b[A\n",
      "Epoch 1:  76%|███████▌  | 2008/2645 [03:15<01:03,  9.99it/s, training_loss=0.205]\u001b[A\n",
      "Epoch 1:  76%|███████▌  | 2008/2645 [03:16<01:03,  9.99it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  76%|███████▌  | 2008/2645 [03:16<01:03,  9.99it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  76%|███████▌  | 2010/2645 [03:16<01:02, 10.17it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  76%|███████▌  | 2010/2645 [03:16<01:02, 10.17it/s, training_loss=0.437]\u001b[A\n",
      "Epoch 1:  76%|███████▌  | 2010/2645 [03:16<01:02, 10.17it/s, training_loss=0.024]\u001b[A\n",
      "Epoch 1:  76%|███████▌  | 2012/2645 [03:16<01:02, 10.07it/s, training_loss=0.024]\u001b[A\n",
      "Epoch 1:  76%|███████▌  | 2012/2645 [03:16<01:02, 10.07it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  76%|███████▌  | 2012/2645 [03:16<01:02, 10.07it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  76%|███████▌  | 2014/2645 [03:16<01:02, 10.08it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  76%|███████▌  | 2014/2645 [03:16<01:02, 10.08it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  76%|███████▌  | 2014/2645 [03:16<01:02, 10.08it/s, training_loss=0.850]\u001b[A\n",
      "Epoch 1:  76%|███████▌  | 2016/2645 [03:16<01:02, 10.00it/s, training_loss=0.850]\u001b[A\n",
      "Epoch 1:  76%|███████▌  | 2016/2645 [03:16<01:02, 10.00it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  76%|███████▌  | 2016/2645 [03:16<01:02, 10.00it/s, training_loss=0.193]\u001b[A\n",
      "Epoch 1:  76%|███████▋  | 2018/2645 [03:16<01:02,  9.99it/s, training_loss=0.193]\u001b[A\n",
      "Epoch 1:  76%|███████▋  | 2018/2645 [03:17<01:02,  9.99it/s, training_loss=0.823]\u001b[A\n",
      "Epoch 1:  76%|███████▋  | 2019/2645 [03:17<01:03,  9.92it/s, training_loss=0.823]\u001b[A\n",
      "Epoch 1:  76%|███████▋  | 2019/2645 [03:17<01:03,  9.92it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  76%|███████▋  | 2019/2645 [03:17<01:03,  9.92it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  76%|███████▋  | 2021/2645 [03:17<01:02, 10.03it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  76%|███████▋  | 2021/2645 [03:17<01:02, 10.03it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  76%|███████▋  | 2021/2645 [03:17<01:02, 10.03it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  76%|███████▋  | 2023/2645 [03:17<01:01, 10.07it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  76%|███████▋  | 2023/2645 [03:17<01:01, 10.07it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  76%|███████▋  | 2023/2645 [03:17<01:01, 10.07it/s, training_loss=0.099]\u001b[A\n",
      "Epoch 1:  77%|███████▋  | 2025/2645 [03:17<01:01, 10.01it/s, training_loss=0.099]\u001b[A\n",
      "Epoch 1:  77%|███████▋  | 2025/2645 [03:17<01:01, 10.01it/s, training_loss=0.820]\u001b[A\n",
      "Epoch 1:  77%|███████▋  | 2025/2645 [03:17<01:01, 10.01it/s, training_loss=0.492]\u001b[A\n",
      "Epoch 1:  77%|███████▋  | 2027/2645 [03:17<01:02,  9.94it/s, training_loss=0.492]\u001b[A\n",
      "Epoch 1:  77%|███████▋  | 2027/2645 [03:17<01:02,  9.94it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  77%|███████▋  | 2027/2645 [03:18<01:02,  9.94it/s, training_loss=0.370]\u001b[A\n",
      "Epoch 1:  77%|███████▋  | 2029/2645 [03:18<01:01,  9.95it/s, training_loss=0.370]\u001b[A\n",
      "Epoch 1:  77%|███████▋  | 2029/2645 [03:18<01:01,  9.95it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  77%|███████▋  | 2030/2645 [03:18<01:02,  9.91it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  77%|███████▋  | 2030/2645 [03:18<01:02,  9.91it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  77%|███████▋  | 2030/2645 [03:18<01:02,  9.91it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  77%|███████▋  | 2032/2645 [03:18<01:01,  9.96it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  77%|███████▋  | 2032/2645 [03:18<01:01,  9.96it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  77%|███████▋  | 2033/2645 [03:18<01:01,  9.93it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  77%|███████▋  | 2033/2645 [03:18<01:01,  9.93it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  77%|███████▋  | 2033/2645 [03:18<01:01,  9.93it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  77%|███████▋  | 2035/2645 [03:18<01:00, 10.01it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  77%|███████▋  | 2035/2645 [03:18<01:00, 10.01it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  77%|███████▋  | 2035/2645 [03:18<01:00, 10.01it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  77%|███████▋  | 2037/2645 [03:18<01:00, 10.05it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  77%|███████▋  | 2037/2645 [03:18<01:00, 10.05it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  77%|███████▋  | 2037/2645 [03:19<01:00, 10.05it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  77%|███████▋  | 2039/2645 [03:19<01:00, 10.08it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  77%|███████▋  | 2039/2645 [03:19<01:00, 10.08it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  77%|███████▋  | 2039/2645 [03:19<01:00, 10.08it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  77%|███████▋  | 2041/2645 [03:19<00:59, 10.07it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  77%|███████▋  | 2041/2645 [03:19<00:59, 10.07it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  77%|███████▋  | 2041/2645 [03:19<00:59, 10.07it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  77%|███████▋  | 2043/2645 [03:19<00:59, 10.07it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  77%|███████▋  | 2043/2645 [03:19<00:59, 10.07it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  77%|███████▋  | 2043/2645 [03:19<00:59, 10.07it/s, training_loss=0.767]\u001b[A\n",
      "Epoch 1:  77%|███████▋  | 2045/2645 [03:19<01:00, 10.00it/s, training_loss=0.767]\u001b[A\n",
      "Epoch 1:  77%|███████▋  | 2045/2645 [03:19<01:00, 10.00it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  77%|███████▋  | 2045/2645 [03:19<01:00, 10.00it/s, training_loss=0.206]\u001b[A\n",
      "Epoch 1:  77%|███████▋  | 2047/2645 [03:19<00:59, 10.09it/s, training_loss=0.206]\u001b[A\n",
      "Epoch 1:  77%|███████▋  | 2047/2645 [03:19<00:59, 10.09it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  77%|███████▋  | 2047/2645 [03:20<00:59, 10.09it/s, training_loss=1.107]\u001b[A\n",
      "Epoch 1:  77%|███████▋  | 2049/2645 [03:20<00:58, 10.12it/s, training_loss=1.107]\u001b[A\n",
      "Epoch 1:  77%|███████▋  | 2049/2645 [03:20<00:58, 10.12it/s, training_loss=0.450]\u001b[A\n",
      "Epoch 1:  77%|███████▋  | 2049/2645 [03:20<00:58, 10.12it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  78%|███████▊  | 2051/2645 [03:20<00:59,  9.98it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  78%|███████▊  | 2051/2645 [03:20<00:59,  9.98it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  78%|███████▊  | 2051/2645 [03:20<00:59,  9.98it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  78%|███████▊  | 2053/2645 [03:20<00:59, 10.02it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  78%|███████▊  | 2053/2645 [03:20<00:59, 10.02it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  78%|███████▊  | 2053/2645 [03:20<00:59, 10.02it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  78%|███████▊  | 2055/2645 [03:20<00:58, 10.01it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  78%|███████▊  | 2055/2645 [03:20<00:58, 10.01it/s, training_loss=0.631]\u001b[A\n",
      "Epoch 1:  78%|███████▊  | 2055/2645 [03:20<00:58, 10.01it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  78%|███████▊  | 2057/2645 [03:20<00:59,  9.93it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  78%|███████▊  | 2057/2645 [03:20<00:59,  9.93it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  78%|███████▊  | 2057/2645 [03:21<00:59,  9.93it/s, training_loss=0.018]\u001b[A\n",
      "Epoch 1:  78%|███████▊  | 2059/2645 [03:21<00:58, 10.00it/s, training_loss=0.018]\u001b[A\n",
      "Epoch 1:  78%|███████▊  | 2059/2645 [03:21<00:58, 10.00it/s, training_loss=0.762]\u001b[A\n",
      "Epoch 1:  78%|███████▊  | 2059/2645 [03:21<00:58, 10.00it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  78%|███████▊  | 2061/2645 [03:21<00:58, 10.06it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  78%|███████▊  | 2061/2645 [03:21<00:58, 10.06it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  78%|███████▊  | 2061/2645 [03:21<00:58, 10.06it/s, training_loss=0.614]\u001b[A\n",
      "Epoch 1:  78%|███████▊  | 2063/2645 [03:21<00:57, 10.06it/s, training_loss=0.614]\u001b[A\n",
      "Epoch 1:  78%|███████▊  | 2063/2645 [03:21<00:57, 10.06it/s, training_loss=0.252]\u001b[A\n",
      "Epoch 1:  78%|███████▊  | 2063/2645 [03:21<00:57, 10.06it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  78%|███████▊  | 2065/2645 [03:21<00:58,  9.96it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  78%|███████▊  | 2065/2645 [03:21<00:58,  9.96it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  78%|███████▊  | 2065/2645 [03:21<00:58,  9.96it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  78%|███████▊  | 2067/2645 [03:21<00:57, 10.05it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  78%|███████▊  | 2067/2645 [03:21<00:57, 10.05it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  78%|███████▊  | 2067/2645 [03:22<00:57, 10.05it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  78%|███████▊  | 2069/2645 [03:22<00:57, 10.08it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  78%|███████▊  | 2069/2645 [03:22<00:57, 10.08it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  78%|███████▊  | 2069/2645 [03:22<00:57, 10.08it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  78%|███████▊  | 2071/2645 [03:22<00:56, 10.12it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  78%|███████▊  | 2071/2645 [03:22<00:56, 10.12it/s, training_loss=0.349]\u001b[A\n",
      "Epoch 1:  78%|███████▊  | 2071/2645 [03:22<00:56, 10.12it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  78%|███████▊  | 2073/2645 [03:22<00:56, 10.10it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  78%|███████▊  | 2073/2645 [03:22<00:56, 10.10it/s, training_loss=0.734]\u001b[A\n",
      "Epoch 1:  78%|███████▊  | 2073/2645 [03:22<00:56, 10.10it/s, training_loss=0.481]\u001b[A\n",
      "Epoch 1:  78%|███████▊  | 2075/2645 [03:22<00:56, 10.01it/s, training_loss=0.481]\u001b[A\n",
      "Epoch 1:  78%|███████▊  | 2075/2645 [03:22<00:56, 10.01it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  78%|███████▊  | 2075/2645 [03:22<00:56, 10.01it/s, training_loss=0.131]\u001b[A\n",
      "Epoch 1:  79%|███████▊  | 2077/2645 [03:22<00:56,  9.99it/s, training_loss=0.131]\u001b[A\n",
      "Epoch 1:  79%|███████▊  | 2077/2645 [03:22<00:56,  9.99it/s, training_loss=0.812]\u001b[A\n",
      "Epoch 1:  79%|███████▊  | 2078/2645 [03:22<00:56,  9.98it/s, training_loss=0.812]\u001b[A\n",
      "Epoch 1:  79%|███████▊  | 2078/2645 [03:23<00:56,  9.98it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  79%|███████▊  | 2078/2645 [03:23<00:56,  9.98it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  79%|███████▊  | 2080/2645 [03:23<00:56, 10.00it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  79%|███████▊  | 2080/2645 [03:23<00:56, 10.00it/s, training_loss=0.193]\u001b[A\n",
      "Epoch 1:  79%|███████▊  | 2081/2645 [03:23<00:56,  9.93it/s, training_loss=0.193]\u001b[A\n",
      "Epoch 1:  79%|███████▊  | 2081/2645 [03:23<00:56,  9.93it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  79%|███████▊  | 2081/2645 [03:23<00:56,  9.93it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  79%|███████▉  | 2083/2645 [03:23<00:56,  9.99it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  79%|███████▉  | 2083/2645 [03:23<00:56,  9.99it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  79%|███████▉  | 2084/2645 [03:23<00:56,  9.90it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  79%|███████▉  | 2084/2645 [03:23<00:56,  9.90it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  79%|███████▉  | 2084/2645 [03:23<00:56,  9.90it/s, training_loss=0.409]\u001b[A\n",
      "Epoch 1:  79%|███████▉  | 2086/2645 [03:23<00:56,  9.98it/s, training_loss=0.409]\u001b[A\n",
      "Epoch 1:  79%|███████▉  | 2086/2645 [03:23<00:56,  9.98it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  79%|███████▉  | 2086/2645 [03:23<00:56,  9.98it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  79%|███████▉  | 2088/2645 [03:23<00:55, 10.07it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  79%|███████▉  | 2088/2645 [03:24<00:55, 10.07it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  79%|███████▉  | 2088/2645 [03:24<00:55, 10.07it/s, training_loss=0.017]\u001b[A\n",
      "Epoch 1:  79%|███████▉  | 2090/2645 [03:24<00:54, 10.11it/s, training_loss=0.017]\u001b[A\n",
      "Epoch 1:  79%|███████▉  | 2090/2645 [03:24<00:54, 10.11it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  79%|███████▉  | 2090/2645 [03:24<00:54, 10.11it/s, training_loss=0.608]\u001b[A\n",
      "Epoch 1:  79%|███████▉  | 2092/2645 [03:24<00:54, 10.08it/s, training_loss=0.608]\u001b[A\n",
      "Epoch 1:  79%|███████▉  | 2092/2645 [03:24<00:54, 10.08it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  79%|███████▉  | 2092/2645 [03:24<00:54, 10.08it/s, training_loss=0.876]\u001b[A\n",
      "Epoch 1:  79%|███████▉  | 2094/2645 [03:24<00:55, 10.00it/s, training_loss=0.876]\u001b[A\n",
      "Epoch 1:  79%|███████▉  | 2094/2645 [03:24<00:55, 10.00it/s, training_loss=0.024]\u001b[A\n",
      "Epoch 1:  79%|███████▉  | 2095/2645 [03:24<00:55,  9.97it/s, training_loss=0.024]\u001b[A\n",
      "Epoch 1:  79%|███████▉  | 2095/2645 [03:24<00:55,  9.97it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  79%|███████▉  | 2095/2645 [03:24<00:55,  9.97it/s, training_loss=0.591]\u001b[A\n",
      "Epoch 1:  79%|███████▉  | 2097/2645 [03:24<00:54, 10.00it/s, training_loss=0.591]\u001b[A\n",
      "Epoch 1:  79%|███████▉  | 2097/2645 [03:24<00:54, 10.00it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  79%|███████▉  | 2097/2645 [03:25<00:54, 10.00it/s, training_loss=0.024]\u001b[A\n",
      "Epoch 1:  79%|███████▉  | 2099/2645 [03:25<00:54, 10.01it/s, training_loss=0.024]\u001b[A\n",
      "Epoch 1:  79%|███████▉  | 2099/2645 [03:25<00:54, 10.01it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  79%|███████▉  | 2099/2645 [03:25<00:54, 10.01it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  79%|███████▉  | 2101/2645 [03:25<00:54,  9.94it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  79%|███████▉  | 2101/2645 [03:25<00:54,  9.94it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  79%|███████▉  | 2101/2645 [03:25<00:54,  9.94it/s, training_loss=0.427]\u001b[A\n",
      "Epoch 1:  80%|███████▉  | 2103/2645 [03:25<00:54,  9.99it/s, training_loss=0.427]\u001b[A\n",
      "Epoch 1:  80%|███████▉  | 2103/2645 [03:25<00:54,  9.99it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  80%|███████▉  | 2103/2645 [03:25<00:54,  9.99it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  80%|███████▉  | 2105/2645 [03:25<00:53, 10.06it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  80%|███████▉  | 2105/2645 [03:25<00:53, 10.06it/s, training_loss=0.709]\u001b[A\n",
      "Epoch 1:  80%|███████▉  | 2105/2645 [03:25<00:53, 10.06it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  80%|███████▉  | 2107/2645 [03:25<00:53, 10.01it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  80%|███████▉  | 2107/2645 [03:25<00:53, 10.01it/s, training_loss=0.369]\u001b[A\n",
      "Epoch 1:  80%|███████▉  | 2107/2645 [03:26<00:53, 10.01it/s, training_loss=0.014]\u001b[A\n",
      "Epoch 1:  80%|███████▉  | 2109/2645 [03:26<00:53,  9.97it/s, training_loss=0.014]\u001b[A\n",
      "Epoch 1:  80%|███████▉  | 2109/2645 [03:26<00:53,  9.97it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  80%|███████▉  | 2109/2645 [03:26<00:53,  9.97it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  80%|███████▉  | 2111/2645 [03:26<00:53,  9.99it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  80%|███████▉  | 2111/2645 [03:26<00:53,  9.99it/s, training_loss=0.571]\u001b[A\n",
      "Epoch 1:  80%|███████▉  | 2112/2645 [03:26<00:53,  9.92it/s, training_loss=0.571]\u001b[A\n",
      "Epoch 1:  80%|███████▉  | 2112/2645 [03:26<00:53,  9.92it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  80%|███████▉  | 2112/2645 [03:26<00:53,  9.92it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  80%|███████▉  | 2114/2645 [03:26<00:53, 10.02it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  80%|███████▉  | 2114/2645 [03:26<00:53, 10.02it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  80%|███████▉  | 2114/2645 [03:26<00:53, 10.02it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 1:  80%|████████  | 2116/2645 [03:26<00:52, 10.05it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 1:  80%|████████  | 2116/2645 [03:26<00:52, 10.05it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  80%|████████  | 2116/2645 [03:26<00:52, 10.05it/s, training_loss=0.013]\u001b[A\n",
      "Epoch 1:  80%|████████  | 2118/2645 [03:26<00:52,  9.98it/s, training_loss=0.013]\u001b[A\n",
      "Epoch 1:  80%|████████  | 2118/2645 [03:27<00:52,  9.98it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  80%|████████  | 2118/2645 [03:27<00:52,  9.98it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  80%|████████  | 2120/2645 [03:27<00:52,  9.99it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  80%|████████  | 2120/2645 [03:27<00:52,  9.99it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  80%|████████  | 2121/2645 [03:27<00:52,  9.99it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  80%|████████  | 2121/2645 [03:27<00:52,  9.99it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  80%|████████  | 2122/2645 [03:27<00:53,  9.82it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  80%|████████  | 2122/2645 [03:27<00:53,  9.82it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  80%|████████  | 2122/2645 [03:27<00:53,  9.82it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  80%|████████  | 2124/2645 [03:27<00:52,  9.90it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  80%|████████  | 2124/2645 [03:27<00:52,  9.90it/s, training_loss=0.240]\u001b[A\n",
      "Epoch 1:  80%|████████  | 2125/2645 [03:27<00:52,  9.86it/s, training_loss=0.240]\u001b[A\n",
      "Epoch 1:  80%|████████  | 2125/2645 [03:27<00:52,  9.86it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  80%|████████  | 2125/2645 [03:27<00:52,  9.86it/s, training_loss=0.218]\u001b[A\n",
      "Epoch 1:  80%|████████  | 2127/2645 [03:27<00:52,  9.93it/s, training_loss=0.218]\u001b[A\n",
      "Epoch 1:  80%|████████  | 2127/2645 [03:27<00:52,  9.93it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  80%|████████  | 2128/2645 [03:27<00:52,  9.84it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  80%|████████  | 2128/2645 [03:28<00:52,  9.84it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  80%|████████  | 2128/2645 [03:28<00:52,  9.84it/s, training_loss=1.361]\u001b[A\n",
      "Epoch 1:  81%|████████  | 2130/2645 [03:28<00:51,  9.92it/s, training_loss=1.361]\u001b[A\n",
      "Epoch 1:  81%|████████  | 2130/2645 [03:28<00:51,  9.92it/s, training_loss=0.357]\u001b[A\n",
      "Epoch 1:  81%|████████  | 2131/2645 [03:28<00:52,  9.76it/s, training_loss=0.357]\u001b[A\n",
      "Epoch 1:  81%|████████  | 2131/2645 [03:28<00:52,  9.76it/s, training_loss=0.211]\u001b[A\n",
      "Epoch 1:  81%|████████  | 2132/2645 [03:28<00:52,  9.80it/s, training_loss=0.211]\u001b[A\n",
      "Epoch 1:  81%|████████  | 2132/2645 [03:28<00:52,  9.80it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  81%|████████  | 2132/2645 [03:28<00:52,  9.80it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  81%|████████  | 2134/2645 [03:28<00:51,  9.92it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  81%|████████  | 2134/2645 [03:28<00:51,  9.92it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  81%|████████  | 2134/2645 [03:28<00:51,  9.92it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  81%|████████  | 2136/2645 [03:28<00:50, 10.15it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  81%|████████  | 2136/2645 [03:28<00:50, 10.15it/s, training_loss=0.013]\u001b[A\n",
      "Epoch 1:  81%|████████  | 2136/2645 [03:28<00:50, 10.15it/s, training_loss=0.816]\u001b[A\n",
      "Epoch 1:  81%|████████  | 2138/2645 [03:28<00:50, 10.13it/s, training_loss=0.816]\u001b[A\n",
      "Epoch 1:  81%|████████  | 2138/2645 [03:29<00:50, 10.13it/s, training_loss=0.019]\u001b[A\n",
      "Epoch 1:  81%|████████  | 2138/2645 [03:29<00:50, 10.13it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  81%|████████  | 2140/2645 [03:29<00:49, 10.18it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  81%|████████  | 2140/2645 [03:29<00:49, 10.18it/s, training_loss=0.076]\u001b[A\n",
      "Epoch 1:  81%|████████  | 2140/2645 [03:29<00:49, 10.18it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  81%|████████  | 2142/2645 [03:29<00:49, 10.06it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  81%|████████  | 2142/2645 [03:29<00:49, 10.06it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  81%|████████  | 2142/2645 [03:29<00:49, 10.06it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  81%|████████  | 2144/2645 [03:29<00:49, 10.12it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  81%|████████  | 2144/2645 [03:29<00:49, 10.12it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  81%|████████  | 2144/2645 [03:29<00:49, 10.12it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  81%|████████  | 2146/2645 [03:29<00:48, 10.19it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  81%|████████  | 2146/2645 [03:29<00:48, 10.19it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  81%|████████  | 2146/2645 [03:29<00:48, 10.19it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  81%|████████  | 2148/2645 [03:29<00:48, 10.21it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  81%|████████  | 2148/2645 [03:30<00:48, 10.21it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  81%|████████  | 2148/2645 [03:30<00:48, 10.21it/s, training_loss=0.778]\u001b[A\n",
      "Epoch 1:  81%|████████▏ | 2150/2645 [03:30<00:48, 10.17it/s, training_loss=0.778]\u001b[A\n",
      "Epoch 1:  81%|████████▏ | 2150/2645 [03:30<00:48, 10.17it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  81%|████████▏ | 2150/2645 [03:30<00:48, 10.17it/s, training_loss=0.049]\u001b[A\n",
      "Epoch 1:  81%|████████▏ | 2152/2645 [03:30<00:48, 10.19it/s, training_loss=0.049]\u001b[A\n",
      "Epoch 1:  81%|████████▏ | 2152/2645 [03:30<00:48, 10.19it/s, training_loss=0.669]\u001b[A\n",
      "Epoch 1:  81%|████████▏ | 2152/2645 [03:30<00:48, 10.19it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  81%|████████▏ | 2154/2645 [03:30<00:48, 10.13it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  81%|████████▏ | 2154/2645 [03:30<00:48, 10.13it/s, training_loss=0.010]\u001b[A\n",
      "Epoch 1:  81%|████████▏ | 2154/2645 [03:30<00:48, 10.13it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  82%|████████▏ | 2156/2645 [03:30<00:48, 10.07it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  82%|████████▏ | 2156/2645 [03:30<00:48, 10.07it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  82%|████████▏ | 2156/2645 [03:30<00:48, 10.07it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  82%|████████▏ | 2158/2645 [03:30<00:48, 10.12it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  82%|████████▏ | 2158/2645 [03:31<00:48, 10.12it/s, training_loss=0.374]\u001b[A\n",
      "Epoch 1:  82%|████████▏ | 2158/2645 [03:31<00:48, 10.12it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  82%|████████▏ | 2160/2645 [03:31<00:48, 10.09it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  82%|████████▏ | 2160/2645 [03:31<00:48, 10.09it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  82%|████████▏ | 2160/2645 [03:31<00:48, 10.09it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 1:  82%|████████▏ | 2162/2645 [03:31<00:48,  9.89it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 1:  82%|████████▏ | 2162/2645 [03:31<00:48,  9.89it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  82%|████████▏ | 2162/2645 [03:31<00:48,  9.89it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  82%|████████▏ | 2164/2645 [03:31<00:48,  9.99it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  82%|████████▏ | 2164/2645 [03:31<00:48,  9.99it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  82%|████████▏ | 2164/2645 [03:31<00:48,  9.99it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  82%|████████▏ | 2166/2645 [03:31<00:47, 10.14it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  82%|████████▏ | 2166/2645 [03:31<00:47, 10.14it/s, training_loss=0.528]\u001b[A\n",
      "Epoch 1:  82%|████████▏ | 2166/2645 [03:31<00:47, 10.14it/s, training_loss=0.042]\u001b[A\n",
      "Epoch 1:  82%|████████▏ | 2168/2645 [03:31<00:47, 10.11it/s, training_loss=0.042]\u001b[A\n",
      "Epoch 1:  82%|████████▏ | 2168/2645 [03:32<00:47, 10.11it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  82%|████████▏ | 2168/2645 [03:32<00:47, 10.11it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  82%|████████▏ | 2170/2645 [03:32<00:46, 10.17it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  82%|████████▏ | 2170/2645 [03:32<00:46, 10.17it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  82%|████████▏ | 2170/2645 [03:32<00:46, 10.17it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  82%|████████▏ | 2172/2645 [03:32<00:46, 10.17it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  82%|████████▏ | 2172/2645 [03:32<00:46, 10.17it/s, training_loss=0.017]\u001b[A\n",
      "Epoch 1:  82%|████████▏ | 2172/2645 [03:32<00:46, 10.17it/s, training_loss=0.146]\u001b[A\n",
      "Epoch 1:  82%|████████▏ | 2174/2645 [03:32<00:46, 10.05it/s, training_loss=0.146]\u001b[A\n",
      "Epoch 1:  82%|████████▏ | 2174/2645 [03:32<00:46, 10.05it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  82%|████████▏ | 2174/2645 [03:32<00:46, 10.05it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  82%|████████▏ | 2176/2645 [03:32<00:46, 10.10it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  82%|████████▏ | 2176/2645 [03:32<00:46, 10.10it/s, training_loss=0.097]\u001b[A\n",
      "Epoch 1:  82%|████████▏ | 2176/2645 [03:32<00:46, 10.10it/s, training_loss=0.549]\u001b[A\n",
      "Epoch 1:  82%|████████▏ | 2178/2645 [03:32<00:46, 10.13it/s, training_loss=0.549]\u001b[A\n",
      "Epoch 1:  82%|████████▏ | 2178/2645 [03:33<00:46, 10.13it/s, training_loss=0.175]\u001b[A\n",
      "Epoch 1:  82%|████████▏ | 2178/2645 [03:33<00:46, 10.13it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  82%|████████▏ | 2180/2645 [03:33<00:46, 10.08it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  82%|████████▏ | 2180/2645 [03:33<00:46, 10.08it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  82%|████████▏ | 2180/2645 [03:33<00:46, 10.08it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  82%|████████▏ | 2182/2645 [03:33<00:46, 10.04it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  82%|████████▏ | 2182/2645 [03:33<00:46, 10.04it/s, training_loss=0.062]\u001b[A\n",
      "Epoch 1:  82%|████████▏ | 2182/2645 [03:33<00:46, 10.04it/s, training_loss=0.013]\u001b[A\n",
      "Epoch 1:  83%|████████▎ | 2184/2645 [03:33<00:46,  9.97it/s, training_loss=0.013]\u001b[A\n",
      "Epoch 1:  83%|████████▎ | 2184/2645 [03:33<00:46,  9.97it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  83%|████████▎ | 2184/2645 [03:33<00:46,  9.97it/s, training_loss=0.074]\u001b[A\n",
      "Epoch 1:  83%|████████▎ | 2186/2645 [03:33<00:45, 10.03it/s, training_loss=0.074]\u001b[A\n",
      "Epoch 1:  83%|████████▎ | 2186/2645 [03:33<00:45, 10.03it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  83%|████████▎ | 2186/2645 [03:33<00:45, 10.03it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  83%|████████▎ | 2188/2645 [03:33<00:44, 10.23it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  83%|████████▎ | 2188/2645 [03:33<00:44, 10.23it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  83%|████████▎ | 2188/2645 [03:34<00:44, 10.23it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  83%|████████▎ | 2190/2645 [03:34<00:44, 10.25it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  83%|████████▎ | 2190/2645 [03:34<00:44, 10.25it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  83%|████████▎ | 2190/2645 [03:34<00:44, 10.25it/s, training_loss=0.864]\u001b[A\n",
      "Epoch 1:  83%|████████▎ | 2192/2645 [03:34<00:44, 10.24it/s, training_loss=0.864]\u001b[A\n",
      "Epoch 1:  83%|████████▎ | 2192/2645 [03:34<00:44, 10.24it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  83%|████████▎ | 2192/2645 [03:34<00:44, 10.24it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  83%|████████▎ | 2194/2645 [03:34<00:44, 10.13it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  83%|████████▎ | 2194/2645 [03:34<00:44, 10.13it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  83%|████████▎ | 2194/2645 [03:34<00:44, 10.13it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  83%|████████▎ | 2196/2645 [03:34<00:44, 10.16it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  83%|████████▎ | 2196/2645 [03:34<00:44, 10.16it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  83%|████████▎ | 2196/2645 [03:34<00:44, 10.16it/s, training_loss=0.273]\u001b[A\n",
      "Epoch 1:  83%|████████▎ | 2198/2645 [03:34<00:43, 10.18it/s, training_loss=0.273]\u001b[A\n",
      "Epoch 1:  83%|████████▎ | 2198/2645 [03:34<00:43, 10.18it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  83%|████████▎ | 2198/2645 [03:35<00:43, 10.18it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  83%|████████▎ | 2200/2645 [03:35<00:43, 10.20it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  83%|████████▎ | 2200/2645 [03:35<00:43, 10.20it/s, training_loss=0.693]\u001b[A\n",
      "Epoch 1:  83%|████████▎ | 2200/2645 [03:35<00:43, 10.20it/s, training_loss=0.161]\u001b[A\n",
      "Epoch 1:  83%|████████▎ | 2202/2645 [03:35<00:43, 10.15it/s, training_loss=0.161]\u001b[A\n",
      "Epoch 1:  83%|████████▎ | 2202/2645 [03:35<00:43, 10.15it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  83%|████████▎ | 2202/2645 [03:35<00:43, 10.15it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  83%|████████▎ | 2204/2645 [03:35<00:42, 10.26it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  83%|████████▎ | 2204/2645 [03:35<00:42, 10.26it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  83%|████████▎ | 2204/2645 [03:35<00:42, 10.26it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  83%|████████▎ | 2206/2645 [03:35<00:42, 10.34it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  83%|████████▎ | 2206/2645 [03:35<00:42, 10.34it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  83%|████████▎ | 2206/2645 [03:35<00:42, 10.34it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  83%|████████▎ | 2208/2645 [03:35<00:41, 10.42it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  83%|████████▎ | 2208/2645 [03:35<00:41, 10.42it/s, training_loss=0.490]\u001b[A\n",
      "Epoch 1:  83%|████████▎ | 2208/2645 [03:36<00:41, 10.42it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  84%|████████▎ | 2210/2645 [03:36<00:41, 10.42it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  84%|████████▎ | 2210/2645 [03:36<00:41, 10.42it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  84%|████████▎ | 2210/2645 [03:36<00:41, 10.42it/s, training_loss=0.336]\u001b[A\n",
      "Epoch 1:  84%|████████▎ | 2212/2645 [03:36<00:41, 10.37it/s, training_loss=0.336]\u001b[A\n",
      "Epoch 1:  84%|████████▎ | 2212/2645 [03:36<00:41, 10.37it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  84%|████████▎ | 2212/2645 [03:36<00:41, 10.37it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  84%|████████▎ | 2214/2645 [03:36<00:41, 10.42it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  84%|████████▎ | 2214/2645 [03:36<00:41, 10.42it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  84%|████████▎ | 2214/2645 [03:36<00:41, 10.42it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 2216/2645 [03:36<00:41, 10.43it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 2216/2645 [03:36<00:41, 10.43it/s, training_loss=0.453]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 2216/2645 [03:36<00:41, 10.43it/s, training_loss=0.014]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 2218/2645 [03:36<00:41, 10.37it/s, training_loss=0.014]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 2218/2645 [03:36<00:41, 10.37it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 2218/2645 [03:36<00:41, 10.37it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 2220/2645 [03:36<00:40, 10.40it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 2220/2645 [03:37<00:40, 10.40it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 2220/2645 [03:37<00:40, 10.40it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 2222/2645 [03:37<00:40, 10.39it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 2222/2645 [03:37<00:40, 10.39it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 2222/2645 [03:37<00:40, 10.39it/s, training_loss=0.361]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 2224/2645 [03:37<00:40, 10.32it/s, training_loss=0.361]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 2224/2645 [03:37<00:40, 10.32it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 2224/2645 [03:37<00:40, 10.32it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 2226/2645 [03:37<00:40, 10.30it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 2226/2645 [03:37<00:40, 10.30it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 2226/2645 [03:37<00:40, 10.30it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 2228/2645 [03:37<00:40, 10.36it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 2228/2645 [03:37<00:40, 10.36it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 2228/2645 [03:37<00:40, 10.36it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 2230/2645 [03:37<00:39, 10.42it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 2230/2645 [03:38<00:39, 10.42it/s, training_loss=0.042]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 2230/2645 [03:38<00:39, 10.42it/s, training_loss=0.526]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 2232/2645 [03:38<00:39, 10.42it/s, training_loss=0.526]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 2232/2645 [03:38<00:39, 10.42it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 2232/2645 [03:38<00:39, 10.42it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 2234/2645 [03:38<00:39, 10.48it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 2234/2645 [03:38<00:39, 10.48it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 2234/2645 [03:38<00:39, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  85%|████████▍ | 2236/2645 [03:38<00:38, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  85%|████████▍ | 2236/2645 [03:38<00:38, 10.51it/s, training_loss=0.903]\u001b[A\n",
      "Epoch 1:  85%|████████▍ | 2236/2645 [03:38<00:38, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  85%|████████▍ | 2238/2645 [03:38<00:38, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  85%|████████▍ | 2238/2645 [03:38<00:38, 10.46it/s, training_loss=0.062]\u001b[A\n",
      "Epoch 1:  85%|████████▍ | 2238/2645 [03:38<00:38, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  85%|████████▍ | 2240/2645 [03:38<00:38, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  85%|████████▍ | 2240/2645 [03:39<00:38, 10.43it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  85%|████████▍ | 2240/2645 [03:39<00:38, 10.43it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  85%|████████▍ | 2242/2645 [03:39<00:39, 10.31it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  85%|████████▍ | 2242/2645 [03:39<00:39, 10.31it/s, training_loss=0.012]\u001b[A\n",
      "Epoch 1:  85%|████████▍ | 2242/2645 [03:39<00:39, 10.31it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  85%|████████▍ | 2244/2645 [03:39<00:38, 10.30it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  85%|████████▍ | 2244/2645 [03:39<00:38, 10.30it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  85%|████████▍ | 2244/2645 [03:39<00:38, 10.30it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  85%|████████▍ | 2246/2645 [03:39<00:38, 10.33it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  85%|████████▍ | 2246/2645 [03:39<00:38, 10.33it/s, training_loss=0.880]\u001b[A\n",
      "Epoch 1:  85%|████████▍ | 2246/2645 [03:39<00:38, 10.33it/s, training_loss=1.639]\u001b[A\n",
      "Epoch 1:  85%|████████▍ | 2248/2645 [03:39<00:38, 10.31it/s, training_loss=1.639]\u001b[A\n",
      "Epoch 1:  85%|████████▍ | 2248/2645 [03:39<00:38, 10.31it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  85%|████████▍ | 2248/2645 [03:39<00:38, 10.31it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  85%|████████▌ | 2250/2645 [03:39<00:38, 10.35it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  85%|████████▌ | 2250/2645 [03:39<00:38, 10.35it/s, training_loss=0.051]\u001b[A\n",
      "Epoch 1:  85%|████████▌ | 2250/2645 [03:40<00:38, 10.35it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  85%|████████▌ | 2252/2645 [03:40<00:38, 10.21it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  85%|████████▌ | 2252/2645 [03:40<00:38, 10.21it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  85%|████████▌ | 2252/2645 [03:40<00:38, 10.21it/s, training_loss=0.215]\u001b[A\n",
      "Epoch 1:  85%|████████▌ | 2254/2645 [03:40<00:38, 10.22it/s, training_loss=0.215]\u001b[A\n",
      "Epoch 1:  85%|████████▌ | 2254/2645 [03:40<00:38, 10.22it/s, training_loss=0.521]\u001b[A\n",
      "Epoch 1:  85%|████████▌ | 2254/2645 [03:40<00:38, 10.22it/s, training_loss=0.361]\u001b[A\n",
      "Epoch 1:  85%|████████▌ | 2256/2645 [03:40<00:38, 10.16it/s, training_loss=0.361]\u001b[A\n",
      "Epoch 1:  85%|████████▌ | 2256/2645 [03:40<00:38, 10.16it/s, training_loss=0.252]\u001b[A\n",
      "Epoch 1:  85%|████████▌ | 2256/2645 [03:40<00:38, 10.16it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  85%|████████▌ | 2258/2645 [03:40<00:38, 10.13it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  85%|████████▌ | 2258/2645 [03:40<00:38, 10.13it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  85%|████████▌ | 2258/2645 [03:40<00:38, 10.13it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  85%|████████▌ | 2260/2645 [03:40<00:37, 10.19it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  85%|████████▌ | 2260/2645 [03:40<00:37, 10.19it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  85%|████████▌ | 2260/2645 [03:41<00:37, 10.19it/s, training_loss=0.092]\u001b[A\n",
      "Epoch 1:  86%|████████▌ | 2262/2645 [03:41<00:37, 10.28it/s, training_loss=0.092]\u001b[A\n",
      "Epoch 1:  86%|████████▌ | 2262/2645 [03:41<00:37, 10.28it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  86%|████████▌ | 2262/2645 [03:41<00:37, 10.28it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  86%|████████▌ | 2264/2645 [03:41<00:36, 10.31it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  86%|████████▌ | 2264/2645 [03:41<00:36, 10.31it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  86%|████████▌ | 2264/2645 [03:41<00:36, 10.31it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  86%|████████▌ | 2266/2645 [03:41<00:36, 10.40it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  86%|████████▌ | 2266/2645 [03:41<00:36, 10.40it/s, training_loss=0.223]\u001b[A\n",
      "Epoch 1:  86%|████████▌ | 2266/2645 [03:41<00:36, 10.40it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  86%|████████▌ | 2268/2645 [03:41<00:36, 10.40it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  86%|████████▌ | 2268/2645 [03:41<00:36, 10.40it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  86%|████████▌ | 2268/2645 [03:41<00:36, 10.40it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  86%|████████▌ | 2270/2645 [03:41<00:35, 10.44it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  86%|████████▌ | 2270/2645 [03:41<00:35, 10.44it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  86%|████████▌ | 2270/2645 [03:42<00:35, 10.44it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  86%|████████▌ | 2272/2645 [03:42<00:35, 10.42it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  86%|████████▌ | 2272/2645 [03:42<00:35, 10.42it/s, training_loss=0.647]\u001b[A\n",
      "Epoch 1:  86%|████████▌ | 2272/2645 [03:42<00:35, 10.42it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  86%|████████▌ | 2274/2645 [03:42<00:35, 10.39it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  86%|████████▌ | 2274/2645 [03:42<00:35, 10.39it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  86%|████████▌ | 2274/2645 [03:42<00:35, 10.39it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  86%|████████▌ | 2276/2645 [03:42<00:35, 10.38it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  86%|████████▌ | 2276/2645 [03:42<00:35, 10.38it/s, training_loss=0.212]\u001b[A\n",
      "Epoch 1:  86%|████████▌ | 2276/2645 [03:42<00:35, 10.38it/s, training_loss=1.024]\u001b[A\n",
      "Epoch 1:  86%|████████▌ | 2278/2645 [03:42<00:35, 10.26it/s, training_loss=1.024]\u001b[A\n",
      "Epoch 1:  86%|████████▌ | 2278/2645 [03:42<00:35, 10.26it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  86%|████████▌ | 2278/2645 [03:42<00:35, 10.26it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  86%|████████▌ | 2280/2645 [03:42<00:35, 10.27it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  86%|████████▌ | 2280/2645 [03:42<00:35, 10.27it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  86%|████████▌ | 2280/2645 [03:42<00:35, 10.27it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  86%|████████▋ | 2282/2645 [03:42<00:35, 10.24it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  86%|████████▋ | 2282/2645 [03:43<00:35, 10.24it/s, training_loss=0.710]\u001b[A\n",
      "Epoch 1:  86%|████████▋ | 2282/2645 [03:43<00:35, 10.24it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  86%|████████▋ | 2284/2645 [03:43<00:35, 10.23it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  86%|████████▋ | 2284/2645 [03:43<00:35, 10.23it/s, training_loss=0.035]\u001b[A\n",
      "Epoch 1:  86%|████████▋ | 2284/2645 [03:43<00:35, 10.23it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  86%|████████▋ | 2286/2645 [03:43<00:35, 10.18it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  86%|████████▋ | 2286/2645 [03:43<00:35, 10.18it/s, training_loss=0.435]\u001b[A\n",
      "Epoch 1:  86%|████████▋ | 2286/2645 [03:43<00:35, 10.18it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 2288/2645 [03:43<00:35, 10.18it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 2288/2645 [03:43<00:35, 10.18it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 2288/2645 [03:43<00:35, 10.18it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 2290/2645 [03:43<00:34, 10.23it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 2290/2645 [03:43<00:34, 10.23it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 2290/2645 [03:43<00:34, 10.23it/s, training_loss=0.031]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 2292/2645 [03:43<00:34, 10.28it/s, training_loss=0.031]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 2292/2645 [03:44<00:34, 10.28it/s, training_loss=0.804]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 2292/2645 [03:44<00:34, 10.28it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 2294/2645 [03:44<00:33, 10.35it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 2294/2645 [03:44<00:33, 10.35it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 2294/2645 [03:44<00:33, 10.35it/s, training_loss=0.765]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 2296/2645 [03:44<00:33, 10.38it/s, training_loss=0.765]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 2296/2645 [03:44<00:33, 10.38it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 2296/2645 [03:44<00:33, 10.38it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 2298/2645 [03:44<00:33, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 2298/2645 [03:44<00:33, 10.45it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 2298/2645 [03:44<00:33, 10.45it/s, training_loss=0.535]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 2300/2645 [03:44<00:33, 10.42it/s, training_loss=0.535]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 2300/2645 [03:44<00:33, 10.42it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 2300/2645 [03:44<00:33, 10.42it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 2302/2645 [03:44<00:32, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 2302/2645 [03:45<00:32, 10.44it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 2302/2645 [03:45<00:32, 10.44it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 2304/2645 [03:45<00:32, 10.41it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 2304/2645 [03:45<00:32, 10.41it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 2304/2645 [03:45<00:32, 10.41it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 2306/2645 [03:45<00:32, 10.38it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 2306/2645 [03:45<00:32, 10.38it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 2306/2645 [03:45<00:32, 10.38it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 2308/2645 [03:45<00:32, 10.35it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 2308/2645 [03:45<00:32, 10.35it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 2308/2645 [03:45<00:32, 10.35it/s, training_loss=0.310]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 2310/2645 [03:45<00:32, 10.27it/s, training_loss=0.310]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 2310/2645 [03:45<00:32, 10.27it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 2310/2645 [03:45<00:32, 10.27it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 2312/2645 [03:45<00:32, 10.34it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 2312/2645 [03:45<00:32, 10.34it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 2312/2645 [03:46<00:32, 10.34it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 2314/2645 [03:46<00:32, 10.34it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 2314/2645 [03:46<00:32, 10.34it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 2314/2645 [03:46<00:32, 10.34it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 2316/2645 [03:46<00:31, 10.36it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 2316/2645 [03:46<00:31, 10.36it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 2316/2645 [03:46<00:31, 10.36it/s, training_loss=0.787]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 2318/2645 [03:46<00:31, 10.36it/s, training_loss=0.787]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 2318/2645 [03:46<00:31, 10.36it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 2318/2645 [03:46<00:31, 10.36it/s, training_loss=0.011]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 2320/2645 [03:46<00:31, 10.32it/s, training_loss=0.011]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 2320/2645 [03:46<00:31, 10.32it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 2320/2645 [03:46<00:31, 10.32it/s, training_loss=0.778]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 2322/2645 [03:46<00:31, 10.36it/s, training_loss=0.778]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 2322/2645 [03:46<00:31, 10.36it/s, training_loss=0.048]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 2322/2645 [03:47<00:31, 10.36it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 2324/2645 [03:47<00:30, 10.39it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 2324/2645 [03:47<00:30, 10.39it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 2324/2645 [03:47<00:30, 10.39it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 2326/2645 [03:47<00:30, 10.45it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 2326/2645 [03:47<00:30, 10.45it/s, training_loss=0.053]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 2326/2645 [03:47<00:30, 10.45it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 2328/2645 [03:47<00:30, 10.37it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 2328/2645 [03:47<00:30, 10.37it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 2328/2645 [03:47<00:30, 10.37it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 2330/2645 [03:47<00:30, 10.40it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 2330/2645 [03:47<00:30, 10.40it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 2330/2645 [03:47<00:30, 10.40it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 2332/2645 [03:47<00:30, 10.38it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 2332/2645 [03:47<00:30, 10.38it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 2332/2645 [03:48<00:30, 10.38it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 2334/2645 [03:48<00:30, 10.30it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 2334/2645 [03:48<00:30, 10.30it/s, training_loss=0.093]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 2334/2645 [03:48<00:30, 10.30it/s, training_loss=0.607]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 2336/2645 [03:48<00:30, 10.17it/s, training_loss=0.607]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 2336/2645 [03:48<00:30, 10.17it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 2336/2645 [03:48<00:30, 10.17it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 2338/2645 [03:48<00:30, 10.08it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 2338/2645 [03:48<00:30, 10.08it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 2338/2645 [03:48<00:30, 10.08it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 2340/2645 [03:48<00:30, 10.07it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 2340/2645 [03:48<00:30, 10.07it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 2340/2645 [03:48<00:30, 10.07it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  89%|████████▊ | 2342/2645 [03:48<00:30, 10.08it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  89%|████████▊ | 2342/2645 [03:48<00:30, 10.08it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  89%|████████▊ | 2342/2645 [03:49<00:30, 10.08it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  89%|████████▊ | 2344/2645 [03:49<00:29, 10.08it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  89%|████████▊ | 2344/2645 [03:49<00:29, 10.08it/s, training_loss=0.855]\u001b[A\n",
      "Epoch 1:  89%|████████▊ | 2344/2645 [03:49<00:29, 10.08it/s, training_loss=0.428]\u001b[A\n",
      "Epoch 1:  89%|████████▊ | 2346/2645 [03:49<00:29, 10.03it/s, training_loss=0.428]\u001b[A\n",
      "Epoch 1:  89%|████████▊ | 2346/2645 [03:49<00:29, 10.03it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  89%|████████▊ | 2346/2645 [03:49<00:29, 10.03it/s, training_loss=0.010]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 2348/2645 [03:49<00:29, 10.06it/s, training_loss=0.010]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 2348/2645 [03:49<00:29, 10.06it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 2348/2645 [03:49<00:29, 10.06it/s, training_loss=0.704]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 2350/2645 [03:49<00:29,  9.96it/s, training_loss=0.704]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 2350/2645 [03:49<00:29,  9.96it/s, training_loss=0.486]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 2351/2645 [03:49<00:29,  9.96it/s, training_loss=0.486]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 2351/2645 [03:49<00:29,  9.96it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 2351/2645 [03:49<00:29,  9.96it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 2353/2645 [03:49<00:29, 10.04it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 2353/2645 [03:50<00:29, 10.04it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 2353/2645 [03:50<00:29, 10.04it/s, training_loss=0.044]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 2355/2645 [03:50<00:28, 10.05it/s, training_loss=0.044]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 2355/2645 [03:50<00:28, 10.05it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 2355/2645 [03:50<00:28, 10.05it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 2357/2645 [03:50<00:28, 10.05it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 2357/2645 [03:50<00:28, 10.05it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 2357/2645 [03:50<00:28, 10.05it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 2359/2645 [03:50<00:28, 10.04it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 2359/2645 [03:50<00:28, 10.04it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 2359/2645 [03:50<00:28, 10.04it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 2361/2645 [03:50<00:28,  9.99it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 2361/2645 [03:50<00:28,  9.99it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 2362/2645 [03:50<00:28,  9.86it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 2362/2645 [03:50<00:28,  9.86it/s, training_loss=0.938]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 2363/2645 [03:50<00:28,  9.88it/s, training_loss=0.938]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 2363/2645 [03:51<00:28,  9.88it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 2363/2645 [03:51<00:28,  9.88it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 2365/2645 [03:51<00:28,  9.92it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 2365/2645 [03:51<00:28,  9.92it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 2366/2645 [03:51<00:28,  9.94it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 2366/2645 [03:51<00:28,  9.94it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 2367/2645 [03:51<00:28,  9.91it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 2367/2645 [03:51<00:28,  9.91it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  90%|████████▉ | 2368/2645 [03:51<00:27,  9.92it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  90%|████████▉ | 2368/2645 [03:51<00:27,  9.92it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  90%|████████▉ | 2369/2645 [03:51<00:27,  9.88it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  90%|████████▉ | 2369/2645 [03:51<00:27,  9.88it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  90%|████████▉ | 2369/2645 [03:51<00:27,  9.88it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  90%|████████▉ | 2371/2645 [03:51<00:27,  9.98it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  90%|████████▉ | 2371/2645 [03:51<00:27,  9.98it/s, training_loss=0.070]\u001b[A\n",
      "Epoch 1:  90%|████████▉ | 2372/2645 [03:51<00:27,  9.96it/s, training_loss=0.070]\u001b[A\n",
      "Epoch 1:  90%|████████▉ | 2372/2645 [03:51<00:27,  9.96it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  90%|████████▉ | 2372/2645 [03:52<00:27,  9.96it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  90%|████████▉ | 2374/2645 [03:52<00:27, 10.03it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  90%|████████▉ | 2374/2645 [03:52<00:27, 10.03it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  90%|████████▉ | 2374/2645 [03:52<00:27, 10.03it/s, training_loss=0.394]\u001b[A\n",
      "Epoch 1:  90%|████████▉ | 2376/2645 [03:52<00:27,  9.96it/s, training_loss=0.394]\u001b[A\n",
      "Epoch 1:  90%|████████▉ | 2376/2645 [03:52<00:27,  9.96it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  90%|████████▉ | 2377/2645 [03:52<00:26,  9.96it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  90%|████████▉ | 2377/2645 [03:52<00:26,  9.96it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  90%|████████▉ | 2377/2645 [03:52<00:26,  9.96it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  90%|████████▉ | 2379/2645 [03:52<00:26,  9.91it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  90%|████████▉ | 2379/2645 [03:52<00:26,  9.91it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  90%|████████▉ | 2379/2645 [03:52<00:26,  9.91it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  90%|█████████ | 2381/2645 [03:52<00:26,  9.96it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  90%|█████████ | 2381/2645 [03:52<00:26,  9.96it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  90%|█████████ | 2381/2645 [03:52<00:26,  9.96it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  90%|█████████ | 2383/2645 [03:52<00:26,  9.99it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  90%|█████████ | 2383/2645 [03:53<00:26,  9.99it/s, training_loss=1.282]\u001b[A\n",
      "Epoch 1:  90%|█████████ | 2384/2645 [03:53<00:26,  9.84it/s, training_loss=1.282]\u001b[A\n",
      "Epoch 1:  90%|█████████ | 2384/2645 [03:53<00:26,  9.84it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  90%|█████████ | 2384/2645 [03:53<00:26,  9.84it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  90%|█████████ | 2386/2645 [03:53<00:26,  9.90it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  90%|█████████ | 2386/2645 [03:53<00:26,  9.90it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  90%|█████████ | 2387/2645 [03:53<00:27,  9.31it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  90%|█████████ | 2387/2645 [03:53<00:27,  9.31it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  90%|█████████ | 2388/2645 [03:53<00:27,  9.39it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  90%|█████████ | 2388/2645 [03:53<00:27,  9.39it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  90%|█████████ | 2389/2645 [03:53<00:26,  9.50it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  90%|█████████ | 2389/2645 [03:53<00:26,  9.50it/s, training_loss=0.153]\u001b[A\n",
      "Epoch 1:  90%|█████████ | 2390/2645 [03:53<00:27,  9.33it/s, training_loss=0.153]\u001b[A\n",
      "Epoch 1:  90%|█████████ | 2390/2645 [03:53<00:27,  9.33it/s, training_loss=0.018]\u001b[A\n",
      "Epoch 1:  90%|█████████ | 2391/2645 [03:53<00:27,  9.19it/s, training_loss=0.018]\u001b[A\n",
      "Epoch 1:  90%|█████████ | 2391/2645 [03:53<00:27,  9.19it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  90%|█████████ | 2392/2645 [03:53<00:27,  9.20it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  90%|█████████ | 2392/2645 [03:54<00:27,  9.20it/s, training_loss=0.823]\u001b[A\n",
      "Epoch 1:  90%|█████████ | 2393/2645 [03:54<00:27,  9.13it/s, training_loss=0.823]\u001b[A\n",
      "Epoch 1:  90%|█████████ | 2393/2645 [03:54<00:27,  9.13it/s, training_loss=0.512]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 2394/2645 [03:54<00:27,  9.02it/s, training_loss=0.512]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 2394/2645 [03:54<00:27,  9.02it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 2395/2645 [03:54<00:27,  9.14it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 2395/2645 [03:54<00:27,  9.14it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 2396/2645 [03:54<00:26,  9.26it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 2396/2645 [03:54<00:26,  9.26it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 2397/2645 [03:54<00:26,  9.26it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 2397/2645 [03:54<00:26,  9.26it/s, training_loss=0.258]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 2398/2645 [03:54<00:26,  9.15it/s, training_loss=0.258]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 2398/2645 [03:54<00:26,  9.15it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 2399/2645 [03:54<00:27,  9.05it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 2399/2645 [03:54<00:27,  9.05it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 2400/2645 [03:54<00:26,  9.13it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 2400/2645 [03:54<00:26,  9.13it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 2401/2645 [03:54<00:26,  9.26it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 2401/2645 [03:54<00:26,  9.26it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 2402/2645 [03:54<00:25,  9.36it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 2402/2645 [03:55<00:25,  9.36it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 2403/2645 [03:55<00:25,  9.43it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 2403/2645 [03:55<00:25,  9.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 2404/2645 [03:55<00:25,  9.53it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 2404/2645 [03:55<00:25,  9.53it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 2405/2645 [03:55<00:25,  9.40it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 2405/2645 [03:55<00:25,  9.40it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 2406/2645 [03:55<00:25,  9.48it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 2406/2645 [03:55<00:25,  9.48it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 2407/2645 [03:55<00:24,  9.57it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 2407/2645 [03:55<00:24,  9.57it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 2408/2645 [03:55<00:24,  9.61it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 2408/2645 [03:55<00:24,  9.61it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 2409/2645 [03:55<00:24,  9.61it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 2409/2645 [03:55<00:24,  9.61it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 2410/2645 [03:55<00:24,  9.44it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 2410/2645 [03:55<00:24,  9.44it/s, training_loss=0.023]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 2411/2645 [03:55<00:24,  9.48it/s, training_loss=0.023]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 2411/2645 [03:56<00:24,  9.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 2412/2645 [03:56<00:24,  9.58it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 2412/2645 [03:56<00:24,  9.58it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 2413/2645 [03:56<00:24,  9.57it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 2413/2645 [03:56<00:24,  9.57it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  91%|█████████▏| 2414/2645 [03:56<00:24,  9.58it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  91%|█████████▏| 2414/2645 [03:56<00:24,  9.58it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  91%|█████████▏| 2415/2645 [03:56<00:23,  9.65it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  91%|█████████▏| 2415/2645 [03:56<00:23,  9.65it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  91%|█████████▏| 2416/2645 [03:56<00:23,  9.69it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  91%|█████████▏| 2416/2645 [03:56<00:23,  9.69it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  91%|█████████▏| 2417/2645 [03:56<00:23,  9.71it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  91%|█████████▏| 2417/2645 [03:56<00:23,  9.71it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  91%|█████████▏| 2418/2645 [03:56<00:23,  9.60it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  91%|█████████▏| 2418/2645 [03:56<00:23,  9.60it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  91%|█████████▏| 2419/2645 [03:56<00:23,  9.62it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  91%|█████████▏| 2419/2645 [03:56<00:23,  9.62it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  91%|█████████▏| 2420/2645 [03:56<00:23,  9.68it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  91%|█████████▏| 2420/2645 [03:56<00:23,  9.68it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 2421/2645 [03:56<00:23,  9.66it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 2421/2645 [03:57<00:23,  9.66it/s, training_loss=0.747]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 2422/2645 [03:57<00:23,  9.59it/s, training_loss=0.747]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 2422/2645 [03:57<00:23,  9.59it/s, training_loss=0.803]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 2423/2645 [03:57<00:23,  9.45it/s, training_loss=0.803]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 2423/2645 [03:57<00:23,  9.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 2424/2645 [03:57<00:23,  9.33it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 2424/2645 [03:57<00:23,  9.33it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 2425/2645 [03:57<00:23,  9.23it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 2425/2645 [03:57<00:23,  9.23it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 2426/2645 [03:57<00:23,  9.17it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 2426/2645 [03:57<00:23,  9.17it/s, training_loss=0.473]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 2427/2645 [03:57<00:23,  9.11it/s, training_loss=0.473]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 2427/2645 [03:57<00:23,  9.11it/s, training_loss=0.434]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 2428/2645 [03:57<00:24,  9.02it/s, training_loss=0.434]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 2428/2645 [03:57<00:24,  9.02it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 2429/2645 [03:57<00:23,  9.14it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 2429/2645 [03:57<00:23,  9.14it/s, training_loss=0.656]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 2430/2645 [03:57<00:23,  9.16it/s, training_loss=0.656]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 2430/2645 [03:58<00:23,  9.16it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 2431/2645 [03:58<00:23,  9.18it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 2431/2645 [03:58<00:23,  9.18it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 2432/2645 [03:58<00:23,  9.26it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 2432/2645 [03:58<00:23,  9.26it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 2433/2645 [03:58<00:22,  9.27it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 2433/2645 [03:58<00:22,  9.27it/s, training_loss=0.389]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 2434/2645 [03:58<00:22,  9.28it/s, training_loss=0.389]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 2434/2645 [03:58<00:22,  9.28it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 2435/2645 [03:58<00:22,  9.19it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 2435/2645 [03:58<00:22,  9.19it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 2436/2645 [03:58<00:22,  9.20it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 2436/2645 [03:58<00:22,  9.20it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 2437/2645 [03:58<00:22,  9.18it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 2437/2645 [03:58<00:22,  9.18it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 2438/2645 [03:58<00:22,  9.29it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 2438/2645 [03:58<00:22,  9.29it/s, training_loss=0.011]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 2439/2645 [03:58<00:21,  9.38it/s, training_loss=0.011]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 2439/2645 [03:59<00:21,  9.38it/s, training_loss=0.615]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 2440/2645 [03:59<00:21,  9.46it/s, training_loss=0.615]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 2440/2645 [03:59<00:21,  9.46it/s, training_loss=0.306]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 2441/2645 [03:59<00:21,  9.42it/s, training_loss=0.306]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 2441/2645 [03:59<00:21,  9.42it/s, training_loss=0.413]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 2442/2645 [03:59<00:21,  9.34it/s, training_loss=0.413]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 2442/2645 [03:59<00:21,  9.34it/s, training_loss=0.123]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 2443/2645 [03:59<00:21,  9.23it/s, training_loss=0.123]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 2443/2645 [03:59<00:21,  9.23it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 2444/2645 [03:59<00:21,  9.18it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 2444/2645 [03:59<00:21,  9.18it/s, training_loss=0.142]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 2445/2645 [03:59<00:22,  9.09it/s, training_loss=0.142]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 2445/2645 [03:59<00:22,  9.09it/s, training_loss=0.672]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 2446/2645 [03:59<00:21,  9.10it/s, training_loss=0.672]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 2446/2645 [03:59<00:21,  9.10it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 2447/2645 [03:59<00:21,  9.11it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 2447/2645 [03:59<00:21,  9.11it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 2448/2645 [03:59<00:21,  9.13it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 2448/2645 [03:59<00:21,  9.13it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 2449/2645 [03:59<00:21,  9.24it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 2449/2645 [04:00<00:21,  9.24it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 2450/2645 [04:00<00:21,  9.27it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 2450/2645 [04:00<00:21,  9.27it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 2451/2645 [04:00<00:20,  9.31it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 2451/2645 [04:00<00:20,  9.31it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 2452/2645 [04:00<00:20,  9.37it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 2452/2645 [04:00<00:20,  9.37it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 2453/2645 [04:00<00:20,  9.38it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 2453/2645 [04:00<00:20,  9.38it/s, training_loss=0.364]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 2454/2645 [04:00<00:20,  9.36it/s, training_loss=0.364]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 2454/2645 [04:00<00:20,  9.36it/s, training_loss=0.021]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 2455/2645 [04:00<00:20,  9.21it/s, training_loss=0.021]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 2455/2645 [04:00<00:20,  9.21it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 2456/2645 [04:00<00:20,  9.21it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 2456/2645 [04:00<00:20,  9.21it/s, training_loss=0.024]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 2457/2645 [04:00<00:20,  9.15it/s, training_loss=0.024]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 2457/2645 [04:00<00:20,  9.15it/s, training_loss=0.823]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 2458/2645 [04:00<00:20,  9.10it/s, training_loss=0.823]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 2458/2645 [04:01<00:20,  9.10it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 2459/2645 [04:01<00:20,  9.08it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 2459/2645 [04:01<00:20,  9.08it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 2460/2645 [04:01<00:20,  9.10it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 2460/2645 [04:01<00:20,  9.10it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 2461/2645 [04:01<00:20,  9.16it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 2461/2645 [04:01<00:20,  9.16it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 2462/2645 [04:01<00:19,  9.28it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 2462/2645 [04:01<00:19,  9.28it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 2463/2645 [04:01<00:19,  9.41it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 2463/2645 [04:01<00:19,  9.41it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 2464/2645 [04:01<00:19,  9.31it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 2464/2645 [04:01<00:19,  9.31it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 2465/2645 [04:01<00:19,  9.41it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 2465/2645 [04:01<00:19,  9.41it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 2465/2645 [04:01<00:19,  9.41it/s, training_loss=0.078]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 2467/2645 [04:01<00:18,  9.60it/s, training_loss=0.078]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 2467/2645 [04:02<00:18,  9.60it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 2468/2645 [04:02<00:18,  9.68it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 2468/2645 [04:02<00:18,  9.68it/s, training_loss=0.921]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 2469/2645 [04:02<00:18,  9.72it/s, training_loss=0.921]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 2469/2645 [04:02<00:18,  9.72it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 2470/2645 [04:02<00:17,  9.79it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 2470/2645 [04:02<00:17,  9.79it/s, training_loss=0.022]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 2471/2645 [04:02<00:17,  9.77it/s, training_loss=0.022]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 2471/2645 [04:02<00:17,  9.77it/s, training_loss=0.938]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 2472/2645 [04:02<00:18,  9.56it/s, training_loss=0.938]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 2472/2645 [04:02<00:18,  9.56it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 2473/2645 [04:02<00:18,  9.38it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 2473/2645 [04:02<00:18,  9.38it/s, training_loss=0.911]\u001b[A\n",
      "Epoch 1:  94%|█████████▎| 2474/2645 [04:02<00:18,  9.24it/s, training_loss=0.911]\u001b[A\n",
      "Epoch 1:  94%|█████████▎| 2474/2645 [04:02<00:18,  9.24it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  94%|█████████▎| 2475/2645 [04:02<00:18,  9.25it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  94%|█████████▎| 2475/2645 [04:02<00:18,  9.25it/s, training_loss=0.806]\u001b[A\n",
      "Epoch 1:  94%|█████████▎| 2476/2645 [04:02<00:18,  9.21it/s, training_loss=0.806]\u001b[A\n",
      "Epoch 1:  94%|█████████▎| 2476/2645 [04:02<00:18,  9.21it/s, training_loss=0.701]\u001b[A\n",
      "Epoch 1:  94%|█████████▎| 2477/2645 [04:02<00:18,  9.25it/s, training_loss=0.701]\u001b[A\n",
      "Epoch 1:  94%|█████████▎| 2477/2645 [04:03<00:18,  9.25it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  94%|█████████▎| 2478/2645 [04:03<00:17,  9.35it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  94%|█████████▎| 2478/2645 [04:03<00:17,  9.35it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  94%|█████████▎| 2479/2645 [04:03<00:17,  9.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  94%|█████████▎| 2479/2645 [04:03<00:17,  9.44it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 2480/2645 [04:03<00:17,  9.42it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 2480/2645 [04:03<00:17,  9.42it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 2481/2645 [04:03<00:17,  9.48it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 2481/2645 [04:03<00:17,  9.48it/s, training_loss=0.914]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 2482/2645 [04:03<00:17,  9.47it/s, training_loss=0.914]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 2482/2645 [04:03<00:17,  9.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 2483/2645 [04:03<00:17,  9.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 2483/2645 [04:03<00:17,  9.43it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 2484/2645 [04:03<00:17,  9.36it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 2484/2645 [04:03<00:17,  9.36it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 2485/2645 [04:03<00:16,  9.42it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 2485/2645 [04:03<00:16,  9.42it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 2486/2645 [04:03<00:17,  9.33it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 2486/2645 [04:04<00:17,  9.33it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 2487/2645 [04:04<00:16,  9.39it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 2487/2645 [04:04<00:16,  9.39it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 2488/2645 [04:04<00:16,  9.37it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 2488/2645 [04:04<00:16,  9.37it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 2489/2645 [04:04<00:16,  9.47it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 2489/2645 [04:04<00:16,  9.47it/s, training_loss=0.167]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 2490/2645 [04:04<00:16,  9.52it/s, training_loss=0.167]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 2490/2645 [04:04<00:16,  9.52it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 2491/2645 [04:04<00:15,  9.64it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 2491/2645 [04:04<00:15,  9.64it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 2492/2645 [04:04<00:15,  9.74it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 2492/2645 [04:04<00:15,  9.74it/s, training_loss=0.035]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 2493/2645 [04:04<00:15,  9.54it/s, training_loss=0.035]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 2493/2645 [04:04<00:15,  9.54it/s, training_loss=0.642]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 2494/2645 [04:04<00:16,  9.34it/s, training_loss=0.642]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 2494/2645 [04:04<00:16,  9.34it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 2495/2645 [04:04<00:16,  9.29it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 2495/2645 [04:04<00:16,  9.29it/s, training_loss=0.546]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 2496/2645 [04:04<00:15,  9.38it/s, training_loss=0.546]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 2496/2645 [04:05<00:15,  9.38it/s, training_loss=1.184]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 2497/2645 [04:05<00:15,  9.36it/s, training_loss=1.184]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 2497/2645 [04:05<00:15,  9.36it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 2498/2645 [04:05<00:15,  9.44it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 2498/2645 [04:05<00:15,  9.44it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 2499/2645 [04:05<00:15,  9.60it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 2499/2645 [04:05<00:15,  9.60it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  95%|█████████▍| 2500/2645 [04:05<00:15,  9.45it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  95%|█████████▍| 2500/2645 [04:05<00:15,  9.45it/s, training_loss=0.542]\u001b[A\n",
      "Epoch 1:  95%|█████████▍| 2501/2645 [04:05<00:15,  9.27it/s, training_loss=0.542]\u001b[A\n",
      "Epoch 1:  95%|█████████▍| 2501/2645 [04:05<00:15,  9.27it/s, training_loss=0.709]\u001b[A\n",
      "Epoch 1:  95%|█████████▍| 2502/2645 [04:05<00:15,  9.38it/s, training_loss=0.709]\u001b[A\n",
      "Epoch 1:  95%|█████████▍| 2502/2645 [04:05<00:15,  9.38it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  95%|█████████▍| 2502/2645 [04:05<00:15,  9.38it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  95%|█████████▍| 2504/2645 [04:05<00:14,  9.49it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  95%|█████████▍| 2504/2645 [04:05<00:14,  9.49it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  95%|█████████▍| 2504/2645 [04:06<00:14,  9.49it/s, training_loss=0.210]\u001b[A\n",
      "Epoch 1:  95%|█████████▍| 2506/2645 [04:06<00:14,  9.67it/s, training_loss=0.210]\u001b[A\n",
      "Epoch 1:  95%|█████████▍| 2506/2645 [04:06<00:14,  9.67it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  95%|█████████▍| 2506/2645 [04:06<00:14,  9.67it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  95%|█████████▍| 2508/2645 [04:06<00:13,  9.83it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  95%|█████████▍| 2508/2645 [04:06<00:13,  9.83it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  95%|█████████▍| 2508/2645 [04:06<00:13,  9.83it/s, training_loss=0.011]\u001b[A\n",
      "Epoch 1:  95%|█████████▍| 2510/2645 [04:06<00:13,  9.90it/s, training_loss=0.011]\u001b[A\n",
      "Epoch 1:  95%|█████████▍| 2510/2645 [04:06<00:13,  9.90it/s, training_loss=0.690]\u001b[A\n",
      "Epoch 1:  95%|█████████▍| 2511/2645 [04:06<00:13,  9.81it/s, training_loss=0.690]\u001b[A\n",
      "Epoch 1:  95%|█████████▍| 2511/2645 [04:06<00:13,  9.81it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 1:  95%|█████████▍| 2512/2645 [04:06<00:13,  9.70it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 1:  95%|█████████▍| 2512/2645 [04:06<00:13,  9.70it/s, training_loss=0.607]\u001b[A\n",
      "Epoch 1:  95%|█████████▌| 2513/2645 [04:06<00:13,  9.48it/s, training_loss=0.607]\u001b[A\n",
      "Epoch 1:  95%|█████████▌| 2513/2645 [04:06<00:13,  9.48it/s, training_loss=0.285]\u001b[A\n",
      "Epoch 1:  95%|█████████▌| 2514/2645 [04:06<00:14,  9.35it/s, training_loss=0.285]\u001b[A\n",
      "Epoch 1:  95%|█████████▌| 2514/2645 [04:06<00:14,  9.35it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  95%|█████████▌| 2515/2645 [04:06<00:14,  9.25it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  95%|█████████▌| 2515/2645 [04:07<00:14,  9.25it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  95%|█████████▌| 2516/2645 [04:07<00:14,  9.14it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  95%|█████████▌| 2516/2645 [04:07<00:14,  9.14it/s, training_loss=0.035]\u001b[A\n",
      "Epoch 1:  95%|█████████▌| 2517/2645 [04:07<00:13,  9.15it/s, training_loss=0.035]\u001b[A\n",
      "Epoch 1:  95%|█████████▌| 2517/2645 [04:07<00:13,  9.15it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  95%|█████████▌| 2518/2645 [04:07<00:13,  9.10it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  95%|█████████▌| 2518/2645 [04:07<00:13,  9.10it/s, training_loss=0.502]\u001b[A\n",
      "Epoch 1:  95%|█████████▌| 2519/2645 [04:07<00:13,  9.25it/s, training_loss=0.502]\u001b[A\n",
      "Epoch 1:  95%|█████████▌| 2519/2645 [04:07<00:13,  9.25it/s, training_loss=0.675]\u001b[A\n",
      "Epoch 1:  95%|█████████▌| 2520/2645 [04:07<00:13,  9.38it/s, training_loss=0.675]\u001b[A\n",
      "Epoch 1:  95%|█████████▌| 2520/2645 [04:07<00:13,  9.38it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  95%|█████████▌| 2521/2645 [04:07<00:13,  9.49it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  95%|█████████▌| 2521/2645 [04:07<00:13,  9.49it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  95%|█████████▌| 2522/2645 [04:07<00:12,  9.59it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  95%|█████████▌| 2522/2645 [04:07<00:12,  9.59it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  95%|█████████▌| 2523/2645 [04:07<00:12,  9.64it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  95%|█████████▌| 2523/2645 [04:07<00:12,  9.64it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  95%|█████████▌| 2524/2645 [04:07<00:12,  9.69it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  95%|█████████▌| 2524/2645 [04:08<00:12,  9.69it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  95%|█████████▌| 2525/2645 [04:08<00:12,  9.69it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  95%|█████████▌| 2525/2645 [04:08<00:12,  9.69it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 2526/2645 [04:08<00:12,  9.71it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 2526/2645 [04:08<00:12,  9.71it/s, training_loss=0.202]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 2527/2645 [04:08<00:12,  9.62it/s, training_loss=0.202]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 2527/2645 [04:08<00:12,  9.62it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 2528/2645 [04:08<00:12,  9.63it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 2528/2645 [04:08<00:12,  9.63it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 2529/2645 [04:08<00:12,  9.66it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 2529/2645 [04:08<00:12,  9.66it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 2530/2645 [04:08<00:11,  9.67it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 2530/2645 [04:08<00:11,  9.67it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 2531/2645 [04:08<00:11,  9.76it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 2531/2645 [04:08<00:11,  9.76it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 2532/2645 [04:08<00:11,  9.79it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 2532/2645 [04:08<00:11,  9.79it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 2532/2645 [04:08<00:11,  9.79it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 2534/2645 [04:08<00:11,  9.86it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 2534/2645 [04:09<00:11,  9.86it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 2535/2645 [04:09<00:11,  9.87it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 2535/2645 [04:09<00:11,  9.87it/s, training_loss=0.367]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 2536/2645 [04:09<00:11,  9.74it/s, training_loss=0.367]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 2536/2645 [04:09<00:11,  9.74it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 2537/2645 [04:09<00:11,  9.79it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 2537/2645 [04:09<00:11,  9.79it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 2538/2645 [04:09<00:10,  9.81it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 2538/2645 [04:09<00:10,  9.81it/s, training_loss=0.465]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 2539/2645 [04:09<00:10,  9.76it/s, training_loss=0.465]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 2539/2645 [04:09<00:10,  9.76it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 2540/2645 [04:09<00:10,  9.81it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 2540/2645 [04:09<00:10,  9.81it/s, training_loss=0.554]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 2541/2645 [04:09<00:10,  9.65it/s, training_loss=0.554]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 2541/2645 [04:09<00:10,  9.65it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 2542/2645 [04:09<00:10,  9.72it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 2542/2645 [04:09<00:10,  9.72it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 2543/2645 [04:09<00:10,  9.80it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 2543/2645 [04:09<00:10,  9.80it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 2543/2645 [04:10<00:10,  9.80it/s, training_loss=0.075]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 2545/2645 [04:10<00:10,  9.88it/s, training_loss=0.075]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 2545/2645 [04:10<00:10,  9.88it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 2545/2645 [04:10<00:10,  9.88it/s, training_loss=0.012]\u001b[A\n",
      "Epoch 1:  96%|█████████▋| 2547/2645 [04:10<00:09,  9.96it/s, training_loss=0.012]\u001b[A\n",
      "Epoch 1:  96%|█████████▋| 2547/2645 [04:10<00:09,  9.96it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  96%|█████████▋| 2547/2645 [04:10<00:09,  9.96it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  96%|█████████▋| 2549/2645 [04:10<00:09,  9.99it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  96%|█████████▋| 2549/2645 [04:10<00:09,  9.99it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  96%|█████████▋| 2549/2645 [04:10<00:09,  9.99it/s, training_loss=0.014]\u001b[A\n",
      "Epoch 1:  96%|█████████▋| 2551/2645 [04:10<00:09,  9.95it/s, training_loss=0.014]\u001b[A\n",
      "Epoch 1:  96%|█████████▋| 2551/2645 [04:10<00:09,  9.95it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  96%|█████████▋| 2552/2645 [04:10<00:09,  9.85it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  96%|█████████▋| 2552/2645 [04:10<00:09,  9.85it/s, training_loss=1.541]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 2553/2645 [04:10<00:09,  9.68it/s, training_loss=1.541]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 2553/2645 [04:10<00:09,  9.68it/s, training_loss=0.719]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 2554/2645 [04:10<00:09,  9.55it/s, training_loss=0.719]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 2554/2645 [04:11<00:09,  9.55it/s, training_loss=0.793]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 2555/2645 [04:11<00:09,  9.52it/s, training_loss=0.793]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 2555/2645 [04:11<00:09,  9.52it/s, training_loss=0.013]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 2556/2645 [04:11<00:09,  9.48it/s, training_loss=0.013]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 2556/2645 [04:11<00:09,  9.48it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 2557/2645 [04:11<00:09,  9.47it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 2557/2645 [04:11<00:09,  9.47it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 2558/2645 [04:11<00:09,  9.57it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 2558/2645 [04:11<00:09,  9.57it/s, training_loss=0.533]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 2559/2645 [04:11<00:09,  9.55it/s, training_loss=0.533]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 2559/2645 [04:11<00:09,  9.55it/s, training_loss=0.055]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 2560/2645 [04:11<00:08,  9.59it/s, training_loss=0.055]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 2560/2645 [04:11<00:08,  9.59it/s, training_loss=0.011]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 2561/2645 [04:11<00:08,  9.63it/s, training_loss=0.011]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 2561/2645 [04:11<00:08,  9.63it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 2562/2645 [04:11<00:08,  9.68it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 2562/2645 [04:11<00:08,  9.68it/s, training_loss=0.859]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 2563/2645 [04:11<00:08,  9.37it/s, training_loss=0.859]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 2563/2645 [04:12<00:08,  9.37it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 2564/2645 [04:12<00:08,  9.32it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 2564/2645 [04:12<00:08,  9.32it/s, training_loss=0.061]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 2565/2645 [04:12<00:08,  9.27it/s, training_loss=0.061]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 2565/2645 [04:12<00:08,  9.27it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 2566/2645 [04:12<00:08,  9.19it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 2566/2645 [04:12<00:08,  9.19it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 2567/2645 [04:12<00:08,  9.41it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 2567/2645 [04:12<00:08,  9.41it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 2568/2645 [04:12<00:08,  9.56it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 2568/2645 [04:12<00:08,  9.56it/s, training_loss=0.014]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 2569/2645 [04:12<00:07,  9.65it/s, training_loss=0.014]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 2569/2645 [04:12<00:07,  9.65it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 2570/2645 [04:12<00:07,  9.72it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 2570/2645 [04:12<00:07,  9.72it/s, training_loss=0.543]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 2571/2645 [04:12<00:07,  9.68it/s, training_loss=0.543]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 2571/2645 [04:12<00:07,  9.68it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 2572/2645 [04:12<00:07,  9.76it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 2572/2645 [04:12<00:07,  9.76it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 2573/2645 [04:12<00:07,  9.73it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 2573/2645 [04:13<00:07,  9.73it/s, training_loss=0.596]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 2574/2645 [04:13<00:07,  9.70it/s, training_loss=0.596]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 2574/2645 [04:13<00:07,  9.70it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 2574/2645 [04:13<00:07,  9.70it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 2576/2645 [04:13<00:07,  9.85it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 2576/2645 [04:13<00:07,  9.85it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 2576/2645 [04:13<00:07,  9.85it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 2578/2645 [04:13<00:06,  9.94it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 2578/2645 [04:13<00:06,  9.94it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 2578/2645 [04:13<00:06,  9.94it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 2580/2645 [04:13<00:06, 10.03it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 2580/2645 [04:13<00:06, 10.03it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 2580/2645 [04:13<00:06, 10.03it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 2582/2645 [04:13<00:06, 10.06it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 2582/2645 [04:13<00:06, 10.06it/s, training_loss=0.014]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 2582/2645 [04:14<00:06, 10.06it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 2584/2645 [04:14<00:06, 10.08it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 2584/2645 [04:14<00:06, 10.08it/s, training_loss=0.047]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 2584/2645 [04:14<00:06, 10.08it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 2586/2645 [04:14<00:05, 10.00it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 2586/2645 [04:14<00:05, 10.00it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 2586/2645 [04:14<00:05, 10.00it/s, training_loss=0.541]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 2588/2645 [04:14<00:05, 10.03it/s, training_loss=0.541]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 2588/2645 [04:14<00:05, 10.03it/s, training_loss=0.140]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 2588/2645 [04:14<00:05, 10.03it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 2590/2645 [04:14<00:05,  9.84it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 2590/2645 [04:14<00:05,  9.84it/s, training_loss=0.018]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 2591/2645 [04:14<00:05,  9.55it/s, training_loss=0.018]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 2591/2645 [04:14<00:05,  9.55it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 2592/2645 [04:14<00:05,  9.63it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 2592/2645 [04:14<00:05,  9.63it/s, training_loss=0.315]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 2593/2645 [04:14<00:05,  9.63it/s, training_loss=0.315]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 2593/2645 [04:15<00:05,  9.63it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 2594/2645 [04:15<00:05,  9.73it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 2594/2645 [04:15<00:05,  9.73it/s, training_loss=0.012]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 2595/2645 [04:15<00:05,  9.70it/s, training_loss=0.012]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 2595/2645 [04:15<00:05,  9.70it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 2595/2645 [04:15<00:05,  9.70it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 2597/2645 [04:15<00:04,  9.91it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 2597/2645 [04:15<00:04,  9.91it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 2597/2645 [04:15<00:04,  9.91it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 2599/2645 [04:15<00:04, 10.05it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 2599/2645 [04:15<00:04, 10.05it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 2599/2645 [04:15<00:04, 10.05it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 2601/2645 [04:15<00:04, 10.08it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 2601/2645 [04:15<00:04, 10.08it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 2601/2645 [04:15<00:04, 10.08it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 2603/2645 [04:15<00:04, 10.18it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 2603/2645 [04:16<00:04, 10.18it/s, training_loss=0.613]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 2603/2645 [04:16<00:04, 10.18it/s, training_loss=0.577]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 2605/2645 [04:16<00:03, 10.23it/s, training_loss=0.577]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 2605/2645 [04:16<00:03, 10.23it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 2605/2645 [04:16<00:03, 10.23it/s, training_loss=0.723]\u001b[A\n",
      "Epoch 1:  99%|█████████▊| 2607/2645 [04:16<00:03, 10.31it/s, training_loss=0.723]\u001b[A\n",
      "Epoch 1:  99%|█████████▊| 2607/2645 [04:16<00:03, 10.31it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  99%|█████████▊| 2607/2645 [04:16<00:03, 10.31it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  99%|█████████▊| 2609/2645 [04:16<00:03, 10.37it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  99%|█████████▊| 2609/2645 [04:16<00:03, 10.37it/s, training_loss=0.808]\u001b[A\n",
      "Epoch 1:  99%|█████████▊| 2609/2645 [04:16<00:03, 10.37it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  99%|█████████▊| 2611/2645 [04:16<00:03, 10.39it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  99%|█████████▊| 2611/2645 [04:16<00:03, 10.39it/s, training_loss=0.916]\u001b[A\n",
      "Epoch 1:  99%|█████████▊| 2611/2645 [04:16<00:03, 10.39it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 2613/2645 [04:16<00:03, 10.26it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 2613/2645 [04:17<00:03, 10.26it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 2613/2645 [04:17<00:03, 10.26it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 2615/2645 [04:17<00:02, 10.23it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 2615/2645 [04:17<00:02, 10.23it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 2615/2645 [04:17<00:02, 10.23it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 2617/2645 [04:17<00:02, 10.27it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 2617/2645 [04:17<00:02, 10.27it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 2617/2645 [04:17<00:02, 10.27it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 2619/2645 [04:17<00:02, 10.36it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 2619/2645 [04:17<00:02, 10.36it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 2619/2645 [04:17<00:02, 10.36it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 2621/2645 [04:17<00:02, 10.38it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 2621/2645 [04:17<00:02, 10.38it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 2621/2645 [04:17<00:02, 10.38it/s, training_loss=0.012]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 2623/2645 [04:17<00:02, 10.40it/s, training_loss=0.012]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 2623/2645 [04:17<00:02, 10.40it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 2623/2645 [04:18<00:02, 10.40it/s, training_loss=0.018]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 2625/2645 [04:18<00:01, 10.42it/s, training_loss=0.018]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 2625/2645 [04:18<00:01, 10.42it/s, training_loss=0.022]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 2625/2645 [04:18<00:01, 10.42it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 2627/2645 [04:18<00:01, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 2627/2645 [04:18<00:01, 10.44it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 2627/2645 [04:18<00:01, 10.44it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 2629/2645 [04:18<00:01, 10.46it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 2629/2645 [04:18<00:01, 10.46it/s, training_loss=0.542]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 2629/2645 [04:18<00:01, 10.46it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 2631/2645 [04:18<00:01, 10.28it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 2631/2645 [04:18<00:01, 10.28it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 2631/2645 [04:18<00:01, 10.28it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1: 100%|█████████▉| 2633/2645 [04:18<00:01, 10.19it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1: 100%|█████████▉| 2633/2645 [04:18<00:01, 10.19it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1: 100%|█████████▉| 2633/2645 [04:19<00:01, 10.19it/s, training_loss=1.060]\u001b[A\n",
      "Epoch 1: 100%|█████████▉| 2635/2645 [04:19<00:00, 10.22it/s, training_loss=1.060]\u001b[A\n",
      "Epoch 1: 100%|█████████▉| 2635/2645 [04:19<00:00, 10.22it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 1: 100%|█████████▉| 2635/2645 [04:19<00:00, 10.22it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1: 100%|█████████▉| 2637/2645 [04:19<00:00, 10.29it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1: 100%|█████████▉| 2637/2645 [04:19<00:00, 10.29it/s, training_loss=0.749]\u001b[A\n",
      "Epoch 1: 100%|█████████▉| 2637/2645 [04:19<00:00, 10.29it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1: 100%|█████████▉| 2639/2645 [04:19<00:00, 10.35it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1: 100%|█████████▉| 2639/2645 [04:19<00:00, 10.35it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1: 100%|█████████▉| 2639/2645 [04:19<00:00, 10.35it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1: 100%|█████████▉| 2641/2645 [04:19<00:00, 10.42it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 1: 100%|█████████▉| 2641/2645 [04:19<00:00, 10.42it/s, training_loss=0.586]\u001b[A\n",
      "Epoch 1: 100%|█████████▉| 2641/2645 [04:19<00:00, 10.42it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1: 100%|█████████▉| 2643/2645 [04:19<00:00, 10.38it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 1: 100%|█████████▉| 2643/2645 [04:19<00:00, 10.38it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 1: 100%|█████████▉| 2643/2645 [04:20<00:00, 10.38it/s, training_loss=0.022]\u001b[A\n",
      "Epoch 1: 100%|██████████| 2645/2645 [04:20<00:00, 10.60it/s, training_loss=0.022]\u001b[A\n",
      "  0%|          | 0/3 [04:20<?, ?it/s]                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n",
      "Training loss: 0.3705513356080972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [04:45<09:31, 285.79s/it]\n",
      "Epoch 2:   0%|          | 0/2645 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 2:   0%|          | 0/2645 [00:00<?, ?it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   0%|          | 1/2645 [00:00<04:26,  9.91it/s, training_loss=0.000]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.969374311364029\n",
      "F1 Score (Weighted): 0.8137324218395255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2:   0%|          | 1/2645 [00:00<04:26,  9.91it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   0%|          | 2/2645 [00:00<04:27,  9.89it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   0%|          | 2/2645 [00:00<04:27,  9.89it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   0%|          | 2/2645 [00:00<04:27,  9.89it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:   0%|          | 4/2645 [00:00<04:24,  9.98it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:   0%|          | 4/2645 [00:00<04:24,  9.98it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   0%|          | 4/2645 [00:00<04:24,  9.98it/s, training_loss=0.020]\u001b[A\n",
      "Epoch 2:   0%|          | 6/2645 [00:00<04:23, 10.02it/s, training_loss=0.020]\u001b[A\n",
      "Epoch 2:   0%|          | 6/2645 [00:00<04:23, 10.02it/s, training_loss=0.070]\u001b[A\n",
      "Epoch 2:   0%|          | 7/2645 [00:00<04:23, 10.01it/s, training_loss=0.070]\u001b[A\n",
      "Epoch 2:   0%|          | 7/2645 [00:00<04:23, 10.01it/s, training_loss=0.342]\u001b[A\n",
      "Epoch 2:   0%|          | 8/2645 [00:00<04:24,  9.97it/s, training_loss=0.342]\u001b[A\n",
      "Epoch 2:   0%|          | 8/2645 [00:00<04:24,  9.97it/s, training_loss=0.972]\u001b[A\n",
      "Epoch 2:   0%|          | 9/2645 [00:00<04:25,  9.94it/s, training_loss=0.972]\u001b[A\n",
      "Epoch 2:   0%|          | 9/2645 [00:00<04:25,  9.94it/s, training_loss=0.579]\u001b[A\n",
      "Epoch 2:   0%|          | 10/2645 [00:01<04:25,  9.94it/s, training_loss=0.579]\u001b[A\n",
      "Epoch 2:   0%|          | 10/2645 [00:01<04:25,  9.94it/s, training_loss=0.653]\u001b[A\n",
      "Epoch 2:   0%|          | 11/2645 [00:01<04:25,  9.94it/s, training_loss=0.653]\u001b[A\n",
      "Epoch 2:   0%|          | 11/2645 [00:01<04:25,  9.94it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   0%|          | 11/2645 [00:01<04:25,  9.94it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 2:   0%|          | 13/2645 [00:01<04:24,  9.94it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 2:   0%|          | 13/2645 [00:01<04:24,  9.94it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 2:   1%|          | 14/2645 [00:01<04:25,  9.91it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 2:   1%|          | 14/2645 [00:01<04:25,  9.91it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   1%|          | 14/2645 [00:01<04:25,  9.91it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   1%|          | 16/2645 [00:01<04:23,  9.99it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   1%|          | 16/2645 [00:01<04:23,  9.99it/s, training_loss=0.051]\u001b[A\n",
      "Epoch 2:   1%|          | 17/2645 [00:01<04:27,  9.83it/s, training_loss=0.051]\u001b[A\n",
      "Epoch 2:   1%|          | 17/2645 [00:01<04:27,  9.83it/s, training_loss=0.737]\u001b[A\n",
      "Epoch 2:   1%|          | 18/2645 [00:01<04:25,  9.88it/s, training_loss=0.737]\u001b[A\n",
      "Epoch 2:   1%|          | 18/2645 [00:01<04:25,  9.88it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   1%|          | 19/2645 [00:01<04:28,  9.80it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   1%|          | 19/2645 [00:02<04:28,  9.80it/s, training_loss=0.171]\u001b[A\n",
      "Epoch 2:   1%|          | 19/2645 [00:02<04:28,  9.80it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   1%|          | 21/2645 [00:02<04:25,  9.90it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   1%|          | 21/2645 [00:02<04:25,  9.90it/s, training_loss=0.849]\u001b[A\n",
      "Epoch 2:   1%|          | 22/2645 [00:02<04:24,  9.92it/s, training_loss=0.849]\u001b[A\n",
      "Epoch 2:   1%|          | 22/2645 [00:02<04:24,  9.92it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   1%|          | 22/2645 [00:02<04:24,  9.92it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   1%|          | 24/2645 [00:02<04:21, 10.02it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   1%|          | 24/2645 [00:02<04:21, 10.02it/s, training_loss=0.285]\u001b[A\n",
      "Epoch 2:   1%|          | 24/2645 [00:02<04:21, 10.02it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:   1%|          | 26/2645 [00:02<04:21, 10.01it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:   1%|          | 26/2645 [00:02<04:21, 10.01it/s, training_loss=0.310]\u001b[A\n",
      "Epoch 2:   1%|          | 26/2645 [00:02<04:21, 10.01it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   1%|          | 28/2645 [00:02<04:20, 10.04it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   1%|          | 28/2645 [00:02<04:20, 10.04it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:   1%|          | 28/2645 [00:02<04:20, 10.04it/s, training_loss=0.013]\u001b[A\n",
      "Epoch 2:   1%|          | 30/2645 [00:03<04:21, 10.00it/s, training_loss=0.013]\u001b[A\n",
      "Epoch 2:   1%|          | 30/2645 [00:03<04:21, 10.00it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   1%|          | 30/2645 [00:03<04:21, 10.00it/s, training_loss=0.791]\u001b[A\n",
      "Epoch 2:   1%|          | 32/2645 [00:03<04:23,  9.93it/s, training_loss=0.791]\u001b[A\n",
      "Epoch 2:   1%|          | 32/2645 [00:03<04:23,  9.93it/s, training_loss=0.684]\u001b[A\n",
      "Epoch 2:   1%|          | 32/2645 [00:03<04:23,  9.93it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:   1%|▏         | 34/2645 [00:03<04:22,  9.96it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:   1%|▏         | 34/2645 [00:03<04:22,  9.96it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 2:   1%|▏         | 35/2645 [00:03<04:24,  9.88it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 2:   1%|▏         | 35/2645 [00:03<04:24,  9.88it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   1%|▏         | 35/2645 [00:03<04:24,  9.88it/s, training_loss=0.654]\u001b[A\n",
      "Epoch 2:   1%|▏         | 37/2645 [00:03<04:20, 10.01it/s, training_loss=0.654]\u001b[A\n",
      "Epoch 2:   1%|▏         | 37/2645 [00:03<04:20, 10.01it/s, training_loss=0.199]\u001b[A\n",
      "Epoch 2:   1%|▏         | 37/2645 [00:03<04:20, 10.01it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   1%|▏         | 39/2645 [00:03<04:19, 10.05it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   1%|▏         | 39/2645 [00:04<04:19, 10.05it/s, training_loss=0.030]\u001b[A\n",
      "Epoch 2:   1%|▏         | 39/2645 [00:04<04:19, 10.05it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   2%|▏         | 41/2645 [00:04<04:20, 10.01it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   2%|▏         | 41/2645 [00:04<04:20, 10.01it/s, training_loss=0.560]\u001b[A\n",
      "Epoch 2:   2%|▏         | 41/2645 [00:04<04:20, 10.01it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   2%|▏         | 43/2645 [00:04<04:20,  9.97it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   2%|▏         | 43/2645 [00:04<04:20,  9.97it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   2%|▏         | 43/2645 [00:04<04:20,  9.97it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   2%|▏         | 45/2645 [00:04<04:18, 10.06it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   2%|▏         | 45/2645 [00:04<04:18, 10.06it/s, training_loss=0.119]\u001b[A\n",
      "Epoch 2:   2%|▏         | 45/2645 [00:04<04:18, 10.06it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   2%|▏         | 47/2645 [00:04<04:16, 10.11it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   2%|▏         | 47/2645 [00:04<04:16, 10.11it/s, training_loss=0.010]\u001b[A\n",
      "Epoch 2:   2%|▏         | 47/2645 [00:04<04:16, 10.11it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   2%|▏         | 49/2645 [00:04<04:17, 10.09it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   2%|▏         | 49/2645 [00:04<04:17, 10.09it/s, training_loss=0.377]\u001b[A\n",
      "Epoch 2:   2%|▏         | 49/2645 [00:05<04:17, 10.09it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   2%|▏         | 51/2645 [00:05<04:14, 10.20it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   2%|▏         | 51/2645 [00:05<04:14, 10.20it/s, training_loss=0.143]\u001b[A\n",
      "Epoch 2:   2%|▏         | 51/2645 [00:05<04:14, 10.20it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   2%|▏         | 53/2645 [00:05<04:12, 10.28it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   2%|▏         | 53/2645 [00:05<04:12, 10.28it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   2%|▏         | 53/2645 [00:05<04:12, 10.28it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   2%|▏         | 55/2645 [00:05<04:09, 10.39it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   2%|▏         | 55/2645 [00:05<04:09, 10.39it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   2%|▏         | 55/2645 [00:05<04:09, 10.39it/s, training_loss=0.056]\u001b[A\n",
      "Epoch 2:   2%|▏         | 57/2645 [00:05<04:08, 10.43it/s, training_loss=0.056]\u001b[A\n",
      "Epoch 2:   2%|▏         | 57/2645 [00:05<04:08, 10.43it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   2%|▏         | 57/2645 [00:05<04:08, 10.43it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:   2%|▏         | 59/2645 [00:05<04:07, 10.46it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:   2%|▏         | 59/2645 [00:05<04:07, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   2%|▏         | 59/2645 [00:06<04:07, 10.46it/s, training_loss=0.768]\u001b[A\n",
      "Epoch 2:   2%|▏         | 61/2645 [00:06<04:07, 10.46it/s, training_loss=0.768]\u001b[A\n",
      "Epoch 2:   2%|▏         | 61/2645 [00:06<04:07, 10.46it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   2%|▏         | 61/2645 [00:06<04:07, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   2%|▏         | 63/2645 [00:06<04:06, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   2%|▏         | 63/2645 [00:06<04:06, 10.49it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   2%|▏         | 63/2645 [00:06<04:06, 10.49it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   2%|▏         | 65/2645 [00:06<04:05, 10.51it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   2%|▏         | 65/2645 [00:06<04:05, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   2%|▏         | 65/2645 [00:06<04:05, 10.51it/s, training_loss=0.117]\u001b[A\n",
      "Epoch 2:   3%|▎         | 67/2645 [00:06<04:05, 10.51it/s, training_loss=0.117]\u001b[A\n",
      "Epoch 2:   3%|▎         | 67/2645 [00:06<04:05, 10.51it/s, training_loss=0.539]\u001b[A\n",
      "Epoch 2:   3%|▎         | 67/2645 [00:06<04:05, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   3%|▎         | 69/2645 [00:06<04:05, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   3%|▎         | 69/2645 [00:06<04:05, 10.49it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   3%|▎         | 69/2645 [00:06<04:05, 10.49it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:   3%|▎         | 71/2645 [00:06<04:04, 10.52it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:   3%|▎         | 71/2645 [00:07<04:04, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   3%|▎         | 71/2645 [00:07<04:04, 10.52it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 2:   3%|▎         | 73/2645 [00:07<04:05, 10.47it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 2:   3%|▎         | 73/2645 [00:07<04:05, 10.47it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   3%|▎         | 73/2645 [00:07<04:05, 10.47it/s, training_loss=0.041]\u001b[A\n",
      "Epoch 2:   3%|▎         | 75/2645 [00:07<04:05, 10.47it/s, training_loss=0.041]\u001b[A\n",
      "Epoch 2:   3%|▎         | 75/2645 [00:07<04:05, 10.47it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   3%|▎         | 75/2645 [00:07<04:05, 10.47it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   3%|▎         | 77/2645 [00:07<04:04, 10.50it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   3%|▎         | 77/2645 [00:07<04:04, 10.50it/s, training_loss=0.295]\u001b[A\n",
      "Epoch 2:   3%|▎         | 77/2645 [00:07<04:04, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   3%|▎         | 79/2645 [00:07<04:04, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   3%|▎         | 79/2645 [00:07<04:04, 10.48it/s, training_loss=0.326]\u001b[A\n",
      "Epoch 2:   3%|▎         | 79/2645 [00:07<04:04, 10.48it/s, training_loss=0.574]\u001b[A\n",
      "Epoch 2:   3%|▎         | 81/2645 [00:07<04:05, 10.44it/s, training_loss=0.574]\u001b[A\n",
      "Epoch 2:   3%|▎         | 81/2645 [00:08<04:05, 10.44it/s, training_loss=0.059]\u001b[A\n",
      "Epoch 2:   3%|▎         | 81/2645 [00:08<04:05, 10.44it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   3%|▎         | 83/2645 [00:08<04:05, 10.44it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   3%|▎         | 83/2645 [00:08<04:05, 10.44it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   3%|▎         | 83/2645 [00:08<04:05, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   3%|▎         | 85/2645 [00:08<04:04, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   3%|▎         | 85/2645 [00:08<04:04, 10.49it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   3%|▎         | 85/2645 [00:08<04:04, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   3%|▎         | 87/2645 [00:08<04:03, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   3%|▎         | 87/2645 [00:08<04:03, 10.50it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 2:   3%|▎         | 87/2645 [00:08<04:03, 10.50it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:   3%|▎         | 89/2645 [00:08<04:04, 10.47it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:   3%|▎         | 89/2645 [00:08<04:04, 10.47it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   3%|▎         | 89/2645 [00:08<04:04, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   3%|▎         | 91/2645 [00:08<04:05, 10.41it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   3%|▎         | 91/2645 [00:08<04:05, 10.41it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   3%|▎         | 91/2645 [00:09<04:05, 10.41it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   4%|▎         | 93/2645 [00:09<04:03, 10.46it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   4%|▎         | 93/2645 [00:09<04:03, 10.46it/s, training_loss=0.029]\u001b[A\n",
      "Epoch 2:   4%|▎         | 93/2645 [00:09<04:03, 10.46it/s, training_loss=0.664]\u001b[A\n",
      "Epoch 2:   4%|▎         | 95/2645 [00:09<04:04, 10.41it/s, training_loss=0.664]\u001b[A\n",
      "Epoch 2:   4%|▎         | 95/2645 [00:09<04:04, 10.41it/s, training_loss=0.013]\u001b[A\n",
      "Epoch 2:   4%|▎         | 95/2645 [00:09<04:04, 10.41it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   4%|▎         | 97/2645 [00:09<04:04, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   4%|▎         | 97/2645 [00:09<04:04, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   4%|▎         | 97/2645 [00:09<04:04, 10.44it/s, training_loss=0.032]\u001b[A\n",
      "Epoch 2:   4%|▎         | 99/2645 [00:09<04:03, 10.45it/s, training_loss=0.032]\u001b[A\n",
      "Epoch 2:   4%|▎         | 99/2645 [00:09<04:03, 10.45it/s, training_loss=0.368]\u001b[A\n",
      "Epoch 2:   4%|▎         | 99/2645 [00:09<04:03, 10.45it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 2:   4%|▍         | 101/2645 [00:09<04:04, 10.42it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 2:   4%|▍         | 101/2645 [00:09<04:04, 10.42it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   4%|▍         | 101/2645 [00:10<04:04, 10.42it/s, training_loss=0.735]\u001b[A\n",
      "Epoch 2:   4%|▍         | 103/2645 [00:10<04:03, 10.44it/s, training_loss=0.735]\u001b[A\n",
      "Epoch 2:   4%|▍         | 103/2645 [00:10<04:03, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   4%|▍         | 103/2645 [00:10<04:03, 10.44it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   4%|▍         | 105/2645 [00:10<04:02, 10.49it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   4%|▍         | 105/2645 [00:10<04:02, 10.49it/s, training_loss=0.347]\u001b[A\n",
      "Epoch 2:   4%|▍         | 105/2645 [00:10<04:02, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   4%|▍         | 107/2645 [00:10<04:01, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   4%|▍         | 107/2645 [00:10<04:01, 10.50it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 2:   4%|▍         | 107/2645 [00:10<04:01, 10.50it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   4%|▍         | 109/2645 [00:10<04:01, 10.49it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   4%|▍         | 109/2645 [00:10<04:01, 10.49it/s, training_loss=0.252]\u001b[A\n",
      "Epoch 2:   4%|▍         | 109/2645 [00:10<04:01, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   4%|▍         | 111/2645 [00:10<04:01, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   4%|▍         | 111/2645 [00:10<04:01, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   4%|▍         | 111/2645 [00:10<04:01, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   4%|▍         | 113/2645 [00:10<04:00, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   4%|▍         | 113/2645 [00:11<04:00, 10.51it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:   4%|▍         | 113/2645 [00:11<04:00, 10.51it/s, training_loss=0.011]\u001b[A\n",
      "Epoch 2:   4%|▍         | 115/2645 [00:11<04:00, 10.52it/s, training_loss=0.011]\u001b[A\n",
      "Epoch 2:   4%|▍         | 115/2645 [00:11<04:00, 10.52it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   4%|▍         | 115/2645 [00:11<04:00, 10.52it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   4%|▍         | 117/2645 [00:11<03:59, 10.54it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   4%|▍         | 117/2645 [00:11<03:59, 10.54it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   4%|▍         | 117/2645 [00:11<03:59, 10.54it/s, training_loss=0.138]\u001b[A\n",
      "Epoch 2:   4%|▍         | 119/2645 [00:11<04:00, 10.51it/s, training_loss=0.138]\u001b[A\n",
      "Epoch 2:   4%|▍         | 119/2645 [00:11<04:00, 10.51it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   4%|▍         | 119/2645 [00:11<04:00, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   5%|▍         | 121/2645 [00:11<03:59, 10.55it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   5%|▍         | 121/2645 [00:11<03:59, 10.55it/s, training_loss=0.010]\u001b[A\n",
      "Epoch 2:   5%|▍         | 121/2645 [00:11<03:59, 10.55it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   5%|▍         | 123/2645 [00:11<03:59, 10.53it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   5%|▍         | 123/2645 [00:12<03:59, 10.53it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   5%|▍         | 123/2645 [00:12<03:59, 10.53it/s, training_loss=0.054]\u001b[A\n",
      "Epoch 2:   5%|▍         | 125/2645 [00:12<04:01, 10.45it/s, training_loss=0.054]\u001b[A\n",
      "Epoch 2:   5%|▍         | 125/2645 [00:12<04:01, 10.45it/s, training_loss=0.023]\u001b[A\n",
      "Epoch 2:   5%|▍         | 125/2645 [00:12<04:01, 10.45it/s, training_loss=0.611]\u001b[A\n",
      "Epoch 2:   5%|▍         | 127/2645 [00:12<04:01, 10.43it/s, training_loss=0.611]\u001b[A\n",
      "Epoch 2:   5%|▍         | 127/2645 [00:12<04:01, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   5%|▍         | 127/2645 [00:12<04:01, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   5%|▍         | 129/2645 [00:12<04:00, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   5%|▍         | 129/2645 [00:12<04:00, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   5%|▍         | 129/2645 [00:12<04:00, 10.46it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   5%|▍         | 131/2645 [00:12<03:59, 10.50it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   5%|▍         | 131/2645 [00:12<03:59, 10.50it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 2:   5%|▍         | 131/2645 [00:12<03:59, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   5%|▌         | 133/2645 [00:12<03:59, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   5%|▌         | 133/2645 [00:12<03:59, 10.47it/s, training_loss=0.607]\u001b[A\n",
      "Epoch 2:   5%|▌         | 133/2645 [00:13<03:59, 10.47it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 2:   5%|▌         | 135/2645 [00:13<04:00, 10.44it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 2:   5%|▌         | 135/2645 [00:13<04:00, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   5%|▌         | 135/2645 [00:13<04:00, 10.44it/s, training_loss=0.439]\u001b[A\n",
      "Epoch 2:   5%|▌         | 137/2645 [00:13<03:59, 10.46it/s, training_loss=0.439]\u001b[A\n",
      "Epoch 2:   5%|▌         | 137/2645 [00:13<03:59, 10.46it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 2:   5%|▌         | 137/2645 [00:13<03:59, 10.46it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:   5%|▌         | 139/2645 [00:13<03:59, 10.47it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:   5%|▌         | 139/2645 [00:13<03:59, 10.47it/s, training_loss=0.176]\u001b[A\n",
      "Epoch 2:   5%|▌         | 139/2645 [00:13<03:59, 10.47it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   5%|▌         | 141/2645 [00:13<03:58, 10.49it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   5%|▌         | 141/2645 [00:13<03:58, 10.49it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   5%|▌         | 141/2645 [00:13<03:58, 10.49it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   5%|▌         | 143/2645 [00:13<03:59, 10.47it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   5%|▌         | 143/2645 [00:13<03:59, 10.47it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   5%|▌         | 143/2645 [00:14<03:59, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   5%|▌         | 145/2645 [00:14<03:58, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   5%|▌         | 145/2645 [00:14<03:58, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   5%|▌         | 145/2645 [00:14<03:58, 10.48it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 2:   6%|▌         | 147/2645 [00:14<03:58, 10.46it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 2:   6%|▌         | 147/2645 [00:14<03:58, 10.46it/s, training_loss=0.390]\u001b[A\n",
      "Epoch 2:   6%|▌         | 147/2645 [00:14<03:58, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   6%|▌         | 149/2645 [00:14<03:58, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   6%|▌         | 149/2645 [00:14<03:58, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   6%|▌         | 149/2645 [00:14<03:58, 10.47it/s, training_loss=0.187]\u001b[A\n",
      "Epoch 2:   6%|▌         | 151/2645 [00:14<03:58, 10.48it/s, training_loss=0.187]\u001b[A\n",
      "Epoch 2:   6%|▌         | 151/2645 [00:14<03:58, 10.48it/s, training_loss=0.566]\u001b[A\n",
      "Epoch 2:   6%|▌         | 151/2645 [00:14<03:58, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   6%|▌         | 153/2645 [00:14<03:58, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   6%|▌         | 153/2645 [00:14<03:58, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   6%|▌         | 153/2645 [00:15<03:58, 10.47it/s, training_loss=0.010]\u001b[A\n",
      "Epoch 2:   6%|▌         | 155/2645 [00:15<03:58, 10.43it/s, training_loss=0.010]\u001b[A\n",
      "Epoch 2:   6%|▌         | 155/2645 [00:15<03:58, 10.43it/s, training_loss=0.115]\u001b[A\n",
      "Epoch 2:   6%|▌         | 155/2645 [00:15<03:58, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   6%|▌         | 157/2645 [00:15<03:58, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   6%|▌         | 157/2645 [00:15<03:58, 10.45it/s, training_loss=0.141]\u001b[A\n",
      "Epoch 2:   6%|▌         | 157/2645 [00:15<03:58, 10.45it/s, training_loss=0.857]\u001b[A\n",
      "Epoch 2:   6%|▌         | 159/2645 [00:15<03:58, 10.43it/s, training_loss=0.857]\u001b[A\n",
      "Epoch 2:   6%|▌         | 159/2645 [00:15<03:58, 10.43it/s, training_loss=0.333]\u001b[A\n",
      "Epoch 2:   6%|▌         | 159/2645 [00:15<03:58, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   6%|▌         | 161/2645 [00:15<03:57, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   6%|▌         | 161/2645 [00:15<03:57, 10.44it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   6%|▌         | 161/2645 [00:15<03:57, 10.44it/s, training_loss=0.016]\u001b[A\n",
      "Epoch 2:   6%|▌         | 163/2645 [00:15<03:57, 10.46it/s, training_loss=0.016]\u001b[A\n",
      "Epoch 2:   6%|▌         | 163/2645 [00:15<03:57, 10.46it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   6%|▌         | 163/2645 [00:15<03:57, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   6%|▌         | 165/2645 [00:15<03:57, 10.42it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   6%|▌         | 165/2645 [00:16<03:57, 10.42it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   6%|▌         | 165/2645 [00:16<03:57, 10.42it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   6%|▋         | 167/2645 [00:16<03:57, 10.44it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   6%|▋         | 167/2645 [00:16<03:57, 10.44it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   6%|▋         | 167/2645 [00:16<03:57, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   6%|▋         | 169/2645 [00:16<03:56, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   6%|▋         | 169/2645 [00:16<03:56, 10.48it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   6%|▋         | 169/2645 [00:16<03:56, 10.48it/s, training_loss=0.181]\u001b[A\n",
      "Epoch 2:   6%|▋         | 171/2645 [00:16<03:55, 10.49it/s, training_loss=0.181]\u001b[A\n",
      "Epoch 2:   6%|▋         | 171/2645 [00:16<03:55, 10.49it/s, training_loss=0.090]\u001b[A\n",
      "Epoch 2:   6%|▋         | 171/2645 [00:16<03:55, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   7%|▋         | 173/2645 [00:16<03:55, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   7%|▋         | 173/2645 [00:16<03:55, 10.49it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   7%|▋         | 173/2645 [00:16<03:55, 10.49it/s, training_loss=0.647]\u001b[A\n",
      "Epoch 2:   7%|▋         | 175/2645 [00:16<03:55, 10.47it/s, training_loss=0.647]\u001b[A\n",
      "Epoch 2:   7%|▋         | 175/2645 [00:17<03:55, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   7%|▋         | 175/2645 [00:17<03:55, 10.47it/s, training_loss=0.384]\u001b[A\n",
      "Epoch 2:   7%|▋         | 177/2645 [00:17<03:56, 10.43it/s, training_loss=0.384]\u001b[A\n",
      "Epoch 2:   7%|▋         | 177/2645 [00:17<03:56, 10.43it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   7%|▋         | 177/2645 [00:17<03:56, 10.43it/s, training_loss=0.552]\u001b[A\n",
      "Epoch 2:   7%|▋         | 179/2645 [00:17<03:56, 10.44it/s, training_loss=0.552]\u001b[A\n",
      "Epoch 2:   7%|▋         | 179/2645 [00:17<03:56, 10.44it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 2:   7%|▋         | 179/2645 [00:17<03:56, 10.44it/s, training_loss=1.331]\u001b[A\n",
      "Epoch 2:   7%|▋         | 181/2645 [00:17<03:56, 10.42it/s, training_loss=1.331]\u001b[A\n",
      "Epoch 2:   7%|▋         | 181/2645 [00:17<03:56, 10.42it/s, training_loss=1.109]\u001b[A\n",
      "Epoch 2:   7%|▋         | 181/2645 [00:17<03:56, 10.42it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   7%|▋         | 183/2645 [00:17<03:56, 10.41it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   7%|▋         | 183/2645 [00:17<03:56, 10.41it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   7%|▋         | 183/2645 [00:17<03:56, 10.41it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:   7%|▋         | 185/2645 [00:17<03:55, 10.47it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:   7%|▋         | 185/2645 [00:17<03:55, 10.47it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   7%|▋         | 185/2645 [00:18<03:55, 10.47it/s, training_loss=0.010]\u001b[A\n",
      "Epoch 2:   7%|▋         | 187/2645 [00:18<03:55, 10.45it/s, training_loss=0.010]\u001b[A\n",
      "Epoch 2:   7%|▋         | 187/2645 [00:18<03:55, 10.45it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   7%|▋         | 187/2645 [00:18<03:55, 10.45it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   7%|▋         | 189/2645 [00:18<03:54, 10.45it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   7%|▋         | 189/2645 [00:18<03:54, 10.45it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 2:   7%|▋         | 189/2645 [00:18<03:54, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   7%|▋         | 191/2645 [00:18<03:54, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   7%|▋         | 191/2645 [00:18<03:54, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   7%|▋         | 191/2645 [00:18<03:54, 10.47it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   7%|▋         | 193/2645 [00:18<03:54, 10.46it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   7%|▋         | 193/2645 [00:18<03:54, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   7%|▋         | 193/2645 [00:18<03:54, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   7%|▋         | 195/2645 [00:18<03:55, 10.39it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   7%|▋         | 195/2645 [00:18<03:55, 10.39it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   7%|▋         | 195/2645 [00:19<03:55, 10.39it/s, training_loss=1.657]\u001b[A\n",
      "Epoch 2:   7%|▋         | 197/2645 [00:19<03:57, 10.30it/s, training_loss=1.657]\u001b[A\n",
      "Epoch 2:   7%|▋         | 197/2645 [00:19<03:57, 10.30it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   7%|▋         | 197/2645 [00:19<03:57, 10.30it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   8%|▊         | 199/2645 [00:19<03:57, 10.31it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   8%|▊         | 199/2645 [00:19<03:57, 10.31it/s, training_loss=0.114]\u001b[A\n",
      "Epoch 2:   8%|▊         | 199/2645 [00:19<03:57, 10.31it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   8%|▊         | 201/2645 [00:19<03:57, 10.27it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   8%|▊         | 201/2645 [00:19<03:57, 10.27it/s, training_loss=0.027]\u001b[A\n",
      "Epoch 2:   8%|▊         | 201/2645 [00:19<03:57, 10.27it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   8%|▊         | 203/2645 [00:19<03:59, 10.21it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   8%|▊         | 203/2645 [00:19<03:59, 10.21it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 2:   8%|▊         | 203/2645 [00:19<03:59, 10.21it/s, training_loss=0.677]\u001b[A\n",
      "Epoch 2:   8%|▊         | 205/2645 [00:19<03:57, 10.26it/s, training_loss=0.677]\u001b[A\n",
      "Epoch 2:   8%|▊         | 205/2645 [00:19<03:57, 10.26it/s, training_loss=0.062]\u001b[A\n",
      "Epoch 2:   8%|▊         | 205/2645 [00:20<03:57, 10.26it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 2:   8%|▊         | 207/2645 [00:20<03:57, 10.28it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 2:   8%|▊         | 207/2645 [00:20<03:57, 10.28it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   8%|▊         | 207/2645 [00:20<03:57, 10.28it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 2:   8%|▊         | 209/2645 [00:20<03:55, 10.32it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 2:   8%|▊         | 209/2645 [00:20<03:55, 10.32it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 2:   8%|▊         | 209/2645 [00:20<03:55, 10.32it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   8%|▊         | 211/2645 [00:20<03:54, 10.39it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   8%|▊         | 211/2645 [00:20<03:54, 10.39it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   8%|▊         | 211/2645 [00:20<03:54, 10.39it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   8%|▊         | 213/2645 [00:20<03:52, 10.45it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   8%|▊         | 213/2645 [00:20<03:52, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   8%|▊         | 213/2645 [00:20<03:52, 10.45it/s, training_loss=0.013]\u001b[A\n",
      "Epoch 2:   8%|▊         | 215/2645 [00:20<03:55, 10.32it/s, training_loss=0.013]\u001b[A\n",
      "Epoch 2:   8%|▊         | 215/2645 [00:20<03:55, 10.32it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   8%|▊         | 215/2645 [00:20<03:55, 10.32it/s, training_loss=0.761]\u001b[A\n",
      "Epoch 2:   8%|▊         | 217/2645 [00:20<03:54, 10.38it/s, training_loss=0.761]\u001b[A\n",
      "Epoch 2:   8%|▊         | 217/2645 [00:21<03:54, 10.38it/s, training_loss=0.340]\u001b[A\n",
      "Epoch 2:   8%|▊         | 217/2645 [00:21<03:54, 10.38it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   8%|▊         | 219/2645 [00:21<03:55, 10.31it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   8%|▊         | 219/2645 [00:21<03:55, 10.31it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   8%|▊         | 219/2645 [00:21<03:55, 10.31it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   8%|▊         | 221/2645 [00:21<03:53, 10.37it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   8%|▊         | 221/2645 [00:21<03:53, 10.37it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   8%|▊         | 221/2645 [00:21<03:53, 10.37it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   8%|▊         | 223/2645 [00:21<03:52, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   8%|▊         | 223/2645 [00:21<03:52, 10.43it/s, training_loss=0.456]\u001b[A\n",
      "Epoch 2:   8%|▊         | 223/2645 [00:21<03:52, 10.43it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   9%|▊         | 225/2645 [00:21<03:51, 10.43it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   9%|▊         | 225/2645 [00:21<03:51, 10.43it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   9%|▊         | 225/2645 [00:21<03:51, 10.43it/s, training_loss=0.020]\u001b[A\n",
      "Epoch 2:   9%|▊         | 227/2645 [00:21<03:52, 10.42it/s, training_loss=0.020]\u001b[A\n",
      "Epoch 2:   9%|▊         | 227/2645 [00:22<03:52, 10.42it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   9%|▊         | 227/2645 [00:22<03:52, 10.42it/s, training_loss=0.059]\u001b[A\n",
      "Epoch 2:   9%|▊         | 229/2645 [00:22<03:52, 10.41it/s, training_loss=0.059]\u001b[A\n",
      "Epoch 2:   9%|▊         | 229/2645 [00:22<03:52, 10.41it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:   9%|▊         | 229/2645 [00:22<03:52, 10.41it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   9%|▊         | 231/2645 [00:22<03:51, 10.42it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   9%|▊         | 231/2645 [00:22<03:51, 10.42it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   9%|▊         | 231/2645 [00:22<03:51, 10.42it/s, training_loss=0.019]\u001b[A\n",
      "Epoch 2:   9%|▉         | 233/2645 [00:22<03:51, 10.43it/s, training_loss=0.019]\u001b[A\n",
      "Epoch 2:   9%|▉         | 233/2645 [00:22<03:51, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   9%|▉         | 233/2645 [00:22<03:51, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   9%|▉         | 235/2645 [00:22<03:53, 10.31it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   9%|▉         | 235/2645 [00:22<03:53, 10.31it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 2:   9%|▉         | 235/2645 [00:22<03:53, 10.31it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 2:   9%|▉         | 237/2645 [00:22<03:57, 10.13it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 2:   9%|▉         | 237/2645 [00:23<03:57, 10.13it/s, training_loss=0.020]\u001b[A\n",
      "Epoch 2:   9%|▉         | 237/2645 [00:23<03:57, 10.13it/s, training_loss=0.838]\u001b[A\n",
      "Epoch 2:   9%|▉         | 239/2645 [00:23<03:57, 10.14it/s, training_loss=0.838]\u001b[A\n",
      "Epoch 2:   9%|▉         | 239/2645 [00:23<03:57, 10.14it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   9%|▉         | 239/2645 [00:23<03:57, 10.14it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   9%|▉         | 241/2645 [00:23<03:53, 10.31it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   9%|▉         | 241/2645 [00:23<03:53, 10.31it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   9%|▉         | 241/2645 [00:23<03:53, 10.31it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   9%|▉         | 243/2645 [00:23<03:48, 10.50it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   9%|▉         | 243/2645 [00:23<03:48, 10.50it/s, training_loss=0.240]\u001b[A\n",
      "Epoch 2:   9%|▉         | 243/2645 [00:23<03:48, 10.50it/s, training_loss=0.524]\u001b[A\n",
      "Epoch 2:   9%|▉         | 245/2645 [00:23<03:47, 10.57it/s, training_loss=0.524]\u001b[A\n",
      "Epoch 2:   9%|▉         | 245/2645 [00:23<03:47, 10.57it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   9%|▉         | 245/2645 [00:23<03:47, 10.57it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   9%|▉         | 247/2645 [00:23<03:44, 10.67it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:   9%|▉         | 247/2645 [00:23<03:44, 10.67it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   9%|▉         | 247/2645 [00:24<03:44, 10.67it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   9%|▉         | 249/2645 [00:24<03:42, 10.76it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   9%|▉         | 249/2645 [00:24<03:42, 10.76it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   9%|▉         | 249/2645 [00:24<03:42, 10.76it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   9%|▉         | 251/2645 [00:24<03:41, 10.79it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   9%|▉         | 251/2645 [00:24<03:41, 10.79it/s, training_loss=0.746]\u001b[A\n",
      "Epoch 2:   9%|▉         | 251/2645 [00:24<03:41, 10.79it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  10%|▉         | 253/2645 [00:24<03:42, 10.76it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  10%|▉         | 253/2645 [00:24<03:42, 10.76it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  10%|▉         | 253/2645 [00:24<03:42, 10.76it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 2:  10%|▉         | 255/2645 [00:24<03:44, 10.66it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 2:  10%|▉         | 255/2645 [00:24<03:44, 10.66it/s, training_loss=0.096]\u001b[A\n",
      "Epoch 2:  10%|▉         | 255/2645 [00:24<03:44, 10.66it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  10%|▉         | 257/2645 [00:24<03:43, 10.66it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  10%|▉         | 257/2645 [00:24<03:43, 10.66it/s, training_loss=0.098]\u001b[A\n",
      "Epoch 2:  10%|▉         | 257/2645 [00:24<03:43, 10.66it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  10%|▉         | 259/2645 [00:24<03:43, 10.66it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  10%|▉         | 259/2645 [00:25<03:43, 10.66it/s, training_loss=0.760]\u001b[A\n",
      "Epoch 2:  10%|▉         | 259/2645 [00:25<03:43, 10.66it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  10%|▉         | 261/2645 [00:25<03:43, 10.68it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  10%|▉         | 261/2645 [00:25<03:43, 10.68it/s, training_loss=0.051]\u001b[A\n",
      "Epoch 2:  10%|▉         | 261/2645 [00:25<03:43, 10.68it/s, training_loss=0.455]\u001b[A\n",
      "Epoch 2:  10%|▉         | 263/2645 [00:25<03:43, 10.66it/s, training_loss=0.455]\u001b[A\n",
      "Epoch 2:  10%|▉         | 263/2645 [00:25<03:43, 10.66it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  10%|▉         | 263/2645 [00:25<03:43, 10.66it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  10%|█         | 265/2645 [00:25<03:42, 10.70it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  10%|█         | 265/2645 [00:25<03:42, 10.70it/s, training_loss=0.427]\u001b[A\n",
      "Epoch 2:  10%|█         | 265/2645 [00:25<03:42, 10.70it/s, training_loss=0.409]\u001b[A\n",
      "Epoch 2:  10%|█         | 267/2645 [00:25<03:42, 10.71it/s, training_loss=0.409]\u001b[A\n",
      "Epoch 2:  10%|█         | 267/2645 [00:25<03:42, 10.71it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 2:  10%|█         | 267/2645 [00:25<03:42, 10.71it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  10%|█         | 269/2645 [00:25<03:41, 10.71it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  10%|█         | 269/2645 [00:25<03:41, 10.71it/s, training_loss=0.300]\u001b[A\n",
      "Epoch 2:  10%|█         | 269/2645 [00:26<03:41, 10.71it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 2:  10%|█         | 271/2645 [00:26<03:41, 10.70it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 2:  10%|█         | 271/2645 [00:26<03:41, 10.70it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  10%|█         | 271/2645 [00:26<03:41, 10.70it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  10%|█         | 273/2645 [00:26<03:41, 10.70it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  10%|█         | 273/2645 [00:26<03:41, 10.70it/s, training_loss=0.784]\u001b[A\n",
      "Epoch 2:  10%|█         | 273/2645 [00:26<03:41, 10.70it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  10%|█         | 275/2645 [00:26<03:40, 10.74it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  10%|█         | 275/2645 [00:26<03:40, 10.74it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  10%|█         | 275/2645 [00:26<03:40, 10.74it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  10%|█         | 277/2645 [00:26<03:40, 10.73it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  10%|█         | 277/2645 [00:26<03:40, 10.73it/s, training_loss=0.339]\u001b[A\n",
      "Epoch 2:  10%|█         | 277/2645 [00:26<03:40, 10.73it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  11%|█         | 279/2645 [00:26<03:40, 10.73it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  11%|█         | 279/2645 [00:26<03:40, 10.73it/s, training_loss=0.014]\u001b[A\n",
      "Epoch 2:  11%|█         | 279/2645 [00:27<03:40, 10.73it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  11%|█         | 281/2645 [00:27<03:39, 10.75it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  11%|█         | 281/2645 [00:27<03:39, 10.75it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  11%|█         | 281/2645 [00:27<03:39, 10.75it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  11%|█         | 283/2645 [00:27<03:39, 10.77it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  11%|█         | 283/2645 [00:27<03:39, 10.77it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  11%|█         | 283/2645 [00:27<03:39, 10.77it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  11%|█         | 285/2645 [00:27<03:39, 10.77it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  11%|█         | 285/2645 [00:27<03:39, 10.77it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  11%|█         | 285/2645 [00:27<03:39, 10.77it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  11%|█         | 287/2645 [00:27<03:38, 10.79it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  11%|█         | 287/2645 [00:27<03:38, 10.79it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  11%|█         | 287/2645 [00:27<03:38, 10.79it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  11%|█         | 289/2645 [00:27<03:37, 10.81it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  11%|█         | 289/2645 [00:27<03:37, 10.81it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  11%|█         | 289/2645 [00:27<03:37, 10.81it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  11%|█         | 291/2645 [00:27<03:39, 10.74it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  11%|█         | 291/2645 [00:28<03:39, 10.74it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  11%|█         | 291/2645 [00:28<03:39, 10.74it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  11%|█         | 293/2645 [00:28<03:38, 10.77it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  11%|█         | 293/2645 [00:28<03:38, 10.77it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  11%|█         | 293/2645 [00:28<03:38, 10.77it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  11%|█         | 295/2645 [00:28<03:37, 10.81it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  11%|█         | 295/2645 [00:28<03:37, 10.81it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  11%|█         | 295/2645 [00:28<03:37, 10.81it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  11%|█         | 297/2645 [00:28<03:36, 10.86it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  11%|█         | 297/2645 [00:28<03:36, 10.86it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  11%|█         | 297/2645 [00:28<03:36, 10.86it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  11%|█▏        | 299/2645 [00:28<03:36, 10.85it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  11%|█▏        | 299/2645 [00:28<03:36, 10.85it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  11%|█▏        | 299/2645 [00:28<03:36, 10.85it/s, training_loss=0.659]\u001b[A\n",
      "Epoch 2:  11%|█▏        | 301/2645 [00:28<03:37, 10.76it/s, training_loss=0.659]\u001b[A\n",
      "Epoch 2:  11%|█▏        | 301/2645 [00:28<03:37, 10.76it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  11%|█▏        | 301/2645 [00:29<03:37, 10.76it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  11%|█▏        | 303/2645 [00:29<03:45, 10.38it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  11%|█▏        | 303/2645 [00:29<03:45, 10.38it/s, training_loss=0.147]\u001b[A\n",
      "Epoch 2:  11%|█▏        | 303/2645 [00:29<03:45, 10.38it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  12%|█▏        | 305/2645 [00:29<03:46, 10.32it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  12%|█▏        | 305/2645 [00:29<03:46, 10.32it/s, training_loss=0.366]\u001b[A\n",
      "Epoch 2:  12%|█▏        | 305/2645 [00:29<03:46, 10.32it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  12%|█▏        | 307/2645 [00:29<03:50, 10.15it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  12%|█▏        | 307/2645 [00:29<03:50, 10.15it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  12%|█▏        | 307/2645 [00:29<03:50, 10.15it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  12%|█▏        | 309/2645 [00:29<03:49, 10.19it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  12%|█▏        | 309/2645 [00:29<03:49, 10.19it/s, training_loss=0.544]\u001b[A\n",
      "Epoch 2:  12%|█▏        | 309/2645 [00:29<03:49, 10.19it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  12%|█▏        | 311/2645 [00:29<03:49, 10.19it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  12%|█▏        | 311/2645 [00:29<03:49, 10.19it/s, training_loss=0.375]\u001b[A\n",
      "Epoch 2:  12%|█▏        | 311/2645 [00:30<03:49, 10.19it/s, training_loss=0.317]\u001b[A\n",
      "Epoch 2:  12%|█▏        | 313/2645 [00:30<03:51, 10.07it/s, training_loss=0.317]\u001b[A\n",
      "Epoch 2:  12%|█▏        | 313/2645 [00:30<03:51, 10.07it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  12%|█▏        | 313/2645 [00:30<03:51, 10.07it/s, training_loss=0.892]\u001b[A\n",
      "Epoch 2:  12%|█▏        | 315/2645 [00:30<03:50, 10.09it/s, training_loss=0.892]\u001b[A\n",
      "Epoch 2:  12%|█▏        | 315/2645 [00:30<03:50, 10.09it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  12%|█▏        | 315/2645 [00:30<03:50, 10.09it/s, training_loss=0.118]\u001b[A\n",
      "Epoch 2:  12%|█▏        | 317/2645 [00:30<03:53,  9.98it/s, training_loss=0.118]\u001b[A\n",
      "Epoch 2:  12%|█▏        | 317/2645 [00:30<03:53,  9.98it/s, training_loss=0.757]\u001b[A\n",
      "Epoch 2:  12%|█▏        | 318/2645 [00:30<03:53,  9.95it/s, training_loss=0.757]\u001b[A\n",
      "Epoch 2:  12%|█▏        | 318/2645 [00:30<03:53,  9.95it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  12%|█▏        | 318/2645 [00:30<03:53,  9.95it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  12%|█▏        | 320/2645 [00:30<03:52,  9.99it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  12%|█▏        | 320/2645 [00:30<03:52,  9.99it/s, training_loss=0.398]\u001b[A\n",
      "Epoch 2:  12%|█▏        | 321/2645 [00:30<03:54,  9.89it/s, training_loss=0.398]\u001b[A\n",
      "Epoch 2:  12%|█▏        | 321/2645 [00:30<03:54,  9.89it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  12%|█▏        | 321/2645 [00:31<03:54,  9.89it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  12%|█▏        | 323/2645 [00:31<03:53,  9.93it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  12%|█▏        | 323/2645 [00:31<03:53,  9.93it/s, training_loss=0.232]\u001b[A\n",
      "Epoch 2:  12%|█▏        | 324/2645 [00:31<03:54,  9.88it/s, training_loss=0.232]\u001b[A\n",
      "Epoch 2:  12%|█▏        | 324/2645 [00:31<03:54,  9.88it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  12%|█▏        | 324/2645 [00:31<03:54,  9.88it/s, training_loss=0.407]\u001b[A\n",
      "Epoch 2:  12%|█▏        | 326/2645 [00:31<03:53,  9.92it/s, training_loss=0.407]\u001b[A\n",
      "Epoch 2:  12%|█▏        | 326/2645 [00:31<03:53,  9.92it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  12%|█▏        | 327/2645 [00:31<03:54,  9.88it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  12%|█▏        | 327/2645 [00:31<03:54,  9.88it/s, training_loss=0.011]\u001b[A\n",
      "Epoch 2:  12%|█▏        | 328/2645 [00:31<03:53,  9.90it/s, training_loss=0.011]\u001b[A\n",
      "Epoch 2:  12%|█▏        | 328/2645 [00:31<03:53,  9.90it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  12%|█▏        | 328/2645 [00:31<03:53,  9.90it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  12%|█▏        | 330/2645 [00:31<03:52,  9.98it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  12%|█▏        | 330/2645 [00:31<03:52,  9.98it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  12%|█▏        | 330/2645 [00:31<03:52,  9.98it/s, training_loss=0.022]\u001b[A\n",
      "Epoch 2:  13%|█▎        | 332/2645 [00:31<03:50, 10.05it/s, training_loss=0.022]\u001b[A\n",
      "Epoch 2:  13%|█▎        | 332/2645 [00:32<03:50, 10.05it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  13%|█▎        | 332/2645 [00:32<03:50, 10.05it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  13%|█▎        | 334/2645 [00:32<03:48, 10.12it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  13%|█▎        | 334/2645 [00:32<03:48, 10.12it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  13%|█▎        | 334/2645 [00:32<03:48, 10.12it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  13%|█▎        | 336/2645 [00:32<03:46, 10.21it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  13%|█▎        | 336/2645 [00:32<03:46, 10.21it/s, training_loss=0.398]\u001b[A\n",
      "Epoch 2:  13%|█▎        | 336/2645 [00:32<03:46, 10.21it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  13%|█▎        | 338/2645 [00:32<03:46, 10.18it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  13%|█▎        | 338/2645 [00:32<03:46, 10.18it/s, training_loss=0.670]\u001b[A\n",
      "Epoch 2:  13%|█▎        | 338/2645 [00:32<03:46, 10.18it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  13%|█▎        | 340/2645 [00:32<03:48, 10.11it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  13%|█▎        | 340/2645 [00:32<03:48, 10.11it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  13%|█▎        | 340/2645 [00:32<03:48, 10.11it/s, training_loss=0.720]\u001b[A\n",
      "Epoch 2:  13%|█▎        | 342/2645 [00:32<03:48, 10.07it/s, training_loss=0.720]\u001b[A\n",
      "Epoch 2:  13%|█▎        | 342/2645 [00:33<03:48, 10.07it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  13%|█▎        | 342/2645 [00:33<03:48, 10.07it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  13%|█▎        | 344/2645 [00:33<03:49, 10.01it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  13%|█▎        | 344/2645 [00:33<03:49, 10.01it/s, training_loss=0.590]\u001b[A\n",
      "Epoch 2:  13%|█▎        | 344/2645 [00:33<03:49, 10.01it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  13%|█▎        | 346/2645 [00:33<03:50,  9.98it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  13%|█▎        | 346/2645 [00:33<03:50,  9.98it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  13%|█▎        | 347/2645 [00:33<03:52,  9.90it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  13%|█▎        | 347/2645 [00:33<03:52,  9.90it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  13%|█▎        | 348/2645 [00:33<03:52,  9.90it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  13%|█▎        | 348/2645 [00:33<03:52,  9.90it/s, training_loss=0.250]\u001b[A\n",
      "Epoch 2:  13%|█▎        | 349/2645 [00:33<03:51,  9.90it/s, training_loss=0.250]\u001b[A\n",
      "Epoch 2:  13%|█▎        | 349/2645 [00:33<03:51,  9.90it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  13%|█▎        | 349/2645 [00:33<03:51,  9.90it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  13%|█▎        | 351/2645 [00:33<03:50,  9.95it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  13%|█▎        | 351/2645 [00:33<03:50,  9.95it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  13%|█▎        | 351/2645 [00:34<03:50,  9.95it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  13%|█▎        | 353/2645 [00:34<03:47, 10.07it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  13%|█▎        | 353/2645 [00:34<03:47, 10.07it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  13%|█▎        | 353/2645 [00:34<03:47, 10.07it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  13%|█▎        | 355/2645 [00:34<03:45, 10.15it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  13%|█▎        | 355/2645 [00:34<03:45, 10.15it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  13%|█▎        | 355/2645 [00:34<03:45, 10.15it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  13%|█▎        | 357/2645 [00:34<03:45, 10.13it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  13%|█▎        | 357/2645 [00:34<03:45, 10.13it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  13%|█▎        | 357/2645 [00:34<03:45, 10.13it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  14%|█▎        | 359/2645 [00:34<03:46, 10.10it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  14%|█▎        | 359/2645 [00:34<03:46, 10.10it/s, training_loss=0.087]\u001b[A\n",
      "Epoch 2:  14%|█▎        | 359/2645 [00:34<03:46, 10.10it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  14%|█▎        | 361/2645 [00:34<03:48, 10.01it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  14%|█▎        | 361/2645 [00:34<03:48, 10.01it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  14%|█▎        | 361/2645 [00:35<03:48, 10.01it/s, training_loss=0.119]\u001b[A\n",
      "Epoch 2:  14%|█▎        | 363/2645 [00:35<03:47, 10.02it/s, training_loss=0.119]\u001b[A\n",
      "Epoch 2:  14%|█▎        | 363/2645 [00:35<03:47, 10.02it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  14%|█▎        | 363/2645 [00:35<03:47, 10.02it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  14%|█▍        | 365/2645 [00:35<03:48,  9.99it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  14%|█▍        | 365/2645 [00:35<03:48,  9.99it/s, training_loss=0.933]\u001b[A\n",
      "Epoch 2:  14%|█▍        | 366/2645 [00:35<03:51,  9.85it/s, training_loss=0.933]\u001b[A\n",
      "Epoch 2:  14%|█▍        | 366/2645 [00:35<03:51,  9.85it/s, training_loss=0.451]\u001b[A\n",
      "Epoch 2:  14%|█▍        | 367/2645 [00:35<03:50,  9.89it/s, training_loss=0.451]\u001b[A\n",
      "Epoch 2:  14%|█▍        | 367/2645 [00:35<03:50,  9.89it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  14%|█▍        | 367/2645 [00:35<03:50,  9.89it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 2:  14%|█▍        | 369/2645 [00:35<03:48,  9.94it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 2:  14%|█▍        | 369/2645 [00:35<03:48,  9.94it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  14%|█▍        | 370/2645 [00:35<03:49,  9.91it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  14%|█▍        | 370/2645 [00:35<03:49,  9.91it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  14%|█▍        | 370/2645 [00:35<03:49,  9.91it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  14%|█▍        | 372/2645 [00:35<03:48,  9.96it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  14%|█▍        | 372/2645 [00:36<03:48,  9.96it/s, training_loss=0.853]\u001b[A\n",
      "Epoch 2:  14%|█▍        | 373/2645 [00:36<03:53,  9.72it/s, training_loss=0.853]\u001b[A\n",
      "Epoch 2:  14%|█▍        | 373/2645 [00:36<03:53,  9.72it/s, training_loss=0.466]\u001b[A\n",
      "Epoch 2:  14%|█▍        | 374/2645 [00:36<03:52,  9.77it/s, training_loss=0.466]\u001b[A\n",
      "Epoch 2:  14%|█▍        | 374/2645 [00:36<03:52,  9.77it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  14%|█▍        | 374/2645 [00:36<03:52,  9.77it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  14%|█▍        | 376/2645 [00:36<03:49,  9.90it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  14%|█▍        | 376/2645 [00:36<03:49,  9.90it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  14%|█▍        | 376/2645 [00:36<03:49,  9.90it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  14%|█▍        | 378/2645 [00:36<03:46,  9.99it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  14%|█▍        | 378/2645 [00:36<03:46,  9.99it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  14%|█▍        | 378/2645 [00:36<03:46,  9.99it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  14%|█▍        | 380/2645 [00:36<03:42, 10.17it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  14%|█▍        | 380/2645 [00:36<03:42, 10.17it/s, training_loss=0.721]\u001b[A\n",
      "Epoch 2:  14%|█▍        | 380/2645 [00:36<03:42, 10.17it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  14%|█▍        | 382/2645 [00:36<03:44, 10.09it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  14%|█▍        | 382/2645 [00:37<03:44, 10.09it/s, training_loss=1.402]\u001b[A\n",
      "Epoch 2:  14%|█▍        | 382/2645 [00:37<03:44, 10.09it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  15%|█▍        | 384/2645 [00:37<03:44, 10.06it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  15%|█▍        | 384/2645 [00:37<03:44, 10.06it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 2:  15%|█▍        | 384/2645 [00:37<03:44, 10.06it/s, training_loss=0.030]\u001b[A\n",
      "Epoch 2:  15%|█▍        | 386/2645 [00:37<03:46,  9.95it/s, training_loss=0.030]\u001b[A\n",
      "Epoch 2:  15%|█▍        | 386/2645 [00:37<03:46,  9.95it/s, training_loss=0.019]\u001b[A\n",
      "Epoch 2:  15%|█▍        | 387/2645 [00:37<03:47,  9.95it/s, training_loss=0.019]\u001b[A\n",
      "Epoch 2:  15%|█▍        | 387/2645 [00:37<03:47,  9.95it/s, training_loss=0.059]\u001b[A\n",
      "Epoch 2:  15%|█▍        | 388/2645 [00:37<03:46,  9.96it/s, training_loss=0.059]\u001b[A\n",
      "Epoch 2:  15%|█▍        | 388/2645 [00:37<03:46,  9.96it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  15%|█▍        | 388/2645 [00:37<03:46,  9.96it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  15%|█▍        | 390/2645 [00:37<03:45, 10.02it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  15%|█▍        | 390/2645 [00:37<03:45, 10.02it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  15%|█▍        | 390/2645 [00:37<03:45, 10.02it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  15%|█▍        | 392/2645 [00:37<03:45,  9.98it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  15%|█▍        | 392/2645 [00:38<03:45,  9.98it/s, training_loss=0.879]\u001b[A\n",
      "Epoch 2:  15%|█▍        | 393/2645 [00:38<03:46,  9.94it/s, training_loss=0.879]\u001b[A\n",
      "Epoch 2:  15%|█▍        | 393/2645 [00:38<03:46,  9.94it/s, training_loss=0.812]\u001b[A\n",
      "Epoch 2:  15%|█▍        | 394/2645 [00:38<03:46,  9.93it/s, training_loss=0.812]\u001b[A\n",
      "Epoch 2:  15%|█▍        | 394/2645 [00:38<03:46,  9.93it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  15%|█▍        | 394/2645 [00:38<03:46,  9.93it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  15%|█▍        | 396/2645 [00:38<03:44, 10.04it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  15%|█▍        | 396/2645 [00:38<03:44, 10.04it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  15%|█▍        | 396/2645 [00:38<03:44, 10.04it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  15%|█▌        | 398/2645 [00:38<03:43, 10.06it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  15%|█▌        | 398/2645 [00:38<03:43, 10.06it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  15%|█▌        | 398/2645 [00:38<03:43, 10.06it/s, training_loss=0.435]\u001b[A\n",
      "Epoch 2:  15%|█▌        | 400/2645 [00:38<03:45,  9.95it/s, training_loss=0.435]\u001b[A\n",
      "Epoch 2:  15%|█▌        | 400/2645 [00:38<03:45,  9.95it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  15%|█▌        | 400/2645 [00:38<03:45,  9.95it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  15%|█▌        | 402/2645 [00:38<03:44, 10.01it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  15%|█▌        | 402/2645 [00:39<03:44, 10.01it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  15%|█▌        | 402/2645 [00:39<03:44, 10.01it/s, training_loss=0.330]\u001b[A\n",
      "Epoch 2:  15%|█▌        | 404/2645 [00:39<03:43, 10.02it/s, training_loss=0.330]\u001b[A\n",
      "Epoch 2:  15%|█▌        | 404/2645 [00:39<03:43, 10.02it/s, training_loss=0.811]\u001b[A\n",
      "Epoch 2:  15%|█▌        | 404/2645 [00:39<03:43, 10.02it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  15%|█▌        | 406/2645 [00:39<03:44,  9.97it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  15%|█▌        | 406/2645 [00:39<03:44,  9.97it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  15%|█▌        | 407/2645 [00:39<03:44,  9.96it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  15%|█▌        | 407/2645 [00:39<03:44,  9.96it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  15%|█▌        | 408/2645 [00:39<03:44,  9.96it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  15%|█▌        | 408/2645 [00:39<03:44,  9.96it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  15%|█▌        | 409/2645 [00:39<03:45,  9.90it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  15%|█▌        | 409/2645 [00:39<03:45,  9.90it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  15%|█▌        | 409/2645 [00:39<03:45,  9.90it/s, training_loss=0.394]\u001b[A\n",
      "Epoch 2:  16%|█▌        | 411/2645 [00:39<03:43,  9.97it/s, training_loss=0.394]\u001b[A\n",
      "Epoch 2:  16%|█▌        | 411/2645 [00:39<03:43,  9.97it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  16%|█▌        | 412/2645 [00:39<03:45,  9.91it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  16%|█▌        | 412/2645 [00:40<03:45,  9.91it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  16%|█▌        | 413/2645 [00:40<03:47,  9.80it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  16%|█▌        | 413/2645 [00:40<03:47,  9.80it/s, training_loss=0.014]\u001b[A\n",
      "Epoch 2:  16%|█▌        | 414/2645 [00:40<03:47,  9.82it/s, training_loss=0.014]\u001b[A\n",
      "Epoch 2:  16%|█▌        | 414/2645 [00:40<03:47,  9.82it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  16%|█▌        | 414/2645 [00:40<03:47,  9.82it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  16%|█▌        | 416/2645 [00:40<03:43,  9.95it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  16%|█▌        | 416/2645 [00:40<03:43,  9.95it/s, training_loss=0.203]\u001b[A\n",
      "Epoch 2:  16%|█▌        | 417/2645 [00:40<03:44,  9.93it/s, training_loss=0.203]\u001b[A\n",
      "Epoch 2:  16%|█▌        | 417/2645 [00:40<03:44,  9.93it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  16%|█▌        | 417/2645 [00:40<03:44,  9.93it/s, training_loss=0.014]\u001b[A\n",
      "Epoch 2:  16%|█▌        | 419/2645 [00:40<03:40, 10.09it/s, training_loss=0.014]\u001b[A\n",
      "Epoch 2:  16%|█▌        | 419/2645 [00:40<03:40, 10.09it/s, training_loss=0.044]\u001b[A\n",
      "Epoch 2:  16%|█▌        | 419/2645 [00:40<03:40, 10.09it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  16%|█▌        | 421/2645 [00:40<03:37, 10.21it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  16%|█▌        | 421/2645 [00:40<03:37, 10.21it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  16%|█▌        | 421/2645 [00:41<03:37, 10.21it/s, training_loss=0.027]\u001b[A\n",
      "Epoch 2:  16%|█▌        | 423/2645 [00:41<03:36, 10.28it/s, training_loss=0.027]\u001b[A\n",
      "Epoch 2:  16%|█▌        | 423/2645 [00:41<03:36, 10.28it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  16%|█▌        | 423/2645 [00:41<03:36, 10.28it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  16%|█▌        | 425/2645 [00:41<03:34, 10.37it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  16%|█▌        | 425/2645 [00:41<03:34, 10.37it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  16%|█▌        | 425/2645 [00:41<03:34, 10.37it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  16%|█▌        | 427/2645 [00:41<03:32, 10.45it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  16%|█▌        | 427/2645 [00:41<03:32, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  16%|█▌        | 427/2645 [00:41<03:32, 10.45it/s, training_loss=0.691]\u001b[A\n",
      "Epoch 2:  16%|█▌        | 429/2645 [00:41<03:33, 10.37it/s, training_loss=0.691]\u001b[A\n",
      "Epoch 2:  16%|█▌        | 429/2645 [00:41<03:33, 10.37it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  16%|█▌        | 429/2645 [00:41<03:33, 10.37it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  16%|█▋        | 431/2645 [00:41<03:35, 10.29it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  16%|█▋        | 431/2645 [00:41<03:35, 10.29it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  16%|█▋        | 431/2645 [00:42<03:35, 10.29it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  16%|█▋        | 433/2645 [00:42<03:35, 10.28it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  16%|█▋        | 433/2645 [00:42<03:35, 10.28it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  16%|█▋        | 433/2645 [00:42<03:35, 10.28it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  16%|█▋        | 435/2645 [00:42<03:36, 10.20it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  16%|█▋        | 435/2645 [00:42<03:36, 10.20it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  16%|█▋        | 435/2645 [00:42<03:36, 10.20it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  17%|█▋        | 437/2645 [00:42<03:35, 10.25it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  17%|█▋        | 437/2645 [00:42<03:35, 10.25it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  17%|█▋        | 437/2645 [00:42<03:35, 10.25it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  17%|█▋        | 439/2645 [00:42<03:33, 10.32it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  17%|█▋        | 439/2645 [00:42<03:33, 10.32it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  17%|█▋        | 439/2645 [00:42<03:33, 10.32it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  17%|█▋        | 441/2645 [00:42<03:32, 10.37it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  17%|█▋        | 441/2645 [00:42<03:32, 10.37it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  17%|█▋        | 441/2645 [00:42<03:32, 10.37it/s, training_loss=0.464]\u001b[A\n",
      "Epoch 2:  17%|█▋        | 443/2645 [00:42<03:31, 10.41it/s, training_loss=0.464]\u001b[A\n",
      "Epoch 2:  17%|█▋        | 443/2645 [00:43<03:31, 10.41it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 2:  17%|█▋        | 443/2645 [00:43<03:31, 10.41it/s, training_loss=0.379]\u001b[A\n",
      "Epoch 2:  17%|█▋        | 445/2645 [00:43<03:33, 10.32it/s, training_loss=0.379]\u001b[A\n",
      "Epoch 2:  17%|█▋        | 445/2645 [00:43<03:33, 10.32it/s, training_loss=0.064]\u001b[A\n",
      "Epoch 2:  17%|█▋        | 445/2645 [00:43<03:33, 10.32it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  17%|█▋        | 447/2645 [00:43<03:32, 10.37it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  17%|█▋        | 447/2645 [00:43<03:32, 10.37it/s, training_loss=0.036]\u001b[A\n",
      "Epoch 2:  17%|█▋        | 447/2645 [00:43<03:32, 10.37it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  17%|█▋        | 449/2645 [00:43<03:31, 10.39it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  17%|█▋        | 449/2645 [00:43<03:31, 10.39it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  17%|█▋        | 449/2645 [00:43<03:31, 10.39it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  17%|█▋        | 451/2645 [00:43<03:30, 10.43it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  17%|█▋        | 451/2645 [00:43<03:30, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  17%|█▋        | 451/2645 [00:43<03:30, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  17%|█▋        | 453/2645 [00:43<03:29, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  17%|█▋        | 453/2645 [00:44<03:29, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  17%|█▋        | 453/2645 [00:44<03:29, 10.48it/s, training_loss=0.123]\u001b[A\n",
      "Epoch 2:  17%|█▋        | 455/2645 [00:44<03:29, 10.46it/s, training_loss=0.123]\u001b[A\n",
      "Epoch 2:  17%|█▋        | 455/2645 [00:44<03:29, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  17%|█▋        | 455/2645 [00:44<03:29, 10.46it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  17%|█▋        | 457/2645 [00:44<03:28, 10.49it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  17%|█▋        | 457/2645 [00:44<03:28, 10.49it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  17%|█▋        | 457/2645 [00:44<03:28, 10.49it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  17%|█▋        | 459/2645 [00:44<03:27, 10.52it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  17%|█▋        | 459/2645 [00:44<03:27, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  17%|█▋        | 459/2645 [00:44<03:27, 10.52it/s, training_loss=0.054]\u001b[A\n",
      "Epoch 2:  17%|█▋        | 461/2645 [00:44<03:27, 10.51it/s, training_loss=0.054]\u001b[A\n",
      "Epoch 2:  17%|█▋        | 461/2645 [00:44<03:27, 10.51it/s, training_loss=0.728]\u001b[A\n",
      "Epoch 2:  17%|█▋        | 461/2645 [00:44<03:27, 10.51it/s, training_loss=0.633]\u001b[A\n",
      "Epoch 2:  18%|█▊        | 463/2645 [00:44<03:28, 10.44it/s, training_loss=0.633]\u001b[A\n",
      "Epoch 2:  18%|█▊        | 463/2645 [00:44<03:28, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  18%|█▊        | 463/2645 [00:45<03:28, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  18%|█▊        | 465/2645 [00:45<03:28, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  18%|█▊        | 465/2645 [00:45<03:28, 10.47it/s, training_loss=0.455]\u001b[A\n",
      "Epoch 2:  18%|█▊        | 465/2645 [00:45<03:28, 10.47it/s, training_loss=1.195]\u001b[A\n",
      "Epoch 2:  18%|█▊        | 467/2645 [00:45<03:29, 10.39it/s, training_loss=1.195]\u001b[A\n",
      "Epoch 2:  18%|█▊        | 467/2645 [00:45<03:29, 10.39it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  18%|█▊        | 467/2645 [00:45<03:29, 10.39it/s, training_loss=0.778]\u001b[A\n",
      "Epoch 2:  18%|█▊        | 469/2645 [00:45<03:31, 10.28it/s, training_loss=0.778]\u001b[A\n",
      "Epoch 2:  18%|█▊        | 469/2645 [00:45<03:31, 10.28it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  18%|█▊        | 469/2645 [00:45<03:31, 10.28it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  18%|█▊        | 471/2645 [00:45<03:31, 10.26it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  18%|█▊        | 471/2645 [00:45<03:31, 10.26it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  18%|█▊        | 471/2645 [00:45<03:31, 10.26it/s, training_loss=0.219]\u001b[A\n",
      "Epoch 2:  18%|█▊        | 473/2645 [00:45<03:31, 10.27it/s, training_loss=0.219]\u001b[A\n",
      "Epoch 2:  18%|█▊        | 473/2645 [00:45<03:31, 10.27it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  18%|█▊        | 473/2645 [00:46<03:31, 10.27it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  18%|█▊        | 475/2645 [00:46<03:34, 10.13it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  18%|█▊        | 475/2645 [00:46<03:34, 10.13it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  18%|█▊        | 475/2645 [00:46<03:34, 10.13it/s, training_loss=0.948]\u001b[A\n",
      "Epoch 2:  18%|█▊        | 477/2645 [00:46<03:34, 10.12it/s, training_loss=0.948]\u001b[A\n",
      "Epoch 2:  18%|█▊        | 477/2645 [00:46<03:34, 10.12it/s, training_loss=0.680]\u001b[A\n",
      "Epoch 2:  18%|█▊        | 477/2645 [00:46<03:34, 10.12it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  18%|█▊        | 479/2645 [00:46<03:31, 10.22it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  18%|█▊        | 479/2645 [00:46<03:31, 10.22it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 2:  18%|█▊        | 479/2645 [00:46<03:31, 10.22it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  18%|█▊        | 481/2645 [00:46<03:30, 10.30it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  18%|█▊        | 481/2645 [00:46<03:30, 10.30it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  18%|█▊        | 481/2645 [00:46<03:30, 10.30it/s, training_loss=0.672]\u001b[A\n",
      "Epoch 2:  18%|█▊        | 483/2645 [00:46<03:29, 10.33it/s, training_loss=0.672]\u001b[A\n",
      "Epoch 2:  18%|█▊        | 483/2645 [00:46<03:29, 10.33it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  18%|█▊        | 483/2645 [00:47<03:29, 10.33it/s, training_loss=0.013]\u001b[A\n",
      "Epoch 2:  18%|█▊        | 485/2645 [00:47<03:28, 10.38it/s, training_loss=0.013]\u001b[A\n",
      "Epoch 2:  18%|█▊        | 485/2645 [00:47<03:28, 10.38it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  18%|█▊        | 485/2645 [00:47<03:28, 10.38it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  18%|█▊        | 487/2645 [00:47<03:26, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  18%|█▊        | 487/2645 [00:47<03:26, 10.43it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  18%|█▊        | 487/2645 [00:47<03:26, 10.43it/s, training_loss=0.011]\u001b[A\n",
      "Epoch 2:  18%|█▊        | 489/2645 [00:47<03:27, 10.40it/s, training_loss=0.011]\u001b[A\n",
      "Epoch 2:  18%|█▊        | 489/2645 [00:47<03:27, 10.40it/s, training_loss=0.064]\u001b[A\n",
      "Epoch 2:  18%|█▊        | 489/2645 [00:47<03:27, 10.40it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  19%|█▊        | 491/2645 [00:47<03:28, 10.35it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  19%|█▊        | 491/2645 [00:47<03:28, 10.35it/s, training_loss=0.019]\u001b[A\n",
      "Epoch 2:  19%|█▊        | 491/2645 [00:47<03:28, 10.35it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  19%|█▊        | 493/2645 [00:47<03:31, 10.17it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  19%|█▊        | 493/2645 [00:47<03:31, 10.17it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  19%|█▊        | 493/2645 [00:48<03:31, 10.17it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  19%|█▊        | 495/2645 [00:48<03:30, 10.19it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  19%|█▊        | 495/2645 [00:48<03:30, 10.19it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  19%|█▊        | 495/2645 [00:48<03:30, 10.19it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  19%|█▉        | 497/2645 [00:48<03:32, 10.12it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  19%|█▉        | 497/2645 [00:48<03:32, 10.12it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  19%|█▉        | 497/2645 [00:48<03:32, 10.12it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  19%|█▉        | 499/2645 [00:48<03:32, 10.10it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  19%|█▉        | 499/2645 [00:48<03:32, 10.10it/s, training_loss=0.053]\u001b[A\n",
      "Epoch 2:  19%|█▉        | 499/2645 [00:48<03:32, 10.10it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  19%|█▉        | 501/2645 [00:48<03:30, 10.19it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  19%|█▉        | 501/2645 [00:48<03:30, 10.19it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  19%|█▉        | 501/2645 [00:48<03:30, 10.19it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  19%|█▉        | 503/2645 [00:48<03:30, 10.20it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  19%|█▉        | 503/2645 [00:48<03:30, 10.20it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  19%|█▉        | 503/2645 [00:48<03:30, 10.20it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  19%|█▉        | 505/2645 [00:48<03:29, 10.21it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  19%|█▉        | 505/2645 [00:49<03:29, 10.21it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  19%|█▉        | 505/2645 [00:49<03:29, 10.21it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  19%|█▉        | 507/2645 [00:49<03:30, 10.14it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  19%|█▉        | 507/2645 [00:49<03:30, 10.14it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  19%|█▉        | 507/2645 [00:49<03:30, 10.14it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  19%|█▉        | 509/2645 [00:49<03:33, 10.03it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  19%|█▉        | 509/2645 [00:49<03:33, 10.03it/s, training_loss=0.790]\u001b[A\n",
      "Epoch 2:  19%|█▉        | 509/2645 [00:49<03:33, 10.03it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  19%|█▉        | 511/2645 [00:49<03:31, 10.08it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  19%|█▉        | 511/2645 [00:49<03:31, 10.08it/s, training_loss=0.427]\u001b[A\n",
      "Epoch 2:  19%|█▉        | 511/2645 [00:49<03:31, 10.08it/s, training_loss=0.016]\u001b[A\n",
      "Epoch 2:  19%|█▉        | 513/2645 [00:49<03:34,  9.94it/s, training_loss=0.016]\u001b[A\n",
      "Epoch 2:  19%|█▉        | 513/2645 [00:49<03:34,  9.94it/s, training_loss=0.064]\u001b[A\n",
      "Epoch 2:  19%|█▉        | 514/2645 [00:49<03:34,  9.92it/s, training_loss=0.064]\u001b[A\n",
      "Epoch 2:  19%|█▉        | 514/2645 [00:49<03:34,  9.92it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  19%|█▉        | 515/2645 [00:49<03:34,  9.92it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  19%|█▉        | 515/2645 [00:50<03:34,  9.92it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 2:  20%|█▉        | 516/2645 [00:50<03:34,  9.93it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 2:  20%|█▉        | 516/2645 [00:50<03:34,  9.93it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  20%|█▉        | 516/2645 [00:50<03:34,  9.93it/s, training_loss=0.014]\u001b[A\n",
      "Epoch 2:  20%|█▉        | 518/2645 [00:50<03:33,  9.94it/s, training_loss=0.014]\u001b[A\n",
      "Epoch 2:  20%|█▉        | 518/2645 [00:50<03:33,  9.94it/s, training_loss=0.047]\u001b[A\n",
      "Epoch 2:  20%|█▉        | 519/2645 [00:50<03:33,  9.94it/s, training_loss=0.047]\u001b[A\n",
      "Epoch 2:  20%|█▉        | 519/2645 [00:50<03:33,  9.94it/s, training_loss=0.454]\u001b[A\n",
      "Epoch 2:  20%|█▉        | 520/2645 [00:50<03:33,  9.94it/s, training_loss=0.454]\u001b[A\n",
      "Epoch 2:  20%|█▉        | 520/2645 [00:50<03:33,  9.94it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  20%|█▉        | 520/2645 [00:50<03:33,  9.94it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  20%|█▉        | 522/2645 [00:50<03:32,  9.97it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  20%|█▉        | 522/2645 [00:50<03:32,  9.97it/s, training_loss=0.358]\u001b[A\n",
      "Epoch 2:  20%|█▉        | 523/2645 [00:50<03:34,  9.89it/s, training_loss=0.358]\u001b[A\n",
      "Epoch 2:  20%|█▉        | 523/2645 [00:50<03:34,  9.89it/s, training_loss=0.061]\u001b[A\n",
      "Epoch 2:  20%|█▉        | 524/2645 [00:50<03:34,  9.90it/s, training_loss=0.061]\u001b[A\n",
      "Epoch 2:  20%|█▉        | 524/2645 [00:50<03:34,  9.90it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  20%|█▉        | 524/2645 [00:51<03:34,  9.90it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  20%|█▉        | 526/2645 [00:51<03:32,  9.95it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  20%|█▉        | 526/2645 [00:51<03:32,  9.95it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  20%|█▉        | 527/2645 [00:51<03:34,  9.85it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  20%|█▉        | 527/2645 [00:51<03:34,  9.85it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  20%|█▉        | 528/2645 [00:51<03:34,  9.89it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  20%|█▉        | 528/2645 [00:51<03:34,  9.89it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  20%|█▉        | 528/2645 [00:51<03:34,  9.89it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  20%|██        | 530/2645 [00:51<03:32,  9.94it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  20%|██        | 530/2645 [00:51<03:32,  9.94it/s, training_loss=0.340]\u001b[A\n",
      "Epoch 2:  20%|██        | 531/2645 [00:51<03:35,  9.82it/s, training_loss=0.340]\u001b[A\n",
      "Epoch 2:  20%|██        | 531/2645 [00:51<03:35,  9.82it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  20%|██        | 531/2645 [00:51<03:35,  9.82it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  20%|██        | 533/2645 [00:51<03:34,  9.85it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  20%|██        | 533/2645 [00:51<03:34,  9.85it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  20%|██        | 533/2645 [00:52<03:34,  9.85it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  20%|██        | 535/2645 [00:52<03:31,  9.96it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  20%|██        | 535/2645 [00:52<03:31,  9.96it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  20%|██        | 536/2645 [00:52<03:31,  9.97it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  20%|██        | 536/2645 [00:52<03:31,  9.97it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  20%|██        | 536/2645 [00:52<03:31,  9.97it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  20%|██        | 538/2645 [00:52<03:29, 10.05it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  20%|██        | 538/2645 [00:52<03:29, 10.05it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  20%|██        | 538/2645 [00:52<03:29, 10.05it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  20%|██        | 540/2645 [00:52<03:29, 10.07it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  20%|██        | 540/2645 [00:52<03:29, 10.07it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  20%|██        | 540/2645 [00:52<03:29, 10.07it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  20%|██        | 542/2645 [00:52<03:28, 10.09it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  20%|██        | 542/2645 [00:52<03:28, 10.09it/s, training_loss=0.010]\u001b[A\n",
      "Epoch 2:  20%|██        | 542/2645 [00:52<03:28, 10.09it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  21%|██        | 544/2645 [00:52<03:28, 10.05it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  21%|██        | 544/2645 [00:52<03:28, 10.05it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  21%|██        | 544/2645 [00:53<03:28, 10.05it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  21%|██        | 546/2645 [00:53<03:27, 10.10it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  21%|██        | 546/2645 [00:53<03:27, 10.10it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  21%|██        | 546/2645 [00:53<03:27, 10.10it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  21%|██        | 548/2645 [00:53<03:25, 10.19it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  21%|██        | 548/2645 [00:53<03:25, 10.19it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  21%|██        | 548/2645 [00:53<03:25, 10.19it/s, training_loss=0.014]\u001b[A\n",
      "Epoch 2:  21%|██        | 550/2645 [00:53<03:26, 10.14it/s, training_loss=0.014]\u001b[A\n",
      "Epoch 2:  21%|██        | 550/2645 [00:53<03:26, 10.14it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  21%|██        | 550/2645 [00:53<03:26, 10.14it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  21%|██        | 552/2645 [00:53<03:26, 10.12it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  21%|██        | 552/2645 [00:53<03:26, 10.12it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  21%|██        | 552/2645 [00:53<03:26, 10.12it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  21%|██        | 554/2645 [00:53<03:25, 10.16it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  21%|██        | 554/2645 [00:53<03:25, 10.16it/s, training_loss=0.948]\u001b[A\n",
      "Epoch 2:  21%|██        | 554/2645 [00:54<03:25, 10.16it/s, training_loss=0.682]\u001b[A\n",
      "Epoch 2:  21%|██        | 556/2645 [00:54<03:26, 10.12it/s, training_loss=0.682]\u001b[A\n",
      "Epoch 2:  21%|██        | 556/2645 [00:54<03:26, 10.12it/s, training_loss=0.020]\u001b[A\n",
      "Epoch 2:  21%|██        | 556/2645 [00:54<03:26, 10.12it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  21%|██        | 558/2645 [00:54<03:26, 10.09it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  21%|██        | 558/2645 [00:54<03:26, 10.09it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 2:  21%|██        | 558/2645 [00:54<03:26, 10.09it/s, training_loss=0.017]\u001b[A\n",
      "Epoch 2:  21%|██        | 560/2645 [00:54<03:27, 10.04it/s, training_loss=0.017]\u001b[A\n",
      "Epoch 2:  21%|██        | 560/2645 [00:54<03:27, 10.04it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  21%|██        | 560/2645 [00:54<03:27, 10.04it/s, training_loss=0.051]\u001b[A\n",
      "Epoch 2:  21%|██        | 562/2645 [00:54<03:25, 10.16it/s, training_loss=0.051]\u001b[A\n",
      "Epoch 2:  21%|██        | 562/2645 [00:54<03:25, 10.16it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  21%|██        | 562/2645 [00:54<03:25, 10.16it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  21%|██▏       | 564/2645 [00:54<03:22, 10.28it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  21%|██▏       | 564/2645 [00:54<03:22, 10.28it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  21%|██▏       | 564/2645 [00:55<03:22, 10.28it/s, training_loss=0.900]\u001b[A\n",
      "Epoch 2:  21%|██▏       | 566/2645 [00:55<03:21, 10.33it/s, training_loss=0.900]\u001b[A\n",
      "Epoch 2:  21%|██▏       | 566/2645 [00:55<03:21, 10.33it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  21%|██▏       | 566/2645 [00:55<03:21, 10.33it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  21%|██▏       | 568/2645 [00:55<03:20, 10.37it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  21%|██▏       | 568/2645 [00:55<03:20, 10.37it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  21%|██▏       | 568/2645 [00:55<03:20, 10.37it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  22%|██▏       | 570/2645 [00:55<03:19, 10.38it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  22%|██▏       | 570/2645 [00:55<03:19, 10.38it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  22%|██▏       | 570/2645 [00:55<03:19, 10.38it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  22%|██▏       | 572/2645 [00:55<03:18, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  22%|██▏       | 572/2645 [00:55<03:18, 10.43it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  22%|██▏       | 572/2645 [00:55<03:18, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  22%|██▏       | 574/2645 [00:55<03:17, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  22%|██▏       | 574/2645 [00:55<03:17, 10.46it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  22%|██▏       | 574/2645 [00:56<03:17, 10.46it/s, training_loss=0.398]\u001b[A\n",
      "Epoch 2:  22%|██▏       | 576/2645 [00:56<03:17, 10.47it/s, training_loss=0.398]\u001b[A\n",
      "Epoch 2:  22%|██▏       | 576/2645 [00:56<03:17, 10.47it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  22%|██▏       | 576/2645 [00:56<03:17, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  22%|██▏       | 578/2645 [00:56<03:17, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  22%|██▏       | 578/2645 [00:56<03:17, 10.46it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  22%|██▏       | 578/2645 [00:56<03:17, 10.46it/s, training_loss=0.043]\u001b[A\n",
      "Epoch 2:  22%|██▏       | 580/2645 [00:56<03:18, 10.42it/s, training_loss=0.043]\u001b[A\n",
      "Epoch 2:  22%|██▏       | 580/2645 [00:56<03:18, 10.42it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  22%|██▏       | 580/2645 [00:56<03:18, 10.42it/s, training_loss=0.826]\u001b[A\n",
      "Epoch 2:  22%|██▏       | 582/2645 [00:56<03:18, 10.39it/s, training_loss=0.826]\u001b[A\n",
      "Epoch 2:  22%|██▏       | 582/2645 [00:56<03:18, 10.39it/s, training_loss=0.624]\u001b[A\n",
      "Epoch 2:  22%|██▏       | 582/2645 [00:56<03:18, 10.39it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  22%|██▏       | 584/2645 [00:56<03:19, 10.33it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  22%|██▏       | 584/2645 [00:56<03:19, 10.33it/s, training_loss=0.055]\u001b[A\n",
      "Epoch 2:  22%|██▏       | 584/2645 [00:56<03:19, 10.33it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  22%|██▏       | 586/2645 [00:56<03:18, 10.37it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  22%|██▏       | 586/2645 [00:57<03:18, 10.37it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  22%|██▏       | 586/2645 [00:57<03:18, 10.37it/s, training_loss=0.499]\u001b[A\n",
      "Epoch 2:  22%|██▏       | 588/2645 [00:57<03:18, 10.36it/s, training_loss=0.499]\u001b[A\n",
      "Epoch 2:  22%|██▏       | 588/2645 [00:57<03:18, 10.36it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  22%|██▏       | 588/2645 [00:57<03:18, 10.36it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  22%|██▏       | 590/2645 [00:57<03:16, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  22%|██▏       | 590/2645 [00:57<03:16, 10.45it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  22%|██▏       | 590/2645 [00:57<03:16, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  22%|██▏       | 592/2645 [00:57<03:17, 10.41it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  22%|██▏       | 592/2645 [00:57<03:17, 10.41it/s, training_loss=0.405]\u001b[A\n",
      "Epoch 2:  22%|██▏       | 592/2645 [00:57<03:17, 10.41it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  22%|██▏       | 594/2645 [00:57<03:18, 10.32it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  22%|██▏       | 594/2645 [00:57<03:18, 10.32it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  22%|██▏       | 594/2645 [00:57<03:18, 10.32it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  23%|██▎       | 596/2645 [00:57<03:17, 10.37it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  23%|██▎       | 596/2645 [00:58<03:17, 10.37it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  23%|██▎       | 596/2645 [00:58<03:17, 10.37it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  23%|██▎       | 598/2645 [00:58<03:16, 10.39it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  23%|██▎       | 598/2645 [00:58<03:16, 10.39it/s, training_loss=0.794]\u001b[A\n",
      "Epoch 2:  23%|██▎       | 598/2645 [00:58<03:16, 10.39it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  23%|██▎       | 600/2645 [00:58<03:16, 10.39it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  23%|██▎       | 600/2645 [00:58<03:16, 10.39it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  23%|██▎       | 600/2645 [00:58<03:16, 10.39it/s, training_loss=0.338]\u001b[A\n",
      "Epoch 2:  23%|██▎       | 602/2645 [00:58<03:17, 10.34it/s, training_loss=0.338]\u001b[A\n",
      "Epoch 2:  23%|██▎       | 602/2645 [00:58<03:17, 10.34it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  23%|██▎       | 602/2645 [00:58<03:17, 10.34it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  23%|██▎       | 604/2645 [00:58<03:16, 10.40it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  23%|██▎       | 604/2645 [00:58<03:16, 10.40it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  23%|██▎       | 604/2645 [00:58<03:16, 10.40it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  23%|██▎       | 606/2645 [00:58<03:15, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  23%|██▎       | 606/2645 [00:58<03:15, 10.43it/s, training_loss=0.013]\u001b[A\n",
      "Epoch 2:  23%|██▎       | 606/2645 [00:59<03:15, 10.43it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  23%|██▎       | 608/2645 [00:59<03:17, 10.34it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  23%|██▎       | 608/2645 [00:59<03:17, 10.34it/s, training_loss=0.305]\u001b[A\n",
      "Epoch 2:  23%|██▎       | 608/2645 [00:59<03:17, 10.34it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  23%|██▎       | 610/2645 [00:59<03:16, 10.36it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  23%|██▎       | 610/2645 [00:59<03:16, 10.36it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  23%|██▎       | 610/2645 [00:59<03:16, 10.36it/s, training_loss=0.714]\u001b[A\n",
      "Epoch 2:  23%|██▎       | 612/2645 [00:59<03:16, 10.34it/s, training_loss=0.714]\u001b[A\n",
      "Epoch 2:  23%|██▎       | 612/2645 [00:59<03:16, 10.34it/s, training_loss=1.082]\u001b[A\n",
      "Epoch 2:  23%|██▎       | 612/2645 [00:59<03:16, 10.34it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  23%|██▎       | 614/2645 [00:59<03:15, 10.37it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  23%|██▎       | 614/2645 [00:59<03:15, 10.37it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  23%|██▎       | 614/2645 [00:59<03:15, 10.37it/s, training_loss=0.053]\u001b[A\n",
      "Epoch 2:  23%|██▎       | 616/2645 [00:59<03:15, 10.38it/s, training_loss=0.053]\u001b[A\n",
      "Epoch 2:  23%|██▎       | 616/2645 [00:59<03:15, 10.38it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  23%|██▎       | 616/2645 [01:00<03:15, 10.38it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  23%|██▎       | 618/2645 [01:00<03:14, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  23%|██▎       | 618/2645 [01:00<03:14, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  23%|██▎       | 618/2645 [01:00<03:14, 10.44it/s, training_loss=0.060]\u001b[A\n",
      "Epoch 2:  23%|██▎       | 620/2645 [01:00<03:13, 10.45it/s, training_loss=0.060]\u001b[A\n",
      "Epoch 2:  23%|██▎       | 620/2645 [01:00<03:13, 10.45it/s, training_loss=0.035]\u001b[A\n",
      "Epoch 2:  23%|██▎       | 620/2645 [01:00<03:13, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  24%|██▎       | 622/2645 [01:00<03:13, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  24%|██▎       | 622/2645 [01:00<03:13, 10.43it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  24%|██▎       | 622/2645 [01:00<03:13, 10.43it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  24%|██▎       | 624/2645 [01:00<03:13, 10.42it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  24%|██▎       | 624/2645 [01:00<03:13, 10.42it/s, training_loss=0.524]\u001b[A\n",
      "Epoch 2:  24%|██▎       | 624/2645 [01:00<03:13, 10.42it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  24%|██▎       | 626/2645 [01:00<03:13, 10.42it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  24%|██▎       | 626/2645 [01:00<03:13, 10.42it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  24%|██▎       | 626/2645 [01:01<03:13, 10.42it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  24%|██▎       | 628/2645 [01:01<03:13, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  24%|██▎       | 628/2645 [01:01<03:13, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  24%|██▎       | 628/2645 [01:01<03:13, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  24%|██▍       | 630/2645 [01:01<03:12, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  24%|██▍       | 630/2645 [01:01<03:12, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  24%|██▍       | 630/2645 [01:01<03:12, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  24%|██▍       | 632/2645 [01:01<03:11, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  24%|██▍       | 632/2645 [01:01<03:11, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  24%|██▍       | 632/2645 [01:01<03:11, 10.49it/s, training_loss=0.819]\u001b[A\n",
      "Epoch 2:  24%|██▍       | 634/2645 [01:01<03:11, 10.48it/s, training_loss=0.819]\u001b[A\n",
      "Epoch 2:  24%|██▍       | 634/2645 [01:01<03:11, 10.48it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 2:  24%|██▍       | 634/2645 [01:01<03:11, 10.48it/s, training_loss=0.326]\u001b[A\n",
      "Epoch 2:  24%|██▍       | 636/2645 [01:01<03:12, 10.45it/s, training_loss=0.326]\u001b[A\n",
      "Epoch 2:  24%|██▍       | 636/2645 [01:01<03:12, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  24%|██▍       | 636/2645 [01:01<03:12, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  24%|██▍       | 638/2645 [01:01<03:11, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  24%|██▍       | 638/2645 [01:02<03:11, 10.47it/s, training_loss=0.333]\u001b[A\n",
      "Epoch 2:  24%|██▍       | 638/2645 [01:02<03:11, 10.47it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  24%|██▍       | 640/2645 [01:02<03:11, 10.48it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  24%|██▍       | 640/2645 [01:02<03:11, 10.48it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  24%|██▍       | 640/2645 [01:02<03:11, 10.48it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  24%|██▍       | 642/2645 [01:02<03:11, 10.44it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  24%|██▍       | 642/2645 [01:02<03:11, 10.44it/s, training_loss=0.164]\u001b[A\n",
      "Epoch 2:  24%|██▍       | 642/2645 [01:02<03:11, 10.44it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  24%|██▍       | 644/2645 [01:02<03:14, 10.30it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  24%|██▍       | 644/2645 [01:02<03:14, 10.30it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  24%|██▍       | 644/2645 [01:02<03:14, 10.30it/s, training_loss=0.018]\u001b[A\n",
      "Epoch 2:  24%|██▍       | 646/2645 [01:02<03:13, 10.35it/s, training_loss=0.018]\u001b[A\n",
      "Epoch 2:  24%|██▍       | 646/2645 [01:02<03:13, 10.35it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  24%|██▍       | 646/2645 [01:02<03:13, 10.35it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  24%|██▍       | 648/2645 [01:02<03:11, 10.41it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  24%|██▍       | 648/2645 [01:03<03:11, 10.41it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  24%|██▍       | 648/2645 [01:03<03:11, 10.41it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  25%|██▍       | 650/2645 [01:03<03:11, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  25%|██▍       | 650/2645 [01:03<03:11, 10.43it/s, training_loss=0.135]\u001b[A\n",
      "Epoch 2:  25%|██▍       | 650/2645 [01:03<03:11, 10.43it/s, training_loss=0.224]\u001b[A\n",
      "Epoch 2:  25%|██▍       | 652/2645 [01:03<03:11, 10.39it/s, training_loss=0.224]\u001b[A\n",
      "Epoch 2:  25%|██▍       | 652/2645 [01:03<03:11, 10.39it/s, training_loss=0.015]\u001b[A\n",
      "Epoch 2:  25%|██▍       | 652/2645 [01:03<03:11, 10.39it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  25%|██▍       | 654/2645 [01:03<03:12, 10.35it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  25%|██▍       | 654/2645 [01:03<03:12, 10.35it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  25%|██▍       | 654/2645 [01:03<03:12, 10.35it/s, training_loss=0.012]\u001b[A\n",
      "Epoch 2:  25%|██▍       | 656/2645 [01:03<03:12, 10.35it/s, training_loss=0.012]\u001b[A\n",
      "Epoch 2:  25%|██▍       | 656/2645 [01:03<03:12, 10.35it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  25%|██▍       | 656/2645 [01:03<03:12, 10.35it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  25%|██▍       | 658/2645 [01:03<03:11, 10.36it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  25%|██▍       | 658/2645 [01:03<03:11, 10.36it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  25%|██▍       | 658/2645 [01:04<03:11, 10.36it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  25%|██▍       | 660/2645 [01:04<03:11, 10.37it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  25%|██▍       | 660/2645 [01:04<03:11, 10.37it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  25%|██▍       | 660/2645 [01:04<03:11, 10.37it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 2:  25%|██▌       | 662/2645 [01:04<03:10, 10.40it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 2:  25%|██▌       | 662/2645 [01:04<03:10, 10.40it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  25%|██▌       | 662/2645 [01:04<03:10, 10.40it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  25%|██▌       | 664/2645 [01:04<03:09, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  25%|██▌       | 664/2645 [01:04<03:09, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  25%|██▌       | 664/2645 [01:04<03:09, 10.46it/s, training_loss=0.537]\u001b[A\n",
      "Epoch 2:  25%|██▌       | 666/2645 [01:04<03:10, 10.37it/s, training_loss=0.537]\u001b[A\n",
      "Epoch 2:  25%|██▌       | 666/2645 [01:04<03:10, 10.37it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  25%|██▌       | 666/2645 [01:04<03:10, 10.37it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  25%|██▌       | 668/2645 [01:04<03:09, 10.44it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  25%|██▌       | 668/2645 [01:04<03:09, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  25%|██▌       | 668/2645 [01:05<03:09, 10.44it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  25%|██▌       | 670/2645 [01:05<03:08, 10.48it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  25%|██▌       | 670/2645 [01:05<03:08, 10.48it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  25%|██▌       | 670/2645 [01:05<03:08, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  25%|██▌       | 672/2645 [01:05<03:07, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  25%|██▌       | 672/2645 [01:05<03:07, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  25%|██▌       | 672/2645 [01:05<03:07, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  25%|██▌       | 674/2645 [01:05<03:07, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  25%|██▌       | 674/2645 [01:05<03:07, 10.52it/s, training_loss=0.572]\u001b[A\n",
      "Epoch 2:  25%|██▌       | 674/2645 [01:05<03:07, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  26%|██▌       | 676/2645 [01:05<03:08, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  26%|██▌       | 676/2645 [01:05<03:08, 10.44it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 2:  26%|██▌       | 676/2645 [01:05<03:08, 10.44it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  26%|██▌       | 678/2645 [01:05<03:11, 10.29it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  26%|██▌       | 678/2645 [01:05<03:11, 10.29it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  26%|██▌       | 678/2645 [01:06<03:11, 10.29it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  26%|██▌       | 680/2645 [01:06<03:11, 10.26it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  26%|██▌       | 680/2645 [01:06<03:11, 10.26it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  26%|██▌       | 680/2645 [01:06<03:11, 10.26it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  26%|██▌       | 682/2645 [01:06<03:09, 10.35it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  26%|██▌       | 682/2645 [01:06<03:09, 10.35it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  26%|██▌       | 682/2645 [01:06<03:09, 10.35it/s, training_loss=0.195]\u001b[A\n",
      "Epoch 2:  26%|██▌       | 684/2645 [01:06<03:08, 10.39it/s, training_loss=0.195]\u001b[A\n",
      "Epoch 2:  26%|██▌       | 684/2645 [01:06<03:08, 10.39it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  26%|██▌       | 684/2645 [01:06<03:08, 10.39it/s, training_loss=0.446]\u001b[A\n",
      "Epoch 2:  26%|██▌       | 686/2645 [01:06<03:09, 10.36it/s, training_loss=0.446]\u001b[A\n",
      "Epoch 2:  26%|██▌       | 686/2645 [01:06<03:09, 10.36it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  26%|██▌       | 686/2645 [01:06<03:09, 10.36it/s, training_loss=0.016]\u001b[A\n",
      "Epoch 2:  26%|██▌       | 688/2645 [01:06<03:08, 10.40it/s, training_loss=0.016]\u001b[A\n",
      "Epoch 2:  26%|██▌       | 688/2645 [01:06<03:08, 10.40it/s, training_loss=0.209]\u001b[A\n",
      "Epoch 2:  26%|██▌       | 688/2645 [01:06<03:08, 10.40it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  26%|██▌       | 690/2645 [01:06<03:07, 10.42it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  26%|██▌       | 690/2645 [01:07<03:07, 10.42it/s, training_loss=0.012]\u001b[A\n",
      "Epoch 2:  26%|██▌       | 690/2645 [01:07<03:07, 10.42it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  26%|██▌       | 692/2645 [01:07<03:06, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  26%|██▌       | 692/2645 [01:07<03:06, 10.45it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  26%|██▌       | 692/2645 [01:07<03:06, 10.45it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  26%|██▌       | 694/2645 [01:07<03:06, 10.49it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  26%|██▌       | 694/2645 [01:07<03:06, 10.49it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  26%|██▌       | 694/2645 [01:07<03:06, 10.49it/s, training_loss=0.640]\u001b[A\n",
      "Epoch 2:  26%|██▋       | 696/2645 [01:07<03:07, 10.41it/s, training_loss=0.640]\u001b[A\n",
      "Epoch 2:  26%|██▋       | 696/2645 [01:07<03:07, 10.41it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  26%|██▋       | 696/2645 [01:07<03:07, 10.41it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  26%|██▋       | 698/2645 [01:07<03:06, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  26%|██▋       | 698/2645 [01:07<03:06, 10.46it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  26%|██▋       | 698/2645 [01:07<03:06, 10.46it/s, training_loss=0.026]\u001b[A\n",
      "Epoch 2:  26%|██▋       | 700/2645 [01:07<03:05, 10.46it/s, training_loss=0.026]\u001b[A\n",
      "Epoch 2:  26%|██▋       | 700/2645 [01:08<03:05, 10.46it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  26%|██▋       | 700/2645 [01:08<03:05, 10.46it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  27%|██▋       | 702/2645 [01:08<03:06, 10.41it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  27%|██▋       | 702/2645 [01:08<03:06, 10.41it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  27%|██▋       | 702/2645 [01:08<03:06, 10.41it/s, training_loss=0.089]\u001b[A\n",
      "Epoch 2:  27%|██▋       | 704/2645 [01:08<03:05, 10.44it/s, training_loss=0.089]\u001b[A\n",
      "Epoch 2:  27%|██▋       | 704/2645 [01:08<03:05, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  27%|██▋       | 704/2645 [01:08<03:05, 10.44it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  27%|██▋       | 706/2645 [01:08<03:06, 10.41it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  27%|██▋       | 706/2645 [01:08<03:06, 10.41it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  27%|██▋       | 706/2645 [01:08<03:06, 10.41it/s, training_loss=0.964]\u001b[A\n",
      "Epoch 2:  27%|██▋       | 708/2645 [01:08<03:05, 10.42it/s, training_loss=0.964]\u001b[A\n",
      "Epoch 2:  27%|██▋       | 708/2645 [01:08<03:05, 10.42it/s, training_loss=0.753]\u001b[A\n",
      "Epoch 2:  27%|██▋       | 708/2645 [01:08<03:05, 10.42it/s, training_loss=0.621]\u001b[A\n",
      "Epoch 2:  27%|██▋       | 710/2645 [01:08<03:06, 10.40it/s, training_loss=0.621]\u001b[A\n",
      "Epoch 2:  27%|██▋       | 710/2645 [01:08<03:06, 10.40it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  27%|██▋       | 710/2645 [01:09<03:06, 10.40it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  27%|██▋       | 712/2645 [01:09<03:07, 10.32it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  27%|██▋       | 712/2645 [01:09<03:07, 10.32it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  27%|██▋       | 712/2645 [01:09<03:07, 10.32it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  27%|██▋       | 714/2645 [01:09<03:06, 10.36it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  27%|██▋       | 714/2645 [01:09<03:06, 10.36it/s, training_loss=0.696]\u001b[A\n",
      "Epoch 2:  27%|██▋       | 714/2645 [01:09<03:06, 10.36it/s, training_loss=0.243]\u001b[A\n",
      "Epoch 2:  27%|██▋       | 716/2645 [01:09<03:06, 10.35it/s, training_loss=0.243]\u001b[A\n",
      "Epoch 2:  27%|██▋       | 716/2645 [01:09<03:06, 10.35it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  27%|██▋       | 716/2645 [01:09<03:06, 10.35it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  27%|██▋       | 718/2645 [01:09<03:06, 10.35it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  27%|██▋       | 718/2645 [01:09<03:06, 10.35it/s, training_loss=0.802]\u001b[A\n",
      "Epoch 2:  27%|██▋       | 718/2645 [01:09<03:06, 10.35it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  27%|██▋       | 720/2645 [01:09<03:06, 10.33it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  27%|██▋       | 720/2645 [01:09<03:06, 10.33it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  27%|██▋       | 720/2645 [01:10<03:06, 10.33it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  27%|██▋       | 722/2645 [01:10<03:07, 10.26it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  27%|██▋       | 722/2645 [01:10<03:07, 10.26it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  27%|██▋       | 722/2645 [01:10<03:07, 10.26it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  27%|██▋       | 724/2645 [01:10<03:06, 10.31it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  27%|██▋       | 724/2645 [01:10<03:06, 10.31it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  27%|██▋       | 724/2645 [01:10<03:06, 10.31it/s, training_loss=0.012]\u001b[A\n",
      "Epoch 2:  27%|██▋       | 726/2645 [01:10<03:05, 10.35it/s, training_loss=0.012]\u001b[A\n",
      "Epoch 2:  27%|██▋       | 726/2645 [01:10<03:05, 10.35it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  27%|██▋       | 726/2645 [01:10<03:05, 10.35it/s, training_loss=0.467]\u001b[A\n",
      "Epoch 2:  28%|██▊       | 728/2645 [01:10<03:04, 10.37it/s, training_loss=0.467]\u001b[A\n",
      "Epoch 2:  28%|██▊       | 728/2645 [01:10<03:04, 10.37it/s, training_loss=0.548]\u001b[A\n",
      "Epoch 2:  28%|██▊       | 728/2645 [01:10<03:04, 10.37it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  28%|██▊       | 730/2645 [01:10<03:03, 10.41it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  28%|██▊       | 730/2645 [01:10<03:03, 10.41it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  28%|██▊       | 730/2645 [01:11<03:03, 10.41it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  28%|██▊       | 732/2645 [01:11<03:04, 10.39it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  28%|██▊       | 732/2645 [01:11<03:04, 10.39it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  28%|██▊       | 732/2645 [01:11<03:04, 10.39it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  28%|██▊       | 734/2645 [01:11<03:05, 10.29it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  28%|██▊       | 734/2645 [01:11<03:05, 10.29it/s, training_loss=0.666]\u001b[A\n",
      "Epoch 2:  28%|██▊       | 734/2645 [01:11<03:05, 10.29it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  28%|██▊       | 736/2645 [01:11<03:05, 10.29it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  28%|██▊       | 736/2645 [01:11<03:05, 10.29it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 2:  28%|██▊       | 736/2645 [01:11<03:05, 10.29it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  28%|██▊       | 738/2645 [01:11<03:06, 10.23it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  28%|██▊       | 738/2645 [01:11<03:06, 10.23it/s, training_loss=0.511]\u001b[A\n",
      "Epoch 2:  28%|██▊       | 738/2645 [01:11<03:06, 10.23it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  28%|██▊       | 740/2645 [01:11<03:04, 10.31it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  28%|██▊       | 740/2645 [01:11<03:04, 10.31it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  28%|██▊       | 740/2645 [01:11<03:04, 10.31it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  28%|██▊       | 742/2645 [01:11<03:03, 10.36it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  28%|██▊       | 742/2645 [01:12<03:03, 10.36it/s, training_loss=0.044]\u001b[A\n",
      "Epoch 2:  28%|██▊       | 742/2645 [01:12<03:03, 10.36it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  28%|██▊       | 744/2645 [01:12<03:03, 10.37it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  28%|██▊       | 744/2645 [01:12<03:03, 10.37it/s, training_loss=0.065]\u001b[A\n",
      "Epoch 2:  28%|██▊       | 744/2645 [01:12<03:03, 10.37it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  28%|██▊       | 746/2645 [01:12<03:02, 10.38it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  28%|██▊       | 746/2645 [01:12<03:02, 10.38it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  28%|██▊       | 746/2645 [01:12<03:02, 10.38it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  28%|██▊       | 748/2645 [01:12<03:02, 10.40it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  28%|██▊       | 748/2645 [01:12<03:02, 10.40it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  28%|██▊       | 748/2645 [01:12<03:02, 10.40it/s, training_loss=0.014]\u001b[A\n",
      "Epoch 2:  28%|██▊       | 750/2645 [01:12<03:02, 10.40it/s, training_loss=0.014]\u001b[A\n",
      "Epoch 2:  28%|██▊       | 750/2645 [01:12<03:02, 10.40it/s, training_loss=0.032]\u001b[A\n",
      "Epoch 2:  28%|██▊       | 750/2645 [01:12<03:02, 10.40it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  28%|██▊       | 752/2645 [01:12<03:02, 10.39it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  28%|██▊       | 752/2645 [01:13<03:02, 10.39it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  28%|██▊       | 752/2645 [01:13<03:02, 10.39it/s, training_loss=0.724]\u001b[A\n",
      "Epoch 2:  29%|██▊       | 754/2645 [01:13<03:01, 10.44it/s, training_loss=0.724]\u001b[A\n",
      "Epoch 2:  29%|██▊       | 754/2645 [01:13<03:01, 10.44it/s, training_loss=0.630]\u001b[A\n",
      "Epoch 2:  29%|██▊       | 754/2645 [01:13<03:01, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  29%|██▊       | 756/2645 [01:13<03:00, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  29%|██▊       | 756/2645 [01:13<03:00, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  29%|██▊       | 756/2645 [01:13<03:00, 10.45it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 2:  29%|██▊       | 758/2645 [01:13<03:02, 10.35it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 2:  29%|██▊       | 758/2645 [01:13<03:02, 10.35it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  29%|██▊       | 758/2645 [01:13<03:02, 10.35it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  29%|██▊       | 760/2645 [01:13<03:01, 10.36it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  29%|██▊       | 760/2645 [01:13<03:01, 10.36it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  29%|██▊       | 760/2645 [01:13<03:01, 10.36it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  29%|██▉       | 762/2645 [01:13<03:01, 10.38it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  29%|██▉       | 762/2645 [01:14<03:01, 10.38it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  29%|██▉       | 762/2645 [01:14<03:01, 10.38it/s, training_loss=0.015]\u001b[A\n",
      "Epoch 2:  29%|██▉       | 764/2645 [01:14<03:01, 10.38it/s, training_loss=0.015]\u001b[A\n",
      "Epoch 2:  29%|██▉       | 764/2645 [01:14<03:01, 10.38it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  29%|██▉       | 764/2645 [01:14<03:01, 10.38it/s, training_loss=1.076]\u001b[A\n",
      "Epoch 2:  29%|██▉       | 766/2645 [01:14<03:01, 10.34it/s, training_loss=1.076]\u001b[A\n",
      "Epoch 2:  29%|██▉       | 766/2645 [01:14<03:01, 10.34it/s, training_loss=0.428]\u001b[A\n",
      "Epoch 2:  29%|██▉       | 766/2645 [01:14<03:01, 10.34it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  29%|██▉       | 768/2645 [01:14<03:01, 10.34it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  29%|██▉       | 768/2645 [01:14<03:01, 10.34it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  29%|██▉       | 768/2645 [01:14<03:01, 10.34it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  29%|██▉       | 770/2645 [01:14<03:00, 10.39it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  29%|██▉       | 770/2645 [01:14<03:00, 10.39it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  29%|██▉       | 770/2645 [01:14<03:00, 10.39it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  29%|██▉       | 772/2645 [01:14<03:00, 10.35it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  29%|██▉       | 772/2645 [01:14<03:00, 10.35it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  29%|██▉       | 772/2645 [01:15<03:00, 10.35it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  29%|██▉       | 774/2645 [01:15<03:01, 10.33it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  29%|██▉       | 774/2645 [01:15<03:01, 10.33it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 2:  29%|██▉       | 774/2645 [01:15<03:01, 10.33it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  29%|██▉       | 776/2645 [01:15<03:02, 10.26it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  29%|██▉       | 776/2645 [01:15<03:02, 10.26it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  29%|██▉       | 776/2645 [01:15<03:02, 10.26it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  29%|██▉       | 778/2645 [01:15<03:02, 10.22it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  29%|██▉       | 778/2645 [01:15<03:02, 10.22it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  29%|██▉       | 778/2645 [01:15<03:02, 10.22it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  29%|██▉       | 780/2645 [01:15<03:02, 10.20it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  29%|██▉       | 780/2645 [01:15<03:02, 10.20it/s, training_loss=0.014]\u001b[A\n",
      "Epoch 2:  29%|██▉       | 780/2645 [01:15<03:02, 10.20it/s, training_loss=0.576]\u001b[A\n",
      "Epoch 2:  30%|██▉       | 782/2645 [01:15<03:03, 10.17it/s, training_loss=0.576]\u001b[A\n",
      "Epoch 2:  30%|██▉       | 782/2645 [01:15<03:03, 10.17it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  30%|██▉       | 782/2645 [01:16<03:03, 10.17it/s, training_loss=0.603]\u001b[A\n",
      "Epoch 2:  30%|██▉       | 784/2645 [01:16<03:02, 10.18it/s, training_loss=0.603]\u001b[A\n",
      "Epoch 2:  30%|██▉       | 784/2645 [01:16<03:02, 10.18it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  30%|██▉       | 784/2645 [01:16<03:02, 10.18it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  30%|██▉       | 786/2645 [01:16<03:01, 10.23it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  30%|██▉       | 786/2645 [01:16<03:01, 10.23it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  30%|██▉       | 786/2645 [01:16<03:01, 10.23it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  30%|██▉       | 788/2645 [01:16<03:01, 10.22it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  30%|██▉       | 788/2645 [01:16<03:01, 10.22it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  30%|██▉       | 788/2645 [01:16<03:01, 10.22it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  30%|██▉       | 790/2645 [01:16<03:02, 10.18it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  30%|██▉       | 790/2645 [01:16<03:02, 10.18it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  30%|██▉       | 790/2645 [01:16<03:02, 10.18it/s, training_loss=0.086]\u001b[A\n",
      "Epoch 2:  30%|██▉       | 792/2645 [01:16<03:02, 10.16it/s, training_loss=0.086]\u001b[A\n",
      "Epoch 2:  30%|██▉       | 792/2645 [01:16<03:02, 10.16it/s, training_loss=0.984]\u001b[A\n",
      "Epoch 2:  30%|██▉       | 792/2645 [01:17<03:02, 10.16it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  30%|███       | 794/2645 [01:17<03:02, 10.13it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  30%|███       | 794/2645 [01:17<03:02, 10.13it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  30%|███       | 794/2645 [01:17<03:02, 10.13it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  30%|███       | 796/2645 [01:17<03:01, 10.17it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  30%|███       | 796/2645 [01:17<03:01, 10.17it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  30%|███       | 796/2645 [01:17<03:01, 10.17it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  30%|███       | 798/2645 [01:17<03:02, 10.13it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  30%|███       | 798/2645 [01:17<03:02, 10.13it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  30%|███       | 798/2645 [01:17<03:02, 10.13it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  30%|███       | 800/2645 [01:17<03:01, 10.18it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  30%|███       | 800/2645 [01:17<03:01, 10.18it/s, training_loss=0.886]\u001b[A\n",
      "Epoch 2:  30%|███       | 800/2645 [01:17<03:01, 10.18it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  30%|███       | 802/2645 [01:17<02:59, 10.28it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  30%|███       | 802/2645 [01:17<02:59, 10.28it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  30%|███       | 802/2645 [01:18<02:59, 10.28it/s, training_loss=0.016]\u001b[A\n",
      "Epoch 2:  30%|███       | 804/2645 [01:18<02:58, 10.29it/s, training_loss=0.016]\u001b[A\n",
      "Epoch 2:  30%|███       | 804/2645 [01:18<02:58, 10.29it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  30%|███       | 804/2645 [01:18<02:58, 10.29it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  30%|███       | 806/2645 [01:18<02:57, 10.33it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  30%|███       | 806/2645 [01:18<02:57, 10.33it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  30%|███       | 806/2645 [01:18<02:57, 10.33it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  31%|███       | 808/2645 [01:18<02:57, 10.37it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  31%|███       | 808/2645 [01:18<02:57, 10.37it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  31%|███       | 808/2645 [01:18<02:57, 10.37it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  31%|███       | 810/2645 [01:18<02:56, 10.41it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  31%|███       | 810/2645 [01:18<02:56, 10.41it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  31%|███       | 810/2645 [01:18<02:56, 10.41it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 2:  31%|███       | 812/2645 [01:18<02:55, 10.42it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 2:  31%|███       | 812/2645 [01:18<02:55, 10.42it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  31%|███       | 812/2645 [01:18<02:55, 10.42it/s, training_loss=0.680]\u001b[A\n",
      "Epoch 2:  31%|███       | 814/2645 [01:18<02:55, 10.41it/s, training_loss=0.680]\u001b[A\n",
      "Epoch 2:  31%|███       | 814/2645 [01:19<02:55, 10.41it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  31%|███       | 814/2645 [01:19<02:55, 10.41it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  31%|███       | 816/2645 [01:19<02:55, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  31%|███       | 816/2645 [01:19<02:55, 10.43it/s, training_loss=0.152]\u001b[A\n",
      "Epoch 2:  31%|███       | 816/2645 [01:19<02:55, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  31%|███       | 818/2645 [01:19<02:54, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  31%|███       | 818/2645 [01:19<02:54, 10.45it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  31%|███       | 818/2645 [01:19<02:54, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  31%|███       | 820/2645 [01:19<02:56, 10.36it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  31%|███       | 820/2645 [01:19<02:56, 10.36it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  31%|███       | 820/2645 [01:19<02:56, 10.36it/s, training_loss=0.042]\u001b[A\n",
      "Epoch 2:  31%|███       | 822/2645 [01:19<02:56, 10.35it/s, training_loss=0.042]\u001b[A\n",
      "Epoch 2:  31%|███       | 822/2645 [01:19<02:56, 10.35it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  31%|███       | 822/2645 [01:19<02:56, 10.35it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  31%|███       | 824/2645 [01:19<02:55, 10.35it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  31%|███       | 824/2645 [01:20<02:55, 10.35it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  31%|███       | 824/2645 [01:20<02:55, 10.35it/s, training_loss=0.935]\u001b[A\n",
      "Epoch 2:  31%|███       | 826/2645 [01:20<02:57, 10.26it/s, training_loss=0.935]\u001b[A\n",
      "Epoch 2:  31%|███       | 826/2645 [01:20<02:57, 10.26it/s, training_loss=0.661]\u001b[A\n",
      "Epoch 2:  31%|███       | 826/2645 [01:20<02:57, 10.26it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  31%|███▏      | 828/2645 [01:20<02:58, 10.19it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  31%|███▏      | 828/2645 [01:20<02:58, 10.19it/s, training_loss=0.014]\u001b[A\n",
      "Epoch 2:  31%|███▏      | 828/2645 [01:20<02:58, 10.19it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  31%|███▏      | 830/2645 [01:20<02:59, 10.11it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  31%|███▏      | 830/2645 [01:20<02:59, 10.11it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  31%|███▏      | 830/2645 [01:20<02:59, 10.11it/s, training_loss=0.158]\u001b[A\n",
      "Epoch 2:  31%|███▏      | 832/2645 [01:20<02:58, 10.16it/s, training_loss=0.158]\u001b[A\n",
      "Epoch 2:  31%|███▏      | 832/2645 [01:20<02:58, 10.16it/s, training_loss=0.053]\u001b[A\n",
      "Epoch 2:  31%|███▏      | 832/2645 [01:20<02:58, 10.16it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  32%|███▏      | 834/2645 [01:20<02:57, 10.21it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  32%|███▏      | 834/2645 [01:21<02:57, 10.21it/s, training_loss=0.237]\u001b[A\n",
      "Epoch 2:  32%|███▏      | 834/2645 [01:21<02:57, 10.21it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  32%|███▏      | 836/2645 [01:21<02:56, 10.27it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  32%|███▏      | 836/2645 [01:21<02:56, 10.27it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  32%|███▏      | 836/2645 [01:21<02:56, 10.27it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  32%|███▏      | 838/2645 [01:21<02:54, 10.34it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  32%|███▏      | 838/2645 [01:21<02:54, 10.34it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 2:  32%|███▏      | 838/2645 [01:21<02:54, 10.34it/s, training_loss=0.959]\u001b[A\n",
      "Epoch 2:  32%|███▏      | 840/2645 [01:21<02:54, 10.32it/s, training_loss=0.959]\u001b[A\n",
      "Epoch 2:  32%|███▏      | 840/2645 [01:21<02:54, 10.32it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  32%|███▏      | 840/2645 [01:21<02:54, 10.32it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  32%|███▏      | 842/2645 [01:21<02:53, 10.38it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  32%|███▏      | 842/2645 [01:21<02:53, 10.38it/s, training_loss=0.061]\u001b[A\n",
      "Epoch 2:  32%|███▏      | 842/2645 [01:21<02:53, 10.38it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  32%|███▏      | 844/2645 [01:21<02:54, 10.33it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  32%|███▏      | 844/2645 [01:21<02:54, 10.33it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  32%|███▏      | 844/2645 [01:22<02:54, 10.33it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 2:  32%|███▏      | 846/2645 [01:22<02:54, 10.29it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 2:  32%|███▏      | 846/2645 [01:22<02:54, 10.29it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  32%|███▏      | 846/2645 [01:22<02:54, 10.29it/s, training_loss=0.014]\u001b[A\n",
      "Epoch 2:  32%|███▏      | 848/2645 [01:22<02:56, 10.20it/s, training_loss=0.014]\u001b[A\n",
      "Epoch 2:  32%|███▏      | 848/2645 [01:22<02:56, 10.20it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  32%|███▏      | 848/2645 [01:22<02:56, 10.20it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  32%|███▏      | 850/2645 [01:22<02:56, 10.19it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  32%|███▏      | 850/2645 [01:22<02:56, 10.19it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  32%|███▏      | 850/2645 [01:22<02:56, 10.19it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  32%|███▏      | 852/2645 [01:22<02:55, 10.22it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  32%|███▏      | 852/2645 [01:22<02:55, 10.22it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  32%|███▏      | 852/2645 [01:22<02:55, 10.22it/s, training_loss=0.875]\u001b[A\n",
      "Epoch 2:  32%|███▏      | 854/2645 [01:22<02:55, 10.20it/s, training_loss=0.875]\u001b[A\n",
      "Epoch 2:  32%|███▏      | 854/2645 [01:22<02:55, 10.20it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  32%|███▏      | 854/2645 [01:23<02:55, 10.20it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  32%|███▏      | 856/2645 [01:23<02:54, 10.24it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  32%|███▏      | 856/2645 [01:23<02:54, 10.24it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  32%|███▏      | 856/2645 [01:23<02:54, 10.24it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  32%|███▏      | 858/2645 [01:23<02:57, 10.08it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  32%|███▏      | 858/2645 [01:23<02:57, 10.08it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  32%|███▏      | 858/2645 [01:23<02:57, 10.08it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  33%|███▎      | 860/2645 [01:23<02:57, 10.06it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  33%|███▎      | 860/2645 [01:23<02:57, 10.06it/s, training_loss=0.025]\u001b[A\n",
      "Epoch 2:  33%|███▎      | 860/2645 [01:23<02:57, 10.06it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  33%|███▎      | 862/2645 [01:23<02:58, 10.01it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  33%|███▎      | 862/2645 [01:23<02:58, 10.01it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  33%|███▎      | 862/2645 [01:23<02:58, 10.01it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  33%|███▎      | 864/2645 [01:23<02:58, 10.00it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  33%|███▎      | 864/2645 [01:23<02:58, 10.00it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  33%|███▎      | 864/2645 [01:24<02:58, 10.00it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  33%|███▎      | 866/2645 [01:24<02:56, 10.05it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  33%|███▎      | 866/2645 [01:24<02:56, 10.05it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  33%|███▎      | 866/2645 [01:24<02:56, 10.05it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  33%|███▎      | 868/2645 [01:24<02:56, 10.08it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  33%|███▎      | 868/2645 [01:24<02:56, 10.08it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  33%|███▎      | 868/2645 [01:24<02:56, 10.08it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  33%|███▎      | 870/2645 [01:24<02:55, 10.11it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  33%|███▎      | 870/2645 [01:24<02:55, 10.11it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  33%|███▎      | 870/2645 [01:24<02:55, 10.11it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  33%|███▎      | 872/2645 [01:24<02:54, 10.18it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  33%|███▎      | 872/2645 [01:24<02:54, 10.18it/s, training_loss=0.727]\u001b[A\n",
      "Epoch 2:  33%|███▎      | 872/2645 [01:24<02:54, 10.18it/s, training_loss=0.514]\u001b[A\n",
      "Epoch 2:  33%|███▎      | 874/2645 [01:24<02:56, 10.02it/s, training_loss=0.514]\u001b[A\n",
      "Epoch 2:  33%|███▎      | 874/2645 [01:24<02:56, 10.02it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  33%|███▎      | 874/2645 [01:25<02:56, 10.02it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  33%|███▎      | 876/2645 [01:25<02:56, 10.03it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  33%|███▎      | 876/2645 [01:25<02:56, 10.03it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 2:  33%|███▎      | 876/2645 [01:25<02:56, 10.03it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  33%|███▎      | 878/2645 [01:25<02:57,  9.96it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  33%|███▎      | 878/2645 [01:25<02:57,  9.96it/s, training_loss=0.029]\u001b[A\n",
      "Epoch 2:  33%|███▎      | 879/2645 [01:25<02:57,  9.97it/s, training_loss=0.029]\u001b[A\n",
      "Epoch 2:  33%|███▎      | 879/2645 [01:25<02:57,  9.97it/s, training_loss=0.881]\u001b[A\n",
      "Epoch 2:  33%|███▎      | 880/2645 [01:25<02:57,  9.96it/s, training_loss=0.881]\u001b[A\n",
      "Epoch 2:  33%|███▎      | 880/2645 [01:25<02:57,  9.96it/s, training_loss=0.859]\u001b[A\n",
      "Epoch 2:  33%|███▎      | 881/2645 [01:25<02:57,  9.95it/s, training_loss=0.859]\u001b[A\n",
      "Epoch 2:  33%|███▎      | 881/2645 [01:25<02:57,  9.95it/s, training_loss=0.348]\u001b[A\n",
      "Epoch 2:  33%|███▎      | 882/2645 [01:25<02:57,  9.94it/s, training_loss=0.348]\u001b[A\n",
      "Epoch 2:  33%|███▎      | 882/2645 [01:25<02:57,  9.94it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  33%|███▎      | 882/2645 [01:25<02:57,  9.94it/s, training_loss=0.906]\u001b[A\n",
      "Epoch 2:  33%|███▎      | 884/2645 [01:25<02:57,  9.94it/s, training_loss=0.906]\u001b[A\n",
      "Epoch 2:  33%|███▎      | 884/2645 [01:25<02:57,  9.94it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  33%|███▎      | 884/2645 [01:26<02:57,  9.94it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  33%|███▎      | 886/2645 [01:26<02:55, 10.03it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  33%|███▎      | 886/2645 [01:26<02:55, 10.03it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  33%|███▎      | 886/2645 [01:26<02:55, 10.03it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  34%|███▎      | 888/2645 [01:26<02:54, 10.09it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  34%|███▎      | 888/2645 [01:26<02:54, 10.09it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  34%|███▎      | 888/2645 [01:26<02:54, 10.09it/s, training_loss=0.352]\u001b[A\n",
      "Epoch 2:  34%|███▎      | 890/2645 [01:26<02:54, 10.06it/s, training_loss=0.352]\u001b[A\n",
      "Epoch 2:  34%|███▎      | 890/2645 [01:26<02:54, 10.06it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  34%|███▎      | 890/2645 [01:26<02:54, 10.06it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  34%|███▎      | 892/2645 [01:26<02:55,  9.99it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  34%|███▎      | 892/2645 [01:26<02:55,  9.99it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  34%|███▎      | 892/2645 [01:26<02:55,  9.99it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  34%|███▍      | 894/2645 [01:26<02:55,  9.99it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  34%|███▍      | 894/2645 [01:26<02:55,  9.99it/s, training_loss=0.066]\u001b[A\n",
      "Epoch 2:  34%|███▍      | 895/2645 [01:26<02:56,  9.89it/s, training_loss=0.066]\u001b[A\n",
      "Epoch 2:  34%|███▍      | 895/2645 [01:27<02:56,  9.89it/s, training_loss=0.518]\u001b[A\n",
      "Epoch 2:  34%|███▍      | 896/2645 [01:27<02:56,  9.91it/s, training_loss=0.518]\u001b[A\n",
      "Epoch 2:  34%|███▍      | 896/2645 [01:27<02:56,  9.91it/s, training_loss=0.022]\u001b[A\n",
      "Epoch 2:  34%|███▍      | 897/2645 [01:27<02:56,  9.91it/s, training_loss=0.022]\u001b[A\n",
      "Epoch 2:  34%|███▍      | 897/2645 [01:27<02:56,  9.91it/s, training_loss=0.593]\u001b[A\n",
      "Epoch 2:  34%|███▍      | 898/2645 [01:27<02:56,  9.91it/s, training_loss=0.593]\u001b[A\n",
      "Epoch 2:  34%|███▍      | 898/2645 [01:27<02:56,  9.91it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  34%|███▍      | 898/2645 [01:27<02:56,  9.91it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  34%|███▍      | 900/2645 [01:27<02:55,  9.94it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  34%|███▍      | 900/2645 [01:27<02:55,  9.94it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  34%|███▍      | 900/2645 [01:27<02:55,  9.94it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  34%|███▍      | 902/2645 [01:27<02:54, 10.02it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  34%|███▍      | 902/2645 [01:27<02:54, 10.02it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  34%|███▍      | 902/2645 [01:27<02:54, 10.02it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  34%|███▍      | 904/2645 [01:27<02:53, 10.03it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  34%|███▍      | 904/2645 [01:27<02:53, 10.03it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  34%|███▍      | 904/2645 [01:28<02:53, 10.03it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  34%|███▍      | 906/2645 [01:28<02:53, 10.03it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  34%|███▍      | 906/2645 [01:28<02:53, 10.03it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  34%|███▍      | 906/2645 [01:28<02:53, 10.03it/s, training_loss=0.071]\u001b[A\n",
      "Epoch 2:  34%|███▍      | 908/2645 [01:28<02:53, 10.02it/s, training_loss=0.071]\u001b[A\n",
      "Epoch 2:  34%|███▍      | 908/2645 [01:28<02:53, 10.02it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  34%|███▍      | 908/2645 [01:28<02:53, 10.02it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  34%|███▍      | 910/2645 [01:28<02:53, 10.01it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  34%|███▍      | 910/2645 [01:28<02:53, 10.01it/s, training_loss=0.077]\u001b[A\n",
      "Epoch 2:  34%|███▍      | 910/2645 [01:28<02:53, 10.01it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  34%|███▍      | 912/2645 [01:28<02:54,  9.94it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  34%|███▍      | 912/2645 [01:28<02:54,  9.94it/s, training_loss=0.446]\u001b[A\n",
      "Epoch 2:  35%|███▍      | 913/2645 [01:28<02:54,  9.90it/s, training_loss=0.446]\u001b[A\n",
      "Epoch 2:  35%|███▍      | 913/2645 [01:28<02:54,  9.90it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  35%|███▍      | 914/2645 [01:28<02:54,  9.92it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  35%|███▍      | 914/2645 [01:28<02:54,  9.92it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  35%|███▍      | 914/2645 [01:29<02:54,  9.92it/s, training_loss=0.798]\u001b[A\n",
      "Epoch 2:  35%|███▍      | 916/2645 [01:29<02:52, 10.00it/s, training_loss=0.798]\u001b[A\n",
      "Epoch 2:  35%|███▍      | 916/2645 [01:29<02:52, 10.00it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  35%|███▍      | 916/2645 [01:29<02:52, 10.00it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  35%|███▍      | 918/2645 [01:29<02:52, 10.02it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  35%|███▍      | 918/2645 [01:29<02:52, 10.02it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  35%|███▍      | 918/2645 [01:29<02:52, 10.02it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  35%|███▍      | 920/2645 [01:29<02:51, 10.04it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  35%|███▍      | 920/2645 [01:29<02:51, 10.04it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  35%|███▍      | 920/2645 [01:29<02:51, 10.04it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  35%|███▍      | 922/2645 [01:29<02:51, 10.05it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  35%|███▍      | 922/2645 [01:29<02:51, 10.05it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  35%|███▍      | 922/2645 [01:29<02:51, 10.05it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  35%|███▍      | 924/2645 [01:29<02:52,  9.98it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  35%|███▍      | 924/2645 [01:29<02:52,  9.98it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  35%|███▍      | 925/2645 [01:29<02:52,  9.98it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  35%|███▍      | 925/2645 [01:30<02:52,  9.98it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  35%|███▍      | 925/2645 [01:30<02:52,  9.98it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  35%|███▌      | 927/2645 [01:30<02:50, 10.07it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  35%|███▌      | 927/2645 [01:30<02:50, 10.07it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  35%|███▌      | 927/2645 [01:30<02:50, 10.07it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  35%|███▌      | 929/2645 [01:30<02:48, 10.16it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  35%|███▌      | 929/2645 [01:30<02:48, 10.16it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  35%|███▌      | 929/2645 [01:30<02:48, 10.16it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  35%|███▌      | 931/2645 [01:30<02:48, 10.15it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  35%|███▌      | 931/2645 [01:30<02:48, 10.15it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  35%|███▌      | 931/2645 [01:30<02:48, 10.15it/s, training_loss=0.025]\u001b[A\n",
      "Epoch 2:  35%|███▌      | 933/2645 [01:30<02:49, 10.12it/s, training_loss=0.025]\u001b[A\n",
      "Epoch 2:  35%|███▌      | 933/2645 [01:30<02:49, 10.12it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  35%|███▌      | 933/2645 [01:30<02:49, 10.12it/s, training_loss=0.295]\u001b[A\n",
      "Epoch 2:  35%|███▌      | 935/2645 [01:30<02:48, 10.15it/s, training_loss=0.295]\u001b[A\n",
      "Epoch 2:  35%|███▌      | 935/2645 [01:31<02:48, 10.15it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  35%|███▌      | 935/2645 [01:31<02:48, 10.15it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  35%|███▌      | 937/2645 [01:31<02:47, 10.20it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  35%|███▌      | 937/2645 [01:31<02:47, 10.20it/s, training_loss=0.929]\u001b[A\n",
      "Epoch 2:  35%|███▌      | 937/2645 [01:31<02:47, 10.20it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  36%|███▌      | 939/2645 [01:31<02:47, 10.18it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  36%|███▌      | 939/2645 [01:31<02:47, 10.18it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  36%|███▌      | 939/2645 [01:31<02:47, 10.18it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 2:  36%|███▌      | 941/2645 [01:31<02:48, 10.13it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 2:  36%|███▌      | 941/2645 [01:31<02:48, 10.13it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  36%|███▌      | 941/2645 [01:31<02:48, 10.13it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  36%|███▌      | 943/2645 [01:31<02:46, 10.19it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  36%|███▌      | 943/2645 [01:31<02:46, 10.19it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  36%|███▌      | 943/2645 [01:31<02:46, 10.19it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  36%|███▌      | 945/2645 [01:31<02:47, 10.14it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  36%|███▌      | 945/2645 [01:32<02:47, 10.14it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  36%|███▌      | 945/2645 [01:32<02:47, 10.14it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  36%|███▌      | 947/2645 [01:32<02:47, 10.14it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  36%|███▌      | 947/2645 [01:32<02:47, 10.14it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  36%|███▌      | 947/2645 [01:32<02:47, 10.14it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  36%|███▌      | 949/2645 [01:32<02:45, 10.24it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  36%|███▌      | 949/2645 [01:32<02:45, 10.24it/s, training_loss=0.531]\u001b[A\n",
      "Epoch 2:  36%|███▌      | 949/2645 [01:32<02:45, 10.24it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  36%|███▌      | 951/2645 [01:32<02:45, 10.23it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  36%|███▌      | 951/2645 [01:32<02:45, 10.23it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  36%|███▌      | 951/2645 [01:32<02:45, 10.23it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  36%|███▌      | 953/2645 [01:32<02:44, 10.28it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  36%|███▌      | 953/2645 [01:32<02:44, 10.28it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  36%|███▌      | 953/2645 [01:32<02:44, 10.28it/s, training_loss=0.265]\u001b[A\n",
      "Epoch 2:  36%|███▌      | 955/2645 [01:32<02:44, 10.25it/s, training_loss=0.265]\u001b[A\n",
      "Epoch 2:  36%|███▌      | 955/2645 [01:32<02:44, 10.25it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 2:  36%|███▌      | 955/2645 [01:33<02:44, 10.25it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  36%|███▌      | 957/2645 [01:33<02:45, 10.21it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  36%|███▌      | 957/2645 [01:33<02:45, 10.21it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  36%|███▌      | 957/2645 [01:33<02:45, 10.21it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  36%|███▋      | 959/2645 [01:33<02:44, 10.26it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  36%|███▋      | 959/2645 [01:33<02:44, 10.26it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  36%|███▋      | 959/2645 [01:33<02:44, 10.26it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  36%|███▋      | 961/2645 [01:33<02:44, 10.26it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  36%|███▋      | 961/2645 [01:33<02:44, 10.26it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  36%|███▋      | 961/2645 [01:33<02:44, 10.26it/s, training_loss=0.773]\u001b[A\n",
      "Epoch 2:  36%|███▋      | 963/2645 [01:33<02:44, 10.23it/s, training_loss=0.773]\u001b[A\n",
      "Epoch 2:  36%|███▋      | 963/2645 [01:33<02:44, 10.23it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  36%|███▋      | 963/2645 [01:33<02:44, 10.23it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  36%|███▋      | 965/2645 [01:33<02:43, 10.25it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  36%|███▋      | 965/2645 [01:33<02:43, 10.25it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  36%|███▋      | 965/2645 [01:34<02:43, 10.25it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  37%|███▋      | 967/2645 [01:34<02:43, 10.28it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  37%|███▋      | 967/2645 [01:34<02:43, 10.28it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  37%|███▋      | 967/2645 [01:34<02:43, 10.28it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  37%|███▋      | 969/2645 [01:34<02:43, 10.23it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  37%|███▋      | 969/2645 [01:34<02:43, 10.23it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  37%|███▋      | 969/2645 [01:34<02:43, 10.23it/s, training_loss=0.684]\u001b[A\n",
      "Epoch 2:  37%|███▋      | 971/2645 [01:34<02:44, 10.18it/s, training_loss=0.684]\u001b[A\n",
      "Epoch 2:  37%|███▋      | 971/2645 [01:34<02:44, 10.18it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  37%|███▋      | 971/2645 [01:34<02:44, 10.18it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  37%|███▋      | 973/2645 [01:34<02:45, 10.09it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  37%|███▋      | 973/2645 [01:34<02:45, 10.09it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  37%|███▋      | 973/2645 [01:34<02:45, 10.09it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  37%|███▋      | 975/2645 [01:34<02:44, 10.12it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  37%|███▋      | 975/2645 [01:34<02:44, 10.12it/s, training_loss=0.722]\u001b[A\n",
      "Epoch 2:  37%|███▋      | 975/2645 [01:35<02:44, 10.12it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  37%|███▋      | 977/2645 [01:35<02:44, 10.12it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  37%|███▋      | 977/2645 [01:35<02:44, 10.12it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  37%|███▋      | 977/2645 [01:35<02:44, 10.12it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  37%|███▋      | 979/2645 [01:35<02:44, 10.14it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  37%|███▋      | 979/2645 [01:35<02:44, 10.14it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  37%|███▋      | 979/2645 [01:35<02:44, 10.14it/s, training_loss=1.019]\u001b[A\n",
      "Epoch 2:  37%|███▋      | 981/2645 [01:35<02:44, 10.13it/s, training_loss=1.019]\u001b[A\n",
      "Epoch 2:  37%|███▋      | 981/2645 [01:35<02:44, 10.13it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  37%|███▋      | 981/2645 [01:35<02:44, 10.13it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  37%|███▋      | 983/2645 [01:35<02:43, 10.18it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  37%|███▋      | 983/2645 [01:35<02:43, 10.18it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  37%|███▋      | 983/2645 [01:35<02:43, 10.18it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  37%|███▋      | 985/2645 [01:35<02:41, 10.26it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  37%|███▋      | 985/2645 [01:35<02:41, 10.26it/s, training_loss=0.557]\u001b[A\n",
      "Epoch 2:  37%|███▋      | 985/2645 [01:36<02:41, 10.26it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  37%|███▋      | 987/2645 [01:36<02:41, 10.24it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  37%|███▋      | 987/2645 [01:36<02:41, 10.24it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  37%|███▋      | 987/2645 [01:36<02:41, 10.24it/s, training_loss=0.146]\u001b[A\n",
      "Epoch 2:  37%|███▋      | 989/2645 [01:36<02:42, 10.18it/s, training_loss=0.146]\u001b[A\n",
      "Epoch 2:  37%|███▋      | 989/2645 [01:36<02:42, 10.18it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  37%|███▋      | 989/2645 [01:36<02:42, 10.18it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  37%|███▋      | 991/2645 [01:36<02:44, 10.08it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  37%|███▋      | 991/2645 [01:36<02:44, 10.08it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  37%|███▋      | 991/2645 [01:36<02:44, 10.08it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  38%|███▊      | 993/2645 [01:36<02:43, 10.10it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  38%|███▊      | 993/2645 [01:36<02:43, 10.10it/s, training_loss=1.501]\u001b[A\n",
      "Epoch 2:  38%|███▊      | 993/2645 [01:36<02:43, 10.10it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  38%|███▊      | 995/2645 [01:36<02:42, 10.13it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  38%|███▊      | 995/2645 [01:36<02:42, 10.13it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  38%|███▊      | 995/2645 [01:37<02:42, 10.13it/s, training_loss=0.393]\u001b[A\n",
      "Epoch 2:  38%|███▊      | 997/2645 [01:37<02:43, 10.08it/s, training_loss=0.393]\u001b[A\n",
      "Epoch 2:  38%|███▊      | 997/2645 [01:37<02:43, 10.08it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  38%|███▊      | 997/2645 [01:37<02:43, 10.08it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  38%|███▊      | 999/2645 [01:37<02:42, 10.12it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  38%|███▊      | 999/2645 [01:37<02:42, 10.12it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  38%|███▊      | 999/2645 [01:37<02:42, 10.12it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  38%|███▊      | 1001/2645 [01:37<02:43, 10.06it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  38%|███▊      | 1001/2645 [01:37<02:43, 10.06it/s, training_loss=0.032]\u001b[A\n",
      "Epoch 2:  38%|███▊      | 1001/2645 [01:37<02:43, 10.06it/s, training_loss=0.046]\u001b[A\n",
      "Epoch 2:  38%|███▊      | 1003/2645 [01:37<02:43, 10.01it/s, training_loss=0.046]\u001b[A\n",
      "Epoch 2:  38%|███▊      | 1003/2645 [01:37<02:43, 10.01it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  38%|███▊      | 1003/2645 [01:37<02:43, 10.01it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  38%|███▊      | 1005/2645 [01:37<02:43, 10.03it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  38%|███▊      | 1005/2645 [01:37<02:43, 10.03it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  38%|███▊      | 1005/2645 [01:38<02:43, 10.03it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  38%|███▊      | 1007/2645 [01:38<02:43,  9.99it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  38%|███▊      | 1007/2645 [01:38<02:43,  9.99it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  38%|███▊      | 1008/2645 [01:38<02:43,  9.99it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  38%|███▊      | 1008/2645 [01:38<02:43,  9.99it/s, training_loss=0.554]\u001b[A\n",
      "Epoch 2:  38%|███▊      | 1009/2645 [01:38<02:45,  9.89it/s, training_loss=0.554]\u001b[A\n",
      "Epoch 2:  38%|███▊      | 1009/2645 [01:38<02:45,  9.89it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  38%|███▊      | 1010/2645 [01:38<02:45,  9.89it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  38%|███▊      | 1010/2645 [01:38<02:45,  9.89it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  38%|███▊      | 1010/2645 [01:38<02:45,  9.89it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  38%|███▊      | 1012/2645 [01:38<02:43,  9.96it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  38%|███▊      | 1012/2645 [01:38<02:43,  9.96it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  38%|███▊      | 1013/2645 [01:38<02:45,  9.87it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  38%|███▊      | 1013/2645 [01:38<02:45,  9.87it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  38%|███▊      | 1014/2645 [01:38<02:45,  9.86it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  38%|███▊      | 1014/2645 [01:38<02:45,  9.86it/s, training_loss=0.011]\u001b[A\n",
      "Epoch 2:  38%|███▊      | 1015/2645 [01:38<02:45,  9.86it/s, training_loss=0.011]\u001b[A\n",
      "Epoch 2:  38%|███▊      | 1015/2645 [01:38<02:45,  9.86it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  38%|███▊      | 1015/2645 [01:39<02:45,  9.86it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  38%|███▊      | 1017/2645 [01:39<02:42, 10.00it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  38%|███▊      | 1017/2645 [01:39<02:42, 10.00it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  38%|███▊      | 1017/2645 [01:39<02:42, 10.00it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 2:  39%|███▊      | 1019/2645 [01:39<02:42, 10.03it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 2:  39%|███▊      | 1019/2645 [01:39<02:42, 10.03it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  39%|███▊      | 1019/2645 [01:39<02:42, 10.03it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  39%|███▊      | 1021/2645 [01:39<02:41, 10.07it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  39%|███▊      | 1021/2645 [01:39<02:41, 10.07it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  39%|███▊      | 1021/2645 [01:39<02:41, 10.07it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  39%|███▊      | 1023/2645 [01:39<02:40, 10.14it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  39%|███▊      | 1023/2645 [01:39<02:40, 10.14it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  39%|███▊      | 1023/2645 [01:39<02:40, 10.14it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  39%|███▉      | 1025/2645 [01:39<02:40, 10.09it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  39%|███▉      | 1025/2645 [01:39<02:40, 10.09it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  39%|███▉      | 1025/2645 [01:40<02:40, 10.09it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  39%|███▉      | 1027/2645 [01:40<02:42,  9.98it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  39%|███▉      | 1027/2645 [01:40<02:42,  9.98it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  39%|███▉      | 1027/2645 [01:40<02:42,  9.98it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  39%|███▉      | 1029/2645 [01:40<02:40, 10.09it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  39%|███▉      | 1029/2645 [01:40<02:40, 10.09it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  39%|███▉      | 1029/2645 [01:40<02:40, 10.09it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 2:  39%|███▉      | 1031/2645 [01:40<02:39, 10.14it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 2:  39%|███▉      | 1031/2645 [01:40<02:39, 10.14it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  39%|███▉      | 1031/2645 [01:40<02:39, 10.14it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  39%|███▉      | 1033/2645 [01:40<02:37, 10.22it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  39%|███▉      | 1033/2645 [01:40<02:37, 10.22it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  39%|███▉      | 1033/2645 [01:40<02:37, 10.22it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  39%|███▉      | 1035/2645 [01:40<02:37, 10.21it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  39%|███▉      | 1035/2645 [01:40<02:37, 10.21it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  39%|███▉      | 1035/2645 [01:40<02:37, 10.21it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  39%|███▉      | 1037/2645 [01:40<02:36, 10.30it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  39%|███▉      | 1037/2645 [01:41<02:36, 10.30it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  39%|███▉      | 1037/2645 [01:41<02:36, 10.30it/s, training_loss=0.518]\u001b[A\n",
      "Epoch 2:  39%|███▉      | 1039/2645 [01:41<02:35, 10.34it/s, training_loss=0.518]\u001b[A\n",
      "Epoch 2:  39%|███▉      | 1039/2645 [01:41<02:35, 10.34it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  39%|███▉      | 1039/2645 [01:41<02:35, 10.34it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  39%|███▉      | 1041/2645 [01:41<02:35, 10.34it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  39%|███▉      | 1041/2645 [01:41<02:35, 10.34it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  39%|███▉      | 1041/2645 [01:41<02:35, 10.34it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  39%|███▉      | 1043/2645 [01:41<02:36, 10.22it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  39%|███▉      | 1043/2645 [01:41<02:36, 10.22it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  39%|███▉      | 1043/2645 [01:41<02:36, 10.22it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  40%|███▉      | 1045/2645 [01:41<02:35, 10.26it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  40%|███▉      | 1045/2645 [01:41<02:35, 10.26it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  40%|███▉      | 1045/2645 [01:41<02:35, 10.26it/s, training_loss=0.410]\u001b[A\n",
      "Epoch 2:  40%|███▉      | 1047/2645 [01:41<02:37, 10.18it/s, training_loss=0.410]\u001b[A\n",
      "Epoch 2:  40%|███▉      | 1047/2645 [01:42<02:37, 10.18it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  40%|███▉      | 1047/2645 [01:42<02:37, 10.18it/s, training_loss=0.377]\u001b[A\n",
      "Epoch 2:  40%|███▉      | 1049/2645 [01:42<02:36, 10.22it/s, training_loss=0.377]\u001b[A\n",
      "Epoch 2:  40%|███▉      | 1049/2645 [01:42<02:36, 10.22it/s, training_loss=0.156]\u001b[A\n",
      "Epoch 2:  40%|███▉      | 1049/2645 [01:42<02:36, 10.22it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  40%|███▉      | 1051/2645 [01:42<02:36, 10.18it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  40%|███▉      | 1051/2645 [01:42<02:36, 10.18it/s, training_loss=0.015]\u001b[A\n",
      "Epoch 2:  40%|███▉      | 1051/2645 [01:42<02:36, 10.18it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  40%|███▉      | 1053/2645 [01:42<02:36, 10.19it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  40%|███▉      | 1053/2645 [01:42<02:36, 10.19it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  40%|███▉      | 1053/2645 [01:42<02:36, 10.19it/s, training_loss=1.053]\u001b[A\n",
      "Epoch 2:  40%|███▉      | 1055/2645 [01:42<02:36, 10.15it/s, training_loss=1.053]\u001b[A\n",
      "Epoch 2:  40%|███▉      | 1055/2645 [01:42<02:36, 10.15it/s, training_loss=0.044]\u001b[A\n",
      "Epoch 2:  40%|███▉      | 1055/2645 [01:42<02:36, 10.15it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  40%|███▉      | 1057/2645 [01:42<02:36, 10.13it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  40%|███▉      | 1057/2645 [01:43<02:36, 10.13it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  40%|███▉      | 1057/2645 [01:43<02:36, 10.13it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  40%|████      | 1059/2645 [01:43<02:37, 10.09it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  40%|████      | 1059/2645 [01:43<02:37, 10.09it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  40%|████      | 1059/2645 [01:43<02:37, 10.09it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  40%|████      | 1061/2645 [01:43<02:36, 10.10it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  40%|████      | 1061/2645 [01:43<02:36, 10.10it/s, training_loss=0.014]\u001b[A\n",
      "Epoch 2:  40%|████      | 1061/2645 [01:43<02:36, 10.10it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  40%|████      | 1063/2645 [01:43<02:36, 10.13it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  40%|████      | 1063/2645 [01:43<02:36, 10.13it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  40%|████      | 1063/2645 [01:43<02:36, 10.13it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  40%|████      | 1065/2645 [01:43<02:37, 10.04it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  40%|████      | 1065/2645 [01:43<02:37, 10.04it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  40%|████      | 1065/2645 [01:43<02:37, 10.04it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  40%|████      | 1067/2645 [01:43<02:36, 10.11it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  40%|████      | 1067/2645 [01:44<02:36, 10.11it/s, training_loss=0.084]\u001b[A\n",
      "Epoch 2:  40%|████      | 1067/2645 [01:44<02:36, 10.11it/s, training_loss=0.504]\u001b[A\n",
      "Epoch 2:  40%|████      | 1069/2645 [01:44<02:35, 10.12it/s, training_loss=0.504]\u001b[A\n",
      "Epoch 2:  40%|████      | 1069/2645 [01:44<02:35, 10.12it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  40%|████      | 1069/2645 [01:44<02:35, 10.12it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  40%|████      | 1071/2645 [01:44<02:34, 10.18it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  40%|████      | 1071/2645 [01:44<02:34, 10.18it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  40%|████      | 1071/2645 [01:44<02:34, 10.18it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 2:  41%|████      | 1073/2645 [01:44<02:35, 10.11it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 2:  41%|████      | 1073/2645 [01:44<02:35, 10.11it/s, training_loss=0.347]\u001b[A\n",
      "Epoch 2:  41%|████      | 1073/2645 [01:44<02:35, 10.11it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  41%|████      | 1075/2645 [01:44<02:35, 10.07it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  41%|████      | 1075/2645 [01:44<02:35, 10.07it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  41%|████      | 1075/2645 [01:44<02:35, 10.07it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  41%|████      | 1077/2645 [01:44<02:36, 10.03it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  41%|████      | 1077/2645 [01:45<02:36, 10.03it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  41%|████      | 1077/2645 [01:45<02:36, 10.03it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  41%|████      | 1079/2645 [01:45<02:36,  9.99it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  41%|████      | 1079/2645 [01:45<02:36,  9.99it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  41%|████      | 1079/2645 [01:45<02:36,  9.99it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  41%|████      | 1081/2645 [01:45<02:36,  9.98it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  41%|████      | 1081/2645 [01:45<02:36,  9.98it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  41%|████      | 1082/2645 [01:45<02:37,  9.92it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  41%|████      | 1082/2645 [01:45<02:37,  9.92it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  41%|████      | 1083/2645 [01:45<02:37,  9.90it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  41%|████      | 1083/2645 [01:45<02:37,  9.90it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  41%|████      | 1083/2645 [01:45<02:37,  9.90it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  41%|████      | 1085/2645 [01:45<02:35, 10.03it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  41%|████      | 1085/2645 [01:45<02:35, 10.03it/s, training_loss=0.411]\u001b[A\n",
      "Epoch 2:  41%|████      | 1085/2645 [01:45<02:35, 10.03it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  41%|████      | 1087/2645 [01:45<02:35, 10.05it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  41%|████      | 1087/2645 [01:46<02:35, 10.05it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  41%|████      | 1087/2645 [01:46<02:35, 10.05it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  41%|████      | 1089/2645 [01:46<02:33, 10.12it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  41%|████      | 1089/2645 [01:46<02:33, 10.12it/s, training_loss=0.801]\u001b[A\n",
      "Epoch 2:  41%|████      | 1089/2645 [01:46<02:33, 10.12it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  41%|████      | 1091/2645 [01:46<02:32, 10.21it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  41%|████      | 1091/2645 [01:46<02:32, 10.21it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  41%|████      | 1091/2645 [01:46<02:32, 10.21it/s, training_loss=0.072]\u001b[A\n",
      "Epoch 2:  41%|████▏     | 1093/2645 [01:46<02:31, 10.25it/s, training_loss=0.072]\u001b[A\n",
      "Epoch 2:  41%|████▏     | 1093/2645 [01:46<02:31, 10.25it/s, training_loss=0.012]\u001b[A\n",
      "Epoch 2:  41%|████▏     | 1093/2645 [01:46<02:31, 10.25it/s, training_loss=0.027]\u001b[A\n",
      "Epoch 2:  41%|████▏     | 1095/2645 [01:46<02:33, 10.08it/s, training_loss=0.027]\u001b[A\n",
      "Epoch 2:  41%|████▏     | 1095/2645 [01:46<02:33, 10.08it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 2:  41%|████▏     | 1095/2645 [01:46<02:33, 10.08it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  41%|████▏     | 1097/2645 [01:46<02:34, 10.05it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  41%|████▏     | 1097/2645 [01:47<02:34, 10.05it/s, training_loss=0.889]\u001b[A\n",
      "Epoch 2:  41%|████▏     | 1097/2645 [01:47<02:34, 10.05it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  42%|████▏     | 1099/2645 [01:47<02:33, 10.07it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  42%|████▏     | 1099/2645 [01:47<02:33, 10.07it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  42%|████▏     | 1099/2645 [01:47<02:33, 10.07it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  42%|████▏     | 1101/2645 [01:47<02:31, 10.19it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  42%|████▏     | 1101/2645 [01:47<02:31, 10.19it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  42%|████▏     | 1101/2645 [01:47<02:31, 10.19it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  42%|████▏     | 1103/2645 [01:47<02:31, 10.18it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  42%|████▏     | 1103/2645 [01:47<02:31, 10.18it/s, training_loss=0.871]\u001b[A\n",
      "Epoch 2:  42%|████▏     | 1103/2645 [01:47<02:31, 10.18it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  42%|████▏     | 1105/2645 [01:47<02:32, 10.09it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  42%|████▏     | 1105/2645 [01:47<02:32, 10.09it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  42%|████▏     | 1105/2645 [01:47<02:32, 10.09it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  42%|████▏     | 1107/2645 [01:47<02:31, 10.17it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  42%|████▏     | 1107/2645 [01:48<02:31, 10.17it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  42%|████▏     | 1107/2645 [01:48<02:31, 10.17it/s, training_loss=0.490]\u001b[A\n",
      "Epoch 2:  42%|████▏     | 1109/2645 [01:48<02:30, 10.19it/s, training_loss=0.490]\u001b[A\n",
      "Epoch 2:  42%|████▏     | 1109/2645 [01:48<02:30, 10.19it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  42%|████▏     | 1109/2645 [01:48<02:30, 10.19it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  42%|████▏     | 1111/2645 [01:48<02:30, 10.18it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  42%|████▏     | 1111/2645 [01:48<02:30, 10.18it/s, training_loss=0.763]\u001b[A\n",
      "Epoch 2:  42%|████▏     | 1111/2645 [01:48<02:30, 10.18it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  42%|████▏     | 1113/2645 [01:48<02:31, 10.13it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  42%|████▏     | 1113/2645 [01:48<02:31, 10.13it/s, training_loss=0.039]\u001b[A\n",
      "Epoch 2:  42%|████▏     | 1113/2645 [01:48<02:31, 10.13it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  42%|████▏     | 1115/2645 [01:48<02:32, 10.01it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  42%|████▏     | 1115/2645 [01:48<02:32, 10.01it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  42%|████▏     | 1115/2645 [01:48<02:32, 10.01it/s, training_loss=0.454]\u001b[A\n",
      "Epoch 2:  42%|████▏     | 1117/2645 [01:48<02:31, 10.11it/s, training_loss=0.454]\u001b[A\n",
      "Epoch 2:  42%|████▏     | 1117/2645 [01:48<02:31, 10.11it/s, training_loss=0.873]\u001b[A\n",
      "Epoch 2:  42%|████▏     | 1117/2645 [01:49<02:31, 10.11it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  42%|████▏     | 1119/2645 [01:49<02:30, 10.13it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  42%|████▏     | 1119/2645 [01:49<02:30, 10.13it/s, training_loss=0.507]\u001b[A\n",
      "Epoch 2:  42%|████▏     | 1119/2645 [01:49<02:30, 10.13it/s, training_loss=0.834]\u001b[A\n",
      "Epoch 2:  42%|████▏     | 1121/2645 [01:49<02:30, 10.14it/s, training_loss=0.834]\u001b[A\n",
      "Epoch 2:  42%|████▏     | 1121/2645 [01:49<02:30, 10.14it/s, training_loss=0.923]\u001b[A\n",
      "Epoch 2:  42%|████▏     | 1121/2645 [01:49<02:30, 10.14it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  42%|████▏     | 1123/2645 [01:49<02:29, 10.15it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  42%|████▏     | 1123/2645 [01:49<02:29, 10.15it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  42%|████▏     | 1123/2645 [01:49<02:29, 10.15it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  43%|████▎     | 1125/2645 [01:49<02:28, 10.22it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  43%|████▎     | 1125/2645 [01:49<02:28, 10.22it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  43%|████▎     | 1125/2645 [01:49<02:28, 10.22it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  43%|████▎     | 1127/2645 [01:49<02:28, 10.26it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  43%|████▎     | 1127/2645 [01:49<02:28, 10.26it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  43%|████▎     | 1127/2645 [01:50<02:28, 10.26it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  43%|████▎     | 1129/2645 [01:50<02:28, 10.21it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  43%|████▎     | 1129/2645 [01:50<02:28, 10.21it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  43%|████▎     | 1129/2645 [01:50<02:28, 10.21it/s, training_loss=0.653]\u001b[A\n",
      "Epoch 2:  43%|████▎     | 1131/2645 [01:50<02:30, 10.07it/s, training_loss=0.653]\u001b[A\n",
      "Epoch 2:  43%|████▎     | 1131/2645 [01:50<02:30, 10.07it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  43%|████▎     | 1131/2645 [01:50<02:30, 10.07it/s, training_loss=0.650]\u001b[A\n",
      "Epoch 2:  43%|████▎     | 1133/2645 [01:50<02:29, 10.09it/s, training_loss=0.650]\u001b[A\n",
      "Epoch 2:  43%|████▎     | 1133/2645 [01:50<02:29, 10.09it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  43%|████▎     | 1133/2645 [01:50<02:29, 10.09it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  43%|████▎     | 1135/2645 [01:50<02:31,  9.96it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  43%|████▎     | 1135/2645 [01:50<02:31,  9.96it/s, training_loss=0.033]\u001b[A\n",
      "Epoch 2:  43%|████▎     | 1136/2645 [01:50<02:31,  9.96it/s, training_loss=0.033]\u001b[A\n",
      "Epoch 2:  43%|████▎     | 1136/2645 [01:50<02:31,  9.96it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  43%|████▎     | 1137/2645 [01:50<02:31,  9.95it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  43%|████▎     | 1137/2645 [01:50<02:31,  9.95it/s, training_loss=0.053]\u001b[A\n",
      "Epoch 2:  43%|████▎     | 1138/2645 [01:50<02:31,  9.93it/s, training_loss=0.053]\u001b[A\n",
      "Epoch 2:  43%|████▎     | 1138/2645 [01:51<02:31,  9.93it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 2:  43%|████▎     | 1139/2645 [01:51<02:32,  9.90it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 2:  43%|████▎     | 1139/2645 [01:51<02:32,  9.90it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  43%|████▎     | 1139/2645 [01:51<02:32,  9.90it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  43%|████▎     | 1141/2645 [01:51<02:31,  9.95it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  43%|████▎     | 1141/2645 [01:51<02:31,  9.95it/s, training_loss=0.372]\u001b[A\n",
      "Epoch 2:  43%|████▎     | 1142/2645 [01:51<02:31,  9.92it/s, training_loss=0.372]\u001b[A\n",
      "Epoch 2:  43%|████▎     | 1142/2645 [01:51<02:31,  9.92it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  43%|████▎     | 1142/2645 [01:51<02:31,  9.92it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  43%|████▎     | 1144/2645 [01:51<02:29, 10.04it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  43%|████▎     | 1144/2645 [01:51<02:29, 10.04it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  43%|████▎     | 1144/2645 [01:51<02:29, 10.04it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  43%|████▎     | 1146/2645 [01:51<02:28, 10.11it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  43%|████▎     | 1146/2645 [01:51<02:28, 10.11it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  43%|████▎     | 1146/2645 [01:51<02:28, 10.11it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  43%|████▎     | 1148/2645 [01:51<02:27, 10.16it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  43%|████▎     | 1148/2645 [01:52<02:27, 10.16it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  43%|████▎     | 1148/2645 [01:52<02:27, 10.16it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  43%|████▎     | 1150/2645 [01:52<02:27, 10.15it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  43%|████▎     | 1150/2645 [01:52<02:27, 10.15it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  43%|████▎     | 1150/2645 [01:52<02:27, 10.15it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  44%|████▎     | 1152/2645 [01:52<02:26, 10.22it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  44%|████▎     | 1152/2645 [01:52<02:26, 10.22it/s, training_loss=0.010]\u001b[A\n",
      "Epoch 2:  44%|████▎     | 1152/2645 [01:52<02:26, 10.22it/s, training_loss=0.029]\u001b[A\n",
      "Epoch 2:  44%|████▎     | 1154/2645 [01:52<02:26, 10.14it/s, training_loss=0.029]\u001b[A\n",
      "Epoch 2:  44%|████▎     | 1154/2645 [01:52<02:26, 10.14it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  44%|████▎     | 1154/2645 [01:52<02:26, 10.14it/s, training_loss=0.095]\u001b[A\n",
      "Epoch 2:  44%|████▎     | 1156/2645 [01:52<02:26, 10.13it/s, training_loss=0.095]\u001b[A\n",
      "Epoch 2:  44%|████▎     | 1156/2645 [01:52<02:26, 10.13it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  44%|████▎     | 1156/2645 [01:52<02:26, 10.13it/s, training_loss=0.941]\u001b[A\n",
      "Epoch 2:  44%|████▍     | 1158/2645 [01:52<02:26, 10.18it/s, training_loss=0.941]\u001b[A\n",
      "Epoch 2:  44%|████▍     | 1158/2645 [01:53<02:26, 10.18it/s, training_loss=0.084]\u001b[A\n",
      "Epoch 2:  44%|████▍     | 1158/2645 [01:53<02:26, 10.18it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  44%|████▍     | 1160/2645 [01:53<02:25, 10.23it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  44%|████▍     | 1160/2645 [01:53<02:25, 10.23it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  44%|████▍     | 1160/2645 [01:53<02:25, 10.23it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 2:  44%|████▍     | 1162/2645 [01:53<02:24, 10.28it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 2:  44%|████▍     | 1162/2645 [01:53<02:24, 10.28it/s, training_loss=0.406]\u001b[A\n",
      "Epoch 2:  44%|████▍     | 1162/2645 [01:53<02:24, 10.28it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  44%|████▍     | 1164/2645 [01:53<02:24, 10.26it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  44%|████▍     | 1164/2645 [01:53<02:24, 10.26it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  44%|████▍     | 1164/2645 [01:53<02:24, 10.26it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  44%|████▍     | 1166/2645 [01:53<02:23, 10.30it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  44%|████▍     | 1166/2645 [01:53<02:23, 10.30it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  44%|████▍     | 1166/2645 [01:53<02:23, 10.30it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  44%|████▍     | 1168/2645 [01:53<02:22, 10.37it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  44%|████▍     | 1168/2645 [01:54<02:22, 10.37it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  44%|████▍     | 1168/2645 [01:54<02:22, 10.37it/s, training_loss=0.602]\u001b[A\n",
      "Epoch 2:  44%|████▍     | 1170/2645 [01:54<02:22, 10.35it/s, training_loss=0.602]\u001b[A\n",
      "Epoch 2:  44%|████▍     | 1170/2645 [01:54<02:22, 10.35it/s, training_loss=0.322]\u001b[A\n",
      "Epoch 2:  44%|████▍     | 1170/2645 [01:54<02:22, 10.35it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  44%|████▍     | 1172/2645 [01:54<02:22, 10.36it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  44%|████▍     | 1172/2645 [01:54<02:22, 10.36it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  44%|████▍     | 1172/2645 [01:54<02:22, 10.36it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 2:  44%|████▍     | 1174/2645 [01:54<02:22, 10.32it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 2:  44%|████▍     | 1174/2645 [01:54<02:22, 10.32it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  44%|████▍     | 1174/2645 [01:54<02:22, 10.32it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  44%|████▍     | 1176/2645 [01:54<02:22, 10.34it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  44%|████▍     | 1176/2645 [01:54<02:22, 10.34it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  44%|████▍     | 1176/2645 [01:54<02:22, 10.34it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  45%|████▍     | 1178/2645 [01:54<02:22, 10.26it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  45%|████▍     | 1178/2645 [01:54<02:22, 10.26it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  45%|████▍     | 1178/2645 [01:55<02:22, 10.26it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  45%|████▍     | 1180/2645 [01:55<02:23, 10.22it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  45%|████▍     | 1180/2645 [01:55<02:23, 10.22it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  45%|████▍     | 1180/2645 [01:55<02:23, 10.22it/s, training_loss=0.520]\u001b[A\n",
      "Epoch 2:  45%|████▍     | 1182/2645 [01:55<02:24, 10.14it/s, training_loss=0.520]\u001b[A\n",
      "Epoch 2:  45%|████▍     | 1182/2645 [01:55<02:24, 10.14it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  45%|████▍     | 1182/2645 [01:55<02:24, 10.14it/s, training_loss=0.018]\u001b[A\n",
      "Epoch 2:  45%|████▍     | 1184/2645 [01:55<02:25, 10.06it/s, training_loss=0.018]\u001b[A\n",
      "Epoch 2:  45%|████▍     | 1184/2645 [01:55<02:25, 10.06it/s, training_loss=0.435]\u001b[A\n",
      "Epoch 2:  45%|████▍     | 1184/2645 [01:55<02:25, 10.06it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  45%|████▍     | 1186/2645 [01:55<02:24, 10.11it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  45%|████▍     | 1186/2645 [01:55<02:24, 10.11it/s, training_loss=1.761]\u001b[A\n",
      "Epoch 2:  45%|████▍     | 1186/2645 [01:55<02:24, 10.11it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  45%|████▍     | 1188/2645 [01:55<02:23, 10.15it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  45%|████▍     | 1188/2645 [01:55<02:23, 10.15it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  45%|████▍     | 1188/2645 [01:56<02:23, 10.15it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  45%|████▍     | 1190/2645 [01:56<02:23, 10.12it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  45%|████▍     | 1190/2645 [01:56<02:23, 10.12it/s, training_loss=1.171]\u001b[A\n",
      "Epoch 2:  45%|████▍     | 1190/2645 [01:56<02:23, 10.12it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  45%|████▌     | 1192/2645 [01:56<02:22, 10.18it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  45%|████▌     | 1192/2645 [01:56<02:22, 10.18it/s, training_loss=0.020]\u001b[A\n",
      "Epoch 2:  45%|████▌     | 1192/2645 [01:56<02:22, 10.18it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  45%|████▌     | 1194/2645 [01:56<02:24, 10.05it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  45%|████▌     | 1194/2645 [01:56<02:24, 10.05it/s, training_loss=0.479]\u001b[A\n",
      "Epoch 2:  45%|████▌     | 1194/2645 [01:56<02:24, 10.05it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 2:  45%|████▌     | 1196/2645 [01:56<02:23, 10.07it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 2:  45%|████▌     | 1196/2645 [01:56<02:23, 10.07it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  45%|████▌     | 1196/2645 [01:56<02:23, 10.07it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  45%|████▌     | 1198/2645 [01:56<02:22, 10.16it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  45%|████▌     | 1198/2645 [01:56<02:22, 10.16it/s, training_loss=0.041]\u001b[A\n",
      "Epoch 2:  45%|████▌     | 1198/2645 [01:57<02:22, 10.16it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  45%|████▌     | 1200/2645 [01:57<02:23, 10.07it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  45%|████▌     | 1200/2645 [01:57<02:23, 10.07it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  45%|████▌     | 1200/2645 [01:57<02:23, 10.07it/s, training_loss=0.386]\u001b[A\n",
      "Epoch 2:  45%|████▌     | 1202/2645 [01:57<02:23, 10.04it/s, training_loss=0.386]\u001b[A\n",
      "Epoch 2:  45%|████▌     | 1202/2645 [01:57<02:23, 10.04it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  45%|████▌     | 1202/2645 [01:57<02:23, 10.04it/s, training_loss=0.994]\u001b[A\n",
      "Epoch 2:  46%|████▌     | 1204/2645 [01:57<02:24,  9.94it/s, training_loss=0.994]\u001b[A\n",
      "Epoch 2:  46%|████▌     | 1204/2645 [01:57<02:24,  9.94it/s, training_loss=0.479]\u001b[A\n",
      "Epoch 2:  46%|████▌     | 1205/2645 [01:57<02:24,  9.94it/s, training_loss=0.479]\u001b[A\n",
      "Epoch 2:  46%|████▌     | 1205/2645 [01:57<02:24,  9.94it/s, training_loss=0.012]\u001b[A\n",
      "Epoch 2:  46%|████▌     | 1206/2645 [01:57<02:24,  9.94it/s, training_loss=0.012]\u001b[A\n",
      "Epoch 2:  46%|████▌     | 1206/2645 [01:57<02:24,  9.94it/s, training_loss=0.605]\u001b[A\n",
      "Epoch 2:  46%|████▌     | 1207/2645 [01:57<02:24,  9.95it/s, training_loss=0.605]\u001b[A\n",
      "Epoch 2:  46%|████▌     | 1207/2645 [01:57<02:24,  9.95it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  46%|████▌     | 1207/2645 [01:57<02:24,  9.95it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  46%|████▌     | 1209/2645 [01:57<02:22, 10.06it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  46%|████▌     | 1209/2645 [01:58<02:22, 10.06it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  46%|████▌     | 1209/2645 [01:58<02:22, 10.06it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  46%|████▌     | 1211/2645 [01:58<02:23,  9.99it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  46%|████▌     | 1211/2645 [01:58<02:23,  9.99it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  46%|████▌     | 1211/2645 [01:58<02:23,  9.99it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 2:  46%|████▌     | 1213/2645 [01:58<02:22, 10.02it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 2:  46%|████▌     | 1213/2645 [01:58<02:22, 10.02it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  46%|████▌     | 1213/2645 [01:58<02:22, 10.02it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  46%|████▌     | 1215/2645 [01:58<02:22, 10.01it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  46%|████▌     | 1215/2645 [01:58<02:22, 10.01it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 2:  46%|████▌     | 1215/2645 [01:58<02:22, 10.01it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  46%|████▌     | 1217/2645 [01:58<02:23,  9.98it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  46%|████▌     | 1217/2645 [01:58<02:23,  9.98it/s, training_loss=0.909]\u001b[A\n",
      "Epoch 2:  46%|████▌     | 1218/2645 [01:58<02:28,  9.59it/s, training_loss=0.909]\u001b[A\n",
      "Epoch 2:  46%|████▌     | 1218/2645 [01:58<02:28,  9.59it/s, training_loss=0.421]\u001b[A\n",
      "Epoch 2:  46%|████▌     | 1219/2645 [01:58<02:26,  9.70it/s, training_loss=0.421]\u001b[A\n",
      "Epoch 2:  46%|████▌     | 1219/2645 [01:59<02:26,  9.70it/s, training_loss=0.155]\u001b[A\n",
      "Epoch 2:  46%|████▌     | 1220/2645 [01:59<02:25,  9.78it/s, training_loss=0.155]\u001b[A\n",
      "Epoch 2:  46%|████▌     | 1220/2645 [01:59<02:25,  9.78it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  46%|████▌     | 1220/2645 [01:59<02:25,  9.78it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  46%|████▌     | 1222/2645 [01:59<02:24,  9.86it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  46%|████▌     | 1222/2645 [01:59<02:24,  9.86it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  46%|████▌     | 1223/2645 [01:59<02:24,  9.87it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  46%|████▌     | 1223/2645 [01:59<02:24,  9.87it/s, training_loss=0.369]\u001b[A\n",
      "Epoch 2:  46%|████▋     | 1224/2645 [01:59<02:23,  9.91it/s, training_loss=0.369]\u001b[A\n",
      "Epoch 2:  46%|████▋     | 1224/2645 [01:59<02:23,  9.91it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  46%|████▋     | 1224/2645 [01:59<02:23,  9.91it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  46%|████▋     | 1226/2645 [01:59<02:22,  9.99it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  46%|████▋     | 1226/2645 [01:59<02:22,  9.99it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  46%|████▋     | 1226/2645 [01:59<02:22,  9.99it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  46%|████▋     | 1228/2645 [01:59<02:20, 10.10it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  46%|████▋     | 1228/2645 [01:59<02:20, 10.10it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  46%|████▋     | 1228/2645 [02:00<02:20, 10.10it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  47%|████▋     | 1230/2645 [02:00<02:18, 10.21it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  47%|████▋     | 1230/2645 [02:00<02:18, 10.21it/s, training_loss=0.015]\u001b[A\n",
      "Epoch 2:  47%|████▋     | 1230/2645 [02:00<02:18, 10.21it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  47%|████▋     | 1232/2645 [02:00<02:17, 10.29it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  47%|████▋     | 1232/2645 [02:00<02:17, 10.29it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  47%|████▋     | 1232/2645 [02:00<02:17, 10.29it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  47%|████▋     | 1234/2645 [02:00<02:16, 10.36it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  47%|████▋     | 1234/2645 [02:00<02:16, 10.36it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  47%|████▋     | 1234/2645 [02:00<02:16, 10.36it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  47%|████▋     | 1236/2645 [02:00<02:15, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  47%|████▋     | 1236/2645 [02:00<02:15, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  47%|████▋     | 1236/2645 [02:00<02:15, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  47%|████▋     | 1238/2645 [02:00<02:14, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  47%|████▋     | 1238/2645 [02:00<02:14, 10.46it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 2:  47%|████▋     | 1238/2645 [02:01<02:14, 10.46it/s, training_loss=0.795]\u001b[A\n",
      "Epoch 2:  47%|████▋     | 1240/2645 [02:01<02:14, 10.42it/s, training_loss=0.795]\u001b[A\n",
      "Epoch 2:  47%|████▋     | 1240/2645 [02:01<02:14, 10.42it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  47%|████▋     | 1240/2645 [02:01<02:14, 10.42it/s, training_loss=0.288]\u001b[A\n",
      "Epoch 2:  47%|████▋     | 1242/2645 [02:01<02:15, 10.39it/s, training_loss=0.288]\u001b[A\n",
      "Epoch 2:  47%|████▋     | 1242/2645 [02:01<02:15, 10.39it/s, training_loss=0.137]\u001b[A\n",
      "Epoch 2:  47%|████▋     | 1242/2645 [02:01<02:15, 10.39it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  47%|████▋     | 1244/2645 [02:01<02:14, 10.41it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  47%|████▋     | 1244/2645 [02:01<02:14, 10.41it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  47%|████▋     | 1244/2645 [02:01<02:14, 10.41it/s, training_loss=0.133]\u001b[A\n",
      "Epoch 2:  47%|████▋     | 1246/2645 [02:01<02:14, 10.38it/s, training_loss=0.133]\u001b[A\n",
      "Epoch 2:  47%|████▋     | 1246/2645 [02:01<02:14, 10.38it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  47%|████▋     | 1246/2645 [02:01<02:14, 10.38it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  47%|████▋     | 1248/2645 [02:01<02:14, 10.42it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  47%|████▋     | 1248/2645 [02:01<02:14, 10.42it/s, training_loss=0.017]\u001b[A\n",
      "Epoch 2:  47%|████▋     | 1248/2645 [02:01<02:14, 10.42it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  47%|████▋     | 1250/2645 [02:01<02:14, 10.41it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  47%|████▋     | 1250/2645 [02:02<02:14, 10.41it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  47%|████▋     | 1250/2645 [02:02<02:14, 10.41it/s, training_loss=0.336]\u001b[A\n",
      "Epoch 2:  47%|████▋     | 1252/2645 [02:02<02:13, 10.41it/s, training_loss=0.336]\u001b[A\n",
      "Epoch 2:  47%|████▋     | 1252/2645 [02:02<02:13, 10.41it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  47%|████▋     | 1252/2645 [02:02<02:13, 10.41it/s, training_loss=0.209]\u001b[A\n",
      "Epoch 2:  47%|████▋     | 1254/2645 [02:02<02:14, 10.31it/s, training_loss=0.209]\u001b[A\n",
      "Epoch 2:  47%|████▋     | 1254/2645 [02:02<02:14, 10.31it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  47%|████▋     | 1254/2645 [02:02<02:14, 10.31it/s, training_loss=0.329]\u001b[A\n",
      "Epoch 2:  47%|████▋     | 1256/2645 [02:02<02:16, 10.19it/s, training_loss=0.329]\u001b[A\n",
      "Epoch 2:  47%|████▋     | 1256/2645 [02:02<02:16, 10.19it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 2:  47%|████▋     | 1256/2645 [02:02<02:16, 10.19it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  48%|████▊     | 1258/2645 [02:02<02:15, 10.27it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  48%|████▊     | 1258/2645 [02:02<02:15, 10.27it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  48%|████▊     | 1258/2645 [02:02<02:15, 10.27it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  48%|████▊     | 1260/2645 [02:02<02:14, 10.32it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  48%|████▊     | 1260/2645 [02:03<02:14, 10.32it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  48%|████▊     | 1260/2645 [02:03<02:14, 10.32it/s, training_loss=0.975]\u001b[A\n",
      "Epoch 2:  48%|████▊     | 1262/2645 [02:03<02:13, 10.35it/s, training_loss=0.975]\u001b[A\n",
      "Epoch 2:  48%|████▊     | 1262/2645 [02:03<02:13, 10.35it/s, training_loss=0.619]\u001b[A\n",
      "Epoch 2:  48%|████▊     | 1262/2645 [02:03<02:13, 10.35it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  48%|████▊     | 1264/2645 [02:03<02:13, 10.36it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  48%|████▊     | 1264/2645 [02:03<02:13, 10.36it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  48%|████▊     | 1264/2645 [02:03<02:13, 10.36it/s, training_loss=0.717]\u001b[A\n",
      "Epoch 2:  48%|████▊     | 1266/2645 [02:03<02:14, 10.28it/s, training_loss=0.717]\u001b[A\n",
      "Epoch 2:  48%|████▊     | 1266/2645 [02:03<02:14, 10.28it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  48%|████▊     | 1266/2645 [02:03<02:14, 10.28it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  48%|████▊     | 1268/2645 [02:03<02:12, 10.35it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  48%|████▊     | 1268/2645 [02:03<02:12, 10.35it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  48%|████▊     | 1268/2645 [02:03<02:12, 10.35it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  48%|████▊     | 1270/2645 [02:03<02:11, 10.42it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  48%|████▊     | 1270/2645 [02:04<02:11, 10.42it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  48%|████▊     | 1270/2645 [02:04<02:11, 10.42it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  48%|████▊     | 1272/2645 [02:04<02:11, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  48%|████▊     | 1272/2645 [02:04<02:11, 10.43it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  48%|████▊     | 1272/2645 [02:04<02:11, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  48%|████▊     | 1274/2645 [02:04<02:11, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  48%|████▊     | 1274/2645 [02:04<02:11, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  48%|████▊     | 1274/2645 [02:04<02:11, 10.45it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  48%|████▊     | 1276/2645 [02:04<02:11, 10.38it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  48%|████▊     | 1276/2645 [02:04<02:11, 10.38it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  48%|████▊     | 1276/2645 [02:04<02:11, 10.38it/s, training_loss=0.676]\u001b[A\n",
      "Epoch 2:  48%|████▊     | 1278/2645 [02:04<02:12, 10.33it/s, training_loss=0.676]\u001b[A\n",
      "Epoch 2:  48%|████▊     | 1278/2645 [02:04<02:12, 10.33it/s, training_loss=0.637]\u001b[A\n",
      "Epoch 2:  48%|████▊     | 1278/2645 [02:04<02:12, 10.33it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  48%|████▊     | 1280/2645 [02:04<02:12, 10.34it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  48%|████▊     | 1280/2645 [02:04<02:12, 10.34it/s, training_loss=0.436]\u001b[A\n",
      "Epoch 2:  48%|████▊     | 1280/2645 [02:05<02:12, 10.34it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  48%|████▊     | 1282/2645 [02:05<02:11, 10.37it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  48%|████▊     | 1282/2645 [02:05<02:11, 10.37it/s, training_loss=0.431]\u001b[A\n",
      "Epoch 2:  48%|████▊     | 1282/2645 [02:05<02:11, 10.37it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  49%|████▊     | 1284/2645 [02:05<02:11, 10.38it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  49%|████▊     | 1284/2645 [02:05<02:11, 10.38it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  49%|████▊     | 1284/2645 [02:05<02:11, 10.38it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  49%|████▊     | 1286/2645 [02:05<02:10, 10.39it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  49%|████▊     | 1286/2645 [02:05<02:10, 10.39it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  49%|████▊     | 1286/2645 [02:05<02:10, 10.39it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 2:  49%|████▊     | 1288/2645 [02:05<02:10, 10.38it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 2:  49%|████▊     | 1288/2645 [02:05<02:10, 10.38it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  49%|████▊     | 1288/2645 [02:05<02:10, 10.38it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  49%|████▉     | 1290/2645 [02:05<02:09, 10.45it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  49%|████▉     | 1290/2645 [02:05<02:09, 10.45it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  49%|████▉     | 1290/2645 [02:06<02:09, 10.45it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  49%|████▉     | 1292/2645 [02:06<02:09, 10.46it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  49%|████▉     | 1292/2645 [02:06<02:09, 10.46it/s, training_loss=0.206]\u001b[A\n",
      "Epoch 2:  49%|████▉     | 1292/2645 [02:06<02:09, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  49%|████▉     | 1294/2645 [02:06<02:09, 10.41it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  49%|████▉     | 1294/2645 [02:06<02:09, 10.41it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  49%|████▉     | 1294/2645 [02:06<02:09, 10.41it/s, training_loss=0.464]\u001b[A\n",
      "Epoch 2:  49%|████▉     | 1296/2645 [02:06<02:11, 10.23it/s, training_loss=0.464]\u001b[A\n",
      "Epoch 2:  49%|████▉     | 1296/2645 [02:06<02:11, 10.23it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  49%|████▉     | 1296/2645 [02:06<02:11, 10.23it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  49%|████▉     | 1298/2645 [02:06<02:12, 10.19it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  49%|████▉     | 1298/2645 [02:06<02:12, 10.19it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  49%|████▉     | 1298/2645 [02:06<02:12, 10.19it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  49%|████▉     | 1300/2645 [02:06<02:10, 10.27it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  49%|████▉     | 1300/2645 [02:06<02:10, 10.27it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  49%|████▉     | 1300/2645 [02:07<02:10, 10.27it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  49%|████▉     | 1302/2645 [02:07<02:10, 10.29it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  49%|████▉     | 1302/2645 [02:07<02:10, 10.29it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  49%|████▉     | 1302/2645 [02:07<02:10, 10.29it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  49%|████▉     | 1304/2645 [02:07<02:11, 10.21it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  49%|████▉     | 1304/2645 [02:07<02:11, 10.21it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  49%|████▉     | 1304/2645 [02:07<02:11, 10.21it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  49%|████▉     | 1306/2645 [02:07<02:12, 10.14it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  49%|████▉     | 1306/2645 [02:07<02:12, 10.14it/s, training_loss=0.939]\u001b[A\n",
      "Epoch 2:  49%|████▉     | 1306/2645 [02:07<02:12, 10.14it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  49%|████▉     | 1308/2645 [02:07<02:12, 10.07it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  49%|████▉     | 1308/2645 [02:07<02:12, 10.07it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  49%|████▉     | 1308/2645 [02:07<02:12, 10.07it/s, training_loss=0.548]\u001b[A\n",
      "Epoch 2:  50%|████▉     | 1310/2645 [02:07<02:12, 10.08it/s, training_loss=0.548]\u001b[A\n",
      "Epoch 2:  50%|████▉     | 1310/2645 [02:07<02:12, 10.08it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  50%|████▉     | 1310/2645 [02:08<02:12, 10.08it/s, training_loss=0.541]\u001b[A\n",
      "Epoch 2:  50%|████▉     | 1312/2645 [02:08<02:11, 10.11it/s, training_loss=0.541]\u001b[A\n",
      "Epoch 2:  50%|████▉     | 1312/2645 [02:08<02:11, 10.11it/s, training_loss=0.028]\u001b[A\n",
      "Epoch 2:  50%|████▉     | 1312/2645 [02:08<02:11, 10.11it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  50%|████▉     | 1314/2645 [02:08<02:12, 10.08it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  50%|████▉     | 1314/2645 [02:08<02:12, 10.08it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  50%|████▉     | 1314/2645 [02:08<02:12, 10.08it/s, training_loss=0.878]\u001b[A\n",
      "Epoch 2:  50%|████▉     | 1316/2645 [02:08<02:12, 10.00it/s, training_loss=0.878]\u001b[A\n",
      "Epoch 2:  50%|████▉     | 1316/2645 [02:08<02:12, 10.00it/s, training_loss=0.567]\u001b[A\n",
      "Epoch 2:  50%|████▉     | 1316/2645 [02:08<02:12, 10.00it/s, training_loss=0.053]\u001b[A\n",
      "Epoch 2:  50%|████▉     | 1318/2645 [02:08<02:12,  9.99it/s, training_loss=0.053]\u001b[A\n",
      "Epoch 2:  50%|████▉     | 1318/2645 [02:08<02:12,  9.99it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  50%|████▉     | 1318/2645 [02:08<02:12,  9.99it/s, training_loss=1.054]\u001b[A\n",
      "Epoch 2:  50%|████▉     | 1320/2645 [02:08<02:12, 10.00it/s, training_loss=1.054]\u001b[A\n",
      "Epoch 2:  50%|████▉     | 1320/2645 [02:08<02:12, 10.00it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  50%|████▉     | 1320/2645 [02:09<02:12, 10.00it/s, training_loss=0.842]\u001b[A\n",
      "Epoch 2:  50%|████▉     | 1322/2645 [02:09<02:12,  9.99it/s, training_loss=0.842]\u001b[A\n",
      "Epoch 2:  50%|████▉     | 1322/2645 [02:09<02:12,  9.99it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  50%|█████     | 1323/2645 [02:09<02:13,  9.92it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  50%|█████     | 1323/2645 [02:09<02:13,  9.92it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  50%|█████     | 1323/2645 [02:09<02:13,  9.92it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  50%|█████     | 1325/2645 [02:09<02:12,  9.99it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  50%|█████     | 1325/2645 [02:09<02:12,  9.99it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  50%|█████     | 1326/2645 [02:09<02:13,  9.89it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  50%|█████     | 1326/2645 [02:09<02:13,  9.89it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  50%|█████     | 1327/2645 [02:09<02:19,  9.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  50%|█████     | 1327/2645 [02:09<02:19,  9.48it/s, training_loss=0.788]\u001b[A\n",
      "Epoch 2:  50%|█████     | 1328/2645 [02:09<02:17,  9.60it/s, training_loss=0.788]\u001b[A\n",
      "Epoch 2:  50%|█████     | 1328/2645 [02:09<02:17,  9.60it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  50%|█████     | 1328/2645 [02:09<02:17,  9.60it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  50%|█████     | 1330/2645 [02:09<02:14,  9.75it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  50%|█████     | 1330/2645 [02:09<02:14,  9.75it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  50%|█████     | 1330/2645 [02:10<02:14,  9.75it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  50%|█████     | 1332/2645 [02:10<02:12,  9.88it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  50%|█████     | 1332/2645 [02:10<02:12,  9.88it/s, training_loss=0.014]\u001b[A\n",
      "Epoch 2:  50%|█████     | 1333/2645 [02:10<02:13,  9.82it/s, training_loss=0.014]\u001b[A\n",
      "Epoch 2:  50%|█████     | 1333/2645 [02:10<02:13,  9.82it/s, training_loss=0.126]\u001b[A\n",
      "Epoch 2:  50%|█████     | 1334/2645 [02:10<02:14,  9.73it/s, training_loss=0.126]\u001b[A\n",
      "Epoch 2:  50%|█████     | 1334/2645 [02:10<02:14,  9.73it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  50%|█████     | 1334/2645 [02:10<02:14,  9.73it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  51%|█████     | 1336/2645 [02:10<02:13,  9.80it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  51%|█████     | 1336/2645 [02:10<02:13,  9.80it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  51%|█████     | 1336/2645 [02:10<02:13,  9.80it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  51%|█████     | 1338/2645 [02:10<02:15,  9.67it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  51%|█████     | 1338/2645 [02:10<02:15,  9.67it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  51%|█████     | 1338/2645 [02:10<02:15,  9.67it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  51%|█████     | 1340/2645 [02:10<02:13,  9.78it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  51%|█████     | 1340/2645 [02:10<02:13,  9.78it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 2:  51%|█████     | 1341/2645 [02:10<02:13,  9.79it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 2:  51%|█████     | 1341/2645 [02:11<02:13,  9.79it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  51%|█████     | 1341/2645 [02:11<02:13,  9.79it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  51%|█████     | 1343/2645 [02:11<02:11,  9.88it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  51%|█████     | 1343/2645 [02:11<02:11,  9.88it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  51%|█████     | 1344/2645 [02:11<02:12,  9.81it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  51%|█████     | 1344/2645 [02:11<02:12,  9.81it/s, training_loss=0.546]\u001b[A\n",
      "Epoch 2:  51%|█████     | 1345/2645 [02:11<02:12,  9.83it/s, training_loss=0.546]\u001b[A\n",
      "Epoch 2:  51%|█████     | 1345/2645 [02:11<02:12,  9.83it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  51%|█████     | 1345/2645 [02:11<02:12,  9.83it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  51%|█████     | 1347/2645 [02:11<02:10,  9.91it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  51%|█████     | 1347/2645 [02:11<02:10,  9.91it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  51%|█████     | 1348/2645 [02:11<02:11,  9.84it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  51%|█████     | 1348/2645 [02:11<02:11,  9.84it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  51%|█████     | 1348/2645 [02:11<02:11,  9.84it/s, training_loss=0.551]\u001b[A\n",
      "Epoch 2:  51%|█████     | 1350/2645 [02:11<02:11,  9.86it/s, training_loss=0.551]\u001b[A\n",
      "Epoch 2:  51%|█████     | 1350/2645 [02:11<02:11,  9.86it/s, training_loss=0.022]\u001b[A\n",
      "Epoch 2:  51%|█████     | 1351/2645 [02:11<02:11,  9.87it/s, training_loss=0.022]\u001b[A\n",
      "Epoch 2:  51%|█████     | 1351/2645 [02:12<02:11,  9.87it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  51%|█████     | 1351/2645 [02:12<02:11,  9.87it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  51%|█████     | 1353/2645 [02:12<02:10,  9.91it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  51%|█████     | 1353/2645 [02:12<02:10,  9.91it/s, training_loss=0.905]\u001b[A\n",
      "Epoch 2:  51%|█████     | 1354/2645 [02:12<02:10,  9.89it/s, training_loss=0.905]\u001b[A\n",
      "Epoch 2:  51%|█████     | 1354/2645 [02:12<02:10,  9.89it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  51%|█████     | 1354/2645 [02:12<02:10,  9.89it/s, training_loss=0.963]\u001b[A\n",
      "Epoch 2:  51%|█████▏    | 1356/2645 [02:12<02:09,  9.97it/s, training_loss=0.963]\u001b[A\n",
      "Epoch 2:  51%|█████▏    | 1356/2645 [02:12<02:09,  9.97it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  51%|█████▏    | 1357/2645 [02:12<02:09,  9.92it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  51%|█████▏    | 1357/2645 [02:12<02:09,  9.92it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  51%|█████▏    | 1358/2645 [02:12<02:12,  9.68it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  51%|█████▏    | 1358/2645 [02:12<02:12,  9.68it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  51%|█████▏    | 1359/2645 [02:12<02:12,  9.71it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  51%|█████▏    | 1359/2645 [02:12<02:12,  9.71it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 2:  51%|█████▏    | 1360/2645 [02:12<02:13,  9.63it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 2:  51%|█████▏    | 1360/2645 [02:12<02:13,  9.63it/s, training_loss=0.388]\u001b[A\n",
      "Epoch 2:  51%|█████▏    | 1361/2645 [02:12<02:12,  9.71it/s, training_loss=0.388]\u001b[A\n",
      "Epoch 2:  51%|█████▏    | 1361/2645 [02:13<02:12,  9.71it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  51%|█████▏    | 1361/2645 [02:13<02:12,  9.71it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  52%|█████▏    | 1363/2645 [02:13<02:10,  9.84it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  52%|█████▏    | 1363/2645 [02:13<02:10,  9.84it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  52%|█████▏    | 1363/2645 [02:13<02:10,  9.84it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  52%|█████▏    | 1365/2645 [02:13<02:07, 10.01it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  52%|█████▏    | 1365/2645 [02:13<02:07, 10.01it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  52%|█████▏    | 1365/2645 [02:13<02:07, 10.01it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  52%|█████▏    | 1367/2645 [02:13<02:06, 10.09it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  52%|█████▏    | 1367/2645 [02:13<02:06, 10.09it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  52%|█████▏    | 1367/2645 [02:13<02:06, 10.09it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 2:  52%|█████▏    | 1369/2645 [02:13<02:07, 10.02it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 2:  52%|█████▏    | 1369/2645 [02:13<02:07, 10.02it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  52%|█████▏    | 1369/2645 [02:13<02:07, 10.02it/s, training_loss=0.084]\u001b[A\n",
      "Epoch 2:  52%|█████▏    | 1371/2645 [02:13<02:07, 10.00it/s, training_loss=0.084]\u001b[A\n",
      "Epoch 2:  52%|█████▏    | 1371/2645 [02:14<02:07, 10.00it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  52%|█████▏    | 1371/2645 [02:14<02:07, 10.00it/s, training_loss=0.438]\u001b[A\n",
      "Epoch 2:  52%|█████▏    | 1373/2645 [02:14<02:06, 10.05it/s, training_loss=0.438]\u001b[A\n",
      "Epoch 2:  52%|█████▏    | 1373/2645 [02:14<02:06, 10.05it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  52%|█████▏    | 1373/2645 [02:14<02:06, 10.05it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  52%|█████▏    | 1375/2645 [02:14<02:05, 10.14it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  52%|█████▏    | 1375/2645 [02:14<02:05, 10.14it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  52%|█████▏    | 1375/2645 [02:14<02:05, 10.14it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  52%|█████▏    | 1377/2645 [02:14<02:05, 10.09it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  52%|█████▏    | 1377/2645 [02:14<02:05, 10.09it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  52%|█████▏    | 1377/2645 [02:14<02:05, 10.09it/s, training_loss=0.892]\u001b[A\n",
      "Epoch 2:  52%|█████▏    | 1379/2645 [02:14<02:04, 10.13it/s, training_loss=0.892]\u001b[A\n",
      "Epoch 2:  52%|█████▏    | 1379/2645 [02:14<02:04, 10.13it/s, training_loss=0.633]\u001b[A\n",
      "Epoch 2:  52%|█████▏    | 1379/2645 [02:14<02:04, 10.13it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  52%|█████▏    | 1381/2645 [02:14<02:05, 10.07it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  52%|█████▏    | 1381/2645 [02:15<02:05, 10.07it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  52%|█████▏    | 1381/2645 [02:15<02:05, 10.07it/s, training_loss=0.781]\u001b[A\n",
      "Epoch 2:  52%|█████▏    | 1383/2645 [02:15<02:05, 10.09it/s, training_loss=0.781]\u001b[A\n",
      "Epoch 2:  52%|█████▏    | 1383/2645 [02:15<02:05, 10.09it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  52%|█████▏    | 1383/2645 [02:15<02:05, 10.09it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  52%|█████▏    | 1385/2645 [02:15<02:05, 10.07it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  52%|█████▏    | 1385/2645 [02:15<02:05, 10.07it/s, training_loss=0.654]\u001b[A\n",
      "Epoch 2:  52%|█████▏    | 1385/2645 [02:15<02:05, 10.07it/s, training_loss=0.929]\u001b[A\n",
      "Epoch 2:  52%|█████▏    | 1387/2645 [02:15<02:04, 10.09it/s, training_loss=0.929]\u001b[A\n",
      "Epoch 2:  52%|█████▏    | 1387/2645 [02:15<02:04, 10.09it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  52%|█████▏    | 1387/2645 [02:15<02:04, 10.09it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  53%|█████▎    | 1389/2645 [02:15<02:03, 10.14it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  53%|█████▎    | 1389/2645 [02:15<02:03, 10.14it/s, training_loss=1.156]\u001b[A\n",
      "Epoch 2:  53%|█████▎    | 1389/2645 [02:15<02:03, 10.14it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  53%|█████▎    | 1391/2645 [02:15<02:04, 10.10it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  53%|█████▎    | 1391/2645 [02:16<02:04, 10.10it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  53%|█████▎    | 1391/2645 [02:16<02:04, 10.10it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  53%|█████▎    | 1393/2645 [02:16<02:04, 10.10it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  53%|█████▎    | 1393/2645 [02:16<02:04, 10.10it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  53%|█████▎    | 1393/2645 [02:16<02:04, 10.10it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  53%|█████▎    | 1395/2645 [02:16<02:02, 10.21it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  53%|█████▎    | 1395/2645 [02:16<02:02, 10.21it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  53%|█████▎    | 1395/2645 [02:16<02:02, 10.21it/s, training_loss=0.744]\u001b[A\n",
      "Epoch 2:  53%|█████▎    | 1397/2645 [02:16<02:01, 10.28it/s, training_loss=0.744]\u001b[A\n",
      "Epoch 2:  53%|█████▎    | 1397/2645 [02:16<02:01, 10.28it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  53%|█████▎    | 1397/2645 [02:16<02:01, 10.28it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  53%|█████▎    | 1399/2645 [02:16<02:00, 10.34it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  53%|█████▎    | 1399/2645 [02:16<02:00, 10.34it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  53%|█████▎    | 1399/2645 [02:16<02:00, 10.34it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  53%|█████▎    | 1401/2645 [02:16<01:59, 10.40it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  53%|█████▎    | 1401/2645 [02:17<01:59, 10.40it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  53%|█████▎    | 1401/2645 [02:17<01:59, 10.40it/s, training_loss=0.039]\u001b[A\n",
      "Epoch 2:  53%|█████▎    | 1403/2645 [02:17<02:00, 10.33it/s, training_loss=0.039]\u001b[A\n",
      "Epoch 2:  53%|█████▎    | 1403/2645 [02:17<02:00, 10.33it/s, training_loss=0.549]\u001b[A\n",
      "Epoch 2:  53%|█████▎    | 1403/2645 [02:17<02:00, 10.33it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  53%|█████▎    | 1405/2645 [02:17<02:00, 10.33it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  53%|█████▎    | 1405/2645 [02:17<02:00, 10.33it/s, training_loss=0.337]\u001b[A\n",
      "Epoch 2:  53%|█████▎    | 1405/2645 [02:17<02:00, 10.33it/s, training_loss=0.415]\u001b[A\n",
      "Epoch 2:  53%|█████▎    | 1407/2645 [02:17<01:59, 10.34it/s, training_loss=0.415]\u001b[A\n",
      "Epoch 2:  53%|█████▎    | 1407/2645 [02:17<01:59, 10.34it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  53%|█████▎    | 1407/2645 [02:17<01:59, 10.34it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  53%|█████▎    | 1409/2645 [02:17<01:59, 10.38it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  53%|█████▎    | 1409/2645 [02:17<01:59, 10.38it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  53%|█████▎    | 1409/2645 [02:17<01:59, 10.38it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  53%|█████▎    | 1411/2645 [02:17<01:58, 10.43it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  53%|█████▎    | 1411/2645 [02:17<01:58, 10.43it/s, training_loss=0.434]\u001b[A\n",
      "Epoch 2:  53%|█████▎    | 1411/2645 [02:18<01:58, 10.43it/s, training_loss=0.901]\u001b[A\n",
      "Epoch 2:  53%|█████▎    | 1413/2645 [02:18<01:58, 10.42it/s, training_loss=0.901]\u001b[A\n",
      "Epoch 2:  53%|█████▎    | 1413/2645 [02:18<01:58, 10.42it/s, training_loss=0.625]\u001b[A\n",
      "Epoch 2:  53%|█████▎    | 1413/2645 [02:18<01:58, 10.42it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  53%|█████▎    | 1415/2645 [02:18<01:59, 10.31it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  53%|█████▎    | 1415/2645 [02:18<01:59, 10.31it/s, training_loss=0.439]\u001b[A\n",
      "Epoch 2:  53%|█████▎    | 1415/2645 [02:18<01:59, 10.31it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  54%|█████▎    | 1417/2645 [02:18<02:00, 10.20it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  54%|█████▎    | 1417/2645 [02:18<02:00, 10.20it/s, training_loss=0.494]\u001b[A\n",
      "Epoch 2:  54%|█████▎    | 1417/2645 [02:18<02:00, 10.20it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  54%|█████▎    | 1419/2645 [02:18<02:01, 10.08it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  54%|█████▎    | 1419/2645 [02:18<02:01, 10.08it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  54%|█████▎    | 1419/2645 [02:18<02:01, 10.08it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  54%|█████▎    | 1421/2645 [02:18<02:03,  9.93it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  54%|█████▎    | 1421/2645 [02:18<02:03,  9.93it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  54%|█████▍    | 1422/2645 [02:18<02:03,  9.94it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  54%|█████▍    | 1422/2645 [02:19<02:03,  9.94it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  54%|█████▍    | 1423/2645 [02:19<02:02,  9.94it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  54%|█████▍    | 1423/2645 [02:19<02:02,  9.94it/s, training_loss=0.558]\u001b[A\n",
      "Epoch 2:  54%|█████▍    | 1424/2645 [02:19<02:03,  9.87it/s, training_loss=0.558]\u001b[A\n",
      "Epoch 2:  54%|█████▍    | 1424/2645 [02:19<02:03,  9.87it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  54%|█████▍    | 1424/2645 [02:19<02:03,  9.87it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  54%|█████▍    | 1426/2645 [02:19<02:02,  9.97it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  54%|█████▍    | 1426/2645 [02:19<02:02,  9.97it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  54%|█████▍    | 1426/2645 [02:19<02:02,  9.97it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  54%|█████▍    | 1428/2645 [02:19<02:01, 10.05it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  54%|█████▍    | 1428/2645 [02:19<02:01, 10.05it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  54%|█████▍    | 1428/2645 [02:19<02:01, 10.05it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  54%|█████▍    | 1430/2645 [02:19<01:59, 10.19it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  54%|█████▍    | 1430/2645 [02:19<01:59, 10.19it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  54%|█████▍    | 1430/2645 [02:19<01:59, 10.19it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  54%|█████▍    | 1432/2645 [02:19<01:57, 10.28it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  54%|█████▍    | 1432/2645 [02:20<01:57, 10.28it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  54%|█████▍    | 1432/2645 [02:20<01:57, 10.28it/s, training_loss=0.063]\u001b[A\n",
      "Epoch 2:  54%|█████▍    | 1434/2645 [02:20<01:58, 10.25it/s, training_loss=0.063]\u001b[A\n",
      "Epoch 2:  54%|█████▍    | 1434/2645 [02:20<01:58, 10.25it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  54%|█████▍    | 1434/2645 [02:20<01:58, 10.25it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  54%|█████▍    | 1436/2645 [02:20<01:57, 10.30it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  54%|█████▍    | 1436/2645 [02:20<01:57, 10.30it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  54%|█████▍    | 1436/2645 [02:20<01:57, 10.30it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  54%|█████▍    | 1438/2645 [02:20<01:57, 10.23it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  54%|█████▍    | 1438/2645 [02:20<01:57, 10.23it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  54%|█████▍    | 1438/2645 [02:20<01:57, 10.23it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  54%|█████▍    | 1440/2645 [02:20<01:56, 10.30it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  54%|█████▍    | 1440/2645 [02:20<01:56, 10.30it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  54%|█████▍    | 1440/2645 [02:20<01:56, 10.30it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 2:  55%|█████▍    | 1442/2645 [02:20<01:56, 10.35it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 2:  55%|█████▍    | 1442/2645 [02:21<01:56, 10.35it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  55%|█████▍    | 1442/2645 [02:21<01:56, 10.35it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  55%|█████▍    | 1444/2645 [02:21<01:56, 10.32it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  55%|█████▍    | 1444/2645 [02:21<01:56, 10.32it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  55%|█████▍    | 1444/2645 [02:21<01:56, 10.32it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  55%|█████▍    | 1446/2645 [02:21<01:56, 10.32it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  55%|█████▍    | 1446/2645 [02:21<01:56, 10.32it/s, training_loss=0.268]\u001b[A\n",
      "Epoch 2:  55%|█████▍    | 1446/2645 [02:21<01:56, 10.32it/s, training_loss=0.023]\u001b[A\n",
      "Epoch 2:  55%|█████▍    | 1448/2645 [02:21<01:56, 10.25it/s, training_loss=0.023]\u001b[A\n",
      "Epoch 2:  55%|█████▍    | 1448/2645 [02:21<01:56, 10.25it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  55%|█████▍    | 1448/2645 [02:21<01:56, 10.25it/s, training_loss=0.965]\u001b[A\n",
      "Epoch 2:  55%|█████▍    | 1450/2645 [02:21<01:57, 10.18it/s, training_loss=0.965]\u001b[A\n",
      "Epoch 2:  55%|█████▍    | 1450/2645 [02:21<01:57, 10.18it/s, training_loss=0.342]\u001b[A\n",
      "Epoch 2:  55%|█████▍    | 1450/2645 [02:21<01:57, 10.18it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  55%|█████▍    | 1452/2645 [02:21<01:56, 10.26it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  55%|█████▍    | 1452/2645 [02:21<01:56, 10.26it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  55%|█████▍    | 1452/2645 [02:22<01:56, 10.26it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  55%|█████▍    | 1454/2645 [02:22<01:55, 10.31it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  55%|█████▍    | 1454/2645 [02:22<01:55, 10.31it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  55%|█████▍    | 1454/2645 [02:22<01:55, 10.31it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  55%|█████▌    | 1456/2645 [02:22<01:54, 10.37it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  55%|█████▌    | 1456/2645 [02:22<01:54, 10.37it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  55%|█████▌    | 1456/2645 [02:22<01:54, 10.37it/s, training_loss=0.019]\u001b[A\n",
      "Epoch 2:  55%|█████▌    | 1458/2645 [02:22<01:55, 10.29it/s, training_loss=0.019]\u001b[A\n",
      "Epoch 2:  55%|█████▌    | 1458/2645 [02:22<01:55, 10.29it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  55%|█████▌    | 1458/2645 [02:22<01:55, 10.29it/s, training_loss=0.338]\u001b[A\n",
      "Epoch 2:  55%|█████▌    | 1460/2645 [02:22<01:56, 10.15it/s, training_loss=0.338]\u001b[A\n",
      "Epoch 2:  55%|█████▌    | 1460/2645 [02:22<01:56, 10.15it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  55%|█████▌    | 1460/2645 [02:22<01:56, 10.15it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  55%|█████▌    | 1462/2645 [02:22<01:55, 10.27it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  55%|█████▌    | 1462/2645 [02:22<01:55, 10.27it/s, training_loss=0.367]\u001b[A\n",
      "Epoch 2:  55%|█████▌    | 1462/2645 [02:23<01:55, 10.27it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  55%|█████▌    | 1464/2645 [02:23<01:54, 10.31it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  55%|█████▌    | 1464/2645 [02:23<01:54, 10.31it/s, training_loss=0.668]\u001b[A\n",
      "Epoch 2:  55%|█████▌    | 1464/2645 [02:23<01:54, 10.31it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  55%|█████▌    | 1466/2645 [02:23<01:54, 10.32it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  55%|█████▌    | 1466/2645 [02:23<01:54, 10.32it/s, training_loss=0.962]\u001b[A\n",
      "Epoch 2:  55%|█████▌    | 1466/2645 [02:23<01:54, 10.32it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  56%|█████▌    | 1468/2645 [02:23<01:53, 10.33it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  56%|█████▌    | 1468/2645 [02:23<01:53, 10.33it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  56%|█████▌    | 1468/2645 [02:23<01:53, 10.33it/s, training_loss=0.700]\u001b[A\n",
      "Epoch 2:  56%|█████▌    | 1470/2645 [02:23<01:55, 10.17it/s, training_loss=0.700]\u001b[A\n",
      "Epoch 2:  56%|█████▌    | 1470/2645 [02:23<01:55, 10.17it/s, training_loss=0.015]\u001b[A\n",
      "Epoch 2:  56%|█████▌    | 1470/2645 [02:23<01:55, 10.17it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 2:  56%|█████▌    | 1472/2645 [02:23<01:56, 10.08it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 2:  56%|█████▌    | 1472/2645 [02:23<01:56, 10.08it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  56%|█████▌    | 1472/2645 [02:24<01:56, 10.08it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  56%|█████▌    | 1474/2645 [02:24<01:56, 10.07it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  56%|█████▌    | 1474/2645 [02:24<01:56, 10.07it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  56%|█████▌    | 1474/2645 [02:24<01:56, 10.07it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  56%|█████▌    | 1476/2645 [02:24<01:55, 10.12it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  56%|█████▌    | 1476/2645 [02:24<01:55, 10.12it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  56%|█████▌    | 1476/2645 [02:24<01:55, 10.12it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  56%|█████▌    | 1478/2645 [02:24<01:54, 10.15it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  56%|█████▌    | 1478/2645 [02:24<01:54, 10.15it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  56%|█████▌    | 1478/2645 [02:24<01:54, 10.15it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  56%|█████▌    | 1480/2645 [02:24<01:55, 10.09it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  56%|█████▌    | 1480/2645 [02:24<01:55, 10.09it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  56%|█████▌    | 1480/2645 [02:24<01:55, 10.09it/s, training_loss=0.018]\u001b[A\n",
      "Epoch 2:  56%|█████▌    | 1482/2645 [02:24<01:55, 10.03it/s, training_loss=0.018]\u001b[A\n",
      "Epoch 2:  56%|█████▌    | 1482/2645 [02:24<01:55, 10.03it/s, training_loss=0.547]\u001b[A\n",
      "Epoch 2:  56%|█████▌    | 1482/2645 [02:25<01:55, 10.03it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  56%|█████▌    | 1484/2645 [02:25<01:55, 10.06it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  56%|█████▌    | 1484/2645 [02:25<01:55, 10.06it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  56%|█████▌    | 1484/2645 [02:25<01:55, 10.06it/s, training_loss=0.228]\u001b[A\n",
      "Epoch 2:  56%|█████▌    | 1486/2645 [02:25<01:54, 10.10it/s, training_loss=0.228]\u001b[A\n",
      "Epoch 2:  56%|█████▌    | 1486/2645 [02:25<01:54, 10.10it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  56%|█████▌    | 1486/2645 [02:25<01:54, 10.10it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  56%|█████▋    | 1488/2645 [02:25<01:54, 10.13it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  56%|█████▋    | 1488/2645 [02:25<01:54, 10.13it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  56%|█████▋    | 1488/2645 [02:25<01:54, 10.13it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 2:  56%|█████▋    | 1490/2645 [02:25<01:53, 10.14it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 2:  56%|█████▋    | 1490/2645 [02:25<01:53, 10.14it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  56%|█████▋    | 1490/2645 [02:25<01:53, 10.14it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  56%|█████▋    | 1492/2645 [02:25<01:54, 10.05it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  56%|█████▋    | 1492/2645 [02:25<01:54, 10.05it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  56%|█████▋    | 1492/2645 [02:26<01:54, 10.05it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  56%|█████▋    | 1494/2645 [02:26<01:54, 10.04it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  56%|█████▋    | 1494/2645 [02:26<01:54, 10.04it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  56%|█████▋    | 1494/2645 [02:26<01:54, 10.04it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  57%|█████▋    | 1496/2645 [02:26<01:54, 10.07it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  57%|█████▋    | 1496/2645 [02:26<01:54, 10.07it/s, training_loss=0.049]\u001b[A\n",
      "Epoch 2:  57%|█████▋    | 1496/2645 [02:26<01:54, 10.07it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  57%|█████▋    | 1498/2645 [02:26<01:53, 10.10it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  57%|█████▋    | 1498/2645 [02:26<01:53, 10.10it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  57%|█████▋    | 1498/2645 [02:26<01:53, 10.10it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  57%|█████▋    | 1500/2645 [02:26<01:53, 10.10it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  57%|█████▋    | 1500/2645 [02:26<01:53, 10.10it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  57%|█████▋    | 1500/2645 [02:26<01:53, 10.10it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  57%|█████▋    | 1502/2645 [02:26<01:54,  9.97it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  57%|█████▋    | 1502/2645 [02:26<01:54,  9.97it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 2:  57%|█████▋    | 1503/2645 [02:26<01:54,  9.94it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 2:  57%|█████▋    | 1503/2645 [02:27<01:54,  9.94it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  57%|█████▋    | 1503/2645 [02:27<01:54,  9.94it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  57%|█████▋    | 1505/2645 [02:27<01:53, 10.01it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  57%|█████▋    | 1505/2645 [02:27<01:53, 10.01it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  57%|█████▋    | 1505/2645 [02:27<01:53, 10.01it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  57%|█████▋    | 1507/2645 [02:27<01:53, 10.04it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  57%|█████▋    | 1507/2645 [02:27<01:53, 10.04it/s, training_loss=0.810]\u001b[A\n",
      "Epoch 2:  57%|█████▋    | 1507/2645 [02:27<01:53, 10.04it/s, training_loss=0.591]\u001b[A\n",
      "Epoch 2:  57%|█████▋    | 1509/2645 [02:27<01:53, 10.04it/s, training_loss=0.591]\u001b[A\n",
      "Epoch 2:  57%|█████▋    | 1509/2645 [02:27<01:53, 10.04it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  57%|█████▋    | 1509/2645 [02:27<01:53, 10.04it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 2:  57%|█████▋    | 1511/2645 [02:27<01:52, 10.11it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 2:  57%|█████▋    | 1511/2645 [02:27<01:52, 10.11it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  57%|█████▋    | 1511/2645 [02:27<01:52, 10.11it/s, training_loss=0.471]\u001b[A\n",
      "Epoch 2:  57%|█████▋    | 1513/2645 [02:27<01:52, 10.09it/s, training_loss=0.471]\u001b[A\n",
      "Epoch 2:  57%|█████▋    | 1513/2645 [02:28<01:52, 10.09it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  57%|█████▋    | 1513/2645 [02:28<01:52, 10.09it/s, training_loss=0.036]\u001b[A\n",
      "Epoch 2:  57%|█████▋    | 1515/2645 [02:28<01:51, 10.15it/s, training_loss=0.036]\u001b[A\n",
      "Epoch 2:  57%|█████▋    | 1515/2645 [02:28<01:51, 10.15it/s, training_loss=0.348]\u001b[A\n",
      "Epoch 2:  57%|█████▋    | 1515/2645 [02:28<01:51, 10.15it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  57%|█████▋    | 1517/2645 [02:28<01:50, 10.23it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  57%|█████▋    | 1517/2645 [02:28<01:50, 10.23it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  57%|█████▋    | 1517/2645 [02:28<01:50, 10.23it/s, training_loss=0.978]\u001b[A\n",
      "Epoch 2:  57%|█████▋    | 1519/2645 [02:28<01:49, 10.28it/s, training_loss=0.978]\u001b[A\n",
      "Epoch 2:  57%|█████▋    | 1519/2645 [02:28<01:49, 10.28it/s, training_loss=1.000]\u001b[A\n",
      "Epoch 2:  57%|█████▋    | 1519/2645 [02:28<01:49, 10.28it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  58%|█████▊    | 1521/2645 [02:28<01:48, 10.33it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  58%|█████▊    | 1521/2645 [02:28<01:48, 10.33it/s, training_loss=0.081]\u001b[A\n",
      "Epoch 2:  58%|█████▊    | 1521/2645 [02:28<01:48, 10.33it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  58%|█████▊    | 1523/2645 [02:28<01:49, 10.28it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  58%|█████▊    | 1523/2645 [02:28<01:49, 10.28it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  58%|█████▊    | 1523/2645 [02:29<01:49, 10.28it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  58%|█████▊    | 1525/2645 [02:29<01:49, 10.27it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  58%|█████▊    | 1525/2645 [02:29<01:49, 10.27it/s, training_loss=0.010]\u001b[A\n",
      "Epoch 2:  58%|█████▊    | 1525/2645 [02:29<01:49, 10.27it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  58%|█████▊    | 1527/2645 [02:29<01:48, 10.30it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  58%|█████▊    | 1527/2645 [02:29<01:48, 10.30it/s, training_loss=0.716]\u001b[A\n",
      "Epoch 2:  58%|█████▊    | 1527/2645 [02:29<01:48, 10.30it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  58%|█████▊    | 1529/2645 [02:29<01:48, 10.33it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  58%|█████▊    | 1529/2645 [02:29<01:48, 10.33it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  58%|█████▊    | 1529/2645 [02:29<01:48, 10.33it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  58%|█████▊    | 1531/2645 [02:29<01:47, 10.40it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  58%|█████▊    | 1531/2645 [02:29<01:47, 10.40it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  58%|█████▊    | 1531/2645 [02:29<01:47, 10.40it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  58%|█████▊    | 1533/2645 [02:29<01:46, 10.45it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  58%|█████▊    | 1533/2645 [02:29<01:46, 10.45it/s, training_loss=0.017]\u001b[A\n",
      "Epoch 2:  58%|█████▊    | 1533/2645 [02:30<01:46, 10.45it/s, training_loss=0.707]\u001b[A\n",
      "Epoch 2:  58%|█████▊    | 1535/2645 [02:30<01:47, 10.29it/s, training_loss=0.707]\u001b[A\n",
      "Epoch 2:  58%|█████▊    | 1535/2645 [02:30<01:47, 10.29it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  58%|█████▊    | 1535/2645 [02:30<01:47, 10.29it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  58%|█████▊    | 1537/2645 [02:30<01:48, 10.20it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  58%|█████▊    | 1537/2645 [02:30<01:48, 10.20it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  58%|█████▊    | 1537/2645 [02:30<01:48, 10.20it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  58%|█████▊    | 1539/2645 [02:30<01:49, 10.07it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  58%|█████▊    | 1539/2645 [02:30<01:49, 10.07it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  58%|█████▊    | 1539/2645 [02:30<01:49, 10.07it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  58%|█████▊    | 1541/2645 [02:30<01:47, 10.23it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  58%|█████▊    | 1541/2645 [02:30<01:47, 10.23it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  58%|█████▊    | 1541/2645 [02:30<01:47, 10.23it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  58%|█████▊    | 1543/2645 [02:30<01:46, 10.30it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  58%|█████▊    | 1543/2645 [02:30<01:46, 10.30it/s, training_loss=0.023]\u001b[A\n",
      "Epoch 2:  58%|█████▊    | 1543/2645 [02:31<01:46, 10.30it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  58%|█████▊    | 1545/2645 [02:31<01:46, 10.31it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  58%|█████▊    | 1545/2645 [02:31<01:46, 10.31it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  58%|█████▊    | 1545/2645 [02:31<01:46, 10.31it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  58%|█████▊    | 1547/2645 [02:31<01:47, 10.24it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  58%|█████▊    | 1547/2645 [02:31<01:47, 10.24it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  58%|█████▊    | 1547/2645 [02:31<01:47, 10.24it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  59%|█████▊    | 1549/2645 [02:31<01:46, 10.25it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  59%|█████▊    | 1549/2645 [02:31<01:46, 10.25it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  59%|█████▊    | 1549/2645 [02:31<01:46, 10.25it/s, training_loss=0.013]\u001b[A\n",
      "Epoch 2:  59%|█████▊    | 1551/2645 [02:31<01:46, 10.28it/s, training_loss=0.013]\u001b[A\n",
      "Epoch 2:  59%|█████▊    | 1551/2645 [02:31<01:46, 10.28it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  59%|█████▊    | 1551/2645 [02:31<01:46, 10.28it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  59%|█████▊    | 1553/2645 [02:31<01:45, 10.34it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  59%|█████▊    | 1553/2645 [02:31<01:45, 10.34it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  59%|█████▊    | 1553/2645 [02:31<01:45, 10.34it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  59%|█████▉    | 1555/2645 [02:32<01:45, 10.37it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  59%|█████▉    | 1555/2645 [02:32<01:45, 10.37it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  59%|█████▉    | 1555/2645 [02:32<01:45, 10.37it/s, training_loss=0.076]\u001b[A\n",
      "Epoch 2:  59%|█████▉    | 1557/2645 [02:32<01:45, 10.30it/s, training_loss=0.076]\u001b[A\n",
      "Epoch 2:  59%|█████▉    | 1557/2645 [02:32<01:45, 10.30it/s, training_loss=0.825]\u001b[A\n",
      "Epoch 2:  59%|█████▉    | 1557/2645 [02:32<01:45, 10.30it/s, training_loss=0.668]\u001b[A\n",
      "Epoch 2:  59%|█████▉    | 1559/2645 [02:32<01:47, 10.14it/s, training_loss=0.668]\u001b[A\n",
      "Epoch 2:  59%|█████▉    | 1559/2645 [02:32<01:47, 10.14it/s, training_loss=0.388]\u001b[A\n",
      "Epoch 2:  59%|█████▉    | 1559/2645 [02:32<01:47, 10.14it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  59%|█████▉    | 1561/2645 [02:32<01:47, 10.12it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  59%|█████▉    | 1561/2645 [02:32<01:47, 10.12it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  59%|█████▉    | 1561/2645 [02:32<01:47, 10.12it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  59%|█████▉    | 1563/2645 [02:32<01:47, 10.05it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  59%|█████▉    | 1563/2645 [02:32<01:47, 10.05it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  59%|█████▉    | 1563/2645 [02:32<01:47, 10.05it/s, training_loss=0.444]\u001b[A\n",
      "Epoch 2:  59%|█████▉    | 1565/2645 [02:33<01:47, 10.08it/s, training_loss=0.444]\u001b[A\n",
      "Epoch 2:  59%|█████▉    | 1565/2645 [02:33<01:47, 10.08it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  59%|█████▉    | 1565/2645 [02:33<01:47, 10.08it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  59%|█████▉    | 1567/2645 [02:33<01:46, 10.09it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  59%|█████▉    | 1567/2645 [02:33<01:46, 10.09it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  59%|█████▉    | 1567/2645 [02:33<01:46, 10.09it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  59%|█████▉    | 1569/2645 [02:33<01:46, 10.08it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  59%|█████▉    | 1569/2645 [02:33<01:46, 10.08it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  59%|█████▉    | 1569/2645 [02:33<01:46, 10.08it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  59%|█████▉    | 1571/2645 [02:33<01:46, 10.05it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  59%|█████▉    | 1571/2645 [02:33<01:46, 10.05it/s, training_loss=0.582]\u001b[A\n",
      "Epoch 2:  59%|█████▉    | 1571/2645 [02:33<01:46, 10.05it/s, training_loss=0.293]\u001b[A\n",
      "Epoch 2:  59%|█████▉    | 1573/2645 [02:33<01:47,  9.96it/s, training_loss=0.293]\u001b[A\n",
      "Epoch 2:  59%|█████▉    | 1573/2645 [02:33<01:47,  9.96it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  60%|█████▉    | 1574/2645 [02:33<01:47,  9.96it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  60%|█████▉    | 1574/2645 [02:34<01:47,  9.96it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  60%|█████▉    | 1575/2645 [02:34<01:47,  9.95it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  60%|█████▉    | 1575/2645 [02:34<01:47,  9.95it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  60%|█████▉    | 1575/2645 [02:34<01:47,  9.95it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  60%|█████▉    | 1577/2645 [02:34<01:46, 10.00it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  60%|█████▉    | 1577/2645 [02:34<01:46, 10.00it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  60%|█████▉    | 1577/2645 [02:34<01:46, 10.00it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  60%|█████▉    | 1579/2645 [02:34<01:47,  9.94it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  60%|█████▉    | 1579/2645 [02:34<01:47,  9.94it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 2:  60%|█████▉    | 1580/2645 [02:34<01:47,  9.90it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 2:  60%|█████▉    | 1580/2645 [02:34<01:47,  9.90it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  60%|█████▉    | 1580/2645 [02:34<01:47,  9.90it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  60%|█████▉    | 1582/2645 [02:34<01:47,  9.92it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  60%|█████▉    | 1582/2645 [02:34<01:47,  9.92it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  60%|█████▉    | 1582/2645 [02:34<01:47,  9.92it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  60%|█████▉    | 1584/2645 [02:34<01:46, 10.00it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  60%|█████▉    | 1584/2645 [02:35<01:46, 10.00it/s, training_loss=0.013]\u001b[A\n",
      "Epoch 2:  60%|█████▉    | 1584/2645 [02:35<01:46, 10.00it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  60%|█████▉    | 1586/2645 [02:35<01:45, 10.03it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  60%|█████▉    | 1586/2645 [02:35<01:45, 10.03it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  60%|█████▉    | 1586/2645 [02:35<01:45, 10.03it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  60%|██████    | 1588/2645 [02:35<01:45, 10.04it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  60%|██████    | 1588/2645 [02:35<01:45, 10.04it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  60%|██████    | 1588/2645 [02:35<01:45, 10.04it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  60%|██████    | 1590/2645 [02:35<01:45, 10.00it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  60%|██████    | 1590/2645 [02:35<01:45, 10.00it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  60%|██████    | 1590/2645 [02:35<01:45, 10.00it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  60%|██████    | 1592/2645 [02:35<01:44, 10.06it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  60%|██████    | 1592/2645 [02:35<01:44, 10.06it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  60%|██████    | 1592/2645 [02:35<01:44, 10.06it/s, training_loss=0.197]\u001b[A\n",
      "Epoch 2:  60%|██████    | 1594/2645 [02:35<01:44, 10.06it/s, training_loss=0.197]\u001b[A\n",
      "Epoch 2:  60%|██████    | 1594/2645 [02:35<01:44, 10.06it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  60%|██████    | 1594/2645 [02:36<01:44, 10.06it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  60%|██████    | 1596/2645 [02:36<01:44, 10.04it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  60%|██████    | 1596/2645 [02:36<01:44, 10.04it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  60%|██████    | 1596/2645 [02:36<01:44, 10.04it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  60%|██████    | 1598/2645 [02:36<01:43, 10.08it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  60%|██████    | 1598/2645 [02:36<01:43, 10.08it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  60%|██████    | 1598/2645 [02:36<01:43, 10.08it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  60%|██████    | 1600/2645 [02:36<01:44,  9.98it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  60%|██████    | 1600/2645 [02:36<01:44,  9.98it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  60%|██████    | 1600/2645 [02:36<01:44,  9.98it/s, training_loss=0.379]\u001b[A\n",
      "Epoch 2:  61%|██████    | 1602/2645 [02:36<01:44,  9.99it/s, training_loss=0.379]\u001b[A\n",
      "Epoch 2:  61%|██████    | 1602/2645 [02:36<01:44,  9.99it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  61%|██████    | 1603/2645 [02:36<01:45,  9.83it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  61%|██████    | 1603/2645 [02:36<01:45,  9.83it/s, training_loss=0.241]\u001b[A\n",
      "Epoch 2:  61%|██████    | 1604/2645 [02:36<01:45,  9.86it/s, training_loss=0.241]\u001b[A\n",
      "Epoch 2:  61%|██████    | 1604/2645 [02:37<01:45,  9.86it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  61%|██████    | 1604/2645 [02:37<01:45,  9.86it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  61%|██████    | 1606/2645 [02:37<01:44,  9.93it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  61%|██████    | 1606/2645 [02:37<01:44,  9.93it/s, training_loss=0.207]\u001b[A\n",
      "Epoch 2:  61%|██████    | 1607/2645 [02:37<01:45,  9.88it/s, training_loss=0.207]\u001b[A\n",
      "Epoch 2:  61%|██████    | 1607/2645 [02:37<01:45,  9.88it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  61%|██████    | 1607/2645 [02:37<01:45,  9.88it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  61%|██████    | 1609/2645 [02:37<01:43,  9.98it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  61%|██████    | 1609/2645 [02:37<01:43,  9.98it/s, training_loss=0.432]\u001b[A\n",
      "Epoch 2:  61%|██████    | 1610/2645 [02:37<01:44,  9.92it/s, training_loss=0.432]\u001b[A\n",
      "Epoch 2:  61%|██████    | 1610/2645 [02:37<01:44,  9.92it/s, training_loss=0.662]\u001b[A\n",
      "Epoch 2:  61%|██████    | 1611/2645 [02:37<01:45,  9.79it/s, training_loss=0.662]\u001b[A\n",
      "Epoch 2:  61%|██████    | 1611/2645 [02:37<01:45,  9.79it/s, training_loss=0.584]\u001b[A\n",
      "Epoch 2:  61%|██████    | 1612/2645 [02:37<01:45,  9.83it/s, training_loss=0.584]\u001b[A\n",
      "Epoch 2:  61%|██████    | 1612/2645 [02:37<01:45,  9.83it/s, training_loss=1.789]\u001b[A\n",
      "Epoch 2:  61%|██████    | 1613/2645 [02:37<01:44,  9.85it/s, training_loss=1.789]\u001b[A\n",
      "Epoch 2:  61%|██████    | 1613/2645 [02:37<01:44,  9.85it/s, training_loss=0.167]\u001b[A\n",
      "Epoch 2:  61%|██████    | 1614/2645 [02:37<01:44,  9.88it/s, training_loss=0.167]\u001b[A\n",
      "Epoch 2:  61%|██████    | 1614/2645 [02:38<01:44,  9.88it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  61%|██████    | 1614/2645 [02:38<01:44,  9.88it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  61%|██████    | 1616/2645 [02:38<01:43,  9.96it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  61%|██████    | 1616/2645 [02:38<01:43,  9.96it/s, training_loss=0.285]\u001b[A\n",
      "Epoch 2:  61%|██████    | 1617/2645 [02:38<01:44,  9.80it/s, training_loss=0.285]\u001b[A\n",
      "Epoch 2:  61%|██████    | 1617/2645 [02:38<01:44,  9.80it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  61%|██████    | 1618/2645 [02:38<01:44,  9.83it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  61%|██████    | 1618/2645 [02:38<01:44,  9.83it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  61%|██████    | 1618/2645 [02:38<01:44,  9.83it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  61%|██████    | 1620/2645 [02:38<01:43,  9.92it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  61%|██████    | 1620/2645 [02:38<01:43,  9.92it/s, training_loss=0.595]\u001b[A\n",
      "Epoch 2:  61%|██████▏   | 1621/2645 [02:38<01:44,  9.84it/s, training_loss=0.595]\u001b[A\n",
      "Epoch 2:  61%|██████▏   | 1621/2645 [02:38<01:44,  9.84it/s, training_loss=0.620]\u001b[A\n",
      "Epoch 2:  61%|██████▏   | 1622/2645 [02:38<01:43,  9.88it/s, training_loss=0.620]\u001b[A\n",
      "Epoch 2:  61%|██████▏   | 1622/2645 [02:38<01:43,  9.88it/s, training_loss=0.147]\u001b[A\n",
      "Epoch 2:  61%|██████▏   | 1623/2645 [02:38<01:43,  9.90it/s, training_loss=0.147]\u001b[A\n",
      "Epoch 2:  61%|██████▏   | 1623/2645 [02:38<01:43,  9.90it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  61%|██████▏   | 1623/2645 [02:39<01:43,  9.90it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  61%|██████▏   | 1625/2645 [02:39<01:42,  9.96it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  61%|██████▏   | 1625/2645 [02:39<01:42,  9.96it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  61%|██████▏   | 1626/2645 [02:39<01:42,  9.90it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  61%|██████▏   | 1626/2645 [02:39<01:42,  9.90it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  61%|██████▏   | 1626/2645 [02:39<01:42,  9.90it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  62%|██████▏   | 1628/2645 [02:39<01:41,  9.99it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  62%|██████▏   | 1628/2645 [02:39<01:41,  9.99it/s, training_loss=0.828]\u001b[A\n",
      "Epoch 2:  62%|██████▏   | 1629/2645 [02:39<01:42,  9.94it/s, training_loss=0.828]\u001b[A\n",
      "Epoch 2:  62%|██████▏   | 1629/2645 [02:39<01:42,  9.94it/s, training_loss=0.196]\u001b[A\n",
      "Epoch 2:  62%|██████▏   | 1630/2645 [02:39<01:43,  9.83it/s, training_loss=0.196]\u001b[A\n",
      "Epoch 2:  62%|██████▏   | 1630/2645 [02:39<01:43,  9.83it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  62%|██████▏   | 1630/2645 [02:39<01:43,  9.83it/s, training_loss=0.030]\u001b[A\n",
      "Epoch 2:  62%|██████▏   | 1632/2645 [02:39<01:42,  9.88it/s, training_loss=0.030]\u001b[A\n",
      "Epoch 2:  62%|██████▏   | 1632/2645 [02:39<01:42,  9.88it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  62%|██████▏   | 1633/2645 [02:39<01:43,  9.82it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  62%|██████▏   | 1633/2645 [02:39<01:43,  9.82it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  62%|██████▏   | 1633/2645 [02:40<01:43,  9.82it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  62%|██████▏   | 1635/2645 [02:40<01:42,  9.90it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  62%|██████▏   | 1635/2645 [02:40<01:42,  9.90it/s, training_loss=0.013]\u001b[A\n",
      "Epoch 2:  62%|██████▏   | 1636/2645 [02:40<01:43,  9.77it/s, training_loss=0.013]\u001b[A\n",
      "Epoch 2:  62%|██████▏   | 1636/2645 [02:40<01:43,  9.77it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  62%|██████▏   | 1636/2645 [02:40<01:43,  9.77it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  62%|██████▏   | 1638/2645 [02:40<01:42,  9.82it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  62%|██████▏   | 1638/2645 [02:40<01:42,  9.82it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  62%|██████▏   | 1638/2645 [02:40<01:42,  9.82it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  62%|██████▏   | 1640/2645 [02:40<01:41,  9.89it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  62%|██████▏   | 1640/2645 [02:40<01:41,  9.89it/s, training_loss=0.981]\u001b[A\n",
      "Epoch 2:  62%|██████▏   | 1641/2645 [02:40<01:42,  9.79it/s, training_loss=0.981]\u001b[A\n",
      "Epoch 2:  62%|██████▏   | 1641/2645 [02:40<01:42,  9.79it/s, training_loss=0.314]\u001b[A\n",
      "Epoch 2:  62%|██████▏   | 1642/2645 [02:40<01:42,  9.81it/s, training_loss=0.314]\u001b[A\n",
      "Epoch 2:  62%|██████▏   | 1642/2645 [02:40<01:42,  9.81it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  62%|██████▏   | 1642/2645 [02:40<01:42,  9.81it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 2:  62%|██████▏   | 1644/2645 [02:40<01:41,  9.87it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 2:  62%|██████▏   | 1644/2645 [02:41<01:41,  9.87it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  62%|██████▏   | 1644/2645 [02:41<01:41,  9.87it/s, training_loss=0.775]\u001b[A\n",
      "Epoch 2:  62%|██████▏   | 1646/2645 [02:41<01:40,  9.89it/s, training_loss=0.775]\u001b[A\n",
      "Epoch 2:  62%|██████▏   | 1646/2645 [02:41<01:40,  9.89it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  62%|██████▏   | 1646/2645 [02:41<01:40,  9.89it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  62%|██████▏   | 1648/2645 [02:41<01:39,  9.98it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  62%|██████▏   | 1648/2645 [02:41<01:39,  9.98it/s, training_loss=0.017]\u001b[A\n",
      "Epoch 2:  62%|██████▏   | 1648/2645 [02:41<01:39,  9.98it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  62%|██████▏   | 1650/2645 [02:41<01:38, 10.07it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  62%|██████▏   | 1650/2645 [02:41<01:38, 10.07it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  62%|██████▏   | 1650/2645 [02:41<01:38, 10.07it/s, training_loss=0.411]\u001b[A\n",
      "Epoch 2:  62%|██████▏   | 1652/2645 [02:41<01:39,  9.97it/s, training_loss=0.411]\u001b[A\n",
      "Epoch 2:  62%|██████▏   | 1652/2645 [02:41<01:39,  9.97it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  62%|██████▏   | 1652/2645 [02:41<01:39,  9.97it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  63%|██████▎   | 1654/2645 [02:41<01:39,  9.99it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  63%|██████▎   | 1654/2645 [02:42<01:39,  9.99it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  63%|██████▎   | 1654/2645 [02:42<01:39,  9.99it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  63%|██████▎   | 1656/2645 [02:42<01:38, 10.01it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  63%|██████▎   | 1656/2645 [02:42<01:38, 10.01it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  63%|██████▎   | 1656/2645 [02:42<01:38, 10.01it/s, training_loss=0.205]\u001b[A\n",
      "Epoch 2:  63%|██████▎   | 1658/2645 [02:42<01:39,  9.88it/s, training_loss=0.205]\u001b[A\n",
      "Epoch 2:  63%|██████▎   | 1658/2645 [02:42<01:39,  9.88it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  63%|██████▎   | 1658/2645 [02:42<01:39,  9.88it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  63%|██████▎   | 1660/2645 [02:42<01:38, 10.00it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  63%|██████▎   | 1660/2645 [02:42<01:38, 10.00it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  63%|██████▎   | 1660/2645 [02:42<01:38, 10.00it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  63%|██████▎   | 1662/2645 [02:42<01:38,  9.96it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  63%|██████▎   | 1662/2645 [02:42<01:38,  9.96it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  63%|██████▎   | 1663/2645 [02:42<01:40,  9.79it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  63%|██████▎   | 1663/2645 [02:42<01:40,  9.79it/s, training_loss=0.282]\u001b[A\n",
      "Epoch 2:  63%|██████▎   | 1664/2645 [02:42<01:40,  9.77it/s, training_loss=0.282]\u001b[A\n",
      "Epoch 2:  63%|██████▎   | 1664/2645 [02:43<01:40,  9.77it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  63%|██████▎   | 1665/2645 [02:43<01:40,  9.77it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  63%|██████▎   | 1665/2645 [02:43<01:40,  9.77it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  63%|██████▎   | 1666/2645 [02:43<01:40,  9.74it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  63%|██████▎   | 1666/2645 [02:43<01:40,  9.74it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  63%|██████▎   | 1666/2645 [02:43<01:40,  9.74it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  63%|██████▎   | 1668/2645 [02:43<01:38,  9.87it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  63%|██████▎   | 1668/2645 [02:43<01:38,  9.87it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  63%|██████▎   | 1669/2645 [02:43<01:38,  9.91it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  63%|██████▎   | 1669/2645 [02:43<01:38,  9.91it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  63%|██████▎   | 1669/2645 [02:43<01:38,  9.91it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  63%|██████▎   | 1671/2645 [02:43<01:37,  9.97it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  63%|██████▎   | 1671/2645 [02:43<01:37,  9.97it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  63%|██████▎   | 1671/2645 [02:43<01:37,  9.97it/s, training_loss=0.563]\u001b[A\n",
      "Epoch 2:  63%|██████▎   | 1673/2645 [02:43<01:36, 10.05it/s, training_loss=0.563]\u001b[A\n",
      "Epoch 2:  63%|██████▎   | 1673/2645 [02:43<01:36, 10.05it/s, training_loss=0.010]\u001b[A\n",
      "Epoch 2:  63%|██████▎   | 1673/2645 [02:44<01:36, 10.05it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  63%|██████▎   | 1675/2645 [02:44<01:36, 10.09it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  63%|██████▎   | 1675/2645 [02:44<01:36, 10.09it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  63%|██████▎   | 1675/2645 [02:44<01:36, 10.09it/s, training_loss=0.054]\u001b[A\n",
      "Epoch 2:  63%|██████▎   | 1677/2645 [02:44<01:36,  9.99it/s, training_loss=0.054]\u001b[A\n",
      "Epoch 2:  63%|██████▎   | 1677/2645 [02:44<01:36,  9.99it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  63%|██████▎   | 1677/2645 [02:44<01:36,  9.99it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  63%|██████▎   | 1679/2645 [02:44<01:36, 10.00it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  63%|██████▎   | 1679/2645 [02:44<01:36, 10.00it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  63%|██████▎   | 1679/2645 [02:44<01:36, 10.00it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  64%|██████▎   | 1681/2645 [02:44<01:35, 10.09it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  64%|██████▎   | 1681/2645 [02:44<01:35, 10.09it/s, training_loss=0.244]\u001b[A\n",
      "Epoch 2:  64%|██████▎   | 1681/2645 [02:44<01:35, 10.09it/s, training_loss=0.769]\u001b[A\n",
      "Epoch 2:  64%|██████▎   | 1683/2645 [02:44<01:35, 10.05it/s, training_loss=0.769]\u001b[A\n",
      "Epoch 2:  64%|██████▎   | 1683/2645 [02:44<01:35, 10.05it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  64%|██████▎   | 1683/2645 [02:45<01:35, 10.05it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  64%|██████▎   | 1685/2645 [02:45<01:35, 10.09it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  64%|██████▎   | 1685/2645 [02:45<01:35, 10.09it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  64%|██████▎   | 1685/2645 [02:45<01:35, 10.09it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  64%|██████▍   | 1687/2645 [02:45<01:34, 10.15it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  64%|██████▍   | 1687/2645 [02:45<01:34, 10.15it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 2:  64%|██████▍   | 1687/2645 [02:45<01:34, 10.15it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  64%|██████▍   | 1689/2645 [02:45<01:34, 10.07it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  64%|██████▍   | 1689/2645 [02:45<01:34, 10.07it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  64%|██████▍   | 1689/2645 [02:45<01:34, 10.07it/s, training_loss=0.245]\u001b[A\n",
      "Epoch 2:  64%|██████▍   | 1691/2645 [02:45<01:34, 10.09it/s, training_loss=0.245]\u001b[A\n",
      "Epoch 2:  64%|██████▍   | 1691/2645 [02:45<01:34, 10.09it/s, training_loss=1.029]\u001b[A\n",
      "Epoch 2:  64%|██████▍   | 1691/2645 [02:45<01:34, 10.09it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  64%|██████▍   | 1693/2645 [02:45<01:34, 10.11it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  64%|██████▍   | 1693/2645 [02:45<01:34, 10.11it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  64%|██████▍   | 1693/2645 [02:46<01:34, 10.11it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  64%|██████▍   | 1695/2645 [02:46<01:33, 10.15it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  64%|██████▍   | 1695/2645 [02:46<01:33, 10.15it/s, training_loss=0.123]\u001b[A\n",
      "Epoch 2:  64%|██████▍   | 1695/2645 [02:46<01:33, 10.15it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  64%|██████▍   | 1697/2645 [02:46<01:33, 10.09it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  64%|██████▍   | 1697/2645 [02:46<01:33, 10.09it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 2:  64%|██████▍   | 1697/2645 [02:46<01:33, 10.09it/s, training_loss=0.030]\u001b[A\n",
      "Epoch 2:  64%|██████▍   | 1699/2645 [02:46<01:33, 10.08it/s, training_loss=0.030]\u001b[A\n",
      "Epoch 2:  64%|██████▍   | 1699/2645 [02:46<01:33, 10.08it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  64%|██████▍   | 1699/2645 [02:46<01:33, 10.08it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  64%|██████▍   | 1701/2645 [02:46<01:33, 10.10it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  64%|██████▍   | 1701/2645 [02:46<01:33, 10.10it/s, training_loss=0.325]\u001b[A\n",
      "Epoch 2:  64%|██████▍   | 1701/2645 [02:46<01:33, 10.10it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  64%|██████▍   | 1703/2645 [02:46<01:34,  9.98it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  64%|██████▍   | 1703/2645 [02:46<01:34,  9.98it/s, training_loss=0.573]\u001b[A\n",
      "Epoch 2:  64%|██████▍   | 1704/2645 [02:46<01:34,  9.97it/s, training_loss=0.573]\u001b[A\n",
      "Epoch 2:  64%|██████▍   | 1704/2645 [02:47<01:34,  9.97it/s, training_loss=0.726]\u001b[A\n",
      "Epoch 2:  64%|██████▍   | 1705/2645 [02:47<01:34,  9.98it/s, training_loss=0.726]\u001b[A\n",
      "Epoch 2:  64%|██████▍   | 1705/2645 [02:47<01:34,  9.98it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  64%|██████▍   | 1705/2645 [02:47<01:34,  9.98it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  65%|██████▍   | 1707/2645 [02:47<01:35,  9.78it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  65%|██████▍   | 1707/2645 [02:47<01:35,  9.78it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  65%|██████▍   | 1707/2645 [02:47<01:35,  9.78it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  65%|██████▍   | 1709/2645 [02:47<01:37,  9.60it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  65%|██████▍   | 1709/2645 [02:47<01:37,  9.60it/s, training_loss=0.685]\u001b[A\n",
      "Epoch 2:  65%|██████▍   | 1710/2645 [02:47<01:38,  9.47it/s, training_loss=0.685]\u001b[A\n",
      "Epoch 2:  65%|██████▍   | 1710/2645 [02:47<01:38,  9.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  65%|██████▍   | 1711/2645 [02:47<01:39,  9.38it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  65%|██████▍   | 1711/2645 [02:47<01:39,  9.38it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  65%|██████▍   | 1712/2645 [02:47<01:38,  9.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  65%|██████▍   | 1712/2645 [02:47<01:38,  9.45it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  65%|██████▍   | 1713/2645 [02:47<01:38,  9.45it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  65%|██████▍   | 1713/2645 [02:47<01:38,  9.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  65%|██████▍   | 1714/2645 [02:47<01:38,  9.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  65%|██████▍   | 1714/2645 [02:48<01:38,  9.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  65%|██████▍   | 1715/2645 [02:48<01:38,  9.41it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  65%|██████▍   | 1715/2645 [02:48<01:38,  9.41it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  65%|██████▍   | 1716/2645 [02:48<01:39,  9.31it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  65%|██████▍   | 1716/2645 [02:48<01:39,  9.31it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  65%|██████▍   | 1717/2645 [02:48<01:40,  9.19it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  65%|██████▍   | 1717/2645 [02:48<01:40,  9.19it/s, training_loss=0.038]\u001b[A\n",
      "Epoch 2:  65%|██████▍   | 1718/2645 [02:48<01:41,  9.12it/s, training_loss=0.038]\u001b[A\n",
      "Epoch 2:  65%|██████▍   | 1718/2645 [02:48<01:41,  9.12it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  65%|██████▍   | 1719/2645 [02:48<01:42,  9.06it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  65%|██████▍   | 1719/2645 [02:48<01:42,  9.06it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  65%|██████▌   | 1720/2645 [02:48<01:41,  9.09it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  65%|██████▌   | 1720/2645 [02:48<01:41,  9.09it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 2:  65%|██████▌   | 1721/2645 [02:48<01:42,  9.02it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 2:  65%|██████▌   | 1721/2645 [02:48<01:42,  9.02it/s, training_loss=0.846]\u001b[A\n",
      "Epoch 2:  65%|██████▌   | 1722/2645 [02:48<01:42,  9.03it/s, training_loss=0.846]\u001b[A\n",
      "Epoch 2:  65%|██████▌   | 1722/2645 [02:48<01:42,  9.03it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  65%|██████▌   | 1723/2645 [02:48<01:42,  9.01it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  65%|██████▌   | 1723/2645 [02:49<01:42,  9.01it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  65%|██████▌   | 1724/2645 [02:49<01:43,  8.92it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  65%|██████▌   | 1724/2645 [02:49<01:43,  8.92it/s, training_loss=0.085]\u001b[A\n",
      "Epoch 2:  65%|██████▌   | 1724/2645 [02:49<01:43,  8.92it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  65%|██████▌   | 1726/2645 [02:49<01:40,  9.17it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  65%|██████▌   | 1726/2645 [02:49<01:40,  9.17it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  65%|██████▌   | 1727/2645 [02:49<01:38,  9.31it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  65%|██████▌   | 1727/2645 [02:49<01:38,  9.31it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  65%|██████▌   | 1728/2645 [02:49<01:37,  9.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  65%|██████▌   | 1728/2645 [02:49<01:37,  9.43it/s, training_loss=0.012]\u001b[A\n",
      "Epoch 2:  65%|██████▌   | 1729/2645 [02:49<01:35,  9.56it/s, training_loss=0.012]\u001b[A\n",
      "Epoch 2:  65%|██████▌   | 1729/2645 [02:49<01:35,  9.56it/s, training_loss=0.779]\u001b[A\n",
      "Epoch 2:  65%|██████▌   | 1730/2645 [02:49<01:34,  9.66it/s, training_loss=0.779]\u001b[A\n",
      "Epoch 2:  65%|██████▌   | 1730/2645 [02:49<01:34,  9.66it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  65%|██████▌   | 1731/2645 [02:49<01:33,  9.73it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  65%|██████▌   | 1731/2645 [02:49<01:33,  9.73it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  65%|██████▌   | 1731/2645 [02:50<01:33,  9.73it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  66%|██████▌   | 1733/2645 [02:50<01:32,  9.84it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  66%|██████▌   | 1733/2645 [02:50<01:32,  9.84it/s, training_loss=0.700]\u001b[A\n",
      "Epoch 2:  66%|██████▌   | 1734/2645 [02:50<01:33,  9.73it/s, training_loss=0.700]\u001b[A\n",
      "Epoch 2:  66%|██████▌   | 1734/2645 [02:50<01:33,  9.73it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  66%|██████▌   | 1734/2645 [02:50<01:33,  9.73it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  66%|██████▌   | 1736/2645 [02:50<01:32,  9.81it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  66%|██████▌   | 1736/2645 [02:50<01:32,  9.81it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  66%|██████▌   | 1737/2645 [02:50<01:35,  9.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  66%|██████▌   | 1737/2645 [02:50<01:35,  9.50it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  66%|██████▌   | 1738/2645 [02:50<01:34,  9.64it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  66%|██████▌   | 1738/2645 [02:50<01:34,  9.64it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  66%|██████▌   | 1738/2645 [02:50<01:34,  9.64it/s, training_loss=0.898]\u001b[A\n",
      "Epoch 2:  66%|██████▌   | 1740/2645 [02:50<01:32,  9.74it/s, training_loss=0.898]\u001b[A\n",
      "Epoch 2:  66%|██████▌   | 1740/2645 [02:50<01:32,  9.74it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  66%|██████▌   | 1740/2645 [02:50<01:32,  9.74it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  66%|██████▌   | 1742/2645 [02:50<01:31,  9.88it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  66%|██████▌   | 1742/2645 [02:51<01:31,  9.88it/s, training_loss=0.474]\u001b[A\n",
      "Epoch 2:  66%|██████▌   | 1743/2645 [02:51<01:31,  9.86it/s, training_loss=0.474]\u001b[A\n",
      "Epoch 2:  66%|██████▌   | 1743/2645 [02:51<01:31,  9.86it/s, training_loss=0.151]\u001b[A\n",
      "Epoch 2:  66%|██████▌   | 1743/2645 [02:51<01:31,  9.86it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  66%|██████▌   | 1745/2645 [02:51<01:30,  9.99it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  66%|██████▌   | 1745/2645 [02:51<01:30,  9.99it/s, training_loss=0.161]\u001b[A\n",
      "Epoch 2:  66%|██████▌   | 1745/2645 [02:51<01:30,  9.99it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  66%|██████▌   | 1747/2645 [02:51<01:31,  9.81it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  66%|██████▌   | 1747/2645 [02:51<01:31,  9.81it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  66%|██████▌   | 1748/2645 [02:51<01:34,  9.46it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  66%|██████▌   | 1748/2645 [02:51<01:34,  9.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  66%|██████▌   | 1748/2645 [02:51<01:34,  9.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  66%|██████▌   | 1750/2645 [02:51<01:32,  9.65it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  66%|██████▌   | 1750/2645 [02:51<01:32,  9.65it/s, training_loss=0.654]\u001b[A\n",
      "Epoch 2:  66%|██████▌   | 1751/2645 [02:51<01:32,  9.68it/s, training_loss=0.654]\u001b[A\n",
      "Epoch 2:  66%|██████▌   | 1751/2645 [02:51<01:32,  9.68it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  66%|██████▌   | 1751/2645 [02:52<01:32,  9.68it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 2:  66%|██████▋   | 1753/2645 [02:52<01:31,  9.76it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 2:  66%|██████▋   | 1753/2645 [02:52<01:31,  9.76it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  66%|██████▋   | 1754/2645 [02:52<01:30,  9.80it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  66%|██████▋   | 1754/2645 [02:52<01:30,  9.80it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  66%|██████▋   | 1755/2645 [02:52<01:30,  9.83it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  66%|██████▋   | 1755/2645 [02:52<01:30,  9.83it/s, training_loss=0.932]\u001b[A\n",
      "Epoch 2:  66%|██████▋   | 1756/2645 [02:52<01:30,  9.86it/s, training_loss=0.932]\u001b[A\n",
      "Epoch 2:  66%|██████▋   | 1756/2645 [02:52<01:30,  9.86it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  66%|██████▋   | 1757/2645 [02:52<01:29,  9.88it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  66%|██████▋   | 1757/2645 [02:52<01:29,  9.88it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  66%|██████▋   | 1758/2645 [02:52<01:32,  9.59it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  66%|██████▋   | 1758/2645 [02:52<01:32,  9.59it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  66%|██████▋   | 1758/2645 [02:52<01:32,  9.59it/s, training_loss=0.826]\u001b[A\n",
      "Epoch 2:  67%|██████▋   | 1760/2645 [02:52<01:31,  9.69it/s, training_loss=0.826]\u001b[A\n",
      "Epoch 2:  67%|██████▋   | 1760/2645 [02:52<01:31,  9.69it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  67%|██████▋   | 1761/2645 [02:52<01:30,  9.78it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  67%|██████▋   | 1761/2645 [02:52<01:30,  9.78it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  67%|██████▋   | 1761/2645 [02:53<01:30,  9.78it/s, training_loss=0.505]\u001b[A\n",
      "Epoch 2:  67%|██████▋   | 1763/2645 [02:53<01:29,  9.88it/s, training_loss=0.505]\u001b[A\n",
      "Epoch 2:  67%|██████▋   | 1763/2645 [02:53<01:29,  9.88it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  67%|██████▋   | 1763/2645 [02:53<01:29,  9.88it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  67%|██████▋   | 1765/2645 [02:53<01:27, 10.03it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  67%|██████▋   | 1765/2645 [02:53<01:27, 10.03it/s, training_loss=0.016]\u001b[A\n",
      "Epoch 2:  67%|██████▋   | 1765/2645 [02:53<01:27, 10.03it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  67%|██████▋   | 1767/2645 [02:53<01:27, 10.07it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  67%|██████▋   | 1767/2645 [02:53<01:27, 10.07it/s, training_loss=0.036]\u001b[A\n",
      "Epoch 2:  67%|██████▋   | 1767/2645 [02:53<01:27, 10.07it/s, training_loss=0.198]\u001b[A\n",
      "Epoch 2:  67%|██████▋   | 1769/2645 [02:53<01:27, 10.03it/s, training_loss=0.198]\u001b[A\n",
      "Epoch 2:  67%|██████▋   | 1769/2645 [02:53<01:27, 10.03it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  67%|██████▋   | 1769/2645 [02:53<01:27, 10.03it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  67%|██████▋   | 1771/2645 [02:53<01:27, 10.05it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  67%|██████▋   | 1771/2645 [02:53<01:27, 10.05it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  67%|██████▋   | 1771/2645 [02:54<01:27, 10.05it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  67%|██████▋   | 1773/2645 [02:54<01:26, 10.09it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  67%|██████▋   | 1773/2645 [02:54<01:26, 10.09it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  67%|██████▋   | 1773/2645 [02:54<01:26, 10.09it/s, training_loss=0.710]\u001b[A\n",
      "Epoch 2:  67%|██████▋   | 1775/2645 [02:54<01:26, 10.07it/s, training_loss=0.710]\u001b[A\n",
      "Epoch 2:  67%|██████▋   | 1775/2645 [02:54<01:26, 10.07it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  67%|██████▋   | 1775/2645 [02:54<01:26, 10.07it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  67%|██████▋   | 1777/2645 [02:54<01:26, 10.07it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  67%|██████▋   | 1777/2645 [02:54<01:26, 10.07it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  67%|██████▋   | 1777/2645 [02:54<01:26, 10.07it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  67%|██████▋   | 1779/2645 [02:54<01:26, 10.06it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  67%|██████▋   | 1779/2645 [02:54<01:26, 10.06it/s, training_loss=0.039]\u001b[A\n",
      "Epoch 2:  67%|██████▋   | 1779/2645 [02:54<01:26, 10.06it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  67%|██████▋   | 1781/2645 [02:54<01:26,  9.99it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  67%|██████▋   | 1781/2645 [02:54<01:26,  9.99it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  67%|██████▋   | 1782/2645 [02:54<01:26,  9.93it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  67%|██████▋   | 1782/2645 [02:55<01:26,  9.93it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  67%|██████▋   | 1782/2645 [02:55<01:26,  9.93it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  67%|██████▋   | 1784/2645 [02:55<01:25, 10.08it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  67%|██████▋   | 1784/2645 [02:55<01:25, 10.08it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  67%|██████▋   | 1784/2645 [02:55<01:25, 10.08it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  68%|██████▊   | 1786/2645 [02:55<01:24, 10.13it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  68%|██████▊   | 1786/2645 [02:55<01:24, 10.13it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  68%|██████▊   | 1786/2645 [02:55<01:24, 10.13it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  68%|██████▊   | 1788/2645 [02:55<01:24, 10.17it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  68%|██████▊   | 1788/2645 [02:55<01:24, 10.17it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  68%|██████▊   | 1788/2645 [02:55<01:24, 10.17it/s, training_loss=0.884]\u001b[A\n",
      "Epoch 2:  68%|██████▊   | 1790/2645 [02:55<01:24, 10.09it/s, training_loss=0.884]\u001b[A\n",
      "Epoch 2:  68%|██████▊   | 1790/2645 [02:55<01:24, 10.09it/s, training_loss=0.563]\u001b[A\n",
      "Epoch 2:  68%|██████▊   | 1790/2645 [02:55<01:24, 10.09it/s, training_loss=0.344]\u001b[A\n",
      "Epoch 2:  68%|██████▊   | 1792/2645 [02:55<01:25,  9.99it/s, training_loss=0.344]\u001b[A\n",
      "Epoch 2:  68%|██████▊   | 1792/2645 [02:56<01:25,  9.99it/s, training_loss=0.353]\u001b[A\n",
      "Epoch 2:  68%|██████▊   | 1793/2645 [02:56<01:25,  9.96it/s, training_loss=0.353]\u001b[A\n",
      "Epoch 2:  68%|██████▊   | 1793/2645 [02:56<01:25,  9.96it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  68%|██████▊   | 1793/2645 [02:56<01:25,  9.96it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  68%|██████▊   | 1795/2645 [02:56<01:25,  9.94it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  68%|██████▊   | 1795/2645 [02:56<01:25,  9.94it/s, training_loss=0.791]\u001b[A\n",
      "Epoch 2:  68%|██████▊   | 1796/2645 [02:56<01:25,  9.95it/s, training_loss=0.791]\u001b[A\n",
      "Epoch 2:  68%|██████▊   | 1796/2645 [02:56<01:25,  9.95it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  68%|██████▊   | 1796/2645 [02:56<01:25,  9.95it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  68%|██████▊   | 1798/2645 [02:56<01:24,  9.97it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  68%|██████▊   | 1798/2645 [02:56<01:24,  9.97it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  68%|██████▊   | 1798/2645 [02:56<01:24,  9.97it/s, training_loss=1.075]\u001b[A\n",
      "Epoch 2:  68%|██████▊   | 1800/2645 [02:56<01:24, 10.04it/s, training_loss=1.075]\u001b[A\n",
      "Epoch 2:  68%|██████▊   | 1800/2645 [02:56<01:24, 10.04it/s, training_loss=0.900]\u001b[A\n",
      "Epoch 2:  68%|██████▊   | 1800/2645 [02:56<01:24, 10.04it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  68%|██████▊   | 1802/2645 [02:56<01:23, 10.07it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  68%|██████▊   | 1802/2645 [02:57<01:23, 10.07it/s, training_loss=0.587]\u001b[A\n",
      "Epoch 2:  68%|██████▊   | 1802/2645 [02:57<01:23, 10.07it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  68%|██████▊   | 1804/2645 [02:57<01:23, 10.04it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  68%|██████▊   | 1804/2645 [02:57<01:23, 10.04it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  68%|██████▊   | 1804/2645 [02:57<01:23, 10.04it/s, training_loss=0.120]\u001b[A\n",
      "Epoch 2:  68%|██████▊   | 1806/2645 [02:57<01:24,  9.98it/s, training_loss=0.120]\u001b[A\n",
      "Epoch 2:  68%|██████▊   | 1806/2645 [02:57<01:24,  9.98it/s, training_loss=0.705]\u001b[A\n",
      "Epoch 2:  68%|██████▊   | 1807/2645 [02:57<01:24,  9.94it/s, training_loss=0.705]\u001b[A\n",
      "Epoch 2:  68%|██████▊   | 1807/2645 [02:57<01:24,  9.94it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  68%|██████▊   | 1807/2645 [02:57<01:24,  9.94it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  68%|██████▊   | 1809/2645 [02:57<01:23,  9.98it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  68%|██████▊   | 1809/2645 [02:57<01:23,  9.98it/s, training_loss=0.835]\u001b[A\n",
      "Epoch 2:  68%|██████▊   | 1810/2645 [02:57<01:24,  9.91it/s, training_loss=0.835]\u001b[A\n",
      "Epoch 2:  68%|██████▊   | 1810/2645 [02:57<01:24,  9.91it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  68%|██████▊   | 1811/2645 [02:57<01:24,  9.88it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  68%|██████▊   | 1811/2645 [02:57<01:24,  9.88it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  68%|██████▊   | 1811/2645 [02:58<01:24,  9.88it/s, training_loss=0.863]\u001b[A\n",
      "Epoch 2:  69%|██████▊   | 1813/2645 [02:58<01:23,  9.92it/s, training_loss=0.863]\u001b[A\n",
      "Epoch 2:  69%|██████▊   | 1813/2645 [02:58<01:23,  9.92it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  69%|██████▊   | 1813/2645 [02:58<01:23,  9.92it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  69%|██████▊   | 1815/2645 [02:58<01:22, 10.06it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  69%|██████▊   | 1815/2645 [02:58<01:22, 10.06it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  69%|██████▊   | 1815/2645 [02:58<01:22, 10.06it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 2:  69%|██████▊   | 1817/2645 [02:58<01:21, 10.17it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 2:  69%|██████▊   | 1817/2645 [02:58<01:21, 10.17it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  69%|██████▊   | 1817/2645 [02:58<01:21, 10.17it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  69%|██████▉   | 1819/2645 [02:58<01:20, 10.27it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  69%|██████▉   | 1819/2645 [02:58<01:20, 10.27it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 2:  69%|██████▉   | 1819/2645 [02:58<01:20, 10.27it/s, training_loss=0.766]\u001b[A\n",
      "Epoch 2:  69%|██████▉   | 1821/2645 [02:58<01:20, 10.23it/s, training_loss=0.766]\u001b[A\n",
      "Epoch 2:  69%|██████▉   | 1821/2645 [02:58<01:20, 10.23it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  69%|██████▉   | 1821/2645 [02:59<01:20, 10.23it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  69%|██████▉   | 1823/2645 [02:59<01:20, 10.24it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  69%|██████▉   | 1823/2645 [02:59<01:20, 10.24it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  69%|██████▉   | 1823/2645 [02:59<01:20, 10.24it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  69%|██████▉   | 1825/2645 [02:59<01:19, 10.26it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  69%|██████▉   | 1825/2645 [02:59<01:19, 10.26it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  69%|██████▉   | 1825/2645 [02:59<01:19, 10.26it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  69%|██████▉   | 1827/2645 [02:59<01:19, 10.34it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  69%|██████▉   | 1827/2645 [02:59<01:19, 10.34it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  69%|██████▉   | 1827/2645 [02:59<01:19, 10.34it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  69%|██████▉   | 1829/2645 [02:59<01:18, 10.41it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  69%|██████▉   | 1829/2645 [02:59<01:18, 10.41it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  69%|██████▉   | 1829/2645 [02:59<01:18, 10.41it/s, training_loss=0.020]\u001b[A\n",
      "Epoch 2:  69%|██████▉   | 1831/2645 [02:59<01:18, 10.40it/s, training_loss=0.020]\u001b[A\n",
      "Epoch 2:  69%|██████▉   | 1831/2645 [02:59<01:18, 10.40it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  69%|██████▉   | 1831/2645 [02:59<01:18, 10.40it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  69%|██████▉   | 1833/2645 [02:59<01:17, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  69%|██████▉   | 1833/2645 [03:00<01:17, 10.45it/s, training_loss=0.012]\u001b[A\n",
      "Epoch 2:  69%|██████▉   | 1833/2645 [03:00<01:17, 10.45it/s, training_loss=0.013]\u001b[A\n",
      "Epoch 2:  69%|██████▉   | 1835/2645 [03:00<01:20, 10.09it/s, training_loss=0.013]\u001b[A\n",
      "Epoch 2:  69%|██████▉   | 1835/2645 [03:00<01:20, 10.09it/s, training_loss=0.605]\u001b[A\n",
      "Epoch 2:  69%|██████▉   | 1835/2645 [03:00<01:20, 10.09it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  69%|██████▉   | 1837/2645 [03:00<01:20, 10.07it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  69%|██████▉   | 1837/2645 [03:00<01:20, 10.07it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  69%|██████▉   | 1837/2645 [03:00<01:20, 10.07it/s, training_loss=0.815]\u001b[A\n",
      "Epoch 2:  70%|██████▉   | 1839/2645 [03:00<01:19, 10.18it/s, training_loss=0.815]\u001b[A\n",
      "Epoch 2:  70%|██████▉   | 1839/2645 [03:00<01:19, 10.18it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  70%|██████▉   | 1839/2645 [03:00<01:19, 10.18it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  70%|██████▉   | 1841/2645 [03:00<01:18, 10.31it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  70%|██████▉   | 1841/2645 [03:00<01:18, 10.31it/s, training_loss=0.883]\u001b[A\n",
      "Epoch 2:  70%|██████▉   | 1841/2645 [03:00<01:18, 10.31it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  70%|██████▉   | 1843/2645 [03:00<01:17, 10.33it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  70%|██████▉   | 1843/2645 [03:01<01:17, 10.33it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  70%|██████▉   | 1843/2645 [03:01<01:17, 10.33it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  70%|██████▉   | 1845/2645 [03:01<01:17, 10.31it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  70%|██████▉   | 1845/2645 [03:01<01:17, 10.31it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  70%|██████▉   | 1845/2645 [03:01<01:17, 10.31it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 2:  70%|██████▉   | 1847/2645 [03:01<01:17, 10.34it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 2:  70%|██████▉   | 1847/2645 [03:01<01:17, 10.34it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  70%|██████▉   | 1847/2645 [03:01<01:17, 10.34it/s, training_loss=0.512]\u001b[A\n",
      "Epoch 2:  70%|██████▉   | 1849/2645 [03:01<01:16, 10.40it/s, training_loss=0.512]\u001b[A\n",
      "Epoch 2:  70%|██████▉   | 1849/2645 [03:01<01:16, 10.40it/s, training_loss=0.628]\u001b[A\n",
      "Epoch 2:  70%|██████▉   | 1849/2645 [03:01<01:16, 10.40it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  70%|██████▉   | 1851/2645 [03:01<01:16, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  70%|██████▉   | 1851/2645 [03:01<01:16, 10.44it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  70%|██████▉   | 1851/2645 [03:01<01:16, 10.44it/s, training_loss=0.018]\u001b[A\n",
      "Epoch 2:  70%|███████   | 1853/2645 [03:01<01:15, 10.46it/s, training_loss=0.018]\u001b[A\n",
      "Epoch 2:  70%|███████   | 1853/2645 [03:01<01:15, 10.46it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  70%|███████   | 1853/2645 [03:02<01:15, 10.46it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  70%|███████   | 1855/2645 [03:02<01:15, 10.41it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  70%|███████   | 1855/2645 [03:02<01:15, 10.41it/s, training_loss=0.713]\u001b[A\n",
      "Epoch 2:  70%|███████   | 1855/2645 [03:02<01:15, 10.41it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  70%|███████   | 1857/2645 [03:02<01:16, 10.31it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  70%|███████   | 1857/2645 [03:02<01:16, 10.31it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 2:  70%|███████   | 1857/2645 [03:02<01:16, 10.31it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  70%|███████   | 1859/2645 [03:02<01:17, 10.17it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  70%|███████   | 1859/2645 [03:02<01:17, 10.17it/s, training_loss=0.089]\u001b[A\n",
      "Epoch 2:  70%|███████   | 1859/2645 [03:02<01:17, 10.17it/s, training_loss=0.052]\u001b[A\n",
      "Epoch 2:  70%|███████   | 1861/2645 [03:02<01:17, 10.06it/s, training_loss=0.052]\u001b[A\n",
      "Epoch 2:  70%|███████   | 1861/2645 [03:02<01:17, 10.06it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  70%|███████   | 1861/2645 [03:02<01:17, 10.06it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  70%|███████   | 1863/2645 [03:02<01:17, 10.05it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  70%|███████   | 1863/2645 [03:03<01:17, 10.05it/s, training_loss=0.439]\u001b[A\n",
      "Epoch 2:  70%|███████   | 1863/2645 [03:03<01:17, 10.05it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  71%|███████   | 1865/2645 [03:03<01:17, 10.01it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  71%|███████   | 1865/2645 [03:03<01:17, 10.01it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  71%|███████   | 1865/2645 [03:03<01:17, 10.01it/s, training_loss=0.473]\u001b[A\n",
      "Epoch 2:  71%|███████   | 1867/2645 [03:03<01:18,  9.95it/s, training_loss=0.473]\u001b[A\n",
      "Epoch 2:  71%|███████   | 1867/2645 [03:03<01:18,  9.95it/s, training_loss=0.034]\u001b[A\n",
      "Epoch 2:  71%|███████   | 1867/2645 [03:03<01:18,  9.95it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  71%|███████   | 1869/2645 [03:03<01:16, 10.10it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  71%|███████   | 1869/2645 [03:03<01:16, 10.10it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  71%|███████   | 1869/2645 [03:03<01:16, 10.10it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  71%|███████   | 1871/2645 [03:03<01:15, 10.23it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  71%|███████   | 1871/2645 [03:03<01:15, 10.23it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  71%|███████   | 1871/2645 [03:03<01:15, 10.23it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  71%|███████   | 1873/2645 [03:03<01:14, 10.30it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  71%|███████   | 1873/2645 [03:03<01:14, 10.30it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  71%|███████   | 1873/2645 [03:04<01:14, 10.30it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  71%|███████   | 1875/2645 [03:04<01:14, 10.30it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  71%|███████   | 1875/2645 [03:04<01:14, 10.30it/s, training_loss=0.019]\u001b[A\n",
      "Epoch 2:  71%|███████   | 1875/2645 [03:04<01:14, 10.30it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  71%|███████   | 1877/2645 [03:04<01:14, 10.34it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  71%|███████   | 1877/2645 [03:04<01:14, 10.34it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  71%|███████   | 1877/2645 [03:04<01:14, 10.34it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 2:  71%|███████   | 1879/2645 [03:04<01:15, 10.21it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 2:  71%|███████   | 1879/2645 [03:04<01:15, 10.21it/s, training_loss=0.811]\u001b[A\n",
      "Epoch 2:  71%|███████   | 1879/2645 [03:04<01:15, 10.21it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  71%|███████   | 1881/2645 [03:04<01:14, 10.27it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  71%|███████   | 1881/2645 [03:04<01:14, 10.27it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  71%|███████   | 1881/2645 [03:04<01:14, 10.27it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  71%|███████   | 1883/2645 [03:04<01:13, 10.34it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  71%|███████   | 1883/2645 [03:04<01:13, 10.34it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  71%|███████   | 1883/2645 [03:05<01:13, 10.34it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  71%|███████▏  | 1885/2645 [03:05<01:13, 10.37it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  71%|███████▏  | 1885/2645 [03:05<01:13, 10.37it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  71%|███████▏  | 1885/2645 [03:05<01:13, 10.37it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  71%|███████▏  | 1887/2645 [03:05<01:12, 10.41it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  71%|███████▏  | 1887/2645 [03:05<01:12, 10.41it/s, training_loss=0.011]\u001b[A\n",
      "Epoch 2:  71%|███████▏  | 1887/2645 [03:05<01:12, 10.41it/s, training_loss=0.421]\u001b[A\n",
      "Epoch 2:  71%|███████▏  | 1889/2645 [03:05<01:13, 10.35it/s, training_loss=0.421]\u001b[A\n",
      "Epoch 2:  71%|███████▏  | 1889/2645 [03:05<01:13, 10.35it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  71%|███████▏  | 1889/2645 [03:05<01:13, 10.35it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  71%|███████▏  | 1891/2645 [03:05<01:12, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  71%|███████▏  | 1891/2645 [03:05<01:12, 10.43it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  71%|███████▏  | 1891/2645 [03:05<01:12, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  72%|███████▏  | 1893/2645 [03:05<01:11, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  72%|███████▏  | 1893/2645 [03:05<01:11, 10.48it/s, training_loss=0.828]\u001b[A\n",
      "Epoch 2:  72%|███████▏  | 1893/2645 [03:05<01:11, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  72%|███████▏  | 1895/2645 [03:05<01:11, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  72%|███████▏  | 1895/2645 [03:06<01:11, 10.47it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  72%|███████▏  | 1895/2645 [03:06<01:11, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  72%|███████▏  | 1897/2645 [03:06<01:11, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  72%|███████▏  | 1897/2645 [03:06<01:11, 10.45it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  72%|███████▏  | 1897/2645 [03:06<01:11, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  72%|███████▏  | 1899/2645 [03:06<01:11, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  72%|███████▏  | 1899/2645 [03:06<01:11, 10.49it/s, training_loss=0.621]\u001b[A\n",
      "Epoch 2:  72%|███████▏  | 1899/2645 [03:06<01:11, 10.49it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  72%|███████▏  | 1901/2645 [03:06<01:12, 10.24it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  72%|███████▏  | 1901/2645 [03:06<01:12, 10.24it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  72%|███████▏  | 1901/2645 [03:06<01:12, 10.24it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  72%|███████▏  | 1903/2645 [03:06<01:12, 10.29it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  72%|███████▏  | 1903/2645 [03:06<01:12, 10.29it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  72%|███████▏  | 1903/2645 [03:06<01:12, 10.29it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  72%|███████▏  | 1905/2645 [03:06<01:12, 10.20it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  72%|███████▏  | 1905/2645 [03:07<01:12, 10.20it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 2:  72%|███████▏  | 1905/2645 [03:07<01:12, 10.20it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  72%|███████▏  | 1907/2645 [03:07<01:12, 10.13it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  72%|███████▏  | 1907/2645 [03:07<01:12, 10.13it/s, training_loss=0.602]\u001b[A\n",
      "Epoch 2:  72%|███████▏  | 1907/2645 [03:07<01:12, 10.13it/s, training_loss=0.873]\u001b[A\n",
      "Epoch 2:  72%|███████▏  | 1909/2645 [03:07<01:13, 10.08it/s, training_loss=0.873]\u001b[A\n",
      "Epoch 2:  72%|███████▏  | 1909/2645 [03:07<01:13, 10.08it/s, training_loss=0.562]\u001b[A\n",
      "Epoch 2:  72%|███████▏  | 1909/2645 [03:07<01:13, 10.08it/s, training_loss=0.023]\u001b[A\n",
      "Epoch 2:  72%|███████▏  | 1911/2645 [03:07<01:13, 10.02it/s, training_loss=0.023]\u001b[A\n",
      "Epoch 2:  72%|███████▏  | 1911/2645 [03:07<01:13, 10.02it/s, training_loss=0.235]\u001b[A\n",
      "Epoch 2:  72%|███████▏  | 1911/2645 [03:07<01:13, 10.02it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  72%|███████▏  | 1913/2645 [03:07<01:12, 10.10it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  72%|███████▏  | 1913/2645 [03:07<01:12, 10.10it/s, training_loss=0.031]\u001b[A\n",
      "Epoch 2:  72%|███████▏  | 1913/2645 [03:07<01:12, 10.10it/s, training_loss=0.056]\u001b[A\n",
      "Epoch 2:  72%|███████▏  | 1915/2645 [03:07<01:11, 10.17it/s, training_loss=0.056]\u001b[A\n",
      "Epoch 2:  72%|███████▏  | 1915/2645 [03:08<01:11, 10.17it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  72%|███████▏  | 1915/2645 [03:08<01:11, 10.17it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  72%|███████▏  | 1917/2645 [03:08<01:10, 10.28it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  72%|███████▏  | 1917/2645 [03:08<01:10, 10.28it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  72%|███████▏  | 1917/2645 [03:08<01:10, 10.28it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  73%|███████▎  | 1919/2645 [03:08<01:10, 10.32it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  73%|███████▎  | 1919/2645 [03:08<01:10, 10.32it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  73%|███████▎  | 1919/2645 [03:08<01:10, 10.32it/s, training_loss=0.646]\u001b[A\n",
      "Epoch 2:  73%|███████▎  | 1921/2645 [03:08<01:09, 10.36it/s, training_loss=0.646]\u001b[A\n",
      "Epoch 2:  73%|███████▎  | 1921/2645 [03:08<01:09, 10.36it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  73%|███████▎  | 1921/2645 [03:08<01:09, 10.36it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  73%|███████▎  | 1923/2645 [03:08<01:10, 10.30it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  73%|███████▎  | 1923/2645 [03:08<01:10, 10.30it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  73%|███████▎  | 1923/2645 [03:08<01:10, 10.30it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  73%|███████▎  | 1925/2645 [03:08<01:09, 10.40it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  73%|███████▎  | 1925/2645 [03:09<01:09, 10.40it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  73%|███████▎  | 1925/2645 [03:09<01:09, 10.40it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  73%|███████▎  | 1927/2645 [03:09<01:08, 10.44it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  73%|███████▎  | 1927/2645 [03:09<01:08, 10.44it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  73%|███████▎  | 1927/2645 [03:09<01:08, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  73%|███████▎  | 1929/2645 [03:09<01:08, 10.42it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  73%|███████▎  | 1929/2645 [03:09<01:08, 10.42it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  73%|███████▎  | 1929/2645 [03:09<01:08, 10.42it/s, training_loss=0.781]\u001b[A\n",
      "Epoch 2:  73%|███████▎  | 1931/2645 [03:09<01:08, 10.40it/s, training_loss=0.781]\u001b[A\n",
      "Epoch 2:  73%|███████▎  | 1931/2645 [03:09<01:08, 10.40it/s, training_loss=0.519]\u001b[A\n",
      "Epoch 2:  73%|███████▎  | 1931/2645 [03:09<01:08, 10.40it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  73%|███████▎  | 1933/2645 [03:09<01:08, 10.43it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  73%|███████▎  | 1933/2645 [03:09<01:08, 10.43it/s, training_loss=0.236]\u001b[A\n",
      "Epoch 2:  73%|███████▎  | 1933/2645 [03:09<01:08, 10.43it/s, training_loss=0.297]\u001b[A\n",
      "Epoch 2:  73%|███████▎  | 1935/2645 [03:09<01:08, 10.38it/s, training_loss=0.297]\u001b[A\n",
      "Epoch 2:  73%|███████▎  | 1935/2645 [03:09<01:08, 10.38it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  73%|███████▎  | 1935/2645 [03:10<01:08, 10.38it/s, training_loss=0.018]\u001b[A\n",
      "Epoch 2:  73%|███████▎  | 1937/2645 [03:10<01:07, 10.42it/s, training_loss=0.018]\u001b[A\n",
      "Epoch 2:  73%|███████▎  | 1937/2645 [03:10<01:07, 10.42it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  73%|███████▎  | 1937/2645 [03:10<01:07, 10.42it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  73%|███████▎  | 1939/2645 [03:10<01:07, 10.45it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  73%|███████▎  | 1939/2645 [03:10<01:07, 10.45it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  73%|███████▎  | 1939/2645 [03:10<01:07, 10.45it/s, training_loss=0.290]\u001b[A\n",
      "Epoch 2:  73%|███████▎  | 1941/2645 [03:10<01:07, 10.44it/s, training_loss=0.290]\u001b[A\n",
      "Epoch 2:  73%|███████▎  | 1941/2645 [03:10<01:07, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  73%|███████▎  | 1941/2645 [03:10<01:07, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  73%|███████▎  | 1943/2645 [03:10<01:07, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  73%|███████▎  | 1943/2645 [03:10<01:07, 10.46it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  73%|███████▎  | 1943/2645 [03:10<01:07, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  74%|███████▎  | 1945/2645 [03:10<01:06, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  74%|███████▎  | 1945/2645 [03:10<01:06, 10.46it/s, training_loss=0.628]\u001b[A\n",
      "Epoch 2:  74%|███████▎  | 1945/2645 [03:11<01:06, 10.46it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  74%|███████▎  | 1947/2645 [03:11<01:06, 10.47it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  74%|███████▎  | 1947/2645 [03:11<01:06, 10.47it/s, training_loss=0.011]\u001b[A\n",
      "Epoch 2:  74%|███████▎  | 1947/2645 [03:11<01:06, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  74%|███████▎  | 1949/2645 [03:11<01:06, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  74%|███████▎  | 1949/2645 [03:11<01:06, 10.47it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  74%|███████▎  | 1949/2645 [03:11<01:06, 10.47it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  74%|███████▍  | 1951/2645 [03:11<01:06, 10.41it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  74%|███████▍  | 1951/2645 [03:11<01:06, 10.41it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  74%|███████▍  | 1951/2645 [03:11<01:06, 10.41it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  74%|███████▍  | 1953/2645 [03:11<01:06, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  74%|███████▍  | 1953/2645 [03:11<01:06, 10.44it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  74%|███████▍  | 1953/2645 [03:11<01:06, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  74%|███████▍  | 1955/2645 [03:11<01:05, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  74%|███████▍  | 1955/2645 [03:11<01:05, 10.48it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  74%|███████▍  | 1955/2645 [03:11<01:05, 10.48it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  74%|███████▍  | 1957/2645 [03:11<01:05, 10.51it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  74%|███████▍  | 1957/2645 [03:12<01:05, 10.51it/s, training_loss=0.697]\u001b[A\n",
      "Epoch 2:  74%|███████▍  | 1957/2645 [03:12<01:05, 10.51it/s, training_loss=0.059]\u001b[A\n",
      "Epoch 2:  74%|███████▍  | 1959/2645 [03:12<01:05, 10.44it/s, training_loss=0.059]\u001b[A\n",
      "Epoch 2:  74%|███████▍  | 1959/2645 [03:12<01:05, 10.44it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  74%|███████▍  | 1959/2645 [03:12<01:05, 10.44it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  74%|███████▍  | 1961/2645 [03:12<01:05, 10.41it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  74%|███████▍  | 1961/2645 [03:12<01:05, 10.41it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  74%|███████▍  | 1961/2645 [03:12<01:05, 10.41it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  74%|███████▍  | 1963/2645 [03:12<01:05, 10.43it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  74%|███████▍  | 1963/2645 [03:12<01:05, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  74%|███████▍  | 1963/2645 [03:12<01:05, 10.43it/s, training_loss=0.013]\u001b[A\n",
      "Epoch 2:  74%|███████▍  | 1965/2645 [03:12<01:05, 10.39it/s, training_loss=0.013]\u001b[A\n",
      "Epoch 2:  74%|███████▍  | 1965/2645 [03:12<01:05, 10.39it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  74%|███████▍  | 1965/2645 [03:12<01:05, 10.39it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  74%|███████▍  | 1967/2645 [03:12<01:05, 10.43it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  74%|███████▍  | 1967/2645 [03:13<01:05, 10.43it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  74%|███████▍  | 1967/2645 [03:13<01:05, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  74%|███████▍  | 1969/2645 [03:13<01:04, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  74%|███████▍  | 1969/2645 [03:13<01:04, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  74%|███████▍  | 1969/2645 [03:13<01:04, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  75%|███████▍  | 1971/2645 [03:13<01:04, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  75%|███████▍  | 1971/2645 [03:13<01:04, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  75%|███████▍  | 1971/2645 [03:13<01:04, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  75%|███████▍  | 1973/2645 [03:13<01:03, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  75%|███████▍  | 1973/2645 [03:13<01:03, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  75%|███████▍  | 1973/2645 [03:13<01:03, 10.52it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  75%|███████▍  | 1975/2645 [03:13<01:03, 10.50it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  75%|███████▍  | 1975/2645 [03:13<01:03, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  75%|███████▍  | 1975/2645 [03:13<01:03, 10.50it/s, training_loss=0.212]\u001b[A\n",
      "Epoch 2:  75%|███████▍  | 1977/2645 [03:13<01:03, 10.48it/s, training_loss=0.212]\u001b[A\n",
      "Epoch 2:  75%|███████▍  | 1977/2645 [03:13<01:03, 10.48it/s, training_loss=0.092]\u001b[A\n",
      "Epoch 2:  75%|███████▍  | 1977/2645 [03:14<01:03, 10.48it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  75%|███████▍  | 1979/2645 [03:14<01:03, 10.45it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  75%|███████▍  | 1979/2645 [03:14<01:03, 10.45it/s, training_loss=0.152]\u001b[A\n",
      "Epoch 2:  75%|███████▍  | 1979/2645 [03:14<01:03, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  75%|███████▍  | 1981/2645 [03:14<01:03, 10.39it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  75%|███████▍  | 1981/2645 [03:14<01:03, 10.39it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  75%|███████▍  | 1981/2645 [03:14<01:03, 10.39it/s, training_loss=0.414]\u001b[A\n",
      "Epoch 2:  75%|███████▍  | 1983/2645 [03:14<01:04, 10.27it/s, training_loss=0.414]\u001b[A\n",
      "Epoch 2:  75%|███████▍  | 1983/2645 [03:14<01:04, 10.27it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  75%|███████▍  | 1983/2645 [03:14<01:04, 10.27it/s, training_loss=0.058]\u001b[A\n",
      "Epoch 2:  75%|███████▌  | 1985/2645 [03:14<01:03, 10.33it/s, training_loss=0.058]\u001b[A\n",
      "Epoch 2:  75%|███████▌  | 1985/2645 [03:14<01:03, 10.33it/s, training_loss=1.018]\u001b[A\n",
      "Epoch 2:  75%|███████▌  | 1985/2645 [03:14<01:03, 10.33it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  75%|███████▌  | 1987/2645 [03:14<01:03, 10.37it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  75%|███████▌  | 1987/2645 [03:14<01:03, 10.37it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 2:  75%|███████▌  | 1987/2645 [03:15<01:03, 10.37it/s, training_loss=0.910]\u001b[A\n",
      "Epoch 2:  75%|███████▌  | 1989/2645 [03:15<01:03, 10.38it/s, training_loss=0.910]\u001b[A\n",
      "Epoch 2:  75%|███████▌  | 1989/2645 [03:15<01:03, 10.38it/s, training_loss=0.180]\u001b[A\n",
      "Epoch 2:  75%|███████▌  | 1989/2645 [03:15<01:03, 10.38it/s, training_loss=0.197]\u001b[A\n",
      "Epoch 2:  75%|███████▌  | 1991/2645 [03:15<01:03, 10.32it/s, training_loss=0.197]\u001b[A\n",
      "Epoch 2:  75%|███████▌  | 1991/2645 [03:15<01:03, 10.32it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  75%|███████▌  | 1991/2645 [03:15<01:03, 10.32it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  75%|███████▌  | 1993/2645 [03:15<01:03, 10.31it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  75%|███████▌  | 1993/2645 [03:15<01:03, 10.31it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  75%|███████▌  | 1993/2645 [03:15<01:03, 10.31it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  75%|███████▌  | 1995/2645 [03:15<01:02, 10.39it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  75%|███████▌  | 1995/2645 [03:15<01:02, 10.39it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  75%|███████▌  | 1995/2645 [03:15<01:02, 10.39it/s, training_loss=0.056]\u001b[A\n",
      "Epoch 2:  76%|███████▌  | 1997/2645 [03:15<01:02, 10.41it/s, training_loss=0.056]\u001b[A\n",
      "Epoch 2:  76%|███████▌  | 1997/2645 [03:15<01:02, 10.41it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  76%|███████▌  | 1997/2645 [03:16<01:02, 10.41it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  76%|███████▌  | 1999/2645 [03:16<01:01, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  76%|███████▌  | 1999/2645 [03:16<01:01, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  76%|███████▌  | 1999/2645 [03:16<01:01, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  76%|███████▌  | 2001/2645 [03:16<01:01, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  76%|███████▌  | 2001/2645 [03:16<01:01, 10.48it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  76%|███████▌  | 2001/2645 [03:16<01:01, 10.48it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  76%|███████▌  | 2003/2645 [03:16<01:01, 10.52it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  76%|███████▌  | 2003/2645 [03:16<01:01, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  76%|███████▌  | 2003/2645 [03:16<01:01, 10.52it/s, training_loss=0.564]\u001b[A\n",
      "Epoch 2:  76%|███████▌  | 2005/2645 [03:16<01:00, 10.51it/s, training_loss=0.564]\u001b[A\n",
      "Epoch 2:  76%|███████▌  | 2005/2645 [03:16<01:00, 10.51it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  76%|███████▌  | 2005/2645 [03:16<01:00, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  76%|███████▌  | 2007/2645 [03:16<01:00, 10.53it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  76%|███████▌  | 2007/2645 [03:16<01:00, 10.53it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  76%|███████▌  | 2007/2645 [03:16<01:00, 10.53it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  76%|███████▌  | 2009/2645 [03:16<01:00, 10.53it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  76%|███████▌  | 2009/2645 [03:17<01:00, 10.53it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  76%|███████▌  | 2009/2645 [03:17<01:00, 10.53it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  76%|███████▌  | 2011/2645 [03:17<01:00, 10.55it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  76%|███████▌  | 2011/2645 [03:17<01:00, 10.55it/s, training_loss=0.619]\u001b[A\n",
      "Epoch 2:  76%|███████▌  | 2011/2645 [03:17<01:00, 10.55it/s, training_loss=0.915]\u001b[A\n",
      "Epoch 2:  76%|███████▌  | 2013/2645 [03:17<01:00, 10.51it/s, training_loss=0.915]\u001b[A\n",
      "Epoch 2:  76%|███████▌  | 2013/2645 [03:17<01:00, 10.51it/s, training_loss=0.169]\u001b[A\n",
      "Epoch 2:  76%|███████▌  | 2013/2645 [03:17<01:00, 10.51it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  76%|███████▌  | 2015/2645 [03:17<01:00, 10.49it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  76%|███████▌  | 2015/2645 [03:17<01:00, 10.49it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  76%|███████▌  | 2015/2645 [03:17<01:00, 10.49it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  76%|███████▋  | 2017/2645 [03:17<00:59, 10.53it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  76%|███████▋  | 2017/2645 [03:17<00:59, 10.53it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  76%|███████▋  | 2017/2645 [03:17<00:59, 10.53it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  76%|███████▋  | 2019/2645 [03:17<00:59, 10.53it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  76%|███████▋  | 2019/2645 [03:18<00:59, 10.53it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  76%|███████▋  | 2019/2645 [03:18<00:59, 10.53it/s, training_loss=0.098]\u001b[A\n",
      "Epoch 2:  76%|███████▋  | 2021/2645 [03:18<00:59, 10.49it/s, training_loss=0.098]\u001b[A\n",
      "Epoch 2:  76%|███████▋  | 2021/2645 [03:18<00:59, 10.49it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 2:  76%|███████▋  | 2021/2645 [03:18<00:59, 10.49it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  76%|███████▋  | 2023/2645 [03:18<00:59, 10.48it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  76%|███████▋  | 2023/2645 [03:18<00:59, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  76%|███████▋  | 2023/2645 [03:18<00:59, 10.48it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  77%|███████▋  | 2025/2645 [03:18<00:59, 10.48it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  77%|███████▋  | 2025/2645 [03:18<00:59, 10.48it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  77%|███████▋  | 2025/2645 [03:18<00:59, 10.48it/s, training_loss=0.045]\u001b[A\n",
      "Epoch 2:  77%|███████▋  | 2027/2645 [03:18<00:59, 10.42it/s, training_loss=0.045]\u001b[A\n",
      "Epoch 2:  77%|███████▋  | 2027/2645 [03:18<00:59, 10.42it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  77%|███████▋  | 2027/2645 [03:18<00:59, 10.42it/s, training_loss=0.823]\u001b[A\n",
      "Epoch 2:  77%|███████▋  | 2029/2645 [03:18<00:59, 10.41it/s, training_loss=0.823]\u001b[A\n",
      "Epoch 2:  77%|███████▋  | 2029/2645 [03:18<00:59, 10.41it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  77%|███████▋  | 2029/2645 [03:19<00:59, 10.41it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 2:  77%|███████▋  | 2031/2645 [03:19<00:58, 10.44it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 2:  77%|███████▋  | 2031/2645 [03:19<00:58, 10.44it/s, training_loss=0.059]\u001b[A\n",
      "Epoch 2:  77%|███████▋  | 2031/2645 [03:19<00:58, 10.44it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  77%|███████▋  | 2033/2645 [03:19<00:58, 10.45it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  77%|███████▋  | 2033/2645 [03:19<00:58, 10.45it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  77%|███████▋  | 2033/2645 [03:19<00:58, 10.45it/s, training_loss=0.199]\u001b[A\n",
      "Epoch 2:  77%|███████▋  | 2035/2645 [03:19<00:58, 10.44it/s, training_loss=0.199]\u001b[A\n",
      "Epoch 2:  77%|███████▋  | 2035/2645 [03:19<00:58, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  77%|███████▋  | 2035/2645 [03:19<00:58, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  77%|███████▋  | 2037/2645 [03:19<00:58, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  77%|███████▋  | 2037/2645 [03:19<00:58, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  77%|███████▋  | 2037/2645 [03:19<00:58, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  77%|███████▋  | 2039/2645 [03:19<00:57, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  77%|███████▋  | 2039/2645 [03:19<00:57, 10.51it/s, training_loss=0.138]\u001b[A\n",
      "Epoch 2:  77%|███████▋  | 2039/2645 [03:20<00:57, 10.51it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  77%|███████▋  | 2041/2645 [03:20<00:57, 10.50it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  77%|███████▋  | 2041/2645 [03:20<00:57, 10.50it/s, training_loss=0.388]\u001b[A\n",
      "Epoch 2:  77%|███████▋  | 2041/2645 [03:20<00:57, 10.50it/s, training_loss=0.220]\u001b[A\n",
      "Epoch 2:  77%|███████▋  | 2043/2645 [03:20<00:57, 10.42it/s, training_loss=0.220]\u001b[A\n",
      "Epoch 2:  77%|███████▋  | 2043/2645 [03:20<00:57, 10.42it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  77%|███████▋  | 2043/2645 [03:20<00:57, 10.42it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  77%|███████▋  | 2045/2645 [03:20<00:57, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  77%|███████▋  | 2045/2645 [03:20<00:57, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  77%|███████▋  | 2045/2645 [03:20<00:57, 10.45it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  77%|███████▋  | 2047/2645 [03:20<00:56, 10.50it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  77%|███████▋  | 2047/2645 [03:20<00:56, 10.50it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  77%|███████▋  | 2047/2645 [03:20<00:56, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  77%|███████▋  | 2049/2645 [03:20<00:56, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  77%|███████▋  | 2049/2645 [03:20<00:56, 10.51it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  77%|███████▋  | 2049/2645 [03:20<00:56, 10.51it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  78%|███████▊  | 2051/2645 [03:20<00:56, 10.54it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  78%|███████▊  | 2051/2645 [03:21<00:56, 10.54it/s, training_loss=0.735]\u001b[A\n",
      "Epoch 2:  78%|███████▊  | 2051/2645 [03:21<00:56, 10.54it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  78%|███████▊  | 2053/2645 [03:21<00:56, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  78%|███████▊  | 2053/2645 [03:21<00:56, 10.51it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  78%|███████▊  | 2053/2645 [03:21<00:56, 10.51it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  78%|███████▊  | 2055/2645 [03:21<00:56, 10.52it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  78%|███████▊  | 2055/2645 [03:21<00:56, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  78%|███████▊  | 2055/2645 [03:21<00:56, 10.52it/s, training_loss=0.986]\u001b[A\n",
      "Epoch 2:  78%|███████▊  | 2057/2645 [03:21<00:55, 10.51it/s, training_loss=0.986]\u001b[A\n",
      "Epoch 2:  78%|███████▊  | 2057/2645 [03:21<00:55, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  78%|███████▊  | 2057/2645 [03:21<00:55, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  78%|███████▊  | 2059/2645 [03:21<00:55, 10.53it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  78%|███████▊  | 2059/2645 [03:21<00:55, 10.53it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  78%|███████▊  | 2059/2645 [03:21<00:55, 10.53it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  78%|███████▊  | 2061/2645 [03:21<00:55, 10.48it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  78%|███████▊  | 2061/2645 [03:22<00:55, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  78%|███████▊  | 2061/2645 [03:22<00:55, 10.48it/s, training_loss=0.768]\u001b[A\n",
      "Epoch 2:  78%|███████▊  | 2063/2645 [03:22<00:55, 10.45it/s, training_loss=0.768]\u001b[A\n",
      "Epoch 2:  78%|███████▊  | 2063/2645 [03:22<00:55, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  78%|███████▊  | 2063/2645 [03:22<00:55, 10.45it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  78%|███████▊  | 2065/2645 [03:22<00:55, 10.46it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  78%|███████▊  | 2065/2645 [03:22<00:55, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  78%|███████▊  | 2065/2645 [03:22<00:55, 10.46it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  78%|███████▊  | 2067/2645 [03:22<00:55, 10.49it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  78%|███████▊  | 2067/2645 [03:22<00:55, 10.49it/s, training_loss=0.821]\u001b[A\n",
      "Epoch 2:  78%|███████▊  | 2067/2645 [03:22<00:55, 10.49it/s, training_loss=0.469]\u001b[A\n",
      "Epoch 2:  78%|███████▊  | 2069/2645 [03:22<00:55, 10.46it/s, training_loss=0.469]\u001b[A\n",
      "Epoch 2:  78%|███████▊  | 2069/2645 [03:22<00:55, 10.46it/s, training_loss=0.729]\u001b[A\n",
      "Epoch 2:  78%|███████▊  | 2069/2645 [03:22<00:55, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  78%|███████▊  | 2071/2645 [03:22<00:54, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  78%|███████▊  | 2071/2645 [03:22<00:54, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  78%|███████▊  | 2071/2645 [03:23<00:54, 10.46it/s, training_loss=0.012]\u001b[A\n",
      "Epoch 2:  78%|███████▊  | 2073/2645 [03:23<00:54, 10.46it/s, training_loss=0.012]\u001b[A\n",
      "Epoch 2:  78%|███████▊  | 2073/2645 [03:23<00:54, 10.46it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  78%|███████▊  | 2073/2645 [03:23<00:54, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  78%|███████▊  | 2075/2645 [03:23<00:54, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  78%|███████▊  | 2075/2645 [03:23<00:54, 10.48it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  78%|███████▊  | 2075/2645 [03:23<00:54, 10.48it/s, training_loss=0.026]\u001b[A\n",
      "Epoch 2:  79%|███████▊  | 2077/2645 [03:23<00:54, 10.45it/s, training_loss=0.026]\u001b[A\n",
      "Epoch 2:  79%|███████▊  | 2077/2645 [03:23<00:54, 10.45it/s, training_loss=0.974]\u001b[A\n",
      "Epoch 2:  79%|███████▊  | 2077/2645 [03:23<00:54, 10.45it/s, training_loss=0.108]\u001b[A\n",
      "Epoch 2:  79%|███████▊  | 2079/2645 [03:23<00:54, 10.44it/s, training_loss=0.108]\u001b[A\n",
      "Epoch 2:  79%|███████▊  | 2079/2645 [03:23<00:54, 10.44it/s, training_loss=0.653]\u001b[A\n",
      "Epoch 2:  79%|███████▊  | 2079/2645 [03:23<00:54, 10.44it/s, training_loss=0.478]\u001b[A\n",
      "Epoch 2:  79%|███████▊  | 2081/2645 [03:23<00:54, 10.42it/s, training_loss=0.478]\u001b[A\n",
      "Epoch 2:  79%|███████▊  | 2081/2645 [03:23<00:54, 10.42it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  79%|███████▊  | 2081/2645 [03:24<00:54, 10.42it/s, training_loss=0.187]\u001b[A\n",
      "Epoch 2:  79%|███████▉  | 2083/2645 [03:24<00:54, 10.38it/s, training_loss=0.187]\u001b[A\n",
      "Epoch 2:  79%|███████▉  | 2083/2645 [03:24<00:54, 10.38it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  79%|███████▉  | 2083/2645 [03:24<00:54, 10.38it/s, training_loss=0.482]\u001b[A\n",
      "Epoch 2:  79%|███████▉  | 2085/2645 [03:24<00:53, 10.41it/s, training_loss=0.482]\u001b[A\n",
      "Epoch 2:  79%|███████▉  | 2085/2645 [03:24<00:53, 10.41it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  79%|███████▉  | 2085/2645 [03:24<00:53, 10.41it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  79%|███████▉  | 2087/2645 [03:24<00:53, 10.43it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  79%|███████▉  | 2087/2645 [03:24<00:53, 10.43it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  79%|███████▉  | 2087/2645 [03:24<00:53, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  79%|███████▉  | 2089/2645 [03:24<00:53, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  79%|███████▉  | 2089/2645 [03:24<00:53, 10.48it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  79%|███████▉  | 2089/2645 [03:24<00:53, 10.48it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  79%|███████▉  | 2091/2645 [03:24<00:52, 10.52it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  79%|███████▉  | 2091/2645 [03:24<00:52, 10.52it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  79%|███████▉  | 2091/2645 [03:24<00:52, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  79%|███████▉  | 2093/2645 [03:24<00:52, 10.55it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  79%|███████▉  | 2093/2645 [03:25<00:52, 10.55it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  79%|███████▉  | 2093/2645 [03:25<00:52, 10.55it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  79%|███████▉  | 2095/2645 [03:25<00:52, 10.56it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  79%|███████▉  | 2095/2645 [03:25<00:52, 10.56it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  79%|███████▉  | 2095/2645 [03:25<00:52, 10.56it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  79%|███████▉  | 2097/2645 [03:25<00:51, 10.59it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  79%|███████▉  | 2097/2645 [03:25<00:51, 10.59it/s, training_loss=0.012]\u001b[A\n",
      "Epoch 2:  79%|███████▉  | 2097/2645 [03:25<00:51, 10.59it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  79%|███████▉  | 2099/2645 [03:25<00:51, 10.55it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  79%|███████▉  | 2099/2645 [03:25<00:51, 10.55it/s, training_loss=0.067]\u001b[A\n",
      "Epoch 2:  79%|███████▉  | 2099/2645 [03:25<00:51, 10.55it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  79%|███████▉  | 2101/2645 [03:25<00:52, 10.43it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  79%|███████▉  | 2101/2645 [03:25<00:52, 10.43it/s, training_loss=0.071]\u001b[A\n",
      "Epoch 2:  79%|███████▉  | 2101/2645 [03:25<00:52, 10.43it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  80%|███████▉  | 2103/2645 [03:25<00:51, 10.43it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  80%|███████▉  | 2103/2645 [03:26<00:51, 10.43it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 2:  80%|███████▉  | 2103/2645 [03:26<00:51, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  80%|███████▉  | 2105/2645 [03:26<00:51, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  80%|███████▉  | 2105/2645 [03:26<00:51, 10.44it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  80%|███████▉  | 2105/2645 [03:26<00:51, 10.44it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  80%|███████▉  | 2107/2645 [03:26<00:51, 10.45it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  80%|███████▉  | 2107/2645 [03:26<00:51, 10.45it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  80%|███████▉  | 2107/2645 [03:26<00:51, 10.45it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  80%|███████▉  | 2109/2645 [03:26<00:51, 10.45it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  80%|███████▉  | 2109/2645 [03:26<00:51, 10.45it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  80%|███████▉  | 2109/2645 [03:26<00:51, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  80%|███████▉  | 2111/2645 [03:26<00:51, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  80%|███████▉  | 2111/2645 [03:26<00:51, 10.46it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  80%|███████▉  | 2111/2645 [03:26<00:51, 10.46it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  80%|███████▉  | 2113/2645 [03:26<00:51, 10.43it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  80%|███████▉  | 2113/2645 [03:26<00:51, 10.43it/s, training_loss=0.420]\u001b[A\n",
      "Epoch 2:  80%|███████▉  | 2113/2645 [03:27<00:51, 10.43it/s, training_loss=0.572]\u001b[A\n",
      "Epoch 2:  80%|███████▉  | 2115/2645 [03:27<00:50, 10.42it/s, training_loss=0.572]\u001b[A\n",
      "Epoch 2:  80%|███████▉  | 2115/2645 [03:27<00:50, 10.42it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  80%|███████▉  | 2115/2645 [03:27<00:50, 10.42it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  80%|████████  | 2117/2645 [03:27<00:51, 10.25it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  80%|████████  | 2117/2645 [03:27<00:51, 10.25it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  80%|████████  | 2117/2645 [03:27<00:51, 10.25it/s, training_loss=0.910]\u001b[A\n",
      "Epoch 2:  80%|████████  | 2119/2645 [03:27<00:51, 10.20it/s, training_loss=0.910]\u001b[A\n",
      "Epoch 2:  80%|████████  | 2119/2645 [03:27<00:51, 10.20it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  80%|████████  | 2119/2645 [03:27<00:51, 10.20it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  80%|████████  | 2121/2645 [03:27<00:50, 10.30it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  80%|████████  | 2121/2645 [03:27<00:50, 10.30it/s, training_loss=0.954]\u001b[A\n",
      "Epoch 2:  80%|████████  | 2121/2645 [03:27<00:50, 10.30it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  80%|████████  | 2123/2645 [03:27<00:50, 10.35it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  80%|████████  | 2123/2645 [03:27<00:50, 10.35it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  80%|████████  | 2123/2645 [03:28<00:50, 10.35it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  80%|████████  | 2125/2645 [03:28<00:49, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  80%|████████  | 2125/2645 [03:28<00:49, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  80%|████████  | 2125/2645 [03:28<00:49, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  80%|████████  | 2127/2645 [03:28<00:49, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  80%|████████  | 2127/2645 [03:28<00:49, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  80%|████████  | 2127/2645 [03:28<00:49, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  80%|████████  | 2129/2645 [03:28<00:49, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  80%|████████  | 2129/2645 [03:28<00:49, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  80%|████████  | 2129/2645 [03:28<00:49, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  81%|████████  | 2131/2645 [03:28<00:48, 10.55it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  81%|████████  | 2131/2645 [03:28<00:48, 10.55it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  81%|████████  | 2131/2645 [03:28<00:48, 10.55it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  81%|████████  | 2133/2645 [03:28<00:48, 10.57it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  81%|████████  | 2133/2645 [03:28<00:48, 10.57it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  81%|████████  | 2133/2645 [03:29<00:48, 10.57it/s, training_loss=0.058]\u001b[A\n",
      "Epoch 2:  81%|████████  | 2135/2645 [03:29<00:48, 10.46it/s, training_loss=0.058]\u001b[A\n",
      "Epoch 2:  81%|████████  | 2135/2645 [03:29<00:48, 10.46it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  81%|████████  | 2135/2645 [03:29<00:48, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  81%|████████  | 2137/2645 [03:29<00:48, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  81%|████████  | 2137/2645 [03:29<00:48, 10.45it/s, training_loss=0.327]\u001b[A\n",
      "Epoch 2:  81%|████████  | 2137/2645 [03:29<00:48, 10.45it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  81%|████████  | 2139/2645 [03:29<00:48, 10.45it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  81%|████████  | 2139/2645 [03:29<00:48, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  81%|████████  | 2139/2645 [03:29<00:48, 10.45it/s, training_loss=0.333]\u001b[A\n",
      "Epoch 2:  81%|████████  | 2141/2645 [03:29<00:48, 10.39it/s, training_loss=0.333]\u001b[A\n",
      "Epoch 2:  81%|████████  | 2141/2645 [03:29<00:48, 10.39it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  81%|████████  | 2141/2645 [03:29<00:48, 10.39it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  81%|████████  | 2143/2645 [03:29<00:48, 10.40it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  81%|████████  | 2143/2645 [03:29<00:48, 10.40it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  81%|████████  | 2143/2645 [03:29<00:48, 10.40it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  81%|████████  | 2145/2645 [03:29<00:48, 10.34it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  81%|████████  | 2145/2645 [03:30<00:48, 10.34it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  81%|████████  | 2145/2645 [03:30<00:48, 10.34it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  81%|████████  | 2147/2645 [03:30<00:47, 10.42it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  81%|████████  | 2147/2645 [03:30<00:47, 10.42it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  81%|████████  | 2147/2645 [03:30<00:47, 10.42it/s, training_loss=0.408]\u001b[A\n",
      "Epoch 2:  81%|████████  | 2149/2645 [03:30<00:48, 10.31it/s, training_loss=0.408]\u001b[A\n",
      "Epoch 2:  81%|████████  | 2149/2645 [03:30<00:48, 10.31it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  81%|████████  | 2149/2645 [03:30<00:48, 10.31it/s, training_loss=0.530]\u001b[A\n",
      "Epoch 2:  81%|████████▏ | 2151/2645 [03:30<00:48, 10.22it/s, training_loss=0.530]\u001b[A\n",
      "Epoch 2:  81%|████████▏ | 2151/2645 [03:30<00:48, 10.22it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  81%|████████▏ | 2151/2645 [03:30<00:48, 10.22it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  81%|████████▏ | 2153/2645 [03:30<00:47, 10.34it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  81%|████████▏ | 2153/2645 [03:30<00:47, 10.34it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  81%|████████▏ | 2153/2645 [03:30<00:47, 10.34it/s, training_loss=0.055]\u001b[A\n",
      "Epoch 2:  81%|████████▏ | 2155/2645 [03:30<00:47, 10.37it/s, training_loss=0.055]\u001b[A\n",
      "Epoch 2:  81%|████████▏ | 2155/2645 [03:31<00:47, 10.37it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  81%|████████▏ | 2155/2645 [03:31<00:47, 10.37it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  82%|████████▏ | 2157/2645 [03:31<00:46, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  82%|████████▏ | 2157/2645 [03:31<00:46, 10.43it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  82%|████████▏ | 2157/2645 [03:31<00:46, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  82%|████████▏ | 2159/2645 [03:31<00:46, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  82%|████████▏ | 2159/2645 [03:31<00:46, 10.43it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 2:  82%|████████▏ | 2159/2645 [03:31<00:46, 10.43it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  82%|████████▏ | 2161/2645 [03:31<00:46, 10.41it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  82%|████████▏ | 2161/2645 [03:31<00:46, 10.41it/s, training_loss=0.341]\u001b[A\n",
      "Epoch 2:  82%|████████▏ | 2161/2645 [03:31<00:46, 10.41it/s, training_loss=0.209]\u001b[A\n",
      "Epoch 2:  82%|████████▏ | 2163/2645 [03:31<00:46, 10.40it/s, training_loss=0.209]\u001b[A\n",
      "Epoch 2:  82%|████████▏ | 2163/2645 [03:31<00:46, 10.40it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 2:  82%|████████▏ | 2163/2645 [03:31<00:46, 10.40it/s, training_loss=0.087]\u001b[A\n",
      "Epoch 2:  82%|████████▏ | 2165/2645 [03:31<00:46, 10.40it/s, training_loss=0.087]\u001b[A\n",
      "Epoch 2:  82%|████████▏ | 2165/2645 [03:32<00:46, 10.40it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  82%|████████▏ | 2165/2645 [03:32<00:46, 10.40it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  82%|████████▏ | 2167/2645 [03:32<00:46, 10.35it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  82%|████████▏ | 2167/2645 [03:32<00:46, 10.35it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  82%|████████▏ | 2167/2645 [03:32<00:46, 10.35it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  82%|████████▏ | 2169/2645 [03:32<00:46, 10.23it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  82%|████████▏ | 2169/2645 [03:32<00:46, 10.23it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  82%|████████▏ | 2169/2645 [03:32<00:46, 10.23it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  82%|████████▏ | 2171/2645 [03:32<00:46, 10.13it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  82%|████████▏ | 2171/2645 [03:32<00:46, 10.13it/s, training_loss=0.072]\u001b[A\n",
      "Epoch 2:  82%|████████▏ | 2171/2645 [03:32<00:46, 10.13it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  82%|████████▏ | 2173/2645 [03:32<00:46, 10.07it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  82%|████████▏ | 2173/2645 [03:32<00:46, 10.07it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  82%|████████▏ | 2173/2645 [03:32<00:46, 10.07it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  82%|████████▏ | 2175/2645 [03:32<00:46, 10.10it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  82%|████████▏ | 2175/2645 [03:32<00:46, 10.10it/s, training_loss=0.751]\u001b[A\n",
      "Epoch 2:  82%|████████▏ | 2175/2645 [03:33<00:46, 10.10it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  82%|████████▏ | 2177/2645 [03:33<00:46, 10.16it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  82%|████████▏ | 2177/2645 [03:33<00:46, 10.16it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  82%|████████▏ | 2177/2645 [03:33<00:46, 10.16it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  82%|████████▏ | 2179/2645 [03:33<00:46,  9.94it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  82%|████████▏ | 2179/2645 [03:33<00:46,  9.94it/s, training_loss=0.274]\u001b[A\n",
      "Epoch 2:  82%|████████▏ | 2180/2645 [03:33<00:47,  9.85it/s, training_loss=0.274]\u001b[A\n",
      "Epoch 2:  82%|████████▏ | 2180/2645 [03:33<00:47,  9.85it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  82%|████████▏ | 2181/2645 [03:33<00:46,  9.89it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  82%|████████▏ | 2181/2645 [03:33<00:46,  9.89it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  82%|████████▏ | 2181/2645 [03:33<00:46,  9.89it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  83%|████████▎ | 2183/2645 [03:33<00:46,  9.98it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  83%|████████▎ | 2183/2645 [03:33<00:46,  9.98it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  83%|████████▎ | 2184/2645 [03:33<00:46,  9.93it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  83%|████████▎ | 2184/2645 [03:33<00:46,  9.93it/s, training_loss=0.061]\u001b[A\n",
      "Epoch 2:  83%|████████▎ | 2185/2645 [03:33<00:46,  9.88it/s, training_loss=0.061]\u001b[A\n",
      "Epoch 2:  83%|████████▎ | 2185/2645 [03:34<00:46,  9.88it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  83%|████████▎ | 2185/2645 [03:34<00:46,  9.88it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  83%|████████▎ | 2187/2645 [03:34<00:45,  9.99it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  83%|████████▎ | 2187/2645 [03:34<00:45,  9.99it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  83%|████████▎ | 2187/2645 [03:34<00:45,  9.99it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  83%|████████▎ | 2189/2645 [03:34<00:45, 10.06it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  83%|████████▎ | 2189/2645 [03:34<00:45, 10.06it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  83%|████████▎ | 2189/2645 [03:34<00:45, 10.06it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  83%|████████▎ | 2191/2645 [03:34<00:44, 10.09it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  83%|████████▎ | 2191/2645 [03:34<00:44, 10.09it/s, training_loss=0.018]\u001b[A\n",
      "Epoch 2:  83%|████████▎ | 2191/2645 [03:34<00:44, 10.09it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  83%|████████▎ | 2193/2645 [03:34<00:44, 10.08it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  83%|████████▎ | 2193/2645 [03:34<00:44, 10.08it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  83%|████████▎ | 2193/2645 [03:34<00:44, 10.08it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  83%|████████▎ | 2195/2645 [03:34<00:44, 10.08it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  83%|████████▎ | 2195/2645 [03:34<00:44, 10.08it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  83%|████████▎ | 2195/2645 [03:35<00:44, 10.08it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  83%|████████▎ | 2197/2645 [03:35<00:44, 10.04it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  83%|████████▎ | 2197/2645 [03:35<00:44, 10.04it/s, training_loss=0.365]\u001b[A\n",
      "Epoch 2:  83%|████████▎ | 2197/2645 [03:35<00:44, 10.04it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  83%|████████▎ | 2199/2645 [03:35<00:45,  9.90it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  83%|████████▎ | 2199/2645 [03:35<00:45,  9.90it/s, training_loss=0.579]\u001b[A\n",
      "Epoch 2:  83%|████████▎ | 2199/2645 [03:35<00:45,  9.90it/s, training_loss=0.886]\u001b[A\n",
      "Epoch 2:  83%|████████▎ | 2201/2645 [03:35<00:44, 10.00it/s, training_loss=0.886]\u001b[A\n",
      "Epoch 2:  83%|████████▎ | 2201/2645 [03:35<00:44, 10.00it/s, training_loss=0.556]\u001b[A\n",
      "Epoch 2:  83%|████████▎ | 2201/2645 [03:35<00:44, 10.00it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  83%|████████▎ | 2203/2645 [03:35<00:43, 10.12it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  83%|████████▎ | 2203/2645 [03:35<00:43, 10.12it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  83%|████████▎ | 2203/2645 [03:35<00:43, 10.12it/s, training_loss=0.028]\u001b[A\n",
      "Epoch 2:  83%|████████▎ | 2205/2645 [03:35<00:43, 10.22it/s, training_loss=0.028]\u001b[A\n",
      "Epoch 2:  83%|████████▎ | 2205/2645 [03:35<00:43, 10.22it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  83%|████████▎ | 2205/2645 [03:36<00:43, 10.22it/s, training_loss=0.145]\u001b[A\n",
      "Epoch 2:  83%|████████▎ | 2207/2645 [03:36<00:42, 10.29it/s, training_loss=0.145]\u001b[A\n",
      "Epoch 2:  83%|████████▎ | 2207/2645 [03:36<00:42, 10.29it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  83%|████████▎ | 2207/2645 [03:36<00:42, 10.29it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  84%|████████▎ | 2209/2645 [03:36<00:42, 10.38it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  84%|████████▎ | 2209/2645 [03:36<00:42, 10.38it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  84%|████████▎ | 2209/2645 [03:36<00:42, 10.38it/s, training_loss=0.028]\u001b[A\n",
      "Epoch 2:  84%|████████▎ | 2211/2645 [03:36<00:41, 10.41it/s, training_loss=0.028]\u001b[A\n",
      "Epoch 2:  84%|████████▎ | 2211/2645 [03:36<00:41, 10.41it/s, training_loss=0.015]\u001b[A\n",
      "Epoch 2:  84%|████████▎ | 2211/2645 [03:36<00:41, 10.41it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  84%|████████▎ | 2213/2645 [03:36<00:41, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  84%|████████▎ | 2213/2645 [03:36<00:41, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  84%|████████▎ | 2213/2645 [03:36<00:41, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  84%|████████▎ | 2215/2645 [03:36<00:40, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  84%|████████▎ | 2215/2645 [03:36<00:40, 10.50it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  84%|████████▎ | 2215/2645 [03:37<00:40, 10.50it/s, training_loss=1.577]\u001b[A\n",
      "Epoch 2:  84%|████████▍ | 2217/2645 [03:37<00:40, 10.45it/s, training_loss=1.577]\u001b[A\n",
      "Epoch 2:  84%|████████▍ | 2217/2645 [03:37<00:40, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  84%|████████▍ | 2217/2645 [03:37<00:40, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  84%|████████▍ | 2219/2645 [03:37<00:40, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  84%|████████▍ | 2219/2645 [03:37<00:40, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  84%|████████▍ | 2219/2645 [03:37<00:40, 10.49it/s, training_loss=0.318]\u001b[A\n",
      "Epoch 2:  84%|████████▍ | 2221/2645 [03:37<00:40, 10.46it/s, training_loss=0.318]\u001b[A\n",
      "Epoch 2:  84%|████████▍ | 2221/2645 [03:37<00:40, 10.46it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  84%|████████▍ | 2221/2645 [03:37<00:40, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  84%|████████▍ | 2223/2645 [03:37<00:40, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  84%|████████▍ | 2223/2645 [03:37<00:40, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  84%|████████▍ | 2223/2645 [03:37<00:40, 10.49it/s, training_loss=0.063]\u001b[A\n",
      "Epoch 2:  84%|████████▍ | 2225/2645 [03:37<00:40, 10.50it/s, training_loss=0.063]\u001b[A\n",
      "Epoch 2:  84%|████████▍ | 2225/2645 [03:37<00:40, 10.50it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  84%|████████▍ | 2225/2645 [03:37<00:40, 10.50it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  84%|████████▍ | 2227/2645 [03:37<00:39, 10.51it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  84%|████████▍ | 2227/2645 [03:38<00:39, 10.51it/s, training_loss=0.678]\u001b[A\n",
      "Epoch 2:  84%|████████▍ | 2227/2645 [03:38<00:39, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  84%|████████▍ | 2229/2645 [03:38<00:39, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  84%|████████▍ | 2229/2645 [03:38<00:39, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  84%|████████▍ | 2229/2645 [03:38<00:39, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  84%|████████▍ | 2231/2645 [03:38<00:39, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  84%|████████▍ | 2231/2645 [03:38<00:39, 10.52it/s, training_loss=0.842]\u001b[A\n",
      "Epoch 2:  84%|████████▍ | 2231/2645 [03:38<00:39, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  84%|████████▍ | 2233/2645 [03:38<00:39, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  84%|████████▍ | 2233/2645 [03:38<00:39, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  84%|████████▍ | 2233/2645 [03:38<00:39, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  84%|████████▍ | 2235/2645 [03:38<00:39, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  84%|████████▍ | 2235/2645 [03:38<00:39, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  84%|████████▍ | 2235/2645 [03:38<00:39, 10.50it/s, training_loss=0.012]\u001b[A\n",
      "Epoch 2:  85%|████████▍ | 2237/2645 [03:38<00:38, 10.49it/s, training_loss=0.012]\u001b[A\n",
      "Epoch 2:  85%|████████▍ | 2237/2645 [03:39<00:38, 10.49it/s, training_loss=0.768]\u001b[A\n",
      "Epoch 2:  85%|████████▍ | 2237/2645 [03:39<00:38, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  85%|████████▍ | 2239/2645 [03:39<00:38, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  85%|████████▍ | 2239/2645 [03:39<00:38, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  85%|████████▍ | 2239/2645 [03:39<00:38, 10.48it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  85%|████████▍ | 2241/2645 [03:39<00:38, 10.51it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  85%|████████▍ | 2241/2645 [03:39<00:38, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  85%|████████▍ | 2241/2645 [03:39<00:38, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  85%|████████▍ | 2243/2645 [03:39<00:38, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  85%|████████▍ | 2243/2645 [03:39<00:38, 10.51it/s, training_loss=0.548]\u001b[A\n",
      "Epoch 2:  85%|████████▍ | 2243/2645 [03:39<00:38, 10.51it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  85%|████████▍ | 2245/2645 [03:39<00:38, 10.47it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  85%|████████▍ | 2245/2645 [03:39<00:38, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  85%|████████▍ | 2245/2645 [03:39<00:38, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  85%|████████▍ | 2247/2645 [03:39<00:37, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  85%|████████▍ | 2247/2645 [03:39<00:37, 10.48it/s, training_loss=0.489]\u001b[A\n",
      "Epoch 2:  85%|████████▍ | 2247/2645 [03:40<00:37, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  85%|████████▌ | 2249/2645 [03:40<00:37, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  85%|████████▌ | 2249/2645 [03:40<00:37, 10.47it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  85%|████████▌ | 2249/2645 [03:40<00:37, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  85%|████████▌ | 2251/2645 [03:40<00:37, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  85%|████████▌ | 2251/2645 [03:40<00:37, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  85%|████████▌ | 2251/2645 [03:40<00:37, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  85%|████████▌ | 2253/2645 [03:40<00:37, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  85%|████████▌ | 2253/2645 [03:40<00:37, 10.52it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  85%|████████▌ | 2253/2645 [03:40<00:37, 10.52it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  85%|████████▌ | 2255/2645 [03:40<00:36, 10.55it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  85%|████████▌ | 2255/2645 [03:40<00:36, 10.55it/s, training_loss=0.911]\u001b[A\n",
      "Epoch 2:  85%|████████▌ | 2255/2645 [03:40<00:36, 10.55it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  85%|████████▌ | 2257/2645 [03:40<00:36, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  85%|████████▌ | 2257/2645 [03:40<00:36, 10.52it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  85%|████████▌ | 2257/2645 [03:41<00:36, 10.52it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  85%|████████▌ | 2259/2645 [03:41<00:36, 10.44it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  85%|████████▌ | 2259/2645 [03:41<00:36, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  85%|████████▌ | 2259/2645 [03:41<00:36, 10.44it/s, training_loss=0.835]\u001b[A\n",
      "Epoch 2:  85%|████████▌ | 2261/2645 [03:41<00:36, 10.40it/s, training_loss=0.835]\u001b[A\n",
      "Epoch 2:  85%|████████▌ | 2261/2645 [03:41<00:36, 10.40it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  85%|████████▌ | 2261/2645 [03:41<00:36, 10.40it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  86%|████████▌ | 2263/2645 [03:41<00:36, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  86%|████████▌ | 2263/2645 [03:41<00:36, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  86%|████████▌ | 2263/2645 [03:41<00:36, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  86%|████████▌ | 2265/2645 [03:41<00:36, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  86%|████████▌ | 2265/2645 [03:41<00:36, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  86%|████████▌ | 2265/2645 [03:41<00:36, 10.45it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  86%|████████▌ | 2267/2645 [03:41<00:36, 10.36it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  86%|████████▌ | 2267/2645 [03:41<00:36, 10.36it/s, training_loss=0.133]\u001b[A\n",
      "Epoch 2:  86%|████████▌ | 2267/2645 [03:42<00:36, 10.36it/s, training_loss=0.012]\u001b[A\n",
      "Epoch 2:  86%|████████▌ | 2269/2645 [03:42<00:36, 10.19it/s, training_loss=0.012]\u001b[A\n",
      "Epoch 2:  86%|████████▌ | 2269/2645 [03:42<00:36, 10.19it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  86%|████████▌ | 2269/2645 [03:42<00:36, 10.19it/s, training_loss=0.049]\u001b[A\n",
      "Epoch 2:  86%|████████▌ | 2271/2645 [03:42<00:36, 10.27it/s, training_loss=0.049]\u001b[A\n",
      "Epoch 2:  86%|████████▌ | 2271/2645 [03:42<00:36, 10.27it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  86%|████████▌ | 2271/2645 [03:42<00:36, 10.27it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  86%|████████▌ | 2273/2645 [03:42<00:35, 10.37it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  86%|████████▌ | 2273/2645 [03:42<00:35, 10.37it/s, training_loss=1.249]\u001b[A\n",
      "Epoch 2:  86%|████████▌ | 2273/2645 [03:42<00:35, 10.37it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  86%|████████▌ | 2275/2645 [03:42<00:35, 10.38it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  86%|████████▌ | 2275/2645 [03:42<00:35, 10.38it/s, training_loss=0.974]\u001b[A\n",
      "Epoch 2:  86%|████████▌ | 2275/2645 [03:42<00:35, 10.38it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  86%|████████▌ | 2277/2645 [03:42<00:35, 10.35it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  86%|████████▌ | 2277/2645 [03:42<00:35, 10.35it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  86%|████████▌ | 2277/2645 [03:42<00:35, 10.35it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  86%|████████▌ | 2279/2645 [03:42<00:35, 10.27it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  86%|████████▌ | 2279/2645 [03:43<00:35, 10.27it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  86%|████████▌ | 2279/2645 [03:43<00:35, 10.27it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  86%|████████▌ | 2281/2645 [03:43<00:35, 10.29it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  86%|████████▌ | 2281/2645 [03:43<00:35, 10.29it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  86%|████████▌ | 2281/2645 [03:43<00:35, 10.29it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  86%|████████▋ | 2283/2645 [03:43<00:35, 10.31it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  86%|████████▋ | 2283/2645 [03:43<00:35, 10.31it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  86%|████████▋ | 2283/2645 [03:43<00:35, 10.31it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  86%|████████▋ | 2285/2645 [03:43<00:35, 10.25it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  86%|████████▋ | 2285/2645 [03:43<00:35, 10.25it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  86%|████████▋ | 2285/2645 [03:43<00:35, 10.25it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  86%|████████▋ | 2287/2645 [03:43<00:35, 10.22it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  86%|████████▋ | 2287/2645 [03:43<00:35, 10.22it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  86%|████████▋ | 2287/2645 [03:43<00:35, 10.22it/s, training_loss=0.751]\u001b[A\n",
      "Epoch 2:  87%|████████▋ | 2289/2645 [03:43<00:35, 10.16it/s, training_loss=0.751]\u001b[A\n",
      "Epoch 2:  87%|████████▋ | 2289/2645 [03:44<00:35, 10.16it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  87%|████████▋ | 2289/2645 [03:44<00:35, 10.16it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  87%|████████▋ | 2291/2645 [03:44<00:34, 10.22it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  87%|████████▋ | 2291/2645 [03:44<00:34, 10.22it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  87%|████████▋ | 2291/2645 [03:44<00:34, 10.22it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  87%|████████▋ | 2293/2645 [03:44<00:34, 10.33it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  87%|████████▋ | 2293/2645 [03:44<00:34, 10.33it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  87%|████████▋ | 2293/2645 [03:44<00:34, 10.33it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  87%|████████▋ | 2295/2645 [03:44<00:34, 10.20it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  87%|████████▋ | 2295/2645 [03:44<00:34, 10.20it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  87%|████████▋ | 2295/2645 [03:44<00:34, 10.20it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  87%|████████▋ | 2297/2645 [03:44<00:33, 10.25it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  87%|████████▋ | 2297/2645 [03:44<00:33, 10.25it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  87%|████████▋ | 2297/2645 [03:44<00:33, 10.25it/s, training_loss=0.607]\u001b[A\n",
      "Epoch 2:  87%|████████▋ | 2299/2645 [03:44<00:33, 10.27it/s, training_loss=0.607]\u001b[A\n",
      "Epoch 2:  87%|████████▋ | 2299/2645 [03:45<00:33, 10.27it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  87%|████████▋ | 2299/2645 [03:45<00:33, 10.27it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  87%|████████▋ | 2301/2645 [03:45<00:33, 10.18it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  87%|████████▋ | 2301/2645 [03:45<00:33, 10.18it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  87%|████████▋ | 2301/2645 [03:45<00:33, 10.18it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  87%|████████▋ | 2303/2645 [03:45<00:33, 10.25it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  87%|████████▋ | 2303/2645 [03:45<00:33, 10.25it/s, training_loss=0.789]\u001b[A\n",
      "Epoch 2:  87%|████████▋ | 2303/2645 [03:45<00:33, 10.25it/s, training_loss=0.251]\u001b[A\n",
      "Epoch 2:  87%|████████▋ | 2305/2645 [03:45<00:33, 10.17it/s, training_loss=0.251]\u001b[A\n",
      "Epoch 2:  87%|████████▋ | 2305/2645 [03:45<00:33, 10.17it/s, training_loss=0.919]\u001b[A\n",
      "Epoch 2:  87%|████████▋ | 2305/2645 [03:45<00:33, 10.17it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  87%|████████▋ | 2307/2645 [03:45<00:33, 10.17it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  87%|████████▋ | 2307/2645 [03:45<00:33, 10.17it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  87%|████████▋ | 2307/2645 [03:45<00:33, 10.17it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  87%|████████▋ | 2309/2645 [03:45<00:33, 10.09it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  87%|████████▋ | 2309/2645 [03:46<00:33, 10.09it/s, training_loss=0.539]\u001b[A\n",
      "Epoch 2:  87%|████████▋ | 2309/2645 [03:46<00:33, 10.09it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  87%|████████▋ | 2311/2645 [03:46<00:33, 10.03it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  87%|████████▋ | 2311/2645 [03:46<00:33, 10.03it/s, training_loss=0.898]\u001b[A\n",
      "Epoch 2:  87%|████████▋ | 2311/2645 [03:46<00:33, 10.03it/s, training_loss=0.261]\u001b[A\n",
      "Epoch 2:  87%|████████▋ | 2313/2645 [03:46<00:33,  9.98it/s, training_loss=0.261]\u001b[A\n",
      "Epoch 2:  87%|████████▋ | 2313/2645 [03:46<00:33,  9.98it/s, training_loss=0.063]\u001b[A\n",
      "Epoch 2:  87%|████████▋ | 2314/2645 [03:46<00:33,  9.94it/s, training_loss=0.063]\u001b[A\n",
      "Epoch 2:  87%|████████▋ | 2314/2645 [03:46<00:33,  9.94it/s, training_loss=0.747]\u001b[A\n",
      "Epoch 2:  88%|████████▊ | 2315/2645 [03:46<00:33,  9.93it/s, training_loss=0.747]\u001b[A\n",
      "Epoch 2:  88%|████████▊ | 2315/2645 [03:46<00:33,  9.93it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  88%|████████▊ | 2315/2645 [03:46<00:33,  9.93it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  88%|████████▊ | 2317/2645 [03:46<00:32,  9.97it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  88%|████████▊ | 2317/2645 [03:46<00:32,  9.97it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  88%|████████▊ | 2318/2645 [03:46<00:32,  9.92it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  88%|████████▊ | 2318/2645 [03:46<00:32,  9.92it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  88%|████████▊ | 2318/2645 [03:47<00:32,  9.92it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  88%|████████▊ | 2320/2645 [03:47<00:32, 10.02it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  88%|████████▊ | 2320/2645 [03:47<00:32, 10.02it/s, training_loss=0.805]\u001b[A\n",
      "Epoch 2:  88%|████████▊ | 2320/2645 [03:47<00:32, 10.02it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  88%|████████▊ | 2322/2645 [03:47<00:31, 10.11it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  88%|████████▊ | 2322/2645 [03:47<00:31, 10.11it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  88%|████████▊ | 2322/2645 [03:47<00:31, 10.11it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  88%|████████▊ | 2324/2645 [03:47<00:31, 10.04it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  88%|████████▊ | 2324/2645 [03:47<00:31, 10.04it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  88%|████████▊ | 2324/2645 [03:47<00:31, 10.04it/s, training_loss=0.192]\u001b[A\n",
      "Epoch 2:  88%|████████▊ | 2326/2645 [03:47<00:31, 10.00it/s, training_loss=0.192]\u001b[A\n",
      "Epoch 2:  88%|████████▊ | 2326/2645 [03:47<00:31, 10.00it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  88%|████████▊ | 2326/2645 [03:47<00:31, 10.00it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  88%|████████▊ | 2328/2645 [03:47<00:32,  9.78it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  88%|████████▊ | 2328/2645 [03:47<00:32,  9.78it/s, training_loss=0.735]\u001b[A\n",
      "Epoch 2:  88%|████████▊ | 2329/2645 [03:47<00:32,  9.81it/s, training_loss=0.735]\u001b[A\n",
      "Epoch 2:  88%|████████▊ | 2329/2645 [03:48<00:32,  9.81it/s, training_loss=0.579]\u001b[A\n",
      "Epoch 2:  88%|████████▊ | 2330/2645 [03:48<00:31,  9.85it/s, training_loss=0.579]\u001b[A\n",
      "Epoch 2:  88%|████████▊ | 2330/2645 [03:48<00:31,  9.85it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  88%|████████▊ | 2330/2645 [03:48<00:31,  9.85it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  88%|████████▊ | 2332/2645 [03:48<00:31,  9.91it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  88%|████████▊ | 2332/2645 [03:48<00:31,  9.91it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  88%|████████▊ | 2333/2645 [03:48<00:31,  9.92it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  88%|████████▊ | 2333/2645 [03:48<00:31,  9.92it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  88%|████████▊ | 2334/2645 [03:48<00:31,  9.86it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  88%|████████▊ | 2334/2645 [03:48<00:31,  9.86it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  88%|████████▊ | 2334/2645 [03:48<00:31,  9.86it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  88%|████████▊ | 2336/2645 [03:48<00:31,  9.88it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  88%|████████▊ | 2336/2645 [03:48<00:31,  9.88it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  88%|████████▊ | 2336/2645 [03:48<00:31,  9.88it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  88%|████████▊ | 2338/2645 [03:48<00:30, 10.03it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  88%|████████▊ | 2338/2645 [03:48<00:30, 10.03it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  88%|████████▊ | 2338/2645 [03:49<00:30, 10.03it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  88%|████████▊ | 2340/2645 [03:49<00:29, 10.19it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  88%|████████▊ | 2340/2645 [03:49<00:29, 10.19it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  88%|████████▊ | 2340/2645 [03:49<00:29, 10.19it/s, training_loss=0.016]\u001b[A\n",
      "Epoch 2:  89%|████████▊ | 2342/2645 [03:49<00:29, 10.25it/s, training_loss=0.016]\u001b[A\n",
      "Epoch 2:  89%|████████▊ | 2342/2645 [03:49<00:29, 10.25it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  89%|████████▊ | 2342/2645 [03:49<00:29, 10.25it/s, training_loss=0.791]\u001b[A\n",
      "Epoch 2:  89%|████████▊ | 2344/2645 [03:49<00:29, 10.29it/s, training_loss=0.791]\u001b[A\n",
      "Epoch 2:  89%|████████▊ | 2344/2645 [03:49<00:29, 10.29it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  89%|████████▊ | 2344/2645 [03:49<00:29, 10.29it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  89%|████████▊ | 2346/2645 [03:49<00:28, 10.34it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  89%|████████▊ | 2346/2645 [03:49<00:28, 10.34it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  89%|████████▊ | 2346/2645 [03:49<00:28, 10.34it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  89%|████████▉ | 2348/2645 [03:49<00:28, 10.41it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  89%|████████▉ | 2348/2645 [03:49<00:28, 10.41it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  89%|████████▉ | 2348/2645 [03:49<00:28, 10.41it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  89%|████████▉ | 2350/2645 [03:49<00:28, 10.48it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  89%|████████▉ | 2350/2645 [03:50<00:28, 10.48it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  89%|████████▉ | 2350/2645 [03:50<00:28, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  89%|████████▉ | 2352/2645 [03:50<00:27, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  89%|████████▉ | 2352/2645 [03:50<00:27, 10.52it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  89%|████████▉ | 2352/2645 [03:50<00:27, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  89%|████████▉ | 2354/2645 [03:50<00:27, 10.54it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  89%|████████▉ | 2354/2645 [03:50<00:27, 10.54it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  89%|████████▉ | 2354/2645 [03:50<00:27, 10.54it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  89%|████████▉ | 2356/2645 [03:50<00:27, 10.54it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  89%|████████▉ | 2356/2645 [03:50<00:27, 10.54it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  89%|████████▉ | 2356/2645 [03:50<00:27, 10.54it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  89%|████████▉ | 2358/2645 [03:50<00:27, 10.55it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  89%|████████▉ | 2358/2645 [03:50<00:27, 10.55it/s, training_loss=0.921]\u001b[A\n",
      "Epoch 2:  89%|████████▉ | 2358/2645 [03:50<00:27, 10.55it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  89%|████████▉ | 2360/2645 [03:50<00:27, 10.42it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  89%|████████▉ | 2360/2645 [03:51<00:27, 10.42it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  89%|████████▉ | 2360/2645 [03:51<00:27, 10.42it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  89%|████████▉ | 2362/2645 [03:51<00:27, 10.42it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  89%|████████▉ | 2362/2645 [03:51<00:27, 10.42it/s, training_loss=0.222]\u001b[A\n",
      "Epoch 2:  89%|████████▉ | 2362/2645 [03:51<00:27, 10.42it/s, training_loss=0.616]\u001b[A\n",
      "Epoch 2:  89%|████████▉ | 2364/2645 [03:51<00:27, 10.27it/s, training_loss=0.616]\u001b[A\n",
      "Epoch 2:  89%|████████▉ | 2364/2645 [03:51<00:27, 10.27it/s, training_loss=0.015]\u001b[A\n",
      "Epoch 2:  89%|████████▉ | 2364/2645 [03:51<00:27, 10.27it/s, training_loss=0.712]\u001b[A\n",
      "Epoch 2:  89%|████████▉ | 2366/2645 [03:51<00:27, 10.18it/s, training_loss=0.712]\u001b[A\n",
      "Epoch 2:  89%|████████▉ | 2366/2645 [03:51<00:27, 10.18it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  89%|████████▉ | 2366/2645 [03:51<00:27, 10.18it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  90%|████████▉ | 2368/2645 [03:51<00:27, 10.21it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  90%|████████▉ | 2368/2645 [03:51<00:27, 10.21it/s, training_loss=1.550]\u001b[A\n",
      "Epoch 2:  90%|████████▉ | 2368/2645 [03:51<00:27, 10.21it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  90%|████████▉ | 2370/2645 [03:51<00:26, 10.30it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  90%|████████▉ | 2370/2645 [03:51<00:26, 10.30it/s, training_loss=0.722]\u001b[A\n",
      "Epoch 2:  90%|████████▉ | 2370/2645 [03:52<00:26, 10.30it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  90%|████████▉ | 2372/2645 [03:52<00:26, 10.36it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  90%|████████▉ | 2372/2645 [03:52<00:26, 10.36it/s, training_loss=0.156]\u001b[A\n",
      "Epoch 2:  90%|████████▉ | 2372/2645 [03:52<00:26, 10.36it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  90%|████████▉ | 2374/2645 [03:52<00:26, 10.39it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  90%|████████▉ | 2374/2645 [03:52<00:26, 10.39it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  90%|████████▉ | 2374/2645 [03:52<00:26, 10.39it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  90%|████████▉ | 2376/2645 [03:52<00:25, 10.45it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  90%|████████▉ | 2376/2645 [03:52<00:25, 10.45it/s, training_loss=0.012]\u001b[A\n",
      "Epoch 2:  90%|████████▉ | 2376/2645 [03:52<00:25, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  90%|████████▉ | 2378/2645 [03:52<00:25, 10.42it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  90%|████████▉ | 2378/2645 [03:52<00:25, 10.42it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  90%|████████▉ | 2378/2645 [03:52<00:25, 10.42it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  90%|████████▉ | 2380/2645 [03:52<00:25, 10.47it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  90%|████████▉ | 2380/2645 [03:52<00:25, 10.47it/s, training_loss=0.061]\u001b[A\n",
      "Epoch 2:  90%|████████▉ | 2380/2645 [03:53<00:25, 10.47it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  90%|█████████ | 2382/2645 [03:53<00:25, 10.45it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  90%|█████████ | 2382/2645 [03:53<00:25, 10.45it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  90%|█████████ | 2382/2645 [03:53<00:25, 10.45it/s, training_loss=0.228]\u001b[A\n",
      "Epoch 2:  90%|█████████ | 2384/2645 [03:53<00:24, 10.45it/s, training_loss=0.228]\u001b[A\n",
      "Epoch 2:  90%|█████████ | 2384/2645 [03:53<00:24, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  90%|█████████ | 2384/2645 [03:53<00:24, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  90%|█████████ | 2386/2645 [03:53<00:24, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  90%|█████████ | 2386/2645 [03:53<00:24, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  90%|█████████ | 2386/2645 [03:53<00:24, 10.48it/s, training_loss=0.296]\u001b[A\n",
      "Epoch 2:  90%|█████████ | 2388/2645 [03:53<00:24, 10.47it/s, training_loss=0.296]\u001b[A\n",
      "Epoch 2:  90%|█████████ | 2388/2645 [03:53<00:24, 10.47it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 2:  90%|█████████ | 2388/2645 [03:53<00:24, 10.47it/s, training_loss=0.141]\u001b[A\n",
      "Epoch 2:  90%|█████████ | 2390/2645 [03:53<00:24, 10.43it/s, training_loss=0.141]\u001b[A\n",
      "Epoch 2:  90%|█████████ | 2390/2645 [03:53<00:24, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  90%|█████████ | 2390/2645 [03:53<00:24, 10.43it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  90%|█████████ | 2392/2645 [03:54<00:24, 10.44it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  90%|█████████ | 2392/2645 [03:54<00:24, 10.44it/s, training_loss=0.012]\u001b[A\n",
      "Epoch 2:  90%|█████████ | 2392/2645 [03:54<00:24, 10.44it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  91%|█████████ | 2394/2645 [03:54<00:24, 10.43it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  91%|█████████ | 2394/2645 [03:54<00:24, 10.43it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  91%|█████████ | 2394/2645 [03:54<00:24, 10.43it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  91%|█████████ | 2396/2645 [03:54<00:23, 10.39it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  91%|█████████ | 2396/2645 [03:54<00:23, 10.39it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  91%|█████████ | 2396/2645 [03:54<00:23, 10.39it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  91%|█████████ | 2398/2645 [03:54<00:24, 10.21it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  91%|█████████ | 2398/2645 [03:54<00:24, 10.21it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  91%|█████████ | 2398/2645 [03:54<00:24, 10.21it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  91%|█████████ | 2400/2645 [03:54<00:23, 10.32it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  91%|█████████ | 2400/2645 [03:54<00:23, 10.32it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  91%|█████████ | 2400/2645 [03:54<00:23, 10.32it/s, training_loss=0.065]\u001b[A\n",
      "Epoch 2:  91%|█████████ | 2402/2645 [03:54<00:23, 10.37it/s, training_loss=0.065]\u001b[A\n",
      "Epoch 2:  91%|█████████ | 2402/2645 [03:55<00:23, 10.37it/s, training_loss=0.568]\u001b[A\n",
      "Epoch 2:  91%|█████████ | 2402/2645 [03:55<00:23, 10.37it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 2:  91%|█████████ | 2404/2645 [03:55<00:23, 10.37it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 2:  91%|█████████ | 2404/2645 [03:55<00:23, 10.37it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  91%|█████████ | 2404/2645 [03:55<00:23, 10.37it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  91%|█████████ | 2406/2645 [03:55<00:22, 10.43it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  91%|█████████ | 2406/2645 [03:55<00:22, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  91%|█████████ | 2406/2645 [03:55<00:22, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  91%|█████████ | 2408/2645 [03:55<00:22, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  91%|█████████ | 2408/2645 [03:55<00:22, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  91%|█████████ | 2408/2645 [03:55<00:22, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  91%|█████████ | 2410/2645 [03:55<00:22, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  91%|█████████ | 2410/2645 [03:55<00:22, 10.50it/s, training_loss=0.255]\u001b[A\n",
      "Epoch 2:  91%|█████████ | 2410/2645 [03:55<00:22, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  91%|█████████ | 2412/2645 [03:55<00:22, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  91%|█████████ | 2412/2645 [03:56<00:22, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  91%|█████████ | 2412/2645 [03:56<00:22, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  91%|█████████▏| 2414/2645 [03:56<00:21, 10.54it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  91%|█████████▏| 2414/2645 [03:56<00:21, 10.54it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  91%|█████████▏| 2414/2645 [03:56<00:21, 10.54it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  91%|█████████▏| 2416/2645 [03:56<00:21, 10.53it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  91%|█████████▏| 2416/2645 [03:56<00:21, 10.53it/s, training_loss=0.590]\u001b[A\n",
      "Epoch 2:  91%|█████████▏| 2416/2645 [03:56<00:21, 10.53it/s, training_loss=0.164]\u001b[A\n",
      "Epoch 2:  91%|█████████▏| 2418/2645 [03:56<00:21, 10.45it/s, training_loss=0.164]\u001b[A\n",
      "Epoch 2:  91%|█████████▏| 2418/2645 [03:56<00:21, 10.45it/s, training_loss=0.876]\u001b[A\n",
      "Epoch 2:  91%|█████████▏| 2418/2645 [03:56<00:21, 10.45it/s, training_loss=0.722]\u001b[A\n",
      "Epoch 2:  91%|█████████▏| 2420/2645 [03:56<00:21, 10.39it/s, training_loss=0.722]\u001b[A\n",
      "Epoch 2:  91%|█████████▏| 2420/2645 [03:56<00:21, 10.39it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  91%|█████████▏| 2420/2645 [03:56<00:21, 10.39it/s, training_loss=0.022]\u001b[A\n",
      "Epoch 2:  92%|█████████▏| 2422/2645 [03:56<00:22, 10.05it/s, training_loss=0.022]\u001b[A\n",
      "Epoch 2:  92%|█████████▏| 2422/2645 [03:56<00:22, 10.05it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  92%|█████████▏| 2422/2645 [03:57<00:22, 10.05it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  92%|█████████▏| 2424/2645 [03:57<00:21, 10.20it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  92%|█████████▏| 2424/2645 [03:57<00:21, 10.20it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  92%|█████████▏| 2424/2645 [03:57<00:21, 10.20it/s, training_loss=0.236]\u001b[A\n",
      "Epoch 2:  92%|█████████▏| 2426/2645 [03:57<00:21, 10.29it/s, training_loss=0.236]\u001b[A\n",
      "Epoch 2:  92%|█████████▏| 2426/2645 [03:57<00:21, 10.29it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  92%|█████████▏| 2426/2645 [03:57<00:21, 10.29it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  92%|█████████▏| 2428/2645 [03:57<00:20, 10.37it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  92%|█████████▏| 2428/2645 [03:57<00:20, 10.37it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  92%|█████████▏| 2428/2645 [03:57<00:20, 10.37it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  92%|█████████▏| 2430/2645 [03:57<00:20, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  92%|█████████▏| 2430/2645 [03:57<00:20, 10.44it/s, training_loss=0.059]\u001b[A\n",
      "Epoch 2:  92%|█████████▏| 2430/2645 [03:57<00:20, 10.44it/s, training_loss=0.017]\u001b[A\n",
      "Epoch 2:  92%|█████████▏| 2432/2645 [03:57<00:20, 10.42it/s, training_loss=0.017]\u001b[A\n",
      "Epoch 2:  92%|█████████▏| 2432/2645 [03:57<00:20, 10.42it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  92%|█████████▏| 2432/2645 [03:58<00:20, 10.42it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  92%|█████████▏| 2434/2645 [03:58<00:20, 10.45it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  92%|█████████▏| 2434/2645 [03:58<00:20, 10.45it/s, training_loss=0.797]\u001b[A\n",
      "Epoch 2:  92%|█████████▏| 2434/2645 [03:58<00:20, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  92%|█████████▏| 2436/2645 [03:58<00:19, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  92%|█████████▏| 2436/2645 [03:58<00:19, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  92%|█████████▏| 2436/2645 [03:58<00:19, 10.46it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  92%|█████████▏| 2438/2645 [03:58<00:19, 10.51it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  92%|█████████▏| 2438/2645 [03:58<00:19, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  92%|█████████▏| 2438/2645 [03:58<00:19, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  92%|█████████▏| 2440/2645 [03:58<00:19, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  92%|█████████▏| 2440/2645 [03:58<00:19, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  92%|█████████▏| 2440/2645 [03:58<00:19, 10.52it/s, training_loss=0.754]\u001b[A\n",
      "Epoch 2:  92%|█████████▏| 2442/2645 [03:58<00:19, 10.52it/s, training_loss=0.754]\u001b[A\n",
      "Epoch 2:  92%|█████████▏| 2442/2645 [03:58<00:19, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  92%|█████████▏| 2442/2645 [03:58<00:19, 10.52it/s, training_loss=0.395]\u001b[A\n",
      "Epoch 2:  92%|█████████▏| 2444/2645 [03:58<00:19, 10.51it/s, training_loss=0.395]\u001b[A\n",
      "Epoch 2:  92%|█████████▏| 2444/2645 [03:59<00:19, 10.51it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  92%|█████████▏| 2444/2645 [03:59<00:19, 10.51it/s, training_loss=0.878]\u001b[A\n",
      "Epoch 2:  92%|█████████▏| 2446/2645 [03:59<00:19, 10.43it/s, training_loss=0.878]\u001b[A\n",
      "Epoch 2:  92%|█████████▏| 2446/2645 [03:59<00:19, 10.43it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  92%|█████████▏| 2446/2645 [03:59<00:19, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  93%|█████████▎| 2448/2645 [03:59<00:18, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  93%|█████████▎| 2448/2645 [03:59<00:18, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  93%|█████████▎| 2448/2645 [03:59<00:18, 10.46it/s, training_loss=1.046]\u001b[A\n",
      "Epoch 2:  93%|█████████▎| 2450/2645 [03:59<00:18, 10.46it/s, training_loss=1.046]\u001b[A\n",
      "Epoch 2:  93%|█████████▎| 2450/2645 [03:59<00:18, 10.46it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  93%|█████████▎| 2450/2645 [03:59<00:18, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  93%|█████████▎| 2452/2645 [03:59<00:18, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  93%|█████████▎| 2452/2645 [03:59<00:18, 10.49it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  93%|█████████▎| 2452/2645 [03:59<00:18, 10.49it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  93%|█████████▎| 2454/2645 [03:59<00:18, 10.47it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  93%|█████████▎| 2454/2645 [04:00<00:18, 10.47it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  93%|█████████▎| 2454/2645 [04:00<00:18, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  93%|█████████▎| 2456/2645 [04:00<00:17, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  93%|█████████▎| 2456/2645 [04:00<00:17, 10.51it/s, training_loss=0.028]\u001b[A\n",
      "Epoch 2:  93%|█████████▎| 2456/2645 [04:00<00:17, 10.51it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  93%|█████████▎| 2458/2645 [04:00<00:17, 10.51it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  93%|█████████▎| 2458/2645 [04:00<00:17, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  93%|█████████▎| 2458/2645 [04:00<00:17, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  93%|█████████▎| 2460/2645 [04:00<00:17, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  93%|█████████▎| 2460/2645 [04:00<00:17, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  93%|█████████▎| 2460/2645 [04:00<00:17, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  93%|█████████▎| 2462/2645 [04:00<00:17, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  93%|█████████▎| 2462/2645 [04:00<00:17, 10.52it/s, training_loss=0.068]\u001b[A\n",
      "Epoch 2:  93%|█████████▎| 2462/2645 [04:00<00:17, 10.52it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  93%|█████████▎| 2464/2645 [04:00<00:17, 10.50it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  93%|█████████▎| 2464/2645 [04:00<00:17, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  93%|█████████▎| 2464/2645 [04:01<00:17, 10.50it/s, training_loss=0.015]\u001b[A\n",
      "Epoch 2:  93%|█████████▎| 2466/2645 [04:01<00:17, 10.51it/s, training_loss=0.015]\u001b[A\n",
      "Epoch 2:  93%|█████████▎| 2466/2645 [04:01<00:17, 10.51it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  93%|█████████▎| 2466/2645 [04:01<00:17, 10.51it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  93%|█████████▎| 2468/2645 [04:01<00:16, 10.50it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  93%|█████████▎| 2468/2645 [04:01<00:16, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  93%|█████████▎| 2468/2645 [04:01<00:16, 10.50it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  93%|█████████▎| 2470/2645 [04:01<00:16, 10.38it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  93%|█████████▎| 2470/2645 [04:01<00:16, 10.38it/s, training_loss=0.718]\u001b[A\n",
      "Epoch 2:  93%|█████████▎| 2470/2645 [04:01<00:16, 10.38it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  93%|█████████▎| 2472/2645 [04:01<00:16, 10.40it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  93%|█████████▎| 2472/2645 [04:01<00:16, 10.40it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  93%|█████████▎| 2472/2645 [04:01<00:16, 10.40it/s, training_loss=0.749]\u001b[A\n",
      "Epoch 2:  94%|█████████▎| 2474/2645 [04:01<00:16, 10.43it/s, training_loss=0.749]\u001b[A\n",
      "Epoch 2:  94%|█████████▎| 2474/2645 [04:01<00:16, 10.43it/s, training_loss=1.103]\u001b[A\n",
      "Epoch 2:  94%|█████████▎| 2474/2645 [04:02<00:16, 10.43it/s, training_loss=0.796]\u001b[A\n",
      "Epoch 2:  94%|█████████▎| 2476/2645 [04:02<00:16, 10.26it/s, training_loss=0.796]\u001b[A\n",
      "Epoch 2:  94%|█████████▎| 2476/2645 [04:02<00:16, 10.26it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  94%|█████████▎| 2476/2645 [04:02<00:16, 10.26it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  94%|█████████▎| 2478/2645 [04:02<00:16, 10.28it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  94%|█████████▎| 2478/2645 [04:02<00:16, 10.28it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  94%|█████████▎| 2478/2645 [04:02<00:16, 10.28it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  94%|█████████▍| 2480/2645 [04:02<00:16, 10.22it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  94%|█████████▍| 2480/2645 [04:02<00:16, 10.22it/s, training_loss=0.145]\u001b[A\n",
      "Epoch 2:  94%|█████████▍| 2480/2645 [04:02<00:16, 10.22it/s, training_loss=0.056]\u001b[A\n",
      "Epoch 2:  94%|█████████▍| 2482/2645 [04:02<00:16, 10.13it/s, training_loss=0.056]\u001b[A\n",
      "Epoch 2:  94%|█████████▍| 2482/2645 [04:02<00:16, 10.13it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  94%|█████████▍| 2482/2645 [04:02<00:16, 10.13it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  94%|█████████▍| 2484/2645 [04:02<00:15, 10.13it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  94%|█████████▍| 2484/2645 [04:02<00:15, 10.13it/s, training_loss=0.698]\u001b[A\n",
      "Epoch 2:  94%|█████████▍| 2484/2645 [04:03<00:15, 10.13it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  94%|█████████▍| 2486/2645 [04:03<00:15, 10.00it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  94%|█████████▍| 2486/2645 [04:03<00:15, 10.00it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  94%|█████████▍| 2486/2645 [04:03<00:15, 10.00it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  94%|█████████▍| 2488/2645 [04:03<00:15, 10.02it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  94%|█████████▍| 2488/2645 [04:03<00:15, 10.02it/s, training_loss=1.306]\u001b[A\n",
      "Epoch 2:  94%|█████████▍| 2488/2645 [04:03<00:15, 10.02it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  94%|█████████▍| 2490/2645 [04:03<00:15,  9.97it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  94%|█████████▍| 2490/2645 [04:03<00:15,  9.97it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  94%|█████████▍| 2490/2645 [04:03<00:15,  9.97it/s, training_loss=0.015]\u001b[A\n",
      "Epoch 2:  94%|█████████▍| 2492/2645 [04:03<00:15, 10.01it/s, training_loss=0.015]\u001b[A\n",
      "Epoch 2:  94%|█████████▍| 2492/2645 [04:03<00:15, 10.01it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  94%|█████████▍| 2492/2645 [04:03<00:15, 10.01it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  94%|█████████▍| 2494/2645 [04:03<00:15, 10.03it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  94%|█████████▍| 2494/2645 [04:03<00:15, 10.03it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  94%|█████████▍| 2494/2645 [04:04<00:15, 10.03it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  94%|█████████▍| 2496/2645 [04:04<00:14, 10.01it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  94%|█████████▍| 2496/2645 [04:04<00:14, 10.01it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  94%|█████████▍| 2496/2645 [04:04<00:14, 10.01it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  94%|█████████▍| 2498/2645 [04:04<00:14, 10.10it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  94%|█████████▍| 2498/2645 [04:04<00:14, 10.10it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  94%|█████████▍| 2498/2645 [04:04<00:14, 10.10it/s, training_loss=0.033]\u001b[A\n",
      "Epoch 2:  95%|█████████▍| 2500/2645 [04:04<00:14,  9.83it/s, training_loss=0.033]\u001b[A\n",
      "Epoch 2:  95%|█████████▍| 2500/2645 [04:04<00:14,  9.83it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  95%|█████████▍| 2500/2645 [04:04<00:14,  9.83it/s, training_loss=0.338]\u001b[A\n",
      "Epoch 2:  95%|█████████▍| 2502/2645 [04:04<00:14,  9.93it/s, training_loss=0.338]\u001b[A\n",
      "Epoch 2:  95%|█████████▍| 2502/2645 [04:04<00:14,  9.93it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 2:  95%|█████████▍| 2503/2645 [04:04<00:14,  9.70it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 2:  95%|█████████▍| 2503/2645 [04:04<00:14,  9.70it/s, training_loss=0.614]\u001b[A\n",
      "Epoch 2:  95%|█████████▍| 2503/2645 [04:04<00:14,  9.70it/s, training_loss=0.355]\u001b[A\n",
      "Epoch 2:  95%|█████████▍| 2505/2645 [04:04<00:14,  9.88it/s, training_loss=0.355]\u001b[A\n",
      "Epoch 2:  95%|█████████▍| 2505/2645 [04:05<00:14,  9.88it/s, training_loss=0.439]\u001b[A\n",
      "Epoch 2:  95%|█████████▍| 2506/2645 [04:05<00:14,  9.78it/s, training_loss=0.439]\u001b[A\n",
      "Epoch 2:  95%|█████████▍| 2506/2645 [04:05<00:14,  9.78it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  95%|█████████▍| 2507/2645 [04:05<00:14,  9.62it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  95%|█████████▍| 2507/2645 [04:05<00:14,  9.62it/s, training_loss=0.727]\u001b[A\n",
      "Epoch 2:  95%|█████████▍| 2507/2645 [04:05<00:14,  9.62it/s, training_loss=0.030]\u001b[A\n",
      "Epoch 2:  95%|█████████▍| 2509/2645 [04:05<00:13,  9.80it/s, training_loss=0.030]\u001b[A\n",
      "Epoch 2:  95%|█████████▍| 2509/2645 [04:05<00:13,  9.80it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  95%|█████████▍| 2509/2645 [04:05<00:13,  9.80it/s, training_loss=0.876]\u001b[A\n",
      "Epoch 2:  95%|█████████▍| 2511/2645 [04:05<00:13,  9.95it/s, training_loss=0.876]\u001b[A\n",
      "Epoch 2:  95%|█████████▍| 2511/2645 [04:05<00:13,  9.95it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  95%|█████████▍| 2511/2645 [04:05<00:13,  9.95it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  95%|█████████▌| 2513/2645 [04:05<00:13, 10.10it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  95%|█████████▌| 2513/2645 [04:05<00:13, 10.10it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  95%|█████████▌| 2513/2645 [04:05<00:13, 10.10it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  95%|█████████▌| 2515/2645 [04:05<00:12, 10.18it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  95%|█████████▌| 2515/2645 [04:06<00:12, 10.18it/s, training_loss=0.713]\u001b[A\n",
      "Epoch 2:  95%|█████████▌| 2515/2645 [04:06<00:12, 10.18it/s, training_loss=0.914]\u001b[A\n",
      "Epoch 2:  95%|█████████▌| 2517/2645 [04:06<00:12, 10.20it/s, training_loss=0.914]\u001b[A\n",
      "Epoch 2:  95%|█████████▌| 2517/2645 [04:06<00:12, 10.20it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  95%|█████████▌| 2517/2645 [04:06<00:12, 10.20it/s, training_loss=0.550]\u001b[A\n",
      "Epoch 2:  95%|█████████▌| 2519/2645 [04:06<00:12, 10.22it/s, training_loss=0.550]\u001b[A\n",
      "Epoch 2:  95%|█████████▌| 2519/2645 [04:06<00:12, 10.22it/s, training_loss=0.013]\u001b[A\n",
      "Epoch 2:  95%|█████████▌| 2519/2645 [04:06<00:12, 10.22it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  95%|█████████▌| 2521/2645 [04:06<00:12, 10.20it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  95%|█████████▌| 2521/2645 [04:06<00:12, 10.20it/s, training_loss=0.750]\u001b[A\n",
      "Epoch 2:  95%|█████████▌| 2521/2645 [04:06<00:12, 10.20it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  95%|█████████▌| 2523/2645 [04:06<00:11, 10.25it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  95%|█████████▌| 2523/2645 [04:06<00:11, 10.25it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  95%|█████████▌| 2523/2645 [04:06<00:11, 10.25it/s, training_loss=0.207]\u001b[A\n",
      "Epoch 2:  95%|█████████▌| 2525/2645 [04:06<00:11, 10.10it/s, training_loss=0.207]\u001b[A\n",
      "Epoch 2:  95%|█████████▌| 2525/2645 [04:07<00:11, 10.10it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  95%|█████████▌| 2525/2645 [04:07<00:11, 10.10it/s, training_loss=1.405]\u001b[A\n",
      "Epoch 2:  96%|█████████▌| 2527/2645 [04:07<00:11, 10.16it/s, training_loss=1.405]\u001b[A\n",
      "Epoch 2:  96%|█████████▌| 2527/2645 [04:07<00:11, 10.16it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  96%|█████████▌| 2527/2645 [04:07<00:11, 10.16it/s, training_loss=0.370]\u001b[A\n",
      "Epoch 2:  96%|█████████▌| 2529/2645 [04:07<00:11, 10.25it/s, training_loss=0.370]\u001b[A\n",
      "Epoch 2:  96%|█████████▌| 2529/2645 [04:07<00:11, 10.25it/s, training_loss=0.035]\u001b[A\n",
      "Epoch 2:  96%|█████████▌| 2529/2645 [04:07<00:11, 10.25it/s, training_loss=0.545]\u001b[A\n",
      "Epoch 2:  96%|█████████▌| 2531/2645 [04:07<00:11, 10.26it/s, training_loss=0.545]\u001b[A\n",
      "Epoch 2:  96%|█████████▌| 2531/2645 [04:07<00:11, 10.26it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  96%|█████████▌| 2531/2645 [04:07<00:11, 10.26it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  96%|█████████▌| 2533/2645 [04:07<00:10, 10.35it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  96%|█████████▌| 2533/2645 [04:07<00:10, 10.35it/s, training_loss=0.022]\u001b[A\n",
      "Epoch 2:  96%|█████████▌| 2533/2645 [04:07<00:10, 10.35it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  96%|█████████▌| 2535/2645 [04:07<00:10, 10.35it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  96%|█████████▌| 2535/2645 [04:07<00:10, 10.35it/s, training_loss=0.907]\u001b[A\n",
      "Epoch 2:  96%|█████████▌| 2535/2645 [04:08<00:10, 10.35it/s, training_loss=0.029]\u001b[A\n",
      "Epoch 2:  96%|█████████▌| 2537/2645 [04:08<00:10, 10.32it/s, training_loss=0.029]\u001b[A\n",
      "Epoch 2:  96%|█████████▌| 2537/2645 [04:08<00:10, 10.32it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  96%|█████████▌| 2537/2645 [04:08<00:10, 10.32it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  96%|█████████▌| 2539/2645 [04:08<00:10, 10.31it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  96%|█████████▌| 2539/2645 [04:08<00:10, 10.31it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  96%|█████████▌| 2539/2645 [04:08<00:10, 10.31it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  96%|█████████▌| 2541/2645 [04:08<00:10, 10.33it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  96%|█████████▌| 2541/2645 [04:08<00:10, 10.33it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  96%|█████████▌| 2541/2645 [04:08<00:10, 10.33it/s, training_loss=1.324]\u001b[A\n",
      "Epoch 2:  96%|█████████▌| 2543/2645 [04:08<00:09, 10.35it/s, training_loss=1.324]\u001b[A\n",
      "Epoch 2:  96%|█████████▌| 2543/2645 [04:08<00:09, 10.35it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  96%|█████████▌| 2543/2645 [04:08<00:09, 10.35it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  96%|█████████▌| 2545/2645 [04:08<00:09, 10.34it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  96%|█████████▌| 2545/2645 [04:08<00:09, 10.34it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  96%|█████████▌| 2545/2645 [04:09<00:09, 10.34it/s, training_loss=0.188]\u001b[A\n",
      "Epoch 2:  96%|█████████▋| 2547/2645 [04:09<00:09, 10.32it/s, training_loss=0.188]\u001b[A\n",
      "Epoch 2:  96%|█████████▋| 2547/2645 [04:09<00:09, 10.32it/s, training_loss=0.847]\u001b[A\n",
      "Epoch 2:  96%|█████████▋| 2547/2645 [04:09<00:09, 10.32it/s, training_loss=0.564]\u001b[A\n",
      "Epoch 2:  96%|█████████▋| 2549/2645 [04:09<00:09, 10.27it/s, training_loss=0.564]\u001b[A\n",
      "Epoch 2:  96%|█████████▋| 2549/2645 [04:09<00:09, 10.27it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  96%|█████████▋| 2549/2645 [04:09<00:09, 10.27it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  96%|█████████▋| 2551/2645 [04:09<00:09, 10.29it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  96%|█████████▋| 2551/2645 [04:09<00:09, 10.29it/s, training_loss=0.901]\u001b[A\n",
      "Epoch 2:  96%|█████████▋| 2551/2645 [04:09<00:09, 10.29it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 2553/2645 [04:09<00:08, 10.31it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 2553/2645 [04:09<00:08, 10.31it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 2553/2645 [04:09<00:08, 10.31it/s, training_loss=0.863]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 2555/2645 [04:09<00:08, 10.27it/s, training_loss=0.863]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 2555/2645 [04:09<00:08, 10.27it/s, training_loss=0.454]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 2555/2645 [04:10<00:08, 10.27it/s, training_loss=0.299]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 2557/2645 [04:10<00:08, 10.27it/s, training_loss=0.299]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 2557/2645 [04:10<00:08, 10.27it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 2557/2645 [04:10<00:08, 10.27it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 2559/2645 [04:10<00:08, 10.31it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 2559/2645 [04:10<00:08, 10.31it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 2559/2645 [04:10<00:08, 10.31it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 2561/2645 [04:10<00:08, 10.32it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 2561/2645 [04:10<00:08, 10.32it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 2561/2645 [04:10<00:08, 10.32it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 2563/2645 [04:10<00:07, 10.34it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 2563/2645 [04:10<00:07, 10.34it/s, training_loss=1.354]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 2563/2645 [04:10<00:07, 10.34it/s, training_loss=0.546]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 2565/2645 [04:10<00:07, 10.34it/s, training_loss=0.546]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 2565/2645 [04:10<00:07, 10.34it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 2565/2645 [04:11<00:07, 10.34it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 2567/2645 [04:11<00:07, 10.36it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 2567/2645 [04:11<00:07, 10.36it/s, training_loss=0.069]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 2567/2645 [04:11<00:07, 10.36it/s, training_loss=0.451]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 2569/2645 [04:11<00:07, 10.33it/s, training_loss=0.451]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 2569/2645 [04:11<00:07, 10.33it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 2569/2645 [04:11<00:07, 10.33it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 2571/2645 [04:11<00:07, 10.35it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 2571/2645 [04:11<00:07, 10.35it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 2571/2645 [04:11<00:07, 10.35it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 2573/2645 [04:11<00:06, 10.40it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 2573/2645 [04:11<00:06, 10.40it/s, training_loss=0.054]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 2573/2645 [04:11<00:06, 10.40it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 2575/2645 [04:11<00:06, 10.42it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 2575/2645 [04:11<00:06, 10.42it/s, training_loss=0.685]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 2575/2645 [04:11<00:06, 10.42it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 2577/2645 [04:11<00:06, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 2577/2645 [04:12<00:06, 10.44it/s, training_loss=0.441]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 2577/2645 [04:12<00:06, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 2579/2645 [04:12<00:06, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 2579/2645 [04:12<00:06, 10.45it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 2579/2645 [04:12<00:06, 10.45it/s, training_loss=0.588]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 2581/2645 [04:12<00:06, 10.43it/s, training_loss=0.588]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 2581/2645 [04:12<00:06, 10.43it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 2581/2645 [04:12<00:06, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 2583/2645 [04:12<00:05, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 2583/2645 [04:12<00:05, 10.45it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 2583/2645 [04:12<00:05, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 2585/2645 [04:12<00:05, 10.31it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 2585/2645 [04:12<00:05, 10.31it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 2585/2645 [04:12<00:05, 10.31it/s, training_loss=0.685]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 2587/2645 [04:12<00:05, 10.08it/s, training_loss=0.685]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 2587/2645 [04:13<00:05, 10.08it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 2587/2645 [04:13<00:05, 10.08it/s, training_loss=0.416]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 2589/2645 [04:13<00:05, 10.19it/s, training_loss=0.416]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 2589/2645 [04:13<00:05, 10.19it/s, training_loss=0.022]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 2589/2645 [04:13<00:05, 10.19it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 2591/2645 [04:13<00:05, 10.27it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 2591/2645 [04:13<00:05, 10.27it/s, training_loss=0.792]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 2591/2645 [04:13<00:05, 10.27it/s, training_loss=0.244]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 2593/2645 [04:13<00:05, 10.29it/s, training_loss=0.244]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 2593/2645 [04:13<00:05, 10.29it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 2593/2645 [04:13<00:05, 10.29it/s, training_loss=0.011]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 2595/2645 [04:13<00:04, 10.29it/s, training_loss=0.011]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 2595/2645 [04:13<00:04, 10.29it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 2595/2645 [04:13<00:04, 10.29it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 2597/2645 [04:13<00:04, 10.35it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 2597/2645 [04:14<00:04, 10.35it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 2597/2645 [04:14<00:04, 10.35it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 2599/2645 [04:14<00:04, 10.42it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 2599/2645 [04:14<00:04, 10.42it/s, training_loss=0.756]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 2599/2645 [04:14<00:04, 10.42it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 2601/2645 [04:14<00:04, 10.41it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 2601/2645 [04:14<00:04, 10.41it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 2601/2645 [04:14<00:04, 10.41it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 2603/2645 [04:14<00:04, 10.42it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 2603/2645 [04:14<00:04, 10.42it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 2603/2645 [04:14<00:04, 10.42it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 2605/2645 [04:14<00:03, 10.46it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 2605/2645 [04:14<00:03, 10.46it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 2605/2645 [04:14<00:03, 10.46it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  99%|█████████▊| 2607/2645 [04:14<00:03, 10.35it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  99%|█████████▊| 2607/2645 [04:14<00:03, 10.35it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  99%|█████████▊| 2607/2645 [04:15<00:03, 10.35it/s, training_loss=0.925]\u001b[A\n",
      "Epoch 2:  99%|█████████▊| 2609/2645 [04:15<00:03, 10.37it/s, training_loss=0.925]\u001b[A\n",
      "Epoch 2:  99%|█████████▊| 2609/2645 [04:15<00:03, 10.37it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  99%|█████████▊| 2609/2645 [04:15<00:03, 10.37it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  99%|█████████▊| 2611/2645 [04:15<00:03, 10.42it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  99%|█████████▊| 2611/2645 [04:15<00:03, 10.42it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  99%|█████████▊| 2611/2645 [04:15<00:03, 10.42it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  99%|█████████▉| 2613/2645 [04:15<00:03, 10.37it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  99%|█████████▉| 2613/2645 [04:15<00:03, 10.37it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  99%|█████████▉| 2613/2645 [04:15<00:03, 10.37it/s, training_loss=1.310]\u001b[A\n",
      "Epoch 2:  99%|█████████▉| 2615/2645 [04:15<00:02, 10.32it/s, training_loss=1.310]\u001b[A\n",
      "Epoch 2:  99%|█████████▉| 2615/2645 [04:15<00:02, 10.32it/s, training_loss=0.194]\u001b[A\n",
      "Epoch 2:  99%|█████████▉| 2615/2645 [04:15<00:02, 10.32it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  99%|█████████▉| 2617/2645 [04:15<00:02, 10.23it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  99%|█████████▉| 2617/2645 [04:15<00:02, 10.23it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  99%|█████████▉| 2617/2645 [04:16<00:02, 10.23it/s, training_loss=0.170]\u001b[A\n",
      "Epoch 2:  99%|█████████▉| 2619/2645 [04:16<00:02, 10.27it/s, training_loss=0.170]\u001b[A\n",
      "Epoch 2:  99%|█████████▉| 2619/2645 [04:16<00:02, 10.27it/s, training_loss=0.719]\u001b[A\n",
      "Epoch 2:  99%|█████████▉| 2619/2645 [04:16<00:02, 10.27it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  99%|█████████▉| 2621/2645 [04:16<00:02, 10.32it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  99%|█████████▉| 2621/2645 [04:16<00:02, 10.32it/s, training_loss=1.060]\u001b[A\n",
      "Epoch 2:  99%|█████████▉| 2621/2645 [04:16<00:02, 10.32it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  99%|█████████▉| 2623/2645 [04:16<00:02, 10.36it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  99%|█████████▉| 2623/2645 [04:16<00:02, 10.36it/s, training_loss=0.225]\u001b[A\n",
      "Epoch 2:  99%|█████████▉| 2623/2645 [04:16<00:02, 10.36it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  99%|█████████▉| 2625/2645 [04:16<00:01, 10.34it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  99%|█████████▉| 2625/2645 [04:16<00:01, 10.34it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  99%|█████████▉| 2625/2645 [04:16<00:01, 10.34it/s, training_loss=0.027]\u001b[A\n",
      "Epoch 2:  99%|█████████▉| 2627/2645 [04:16<00:01, 10.39it/s, training_loss=0.027]\u001b[A\n",
      "Epoch 2:  99%|█████████▉| 2627/2645 [04:16<00:01, 10.39it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2:  99%|█████████▉| 2627/2645 [04:16<00:01, 10.39it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  99%|█████████▉| 2629/2645 [04:16<00:01, 10.44it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  99%|█████████▉| 2629/2645 [04:17<00:01, 10.44it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  99%|█████████▉| 2629/2645 [04:17<00:01, 10.44it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  99%|█████████▉| 2631/2645 [04:17<00:01, 10.47it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  99%|█████████▉| 2631/2645 [04:17<00:01, 10.47it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  99%|█████████▉| 2631/2645 [04:17<00:01, 10.47it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2: 100%|█████████▉| 2633/2645 [04:17<00:01, 10.50it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2: 100%|█████████▉| 2633/2645 [04:17<00:01, 10.50it/s, training_loss=0.594]\u001b[A\n",
      "Epoch 2: 100%|█████████▉| 2633/2645 [04:17<00:01, 10.50it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 2: 100%|█████████▉| 2635/2645 [04:17<00:00, 10.45it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 2: 100%|█████████▉| 2635/2645 [04:17<00:00, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2: 100%|█████████▉| 2635/2645 [04:17<00:00, 10.45it/s, training_loss=0.011]\u001b[A\n",
      "Epoch 2: 100%|█████████▉| 2637/2645 [04:17<00:00, 10.44it/s, training_loss=0.011]\u001b[A\n",
      "Epoch 2: 100%|█████████▉| 2637/2645 [04:17<00:00, 10.44it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2: 100%|█████████▉| 2637/2645 [04:17<00:00, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2: 100%|█████████▉| 2639/2645 [04:17<00:00, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2: 100%|█████████▉| 2639/2645 [04:18<00:00, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2: 100%|█████████▉| 2639/2645 [04:18<00:00, 10.46it/s, training_loss=0.029]\u001b[A\n",
      "Epoch 2: 100%|█████████▉| 2641/2645 [04:18<00:00, 10.45it/s, training_loss=0.029]\u001b[A\n",
      "Epoch 2: 100%|█████████▉| 2641/2645 [04:18<00:00, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 2: 100%|█████████▉| 2641/2645 [04:18<00:00, 10.45it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2: 100%|█████████▉| 2643/2645 [04:18<00:00, 10.44it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 2: 100%|█████████▉| 2643/2645 [04:18<00:00, 10.44it/s, training_loss=0.854]\u001b[A\n",
      "Epoch 2: 100%|█████████▉| 2643/2645 [04:18<00:00, 10.44it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 2: 100%|██████████| 2645/2645 [04:18<00:00, 10.67it/s, training_loss=0.008]\u001b[A\n",
      " 33%|███▎      | 1/3 [09:04<09:31, 285.79s/it]                                   \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2\n",
      "Training loss: 0.3568827961023218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [09:30<04:45, 285.44s/it]\n",
      "Epoch 3:   0%|          | 0/2645 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 3:   0%|          | 0/2645 [00:00<?, ?it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   0%|          | 1/2645 [00:00<04:36,  9.57it/s, training_loss=0.000]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 1.010635987369375\n",
      "F1 Score (Weighted): 0.8163749744814437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3:   0%|          | 1/2645 [00:00<04:36,  9.57it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   0%|          | 2/2645 [00:00<04:37,  9.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   0%|          | 2/2645 [00:00<04:37,  9.52it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 3:   0%|          | 2/2645 [00:00<04:37,  9.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   0%|          | 4/2645 [00:00<04:30,  9.77it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   0%|          | 4/2645 [00:00<04:30,  9.77it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   0%|          | 4/2645 [00:00<04:30,  9.77it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   0%|          | 6/2645 [00:00<04:24,  9.99it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   0%|          | 6/2645 [00:00<04:24,  9.99it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 3:   0%|          | 7/2645 [00:00<04:25,  9.92it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 3:   0%|          | 7/2645 [00:00<04:25,  9.92it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   0%|          | 7/2645 [00:00<04:25,  9.92it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   0%|          | 9/2645 [00:00<04:21, 10.08it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   0%|          | 9/2645 [00:00<04:21, 10.08it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 3:   0%|          | 9/2645 [00:01<04:21, 10.08it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   0%|          | 11/2645 [00:01<04:18, 10.20it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   0%|          | 11/2645 [00:01<04:18, 10.20it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   0%|          | 11/2645 [00:01<04:18, 10.20it/s, training_loss=0.099]\u001b[A\n",
      "Epoch 3:   0%|          | 13/2645 [00:01<04:16, 10.24it/s, training_loss=0.099]\u001b[A\n",
      "Epoch 3:   0%|          | 13/2645 [00:01<04:16, 10.24it/s, training_loss=0.714]\u001b[A\n",
      "Epoch 3:   0%|          | 13/2645 [00:01<04:16, 10.24it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 3:   1%|          | 15/2645 [00:01<04:15, 10.29it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 3:   1%|          | 15/2645 [00:01<04:15, 10.29it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 3:   1%|          | 15/2645 [00:01<04:15, 10.29it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   1%|          | 17/2645 [00:01<04:17, 10.22it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   1%|          | 17/2645 [00:01<04:17, 10.22it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   1%|          | 17/2645 [00:01<04:17, 10.22it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   1%|          | 19/2645 [00:01<04:14, 10.31it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   1%|          | 19/2645 [00:01<04:14, 10.31it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   1%|          | 19/2645 [00:02<04:14, 10.31it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   1%|          | 21/2645 [00:02<04:12, 10.38it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   1%|          | 21/2645 [00:02<04:12, 10.38it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   1%|          | 21/2645 [00:02<04:12, 10.38it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   1%|          | 23/2645 [00:02<04:11, 10.43it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   1%|          | 23/2645 [00:02<04:11, 10.43it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   1%|          | 23/2645 [00:02<04:11, 10.43it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 3:   1%|          | 25/2645 [00:02<04:11, 10.42it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 3:   1%|          | 25/2645 [00:02<04:11, 10.42it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   1%|          | 25/2645 [00:02<04:11, 10.42it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   1%|          | 27/2645 [00:02<04:10, 10.47it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   1%|          | 27/2645 [00:02<04:10, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   1%|          | 27/2645 [00:02<04:10, 10.47it/s, training_loss=0.671]\u001b[A\n",
      "Epoch 3:   1%|          | 29/2645 [00:02<04:10, 10.45it/s, training_loss=0.671]\u001b[A\n",
      "Epoch 3:   1%|          | 29/2645 [00:02<04:10, 10.45it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 3:   1%|          | 29/2645 [00:02<04:10, 10.45it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   1%|          | 31/2645 [00:02<04:09, 10.47it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   1%|          | 31/2645 [00:03<04:09, 10.47it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   1%|          | 31/2645 [00:03<04:09, 10.47it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   1%|          | 33/2645 [00:03<04:08, 10.52it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   1%|          | 33/2645 [00:03<04:08, 10.52it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   1%|          | 33/2645 [00:03<04:08, 10.52it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   1%|▏         | 35/2645 [00:03<04:08, 10.52it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   1%|▏         | 35/2645 [00:03<04:08, 10.52it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   1%|▏         | 35/2645 [00:03<04:08, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   1%|▏         | 37/2645 [00:03<04:07, 10.54it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   1%|▏         | 37/2645 [00:03<04:07, 10.54it/s, training_loss=0.324]\u001b[A\n",
      "Epoch 3:   1%|▏         | 37/2645 [00:03<04:07, 10.54it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   1%|▏         | 39/2645 [00:03<04:07, 10.52it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   1%|▏         | 39/2645 [00:03<04:07, 10.52it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 3:   1%|▏         | 39/2645 [00:03<04:07, 10.52it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   2%|▏         | 41/2645 [00:03<04:07, 10.51it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   2%|▏         | 41/2645 [00:04<04:07, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   2%|▏         | 41/2645 [00:04<04:07, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   2%|▏         | 43/2645 [00:04<04:07, 10.53it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   2%|▏         | 43/2645 [00:04<04:07, 10.53it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   2%|▏         | 43/2645 [00:04<04:07, 10.53it/s, training_loss=0.456]\u001b[A\n",
      "Epoch 3:   2%|▏         | 45/2645 [00:04<04:07, 10.51it/s, training_loss=0.456]\u001b[A\n",
      "Epoch 3:   2%|▏         | 45/2645 [00:04<04:07, 10.51it/s, training_loss=0.226]\u001b[A\n",
      "Epoch 3:   2%|▏         | 45/2645 [00:04<04:07, 10.51it/s, training_loss=0.298]\u001b[A\n",
      "Epoch 3:   2%|▏         | 47/2645 [00:04<04:08, 10.47it/s, training_loss=0.298]\u001b[A\n",
      "Epoch 3:   2%|▏         | 47/2645 [00:04<04:08, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   2%|▏         | 47/2645 [00:04<04:08, 10.47it/s, training_loss=0.011]\u001b[A\n",
      "Epoch 3:   2%|▏         | 49/2645 [00:04<04:08, 10.43it/s, training_loss=0.011]\u001b[A\n",
      "Epoch 3:   2%|▏         | 49/2645 [00:04<04:08, 10.43it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   2%|▏         | 49/2645 [00:04<04:08, 10.43it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 3:   2%|▏         | 51/2645 [00:04<04:07, 10.48it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 3:   2%|▏         | 51/2645 [00:04<04:07, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   2%|▏         | 51/2645 [00:05<04:07, 10.48it/s, training_loss=0.033]\u001b[A\n",
      "Epoch 3:   2%|▏         | 53/2645 [00:05<04:07, 10.48it/s, training_loss=0.033]\u001b[A\n",
      "Epoch 3:   2%|▏         | 53/2645 [00:05<04:07, 10.48it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 3:   2%|▏         | 53/2645 [00:05<04:07, 10.48it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   2%|▏         | 55/2645 [00:05<04:07, 10.47it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   2%|▏         | 55/2645 [00:05<04:07, 10.47it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   2%|▏         | 55/2645 [00:05<04:07, 10.47it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   2%|▏         | 57/2645 [00:05<04:06, 10.50it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   2%|▏         | 57/2645 [00:05<04:06, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   2%|▏         | 57/2645 [00:05<04:06, 10.50it/s, training_loss=0.025]\u001b[A\n",
      "Epoch 3:   2%|▏         | 59/2645 [00:05<04:07, 10.46it/s, training_loss=0.025]\u001b[A\n",
      "Epoch 3:   2%|▏         | 59/2645 [00:05<04:07, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   2%|▏         | 59/2645 [00:05<04:07, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   2%|▏         | 61/2645 [00:05<04:06, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   2%|▏         | 61/2645 [00:05<04:06, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   2%|▏         | 61/2645 [00:06<04:06, 10.50it/s, training_loss=0.921]\u001b[A\n",
      "Epoch 3:   2%|▏         | 63/2645 [00:06<04:05, 10.50it/s, training_loss=0.921]\u001b[A\n",
      "Epoch 3:   2%|▏         | 63/2645 [00:06<04:05, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   2%|▏         | 63/2645 [00:06<04:05, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   2%|▏         | 65/2645 [00:06<04:05, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   2%|▏         | 65/2645 [00:06<04:05, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   2%|▏         | 65/2645 [00:06<04:05, 10.51it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   3%|▎         | 67/2645 [00:06<04:04, 10.53it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   3%|▎         | 67/2645 [00:06<04:04, 10.53it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   3%|▎         | 67/2645 [00:06<04:04, 10.53it/s, training_loss=0.783]\u001b[A\n",
      "Epoch 3:   3%|▎         | 69/2645 [00:06<04:05, 10.51it/s, training_loss=0.783]\u001b[A\n",
      "Epoch 3:   3%|▎         | 69/2645 [00:06<04:05, 10.51it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   3%|▎         | 69/2645 [00:06<04:05, 10.51it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   3%|▎         | 71/2645 [00:06<04:04, 10.53it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   3%|▎         | 71/2645 [00:06<04:04, 10.53it/s, training_loss=0.027]\u001b[A\n",
      "Epoch 3:   3%|▎         | 71/2645 [00:06<04:04, 10.53it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   3%|▎         | 73/2645 [00:06<04:04, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   3%|▎         | 73/2645 [00:07<04:04, 10.52it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   3%|▎         | 73/2645 [00:07<04:04, 10.52it/s, training_loss=0.386]\u001b[A\n",
      "Epoch 3:   3%|▎         | 75/2645 [00:07<04:04, 10.49it/s, training_loss=0.386]\u001b[A\n",
      "Epoch 3:   3%|▎         | 75/2645 [00:07<04:04, 10.49it/s, training_loss=0.436]\u001b[A\n",
      "Epoch 3:   3%|▎         | 75/2645 [00:07<04:04, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   3%|▎         | 77/2645 [00:07<04:04, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   3%|▎         | 77/2645 [00:07<04:04, 10.49it/s, training_loss=0.307]\u001b[A\n",
      "Epoch 3:   3%|▎         | 77/2645 [00:07<04:04, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   3%|▎         | 79/2645 [00:07<04:06, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   3%|▎         | 79/2645 [00:07<04:06, 10.43it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   3%|▎         | 79/2645 [00:07<04:06, 10.43it/s, training_loss=0.348]\u001b[A\n",
      "Epoch 3:   3%|▎         | 81/2645 [00:07<04:05, 10.43it/s, training_loss=0.348]\u001b[A\n",
      "Epoch 3:   3%|▎         | 81/2645 [00:07<04:05, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   3%|▎         | 81/2645 [00:07<04:05, 10.43it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   3%|▎         | 83/2645 [00:07<04:05, 10.45it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   3%|▎         | 83/2645 [00:08<04:05, 10.45it/s, training_loss=0.019]\u001b[A\n",
      "Epoch 3:   3%|▎         | 83/2645 [00:08<04:05, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   3%|▎         | 85/2645 [00:08<04:05, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   3%|▎         | 85/2645 [00:08<04:05, 10.44it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   3%|▎         | 85/2645 [00:08<04:05, 10.44it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   3%|▎         | 87/2645 [00:08<04:07, 10.35it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   3%|▎         | 87/2645 [00:08<04:07, 10.35it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   3%|▎         | 87/2645 [00:08<04:07, 10.35it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   3%|▎         | 89/2645 [00:08<04:09, 10.24it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   3%|▎         | 89/2645 [00:08<04:09, 10.24it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   3%|▎         | 89/2645 [00:08<04:09, 10.24it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   3%|▎         | 91/2645 [00:08<04:07, 10.34it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   3%|▎         | 91/2645 [00:08<04:07, 10.34it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   3%|▎         | 91/2645 [00:08<04:07, 10.34it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   4%|▎         | 93/2645 [00:08<04:04, 10.42it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   4%|▎         | 93/2645 [00:09<04:04, 10.42it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   4%|▎         | 93/2645 [00:09<04:04, 10.42it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   4%|▎         | 95/2645 [00:09<04:03, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   4%|▎         | 95/2645 [00:09<04:03, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   4%|▎         | 95/2645 [00:09<04:03, 10.47it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   4%|▎         | 97/2645 [00:09<04:02, 10.51it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   4%|▎         | 97/2645 [00:09<04:02, 10.51it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   4%|▎         | 97/2645 [00:09<04:02, 10.51it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   4%|▎         | 99/2645 [00:09<04:01, 10.52it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   4%|▎         | 99/2645 [00:09<04:01, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   4%|▎         | 99/2645 [00:09<04:01, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   4%|▍         | 101/2645 [00:09<04:02, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   4%|▍         | 101/2645 [00:09<04:02, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   4%|▍         | 101/2645 [00:09<04:02, 10.49it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 3:   4%|▍         | 103/2645 [00:09<04:02, 10.47it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 3:   4%|▍         | 103/2645 [00:09<04:02, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   4%|▍         | 103/2645 [00:10<04:02, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   4%|▍         | 105/2645 [00:10<04:01, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   4%|▍         | 105/2645 [00:10<04:01, 10.50it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   4%|▍         | 105/2645 [00:10<04:01, 10.50it/s, training_loss=0.587]\u001b[A\n",
      "Epoch 3:   4%|▍         | 107/2645 [00:10<04:01, 10.49it/s, training_loss=0.587]\u001b[A\n",
      "Epoch 3:   4%|▍         | 107/2645 [00:10<04:01, 10.49it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   4%|▍         | 107/2645 [00:10<04:01, 10.49it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 3:   4%|▍         | 109/2645 [00:10<04:03, 10.43it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 3:   4%|▍         | 109/2645 [00:10<04:03, 10.43it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   4%|▍         | 109/2645 [00:10<04:03, 10.43it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 3:   4%|▍         | 111/2645 [00:10<04:02, 10.46it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 3:   4%|▍         | 111/2645 [00:10<04:02, 10.46it/s, training_loss=0.624]\u001b[A\n",
      "Epoch 3:   4%|▍         | 111/2645 [00:10<04:02, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   4%|▍         | 113/2645 [00:10<04:03, 10.42it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   4%|▍         | 113/2645 [00:10<04:03, 10.42it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   4%|▍         | 113/2645 [00:11<04:03, 10.42it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   4%|▍         | 115/2645 [00:11<04:01, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   4%|▍         | 115/2645 [00:11<04:01, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   4%|▍         | 115/2645 [00:11<04:01, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   4%|▍         | 117/2645 [00:11<04:00, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   4%|▍         | 117/2645 [00:11<04:00, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   4%|▍         | 117/2645 [00:11<04:00, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   4%|▍         | 119/2645 [00:11<03:59, 10.53it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   4%|▍         | 119/2645 [00:11<03:59, 10.53it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   4%|▍         | 119/2645 [00:11<03:59, 10.53it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   5%|▍         | 121/2645 [00:11<03:59, 10.55it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   5%|▍         | 121/2645 [00:11<03:59, 10.55it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   5%|▍         | 121/2645 [00:11<03:59, 10.55it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   5%|▍         | 123/2645 [00:11<03:58, 10.57it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   5%|▍         | 123/2645 [00:11<03:58, 10.57it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   5%|▍         | 123/2645 [00:11<03:58, 10.57it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   5%|▍         | 125/2645 [00:11<04:03, 10.35it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   5%|▍         | 125/2645 [00:12<04:03, 10.35it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   5%|▍         | 125/2645 [00:12<04:03, 10.35it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   5%|▍         | 127/2645 [00:12<04:02, 10.40it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   5%|▍         | 127/2645 [00:12<04:02, 10.40it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 3:   5%|▍         | 127/2645 [00:12<04:02, 10.40it/s, training_loss=0.525]\u001b[A\n",
      "Epoch 3:   5%|▍         | 129/2645 [00:12<04:11, 10.01it/s, training_loss=0.525]\u001b[A\n",
      "Epoch 3:   5%|▍         | 129/2645 [00:12<04:11, 10.01it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   5%|▍         | 129/2645 [00:12<04:11, 10.01it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   5%|▍         | 131/2645 [00:12<04:15,  9.84it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   5%|▍         | 131/2645 [00:12<04:15,  9.84it/s, training_loss=0.189]\u001b[A\n",
      "Epoch 3:   5%|▍         | 132/2645 [00:12<04:20,  9.64it/s, training_loss=0.189]\u001b[A\n",
      "Epoch 3:   5%|▍         | 132/2645 [00:12<04:20,  9.64it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   5%|▌         | 133/2645 [00:12<04:21,  9.62it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   5%|▌         | 133/2645 [00:12<04:21,  9.62it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   5%|▌         | 133/2645 [00:12<04:21,  9.62it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   5%|▌         | 135/2645 [00:12<04:13,  9.89it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   5%|▌         | 135/2645 [00:13<04:13,  9.89it/s, training_loss=0.081]\u001b[A\n",
      "Epoch 3:   5%|▌         | 135/2645 [00:13<04:13,  9.89it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   5%|▌         | 137/2645 [00:13<04:09, 10.07it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   5%|▌         | 137/2645 [00:13<04:09, 10.07it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   5%|▌         | 137/2645 [00:13<04:09, 10.07it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   5%|▌         | 139/2645 [00:13<04:05, 10.22it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   5%|▌         | 139/2645 [00:13<04:05, 10.22it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   5%|▌         | 139/2645 [00:13<04:05, 10.22it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   5%|▌         | 141/2645 [00:13<04:02, 10.31it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   5%|▌         | 141/2645 [00:13<04:02, 10.31it/s, training_loss=0.097]\u001b[A\n",
      "Epoch 3:   5%|▌         | 141/2645 [00:13<04:02, 10.31it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   5%|▌         | 143/2645 [00:13<04:01, 10.37it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   5%|▌         | 143/2645 [00:13<04:01, 10.37it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   5%|▌         | 143/2645 [00:13<04:01, 10.37it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   5%|▌         | 145/2645 [00:13<04:00, 10.40it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   5%|▌         | 145/2645 [00:14<04:00, 10.40it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 3:   5%|▌         | 145/2645 [00:14<04:00, 10.40it/s, training_loss=0.119]\u001b[A\n",
      "Epoch 3:   6%|▌         | 147/2645 [00:14<04:01, 10.33it/s, training_loss=0.119]\u001b[A\n",
      "Epoch 3:   6%|▌         | 147/2645 [00:14<04:01, 10.33it/s, training_loss=0.010]\u001b[A\n",
      "Epoch 3:   6%|▌         | 147/2645 [00:14<04:01, 10.33it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   6%|▌         | 149/2645 [00:14<04:07, 10.10it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   6%|▌         | 149/2645 [00:14<04:07, 10.10it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   6%|▌         | 149/2645 [00:14<04:07, 10.10it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   6%|▌         | 151/2645 [00:14<04:06, 10.14it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   6%|▌         | 151/2645 [00:14<04:06, 10.14it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   6%|▌         | 151/2645 [00:14<04:06, 10.14it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   6%|▌         | 153/2645 [00:14<04:08, 10.04it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   6%|▌         | 153/2645 [00:14<04:08, 10.04it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   6%|▌         | 153/2645 [00:14<04:08, 10.04it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   6%|▌         | 155/2645 [00:14<04:07, 10.06it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   6%|▌         | 155/2645 [00:15<04:07, 10.06it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   6%|▌         | 155/2645 [00:15<04:07, 10.06it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   6%|▌         | 157/2645 [00:15<04:11,  9.89it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   6%|▌         | 157/2645 [00:15<04:11,  9.89it/s, training_loss=0.040]\u001b[A\n",
      "Epoch 3:   6%|▌         | 158/2645 [00:15<04:18,  9.62it/s, training_loss=0.040]\u001b[A\n",
      "Epoch 3:   6%|▌         | 158/2645 [00:15<04:18,  9.62it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   6%|▌         | 158/2645 [00:15<04:18,  9.62it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   6%|▌         | 160/2645 [00:15<04:11,  9.88it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   6%|▌         | 160/2645 [00:15<04:11,  9.88it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   6%|▌         | 160/2645 [00:15<04:11,  9.88it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   6%|▌         | 162/2645 [00:15<04:06, 10.08it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   6%|▌         | 162/2645 [00:15<04:06, 10.08it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   6%|▌         | 162/2645 [00:15<04:06, 10.08it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   6%|▌         | 164/2645 [00:15<04:02, 10.23it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   6%|▌         | 164/2645 [00:15<04:02, 10.23it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   6%|▌         | 164/2645 [00:16<04:02, 10.23it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   6%|▋         | 166/2645 [00:16<03:59, 10.33it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   6%|▋         | 166/2645 [00:16<03:59, 10.33it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   6%|▋         | 166/2645 [00:16<03:59, 10.33it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   6%|▋         | 168/2645 [00:16<03:58, 10.40it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   6%|▋         | 168/2645 [00:16<03:58, 10.40it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   6%|▋         | 168/2645 [00:16<03:58, 10.40it/s, training_loss=0.028]\u001b[A\n",
      "Epoch 3:   6%|▋         | 170/2645 [00:16<03:57, 10.43it/s, training_loss=0.028]\u001b[A\n",
      "Epoch 3:   6%|▋         | 170/2645 [00:16<03:57, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   6%|▋         | 170/2645 [00:16<03:57, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   7%|▋         | 172/2645 [00:16<03:56, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   7%|▋         | 172/2645 [00:16<03:56, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   7%|▋         | 172/2645 [00:16<03:56, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   7%|▋         | 174/2645 [00:16<03:55, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   7%|▋         | 174/2645 [00:16<03:55, 10.49it/s, training_loss=0.030]\u001b[A\n",
      "Epoch 3:   7%|▋         | 174/2645 [00:16<03:55, 10.49it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   7%|▋         | 176/2645 [00:16<03:55, 10.49it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   7%|▋         | 176/2645 [00:17<03:55, 10.49it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 3:   7%|▋         | 176/2645 [00:17<03:55, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   7%|▋         | 178/2645 [00:17<03:55, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   7%|▋         | 178/2645 [00:17<03:55, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   7%|▋         | 178/2645 [00:17<03:55, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   7%|▋         | 180/2645 [00:17<03:54, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   7%|▋         | 180/2645 [00:17<03:54, 10.49it/s, training_loss=0.115]\u001b[A\n",
      "Epoch 3:   7%|▋         | 180/2645 [00:17<03:54, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   7%|▋         | 182/2645 [00:17<03:54, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   7%|▋         | 182/2645 [00:17<03:54, 10.49it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   7%|▋         | 182/2645 [00:17<03:54, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   7%|▋         | 184/2645 [00:17<03:54, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   7%|▋         | 184/2645 [00:17<03:54, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   7%|▋         | 184/2645 [00:17<03:54, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   7%|▋         | 186/2645 [00:17<03:54, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   7%|▋         | 186/2645 [00:18<03:54, 10.48it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   7%|▋         | 186/2645 [00:18<03:54, 10.48it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   7%|▋         | 188/2645 [00:18<03:53, 10.52it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   7%|▋         | 188/2645 [00:18<03:53, 10.52it/s, training_loss=0.020]\u001b[A\n",
      "Epoch 3:   7%|▋         | 188/2645 [00:18<03:53, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   7%|▋         | 190/2645 [00:18<03:53, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   7%|▋         | 190/2645 [00:18<03:53, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   7%|▋         | 190/2645 [00:18<03:53, 10.50it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 3:   7%|▋         | 192/2645 [00:18<03:53, 10.50it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 3:   7%|▋         | 192/2645 [00:18<03:53, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   7%|▋         | 192/2645 [00:18<03:53, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   7%|▋         | 194/2645 [00:18<03:56, 10.35it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   7%|▋         | 194/2645 [00:18<03:56, 10.35it/s, training_loss=0.749]\u001b[A\n",
      "Epoch 3:   7%|▋         | 194/2645 [00:18<03:56, 10.35it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   7%|▋         | 196/2645 [00:18<03:55, 10.38it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   7%|▋         | 196/2645 [00:18<03:55, 10.38it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   7%|▋         | 196/2645 [00:19<03:55, 10.38it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   7%|▋         | 198/2645 [00:19<03:54, 10.42it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   7%|▋         | 198/2645 [00:19<03:54, 10.42it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   7%|▋         | 198/2645 [00:19<03:54, 10.42it/s, training_loss=0.269]\u001b[A\n",
      "Epoch 3:   8%|▊         | 200/2645 [00:19<03:54, 10.43it/s, training_loss=0.269]\u001b[A\n",
      "Epoch 3:   8%|▊         | 200/2645 [00:19<03:54, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   8%|▊         | 200/2645 [00:19<03:54, 10.43it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   8%|▊         | 202/2645 [00:19<03:53, 10.46it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   8%|▊         | 202/2645 [00:19<03:53, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   8%|▊         | 202/2645 [00:19<03:53, 10.46it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   8%|▊         | 204/2645 [00:19<03:52, 10.48it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   8%|▊         | 204/2645 [00:19<03:52, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   8%|▊         | 204/2645 [00:19<03:52, 10.48it/s, training_loss=0.160]\u001b[A\n",
      "Epoch 3:   8%|▊         | 206/2645 [00:19<03:52, 10.47it/s, training_loss=0.160]\u001b[A\n",
      "Epoch 3:   8%|▊         | 206/2645 [00:19<03:52, 10.47it/s, training_loss=0.212]\u001b[A\n",
      "Epoch 3:   8%|▊         | 206/2645 [00:20<03:52, 10.47it/s, training_loss=0.048]\u001b[A\n",
      "Epoch 3:   8%|▊         | 208/2645 [00:20<03:53, 10.42it/s, training_loss=0.048]\u001b[A\n",
      "Epoch 3:   8%|▊         | 208/2645 [00:20<03:53, 10.42it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   8%|▊         | 208/2645 [00:20<03:53, 10.42it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   8%|▊         | 210/2645 [00:20<03:54, 10.39it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   8%|▊         | 210/2645 [00:20<03:54, 10.39it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 3:   8%|▊         | 210/2645 [00:20<03:54, 10.39it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 3:   8%|▊         | 212/2645 [00:20<03:56, 10.30it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 3:   8%|▊         | 212/2645 [00:20<03:56, 10.30it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   8%|▊         | 212/2645 [00:20<03:56, 10.30it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   8%|▊         | 214/2645 [00:20<03:54, 10.38it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   8%|▊         | 214/2645 [00:20<03:54, 10.38it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   8%|▊         | 214/2645 [00:20<03:54, 10.38it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   8%|▊         | 216/2645 [00:20<03:52, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   8%|▊         | 216/2645 [00:20<03:52, 10.44it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   8%|▊         | 216/2645 [00:20<03:52, 10.44it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 3:   8%|▊         | 218/2645 [00:20<03:52, 10.45it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 3:   8%|▊         | 218/2645 [00:21<03:52, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   8%|▊         | 218/2645 [00:21<03:52, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   8%|▊         | 220/2645 [00:21<03:51, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   8%|▊         | 220/2645 [00:21<03:51, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   8%|▊         | 220/2645 [00:21<03:51, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   8%|▊         | 222/2645 [00:21<03:51, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   8%|▊         | 222/2645 [00:21<03:51, 10.47it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   8%|▊         | 222/2645 [00:21<03:51, 10.47it/s, training_loss=0.123]\u001b[A\n",
      "Epoch 3:   8%|▊         | 224/2645 [00:21<03:51, 10.46it/s, training_loss=0.123]\u001b[A\n",
      "Epoch 3:   8%|▊         | 224/2645 [00:21<03:51, 10.46it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   8%|▊         | 224/2645 [00:21<03:51, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   9%|▊         | 226/2645 [00:21<03:51, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   9%|▊         | 226/2645 [00:21<03:51, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   9%|▊         | 226/2645 [00:21<03:51, 10.44it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 3:   9%|▊         | 228/2645 [00:21<03:50, 10.47it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 3:   9%|▊         | 228/2645 [00:22<03:50, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   9%|▊         | 228/2645 [00:22<03:50, 10.47it/s, training_loss=0.851]\u001b[A\n",
      "Epoch 3:   9%|▊         | 230/2645 [00:22<03:50, 10.46it/s, training_loss=0.851]\u001b[A\n",
      "Epoch 3:   9%|▊         | 230/2645 [00:22<03:50, 10.46it/s, training_loss=0.679]\u001b[A\n",
      "Epoch 3:   9%|▊         | 230/2645 [00:22<03:50, 10.46it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   9%|▉         | 232/2645 [00:22<03:52, 10.39it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   9%|▉         | 232/2645 [00:22<03:52, 10.39it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   9%|▉         | 232/2645 [00:22<03:52, 10.39it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   9%|▉         | 234/2645 [00:22<03:50, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   9%|▉         | 234/2645 [00:22<03:50, 10.46it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   9%|▉         | 234/2645 [00:22<03:50, 10.46it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   9%|▉         | 236/2645 [00:22<03:52, 10.38it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   9%|▉         | 236/2645 [00:22<03:52, 10.38it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   9%|▉         | 236/2645 [00:22<03:52, 10.38it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   9%|▉         | 238/2645 [00:22<03:54, 10.26it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   9%|▉         | 238/2645 [00:23<03:54, 10.26it/s, training_loss=0.485]\u001b[A\n",
      "Epoch 3:   9%|▉         | 238/2645 [00:23<03:54, 10.26it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   9%|▉         | 240/2645 [00:23<03:52, 10.33it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   9%|▉         | 240/2645 [00:23<03:52, 10.33it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   9%|▉         | 240/2645 [00:23<03:52, 10.33it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   9%|▉         | 242/2645 [00:23<03:51, 10.38it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   9%|▉         | 242/2645 [00:23<03:51, 10.38it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   9%|▉         | 242/2645 [00:23<03:51, 10.38it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   9%|▉         | 244/2645 [00:23<03:49, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   9%|▉         | 244/2645 [00:23<03:49, 10.44it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   9%|▉         | 244/2645 [00:23<03:49, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   9%|▉         | 246/2645 [00:23<03:49, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   9%|▉         | 246/2645 [00:23<03:49, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   9%|▉         | 246/2645 [00:23<03:49, 10.47it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   9%|▉         | 248/2645 [00:23<03:47, 10.52it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   9%|▉         | 248/2645 [00:23<03:47, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:   9%|▉         | 248/2645 [00:24<03:47, 10.52it/s, training_loss=0.017]\u001b[A\n",
      "Epoch 3:   9%|▉         | 250/2645 [00:24<03:47, 10.52it/s, training_loss=0.017]\u001b[A\n",
      "Epoch 3:   9%|▉         | 250/2645 [00:24<03:47, 10.52it/s, training_loss=0.791]\u001b[A\n",
      "Epoch 3:   9%|▉         | 250/2645 [00:24<03:47, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  10%|▉         | 252/2645 [00:24<03:47, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  10%|▉         | 252/2645 [00:24<03:47, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  10%|▉         | 252/2645 [00:24<03:47, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  10%|▉         | 254/2645 [00:24<03:47, 10.53it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  10%|▉         | 254/2645 [00:24<03:47, 10.53it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  10%|▉         | 254/2645 [00:24<03:47, 10.53it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  10%|▉         | 256/2645 [00:24<03:48, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  10%|▉         | 256/2645 [00:24<03:48, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  10%|▉         | 256/2645 [00:24<03:48, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  10%|▉         | 258/2645 [00:24<03:51, 10.32it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  10%|▉         | 258/2645 [00:24<03:51, 10.32it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  10%|▉         | 258/2645 [00:25<03:51, 10.32it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  10%|▉         | 260/2645 [00:25<03:49, 10.39it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  10%|▉         | 260/2645 [00:25<03:49, 10.39it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  10%|▉         | 260/2645 [00:25<03:49, 10.39it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  10%|▉         | 262/2645 [00:25<03:49, 10.39it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  10%|▉         | 262/2645 [00:25<03:49, 10.39it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  10%|▉         | 262/2645 [00:25<03:49, 10.39it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  10%|▉         | 264/2645 [00:25<03:48, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  10%|▉         | 264/2645 [00:25<03:48, 10.43it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  10%|▉         | 264/2645 [00:25<03:48, 10.43it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  10%|█         | 266/2645 [00:25<03:49, 10.35it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  10%|█         | 266/2645 [00:25<03:49, 10.35it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  10%|█         | 266/2645 [00:25<03:49, 10.35it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  10%|█         | 268/2645 [00:25<03:47, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  10%|█         | 268/2645 [00:25<03:47, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  10%|█         | 268/2645 [00:25<03:47, 10.43it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  10%|█         | 270/2645 [00:25<03:46, 10.47it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  10%|█         | 270/2645 [00:26<03:46, 10.47it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 3:  10%|█         | 270/2645 [00:26<03:46, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  10%|█         | 272/2645 [00:26<03:46, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  10%|█         | 272/2645 [00:26<03:46, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  10%|█         | 272/2645 [00:26<03:46, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  10%|█         | 274/2645 [00:26<03:45, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  10%|█         | 274/2645 [00:26<03:45, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  10%|█         | 274/2645 [00:26<03:45, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  10%|█         | 276/2645 [00:26<03:45, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  10%|█         | 276/2645 [00:26<03:45, 10.50it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  10%|█         | 276/2645 [00:26<03:45, 10.50it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  11%|█         | 278/2645 [00:26<03:48, 10.35it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  11%|█         | 278/2645 [00:26<03:48, 10.35it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  11%|█         | 278/2645 [00:26<03:48, 10.35it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  11%|█         | 280/2645 [00:26<03:47, 10.41it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  11%|█         | 280/2645 [00:27<03:47, 10.41it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  11%|█         | 280/2645 [00:27<03:47, 10.41it/s, training_loss=0.596]\u001b[A\n",
      "Epoch 3:  11%|█         | 282/2645 [00:27<03:46, 10.43it/s, training_loss=0.596]\u001b[A\n",
      "Epoch 3:  11%|█         | 282/2645 [00:27<03:46, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  11%|█         | 282/2645 [00:27<03:46, 10.43it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  11%|█         | 284/2645 [00:27<03:45, 10.47it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  11%|█         | 284/2645 [00:27<03:45, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  11%|█         | 284/2645 [00:27<03:45, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  11%|█         | 286/2645 [00:27<03:47, 10.38it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  11%|█         | 286/2645 [00:27<03:47, 10.38it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  11%|█         | 286/2645 [00:27<03:47, 10.38it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  11%|█         | 288/2645 [00:27<03:47, 10.38it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  11%|█         | 288/2645 [00:27<03:47, 10.38it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  11%|█         | 288/2645 [00:27<03:47, 10.38it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  11%|█         | 290/2645 [00:27<03:45, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  11%|█         | 290/2645 [00:28<03:45, 10.45it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  11%|█         | 290/2645 [00:28<03:45, 10.45it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  11%|█         | 292/2645 [00:28<03:49, 10.25it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  11%|█         | 292/2645 [00:28<03:49, 10.25it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  11%|█         | 292/2645 [00:28<03:49, 10.25it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  11%|█         | 294/2645 [00:28<03:49, 10.26it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  11%|█         | 294/2645 [00:28<03:49, 10.26it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  11%|█         | 294/2645 [00:28<03:49, 10.26it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  11%|█         | 296/2645 [00:28<03:46, 10.36it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  11%|█         | 296/2645 [00:28<03:46, 10.36it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  11%|█         | 296/2645 [00:28<03:46, 10.36it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  11%|█▏        | 298/2645 [00:28<03:46, 10.38it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  11%|█▏        | 298/2645 [00:28<03:46, 10.38it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  11%|█▏        | 298/2645 [00:28<03:46, 10.38it/s, training_loss=0.646]\u001b[A\n",
      "Epoch 3:  11%|█▏        | 300/2645 [00:28<03:45, 10.39it/s, training_loss=0.646]\u001b[A\n",
      "Epoch 3:  11%|█▏        | 300/2645 [00:28<03:45, 10.39it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  11%|█▏        | 300/2645 [00:29<03:45, 10.39it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 3:  11%|█▏        | 302/2645 [00:29<03:45, 10.39it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 3:  11%|█▏        | 302/2645 [00:29<03:45, 10.39it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  11%|█▏        | 302/2645 [00:29<03:45, 10.39it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  11%|█▏        | 304/2645 [00:29<03:44, 10.42it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  11%|█▏        | 304/2645 [00:29<03:44, 10.42it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  11%|█▏        | 304/2645 [00:29<03:44, 10.42it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  12%|█▏        | 306/2645 [00:29<03:43, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  12%|█▏        | 306/2645 [00:29<03:43, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  12%|█▏        | 306/2645 [00:29<03:43, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  12%|█▏        | 308/2645 [00:29<03:42, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  12%|█▏        | 308/2645 [00:29<03:42, 10.48it/s, training_loss=0.911]\u001b[A\n",
      "Epoch 3:  12%|█▏        | 308/2645 [00:29<03:42, 10.48it/s, training_loss=0.826]\u001b[A\n",
      "Epoch 3:  12%|█▏        | 310/2645 [00:29<03:43, 10.44it/s, training_loss=0.826]\u001b[A\n",
      "Epoch 3:  12%|█▏        | 310/2645 [00:29<03:43, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  12%|█▏        | 310/2645 [00:30<03:43, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  12%|█▏        | 312/2645 [00:30<03:42, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  12%|█▏        | 312/2645 [00:30<03:42, 10.49it/s, training_loss=0.578]\u001b[A\n",
      "Epoch 3:  12%|█▏        | 312/2645 [00:30<03:42, 10.49it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  12%|█▏        | 314/2645 [00:30<03:42, 10.46it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  12%|█▏        | 314/2645 [00:30<03:42, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  12%|█▏        | 314/2645 [00:30<03:42, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  12%|█▏        | 316/2645 [00:30<03:44, 10.36it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  12%|█▏        | 316/2645 [00:30<03:44, 10.36it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  12%|█▏        | 316/2645 [00:30<03:44, 10.36it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 3:  12%|█▏        | 318/2645 [00:30<03:44, 10.37it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 3:  12%|█▏        | 318/2645 [00:30<03:44, 10.37it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  12%|█▏        | 318/2645 [00:30<03:44, 10.37it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  12%|█▏        | 320/2645 [00:30<03:42, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  12%|█▏        | 320/2645 [00:30<03:42, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  12%|█▏        | 320/2645 [00:30<03:42, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  12%|█▏        | 322/2645 [00:30<03:43, 10.40it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  12%|█▏        | 322/2645 [00:31<03:43, 10.40it/s, training_loss=0.014]\u001b[A\n",
      "Epoch 3:  12%|█▏        | 322/2645 [00:31<03:43, 10.40it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  12%|█▏        | 324/2645 [00:31<03:43, 10.39it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  12%|█▏        | 324/2645 [00:31<03:43, 10.39it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  12%|█▏        | 324/2645 [00:31<03:43, 10.39it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  12%|█▏        | 326/2645 [00:31<03:42, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  12%|█▏        | 326/2645 [00:31<03:42, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  12%|█▏        | 326/2645 [00:31<03:42, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  12%|█▏        | 328/2645 [00:31<03:41, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  12%|█▏        | 328/2645 [00:31<03:41, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  12%|█▏        | 328/2645 [00:31<03:41, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  12%|█▏        | 330/2645 [00:31<03:41, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  12%|█▏        | 330/2645 [00:31<03:41, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  12%|█▏        | 330/2645 [00:31<03:41, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  13%|█▎        | 332/2645 [00:31<03:40, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  13%|█▎        | 332/2645 [00:32<03:40, 10.49it/s, training_loss=0.010]\u001b[A\n",
      "Epoch 3:  13%|█▎        | 332/2645 [00:32<03:40, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  13%|█▎        | 334/2645 [00:32<03:40, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  13%|█▎        | 334/2645 [00:32<03:40, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  13%|█▎        | 334/2645 [00:32<03:40, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  13%|█▎        | 336/2645 [00:32<03:39, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  13%|█▎        | 336/2645 [00:32<03:39, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  13%|█▎        | 336/2645 [00:32<03:39, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  13%|█▎        | 338/2645 [00:32<03:39, 10.53it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  13%|█▎        | 338/2645 [00:32<03:39, 10.53it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  13%|█▎        | 338/2645 [00:32<03:39, 10.53it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  13%|█▎        | 340/2645 [00:32<03:38, 10.54it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  13%|█▎        | 340/2645 [00:32<03:38, 10.54it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  13%|█▎        | 340/2645 [00:32<03:38, 10.54it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  13%|█▎        | 342/2645 [00:32<03:39, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  13%|█▎        | 342/2645 [00:32<03:39, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  13%|█▎        | 342/2645 [00:33<03:39, 10.51it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  13%|█▎        | 344/2645 [00:33<03:38, 10.52it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  13%|█▎        | 344/2645 [00:33<03:38, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  13%|█▎        | 344/2645 [00:33<03:38, 10.52it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  13%|█▎        | 346/2645 [00:33<03:39, 10.49it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  13%|█▎        | 346/2645 [00:33<03:39, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  13%|█▎        | 346/2645 [00:33<03:39, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  13%|█▎        | 348/2645 [00:33<03:38, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  13%|█▎        | 348/2645 [00:33<03:38, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  13%|█▎        | 348/2645 [00:33<03:38, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  13%|█▎        | 350/2645 [00:33<03:38, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  13%|█▎        | 350/2645 [00:33<03:38, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  13%|█▎        | 350/2645 [00:33<03:38, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  13%|█▎        | 352/2645 [00:33<03:37, 10.55it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  13%|█▎        | 352/2645 [00:33<03:37, 10.55it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  13%|█▎        | 352/2645 [00:34<03:37, 10.55it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 3:  13%|█▎        | 354/2645 [00:34<03:37, 10.54it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 3:  13%|█▎        | 354/2645 [00:34<03:37, 10.54it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  13%|█▎        | 354/2645 [00:34<03:37, 10.54it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  13%|█▎        | 356/2645 [00:34<03:37, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  13%|█▎        | 356/2645 [00:34<03:37, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  13%|█▎        | 356/2645 [00:34<03:37, 10.52it/s, training_loss=0.761]\u001b[A\n",
      "Epoch 3:  14%|█▎        | 358/2645 [00:34<03:38, 10.44it/s, training_loss=0.761]\u001b[A\n",
      "Epoch 3:  14%|█▎        | 358/2645 [00:34<03:38, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  14%|█▎        | 358/2645 [00:34<03:38, 10.44it/s, training_loss=0.016]\u001b[A\n",
      "Epoch 3:  14%|█▎        | 360/2645 [00:34<03:38, 10.45it/s, training_loss=0.016]\u001b[A\n",
      "Epoch 3:  14%|█▎        | 360/2645 [00:34<03:38, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  14%|█▎        | 360/2645 [00:34<03:38, 10.45it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  14%|█▎        | 362/2645 [00:34<03:37, 10.49it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  14%|█▎        | 362/2645 [00:34<03:37, 10.49it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  14%|█▎        | 362/2645 [00:34<03:37, 10.49it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  14%|█▍        | 364/2645 [00:34<03:37, 10.51it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  14%|█▍        | 364/2645 [00:35<03:37, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  14%|█▍        | 364/2645 [00:35<03:37, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  14%|█▍        | 366/2645 [00:35<03:36, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  14%|█▍        | 366/2645 [00:35<03:36, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  14%|█▍        | 366/2645 [00:35<03:36, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  14%|█▍        | 368/2645 [00:35<03:35, 10.56it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  14%|█▍        | 368/2645 [00:35<03:35, 10.56it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  14%|█▍        | 368/2645 [00:35<03:35, 10.56it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  14%|█▍        | 370/2645 [00:35<03:36, 10.53it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  14%|█▍        | 370/2645 [00:35<03:36, 10.53it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  14%|█▍        | 370/2645 [00:35<03:36, 10.53it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  14%|█▍        | 372/2645 [00:35<03:36, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  14%|█▍        | 372/2645 [00:35<03:36, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  14%|█▍        | 372/2645 [00:35<03:36, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  14%|█▍        | 374/2645 [00:35<03:35, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  14%|█▍        | 374/2645 [00:36<03:35, 10.52it/s, training_loss=0.013]\u001b[A\n",
      "Epoch 3:  14%|█▍        | 374/2645 [00:36<03:35, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  14%|█▍        | 376/2645 [00:36<03:35, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  14%|█▍        | 376/2645 [00:36<03:35, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  14%|█▍        | 376/2645 [00:36<03:35, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  14%|█▍        | 378/2645 [00:36<03:35, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  14%|█▍        | 378/2645 [00:36<03:35, 10.50it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  14%|█▍        | 378/2645 [00:36<03:35, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  14%|█▍        | 380/2645 [00:36<03:34, 10.54it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  14%|█▍        | 380/2645 [00:36<03:34, 10.54it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  14%|█▍        | 380/2645 [00:36<03:34, 10.54it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  14%|█▍        | 382/2645 [00:36<03:34, 10.54it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  14%|█▍        | 382/2645 [00:36<03:34, 10.54it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  14%|█▍        | 382/2645 [00:36<03:34, 10.54it/s, training_loss=0.763]\u001b[A\n",
      "Epoch 3:  15%|█▍        | 384/2645 [00:36<03:35, 10.52it/s, training_loss=0.763]\u001b[A\n",
      "Epoch 3:  15%|█▍        | 384/2645 [00:36<03:35, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  15%|█▍        | 384/2645 [00:37<03:35, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  15%|█▍        | 386/2645 [00:37<03:34, 10.55it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  15%|█▍        | 386/2645 [00:37<03:34, 10.55it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  15%|█▍        | 386/2645 [00:37<03:34, 10.55it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  15%|█▍        | 388/2645 [00:37<03:33, 10.56it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  15%|█▍        | 388/2645 [00:37<03:33, 10.56it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  15%|█▍        | 388/2645 [00:37<03:33, 10.56it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  15%|█▍        | 390/2645 [00:37<03:34, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  15%|█▍        | 390/2645 [00:37<03:34, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  15%|█▍        | 390/2645 [00:37<03:34, 10.52it/s, training_loss=0.667]\u001b[A\n",
      "Epoch 3:  15%|█▍        | 392/2645 [00:37<03:35, 10.46it/s, training_loss=0.667]\u001b[A\n",
      "Epoch 3:  15%|█▍        | 392/2645 [00:37<03:35, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  15%|█▍        | 392/2645 [00:37<03:35, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  15%|█▍        | 394/2645 [00:37<03:35, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  15%|█▍        | 394/2645 [00:37<03:35, 10.47it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  15%|█▍        | 394/2645 [00:38<03:35, 10.47it/s, training_loss=0.023]\u001b[A\n",
      "Epoch 3:  15%|█▍        | 396/2645 [00:38<03:36, 10.40it/s, training_loss=0.023]\u001b[A\n",
      "Epoch 3:  15%|█▍        | 396/2645 [00:38<03:36, 10.40it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  15%|█▍        | 396/2645 [00:38<03:36, 10.40it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  15%|█▌        | 398/2645 [00:38<03:35, 10.41it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  15%|█▌        | 398/2645 [00:38<03:35, 10.41it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  15%|█▌        | 398/2645 [00:38<03:35, 10.41it/s, training_loss=0.480]\u001b[A\n",
      "Epoch 3:  15%|█▌        | 400/2645 [00:38<03:35, 10.40it/s, training_loss=0.480]\u001b[A\n",
      "Epoch 3:  15%|█▌        | 400/2645 [00:38<03:35, 10.40it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  15%|█▌        | 400/2645 [00:38<03:35, 10.40it/s, training_loss=0.550]\u001b[A\n",
      "Epoch 3:  15%|█▌        | 402/2645 [00:38<03:37, 10.31it/s, training_loss=0.550]\u001b[A\n",
      "Epoch 3:  15%|█▌        | 402/2645 [00:38<03:37, 10.31it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  15%|█▌        | 402/2645 [00:38<03:37, 10.31it/s, training_loss=0.503]\u001b[A\n",
      "Epoch 3:  15%|█▌        | 404/2645 [00:38<03:37, 10.29it/s, training_loss=0.503]\u001b[A\n",
      "Epoch 3:  15%|█▌        | 404/2645 [00:38<03:37, 10.29it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  15%|█▌        | 404/2645 [00:38<03:37, 10.29it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  15%|█▌        | 406/2645 [00:38<03:37, 10.31it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  15%|█▌        | 406/2645 [00:39<03:37, 10.31it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  15%|█▌        | 406/2645 [00:39<03:37, 10.31it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  15%|█▌        | 408/2645 [00:39<03:40, 10.16it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  15%|█▌        | 408/2645 [00:39<03:40, 10.16it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  15%|█▌        | 408/2645 [00:39<03:40, 10.16it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  16%|█▌        | 410/2645 [00:39<03:38, 10.22it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  16%|█▌        | 410/2645 [00:39<03:38, 10.22it/s, training_loss=0.366]\u001b[A\n",
      "Epoch 3:  16%|█▌        | 410/2645 [00:39<03:38, 10.22it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  16%|█▌        | 412/2645 [00:39<03:39, 10.16it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  16%|█▌        | 412/2645 [00:39<03:39, 10.16it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 3:  16%|█▌        | 412/2645 [00:39<03:39, 10.16it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  16%|█▌        | 414/2645 [00:39<03:39, 10.17it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  16%|█▌        | 414/2645 [00:39<03:39, 10.17it/s, training_loss=0.239]\u001b[A\n",
      "Epoch 3:  16%|█▌        | 414/2645 [00:39<03:39, 10.17it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  16%|█▌        | 416/2645 [00:39<03:39, 10.14it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  16%|█▌        | 416/2645 [00:40<03:39, 10.14it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  16%|█▌        | 416/2645 [00:40<03:39, 10.14it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  16%|█▌        | 418/2645 [00:40<03:39, 10.13it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  16%|█▌        | 418/2645 [00:40<03:39, 10.13it/s, training_loss=0.660]\u001b[A\n",
      "Epoch 3:  16%|█▌        | 418/2645 [00:40<03:39, 10.13it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  16%|█▌        | 420/2645 [00:40<03:41, 10.04it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  16%|█▌        | 420/2645 [00:40<03:41, 10.04it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  16%|█▌        | 420/2645 [00:40<03:41, 10.04it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  16%|█▌        | 422/2645 [00:40<03:39, 10.13it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  16%|█▌        | 422/2645 [00:40<03:39, 10.13it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  16%|█▌        | 422/2645 [00:40<03:39, 10.13it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  16%|█▌        | 424/2645 [00:40<03:36, 10.25it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  16%|█▌        | 424/2645 [00:40<03:36, 10.25it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  16%|█▌        | 424/2645 [00:40<03:36, 10.25it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  16%|█▌        | 426/2645 [00:40<03:34, 10.33it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  16%|█▌        | 426/2645 [00:41<03:34, 10.33it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  16%|█▌        | 426/2645 [00:41<03:34, 10.33it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  16%|█▌        | 428/2645 [00:41<03:33, 10.41it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  16%|█▌        | 428/2645 [00:41<03:33, 10.41it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  16%|█▌        | 428/2645 [00:41<03:33, 10.41it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  16%|█▋        | 430/2645 [00:41<03:31, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  16%|█▋        | 430/2645 [00:41<03:31, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  16%|█▋        | 430/2645 [00:41<03:31, 10.46it/s, training_loss=1.126]\u001b[A\n",
      "Epoch 3:  16%|█▋        | 432/2645 [00:41<03:31, 10.48it/s, training_loss=1.126]\u001b[A\n",
      "Epoch 3:  16%|█▋        | 432/2645 [00:41<03:31, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  16%|█▋        | 432/2645 [00:41<03:31, 10.48it/s, training_loss=0.548]\u001b[A\n",
      "Epoch 3:  16%|█▋        | 434/2645 [00:41<03:30, 10.49it/s, training_loss=0.548]\u001b[A\n",
      "Epoch 3:  16%|█▋        | 434/2645 [00:41<03:30, 10.49it/s, training_loss=0.182]\u001b[A\n",
      "Epoch 3:  16%|█▋        | 434/2645 [00:41<03:30, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  16%|█▋        | 436/2645 [00:41<03:30, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  16%|█▋        | 436/2645 [00:42<03:30, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  16%|█▋        | 436/2645 [00:42<03:30, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  17%|█▋        | 438/2645 [00:42<03:30, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  17%|█▋        | 438/2645 [00:42<03:30, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  17%|█▋        | 438/2645 [00:42<03:30, 10.47it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  17%|█▋        | 440/2645 [00:42<03:31, 10.44it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  17%|█▋        | 440/2645 [00:42<03:31, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  17%|█▋        | 440/2645 [00:42<03:31, 10.44it/s, training_loss=0.067]\u001b[A\n",
      "Epoch 3:  17%|█▋        | 442/2645 [00:42<03:30, 10.45it/s, training_loss=0.067]\u001b[A\n",
      "Epoch 3:  17%|█▋        | 442/2645 [00:42<03:30, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  17%|█▋        | 442/2645 [00:42<03:30, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  17%|█▋        | 444/2645 [00:42<03:29, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  17%|█▋        | 444/2645 [00:42<03:29, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  17%|█▋        | 444/2645 [00:42<03:29, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  17%|█▋        | 446/2645 [00:42<03:28, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  17%|█▋        | 446/2645 [00:42<03:28, 10.52it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  17%|█▋        | 446/2645 [00:43<03:28, 10.52it/s, training_loss=0.581]\u001b[A\n",
      "Epoch 3:  17%|█▋        | 448/2645 [00:43<03:29, 10.51it/s, training_loss=0.581]\u001b[A\n",
      "Epoch 3:  17%|█▋        | 448/2645 [00:43<03:29, 10.51it/s, training_loss=0.692]\u001b[A\n",
      "Epoch 3:  17%|█▋        | 448/2645 [00:43<03:29, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  17%|█▋        | 450/2645 [00:43<03:29, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  17%|█▋        | 450/2645 [00:43<03:29, 10.50it/s, training_loss=0.684]\u001b[A\n",
      "Epoch 3:  17%|█▋        | 450/2645 [00:43<03:29, 10.50it/s, training_loss=0.101]\u001b[A\n",
      "Epoch 3:  17%|█▋        | 452/2645 [00:43<03:30, 10.39it/s, training_loss=0.101]\u001b[A\n",
      "Epoch 3:  17%|█▋        | 452/2645 [00:43<03:30, 10.39it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  17%|█▋        | 452/2645 [00:43<03:30, 10.39it/s, training_loss=0.189]\u001b[A\n",
      "Epoch 3:  17%|█▋        | 454/2645 [00:43<03:30, 10.42it/s, training_loss=0.189]\u001b[A\n",
      "Epoch 3:  17%|█▋        | 454/2645 [00:43<03:30, 10.42it/s, training_loss=0.280]\u001b[A\n",
      "Epoch 3:  17%|█▋        | 454/2645 [00:43<03:30, 10.42it/s, training_loss=0.462]\u001b[A\n",
      "Epoch 3:  17%|█▋        | 456/2645 [00:43<03:30, 10.42it/s, training_loss=0.462]\u001b[A\n",
      "Epoch 3:  17%|█▋        | 456/2645 [00:43<03:30, 10.42it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  17%|█▋        | 456/2645 [00:44<03:30, 10.42it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  17%|█▋        | 458/2645 [00:44<03:29, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  17%|█▋        | 458/2645 [00:44<03:29, 10.45it/s, training_loss=0.154]\u001b[A\n",
      "Epoch 3:  17%|█▋        | 458/2645 [00:44<03:29, 10.45it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  17%|█▋        | 460/2645 [00:44<03:30, 10.40it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  17%|█▋        | 460/2645 [00:44<03:30, 10.40it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  17%|█▋        | 460/2645 [00:44<03:30, 10.40it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  17%|█▋        | 462/2645 [00:44<03:28, 10.46it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  17%|█▋        | 462/2645 [00:44<03:28, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  17%|█▋        | 462/2645 [00:44<03:28, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  18%|█▊        | 464/2645 [00:44<03:27, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  18%|█▊        | 464/2645 [00:44<03:27, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  18%|█▊        | 464/2645 [00:44<03:27, 10.52it/s, training_loss=0.634]\u001b[A\n",
      "Epoch 3:  18%|█▊        | 466/2645 [00:44<03:28, 10.43it/s, training_loss=0.634]\u001b[A\n",
      "Epoch 3:  18%|█▊        | 466/2645 [00:44<03:28, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  18%|█▊        | 466/2645 [00:44<03:28, 10.43it/s, training_loss=0.889]\u001b[A\n",
      "Epoch 3:  18%|█▊        | 468/2645 [00:44<03:28, 10.45it/s, training_loss=0.889]\u001b[A\n",
      "Epoch 3:  18%|█▊        | 468/2645 [00:45<03:28, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  18%|█▊        | 468/2645 [00:45<03:28, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  18%|█▊        | 470/2645 [00:45<03:27, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  18%|█▊        | 470/2645 [00:45<03:27, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  18%|█▊        | 470/2645 [00:45<03:27, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  18%|█▊        | 472/2645 [00:45<03:27, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  18%|█▊        | 472/2645 [00:45<03:27, 10.46it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  18%|█▊        | 472/2645 [00:45<03:27, 10.46it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  18%|█▊        | 474/2645 [00:45<03:31, 10.28it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  18%|█▊        | 474/2645 [00:45<03:31, 10.28it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  18%|█▊        | 474/2645 [00:45<03:31, 10.28it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  18%|█▊        | 476/2645 [00:45<03:31, 10.26it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  18%|█▊        | 476/2645 [00:45<03:31, 10.26it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  18%|█▊        | 476/2645 [00:45<03:31, 10.26it/s, training_loss=0.353]\u001b[A\n",
      "Epoch 3:  18%|█▊        | 478/2645 [00:45<03:30, 10.32it/s, training_loss=0.353]\u001b[A\n",
      "Epoch 3:  18%|█▊        | 478/2645 [00:46<03:30, 10.32it/s, training_loss=0.636]\u001b[A\n",
      "Epoch 3:  18%|█▊        | 478/2645 [00:46<03:30, 10.32it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  18%|█▊        | 480/2645 [00:46<03:28, 10.37it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  18%|█▊        | 480/2645 [00:46<03:28, 10.37it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  18%|█▊        | 480/2645 [00:46<03:28, 10.37it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  18%|█▊        | 482/2645 [00:46<03:26, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  18%|█▊        | 482/2645 [00:46<03:26, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  18%|█▊        | 482/2645 [00:46<03:26, 10.46it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  18%|█▊        | 484/2645 [00:46<03:28, 10.38it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  18%|█▊        | 484/2645 [00:46<03:28, 10.38it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  18%|█▊        | 484/2645 [00:46<03:28, 10.38it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  18%|█▊        | 486/2645 [00:46<03:26, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  18%|█▊        | 486/2645 [00:46<03:26, 10.45it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  18%|█▊        | 486/2645 [00:46<03:26, 10.45it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  18%|█▊        | 488/2645 [00:46<03:25, 10.50it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  18%|█▊        | 488/2645 [00:46<03:25, 10.50it/s, training_loss=0.018]\u001b[A\n",
      "Epoch 3:  18%|█▊        | 488/2645 [00:47<03:25, 10.50it/s, training_loss=0.697]\u001b[A\n",
      "Epoch 3:  19%|█▊        | 490/2645 [00:47<03:26, 10.45it/s, training_loss=0.697]\u001b[A\n",
      "Epoch 3:  19%|█▊        | 490/2645 [00:47<03:26, 10.45it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  19%|█▊        | 490/2645 [00:47<03:26, 10.45it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  19%|█▊        | 492/2645 [00:47<03:25, 10.45it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  19%|█▊        | 492/2645 [00:47<03:25, 10.45it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  19%|█▊        | 492/2645 [00:47<03:25, 10.45it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  19%|█▊        | 494/2645 [00:47<03:25, 10.46it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  19%|█▊        | 494/2645 [00:47<03:25, 10.46it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  19%|█▊        | 494/2645 [00:47<03:25, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  19%|█▉        | 496/2645 [00:47<03:26, 10.41it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  19%|█▉        | 496/2645 [00:47<03:26, 10.41it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  19%|█▉        | 496/2645 [00:47<03:26, 10.41it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  19%|█▉        | 498/2645 [00:47<03:25, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  19%|█▉        | 498/2645 [00:47<03:25, 10.46it/s, training_loss=0.027]\u001b[A\n",
      "Epoch 3:  19%|█▉        | 498/2645 [00:48<03:25, 10.46it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  19%|█▉        | 500/2645 [00:48<03:24, 10.49it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  19%|█▉        | 500/2645 [00:48<03:24, 10.49it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  19%|█▉        | 500/2645 [00:48<03:24, 10.49it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  19%|█▉        | 502/2645 [00:48<03:23, 10.52it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  19%|█▉        | 502/2645 [00:48<03:23, 10.52it/s, training_loss=0.014]\u001b[A\n",
      "Epoch 3:  19%|█▉        | 502/2645 [00:48<03:23, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  19%|█▉        | 504/2645 [00:48<03:23, 10.53it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  19%|█▉        | 504/2645 [00:48<03:23, 10.53it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  19%|█▉        | 504/2645 [00:48<03:23, 10.53it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  19%|█▉        | 506/2645 [00:48<03:22, 10.56it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  19%|█▉        | 506/2645 [00:48<03:22, 10.56it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  19%|█▉        | 506/2645 [00:48<03:22, 10.56it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  19%|█▉        | 508/2645 [00:48<03:23, 10.49it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  19%|█▉        | 508/2645 [00:48<03:23, 10.49it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  19%|█▉        | 508/2645 [00:48<03:23, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  19%|█▉        | 510/2645 [00:48<03:23, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  19%|█▉        | 510/2645 [00:49<03:23, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  19%|█▉        | 510/2645 [00:49<03:23, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  19%|█▉        | 512/2645 [00:49<03:22, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  19%|█▉        | 512/2645 [00:49<03:22, 10.51it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  19%|█▉        | 512/2645 [00:49<03:22, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  19%|█▉        | 514/2645 [00:49<03:22, 10.54it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  19%|█▉        | 514/2645 [00:49<03:22, 10.54it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  19%|█▉        | 514/2645 [00:49<03:22, 10.54it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  20%|█▉        | 516/2645 [00:49<03:21, 10.56it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  20%|█▉        | 516/2645 [00:49<03:21, 10.56it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  20%|█▉        | 516/2645 [00:49<03:21, 10.56it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  20%|█▉        | 518/2645 [00:49<03:21, 10.56it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  20%|█▉        | 518/2645 [00:49<03:21, 10.56it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  20%|█▉        | 518/2645 [00:49<03:21, 10.56it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  20%|█▉        | 520/2645 [00:49<03:20, 10.59it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  20%|█▉        | 520/2645 [00:50<03:20, 10.59it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  20%|█▉        | 520/2645 [00:50<03:20, 10.59it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  20%|█▉        | 522/2645 [00:50<03:20, 10.57it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  20%|█▉        | 522/2645 [00:50<03:20, 10.57it/s, training_loss=0.099]\u001b[A\n",
      "Epoch 3:  20%|█▉        | 522/2645 [00:50<03:20, 10.57it/s, training_loss=0.739]\u001b[A\n",
      "Epoch 3:  20%|█▉        | 524/2645 [00:50<03:21, 10.51it/s, training_loss=0.739]\u001b[A\n",
      "Epoch 3:  20%|█▉        | 524/2645 [00:50<03:21, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  20%|█▉        | 524/2645 [00:50<03:21, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  20%|█▉        | 526/2645 [00:50<03:21, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  20%|█▉        | 526/2645 [00:50<03:21, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  20%|█▉        | 526/2645 [00:50<03:21, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  20%|█▉        | 528/2645 [00:50<03:21, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  20%|█▉        | 528/2645 [00:50<03:21, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  20%|█▉        | 528/2645 [00:50<03:21, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  20%|██        | 530/2645 [00:50<03:20, 10.54it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  20%|██        | 530/2645 [00:50<03:20, 10.54it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  20%|██        | 530/2645 [00:51<03:20, 10.54it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  20%|██        | 532/2645 [00:51<03:21, 10.48it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  20%|██        | 532/2645 [00:51<03:21, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  20%|██        | 532/2645 [00:51<03:21, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  20%|██        | 534/2645 [00:51<03:21, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  20%|██        | 534/2645 [00:51<03:21, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  20%|██        | 534/2645 [00:51<03:21, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  20%|██        | 536/2645 [00:51<03:20, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  20%|██        | 536/2645 [00:51<03:20, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  20%|██        | 536/2645 [00:51<03:20, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  20%|██        | 538/2645 [00:51<03:20, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  20%|██        | 538/2645 [00:51<03:20, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  20%|██        | 538/2645 [00:51<03:20, 10.49it/s, training_loss=0.094]\u001b[A\n",
      "Epoch 3:  20%|██        | 540/2645 [00:51<03:21, 10.43it/s, training_loss=0.094]\u001b[A\n",
      "Epoch 3:  20%|██        | 540/2645 [00:51<03:21, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  20%|██        | 540/2645 [00:52<03:21, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  20%|██        | 542/2645 [00:52<03:20, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  20%|██        | 542/2645 [00:52<03:20, 10.48it/s, training_loss=0.395]\u001b[A\n",
      "Epoch 3:  20%|██        | 542/2645 [00:52<03:20, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  21%|██        | 544/2645 [00:52<03:20, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  21%|██        | 544/2645 [00:52<03:20, 10.49it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  21%|██        | 544/2645 [00:52<03:20, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  21%|██        | 546/2645 [00:52<03:21, 10.41it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  21%|██        | 546/2645 [00:52<03:21, 10.41it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  21%|██        | 546/2645 [00:52<03:21, 10.41it/s, training_loss=0.021]\u001b[A\n",
      "Epoch 3:  21%|██        | 548/2645 [00:52<03:20, 10.44it/s, training_loss=0.021]\u001b[A\n",
      "Epoch 3:  21%|██        | 548/2645 [00:52<03:20, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  21%|██        | 548/2645 [00:52<03:20, 10.44it/s, training_loss=0.645]\u001b[A\n",
      "Epoch 3:  21%|██        | 550/2645 [00:52<03:22, 10.32it/s, training_loss=0.645]\u001b[A\n",
      "Epoch 3:  21%|██        | 550/2645 [00:52<03:22, 10.32it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  21%|██        | 550/2645 [00:53<03:22, 10.32it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  21%|██        | 552/2645 [00:53<03:23, 10.29it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  21%|██        | 552/2645 [00:53<03:23, 10.29it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  21%|██        | 552/2645 [00:53<03:23, 10.29it/s, training_loss=0.130]\u001b[A\n",
      "Epoch 3:  21%|██        | 554/2645 [00:53<03:24, 10.24it/s, training_loss=0.130]\u001b[A\n",
      "Epoch 3:  21%|██        | 554/2645 [00:53<03:24, 10.24it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  21%|██        | 554/2645 [00:53<03:24, 10.24it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  21%|██        | 556/2645 [00:53<03:22, 10.33it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  21%|██        | 556/2645 [00:53<03:22, 10.33it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  21%|██        | 556/2645 [00:53<03:22, 10.33it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  21%|██        | 558/2645 [00:53<03:20, 10.40it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  21%|██        | 558/2645 [00:53<03:20, 10.40it/s, training_loss=0.011]\u001b[A\n",
      "Epoch 3:  21%|██        | 558/2645 [00:53<03:20, 10.40it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  21%|██        | 560/2645 [00:53<03:19, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  21%|██        | 560/2645 [00:53<03:19, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  21%|██        | 560/2645 [00:53<03:19, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  21%|██        | 562/2645 [00:53<03:19, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  21%|██        | 562/2645 [00:54<03:19, 10.43it/s, training_loss=0.173]\u001b[A\n",
      "Epoch 3:  21%|██        | 562/2645 [00:54<03:19, 10.43it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  21%|██▏       | 564/2645 [00:54<03:19, 10.44it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  21%|██▏       | 564/2645 [00:54<03:19, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  21%|██▏       | 564/2645 [00:54<03:19, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  21%|██▏       | 566/2645 [00:54<03:18, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  21%|██▏       | 566/2645 [00:54<03:18, 10.50it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  21%|██▏       | 566/2645 [00:54<03:18, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  21%|██▏       | 568/2645 [00:54<03:17, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  21%|██▏       | 568/2645 [00:54<03:17, 10.50it/s, training_loss=0.036]\u001b[A\n",
      "Epoch 3:  21%|██▏       | 568/2645 [00:54<03:17, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  22%|██▏       | 570/2645 [00:54<03:21, 10.30it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  22%|██▏       | 570/2645 [00:54<03:21, 10.30it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  22%|██▏       | 570/2645 [00:54<03:21, 10.30it/s, training_loss=0.757]\u001b[A\n",
      "Epoch 3:  22%|██▏       | 572/2645 [00:54<03:21, 10.29it/s, training_loss=0.757]\u001b[A\n",
      "Epoch 3:  22%|██▏       | 572/2645 [00:55<03:21, 10.29it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  22%|██▏       | 572/2645 [00:55<03:21, 10.29it/s, training_loss=0.104]\u001b[A\n",
      "Epoch 3:  22%|██▏       | 574/2645 [00:55<03:22, 10.22it/s, training_loss=0.104]\u001b[A\n",
      "Epoch 3:  22%|██▏       | 574/2645 [00:55<03:22, 10.22it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  22%|██▏       | 574/2645 [00:55<03:22, 10.22it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  22%|██▏       | 576/2645 [00:55<03:24, 10.14it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  22%|██▏       | 576/2645 [00:55<03:24, 10.14it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  22%|██▏       | 576/2645 [00:55<03:24, 10.14it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  22%|██▏       | 578/2645 [00:55<03:21, 10.27it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  22%|██▏       | 578/2645 [00:55<03:21, 10.27it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  22%|██▏       | 578/2645 [00:55<03:21, 10.27it/s, training_loss=0.832]\u001b[A\n",
      "Epoch 3:  22%|██▏       | 580/2645 [00:55<03:20, 10.32it/s, training_loss=0.832]\u001b[A\n",
      "Epoch 3:  22%|██▏       | 580/2645 [00:55<03:20, 10.32it/s, training_loss=1.058]\u001b[A\n",
      "Epoch 3:  22%|██▏       | 580/2645 [00:55<03:20, 10.32it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  22%|██▏       | 582/2645 [00:55<03:19, 10.36it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  22%|██▏       | 582/2645 [00:56<03:19, 10.36it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  22%|██▏       | 582/2645 [00:56<03:19, 10.36it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  22%|██▏       | 584/2645 [00:56<03:17, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  22%|██▏       | 584/2645 [00:56<03:17, 10.43it/s, training_loss=0.011]\u001b[A\n",
      "Epoch 3:  22%|██▏       | 584/2645 [00:56<03:17, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  22%|██▏       | 586/2645 [00:56<03:17, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  22%|██▏       | 586/2645 [00:56<03:17, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  22%|██▏       | 586/2645 [00:56<03:17, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  22%|██▏       | 588/2645 [00:56<03:16, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  22%|██▏       | 588/2645 [00:56<03:16, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  22%|██▏       | 588/2645 [00:56<03:16, 10.48it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  22%|██▏       | 590/2645 [00:56<03:15, 10.53it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  22%|██▏       | 590/2645 [00:56<03:15, 10.53it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  22%|██▏       | 590/2645 [00:56<03:15, 10.53it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  22%|██▏       | 592/2645 [00:56<03:14, 10.55it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  22%|██▏       | 592/2645 [00:56<03:14, 10.55it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  22%|██▏       | 592/2645 [00:57<03:14, 10.55it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  22%|██▏       | 594/2645 [00:57<03:14, 10.56it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  22%|██▏       | 594/2645 [00:57<03:14, 10.56it/s, training_loss=0.112]\u001b[A\n",
      "Epoch 3:  22%|██▏       | 594/2645 [00:57<03:14, 10.56it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 3:  23%|██▎       | 596/2645 [00:57<03:15, 10.47it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 3:  23%|██▎       | 596/2645 [00:57<03:15, 10.47it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  23%|██▎       | 596/2645 [00:57<03:15, 10.47it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  23%|██▎       | 598/2645 [00:57<03:15, 10.50it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  23%|██▎       | 598/2645 [00:57<03:15, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  23%|██▎       | 598/2645 [00:57<03:15, 10.50it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  23%|██▎       | 600/2645 [00:57<03:18, 10.32it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  23%|██▎       | 600/2645 [00:57<03:18, 10.32it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  23%|██▎       | 600/2645 [00:57<03:18, 10.32it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  23%|██▎       | 602/2645 [00:57<03:16, 10.42it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  23%|██▎       | 602/2645 [00:57<03:16, 10.42it/s, training_loss=0.198]\u001b[A\n",
      "Epoch 3:  23%|██▎       | 602/2645 [00:58<03:16, 10.42it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  23%|██▎       | 604/2645 [00:58<03:15, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  23%|██▎       | 604/2645 [00:58<03:15, 10.44it/s, training_loss=0.268]\u001b[A\n",
      "Epoch 3:  23%|██▎       | 604/2645 [00:58<03:15, 10.44it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  23%|██▎       | 606/2645 [00:58<03:16, 10.38it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  23%|██▎       | 606/2645 [00:58<03:16, 10.38it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  23%|██▎       | 606/2645 [00:58<03:16, 10.38it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  23%|██▎       | 608/2645 [00:58<03:17, 10.29it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  23%|██▎       | 608/2645 [00:58<03:17, 10.29it/s, training_loss=0.635]\u001b[A\n",
      "Epoch 3:  23%|██▎       | 608/2645 [00:58<03:17, 10.29it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  23%|██▎       | 610/2645 [00:58<03:18, 10.24it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  23%|██▎       | 610/2645 [00:58<03:18, 10.24it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  23%|██▎       | 610/2645 [00:58<03:18, 10.24it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  23%|██▎       | 612/2645 [00:58<03:21, 10.11it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  23%|██▎       | 612/2645 [00:58<03:21, 10.11it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 3:  23%|██▎       | 612/2645 [00:59<03:21, 10.11it/s, training_loss=0.519]\u001b[A\n",
      "Epoch 3:  23%|██▎       | 614/2645 [00:59<03:22, 10.02it/s, training_loss=0.519]\u001b[A\n",
      "Epoch 3:  23%|██▎       | 614/2645 [00:59<03:22, 10.02it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  23%|██▎       | 614/2645 [00:59<03:22, 10.02it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  23%|██▎       | 616/2645 [00:59<03:22, 10.03it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  23%|██▎       | 616/2645 [00:59<03:22, 10.03it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  23%|██▎       | 616/2645 [00:59<03:22, 10.03it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  23%|██▎       | 618/2645 [00:59<03:18, 10.19it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  23%|██▎       | 618/2645 [00:59<03:18, 10.19it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  23%|██▎       | 618/2645 [00:59<03:18, 10.19it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  23%|██▎       | 620/2645 [00:59<03:18, 10.22it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  23%|██▎       | 620/2645 [00:59<03:18, 10.22it/s, training_loss=0.136]\u001b[A\n",
      "Epoch 3:  23%|██▎       | 620/2645 [00:59<03:18, 10.22it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  24%|██▎       | 622/2645 [00:59<03:16, 10.28it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  24%|██▎       | 622/2645 [00:59<03:16, 10.28it/s, training_loss=0.012]\u001b[A\n",
      "Epoch 3:  24%|██▎       | 622/2645 [00:59<03:16, 10.28it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  24%|██▎       | 624/2645 [00:59<03:15, 10.33it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  24%|██▎       | 624/2645 [01:00<03:15, 10.33it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  24%|██▎       | 624/2645 [01:00<03:15, 10.33it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  24%|██▎       | 626/2645 [01:00<03:14, 10.40it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  24%|██▎       | 626/2645 [01:00<03:14, 10.40it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  24%|██▎       | 626/2645 [01:00<03:14, 10.40it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  24%|██▎       | 628/2645 [01:00<03:13, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  24%|██▎       | 628/2645 [01:00<03:13, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  24%|██▎       | 628/2645 [01:00<03:13, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  24%|██▍       | 630/2645 [01:00<03:12, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  24%|██▍       | 630/2645 [01:00<03:12, 10.49it/s, training_loss=0.260]\u001b[A\n",
      "Epoch 3:  24%|██▍       | 630/2645 [01:00<03:12, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  24%|██▍       | 632/2645 [01:00<03:11, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  24%|██▍       | 632/2645 [01:00<03:11, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  24%|██▍       | 632/2645 [01:00<03:11, 10.49it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 3:  24%|██▍       | 634/2645 [01:00<03:14, 10.32it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 3:  24%|██▍       | 634/2645 [01:01<03:14, 10.32it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  24%|██▍       | 634/2645 [01:01<03:14, 10.32it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  24%|██▍       | 636/2645 [01:01<03:14, 10.35it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  24%|██▍       | 636/2645 [01:01<03:14, 10.35it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  24%|██▍       | 636/2645 [01:01<03:14, 10.35it/s, training_loss=0.076]\u001b[A\n",
      "Epoch 3:  24%|██▍       | 638/2645 [01:01<03:13, 10.38it/s, training_loss=0.076]\u001b[A\n",
      "Epoch 3:  24%|██▍       | 638/2645 [01:01<03:13, 10.38it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  24%|██▍       | 638/2645 [01:01<03:13, 10.38it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  24%|██▍       | 640/2645 [01:01<03:11, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  24%|██▍       | 640/2645 [01:01<03:11, 10.45it/s, training_loss=0.814]\u001b[A\n",
      "Epoch 3:  24%|██▍       | 640/2645 [01:01<03:11, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  24%|██▍       | 642/2645 [01:01<03:11, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  24%|██▍       | 642/2645 [01:01<03:11, 10.44it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  24%|██▍       | 642/2645 [01:01<03:11, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  24%|██▍       | 644/2645 [01:01<03:11, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  24%|██▍       | 644/2645 [01:01<03:11, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  24%|██▍       | 644/2645 [01:02<03:11, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  24%|██▍       | 646/2645 [01:02<03:10, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  24%|██▍       | 646/2645 [01:02<03:10, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  24%|██▍       | 646/2645 [01:02<03:10, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  24%|██▍       | 648/2645 [01:02<03:09, 10.53it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  24%|██▍       | 648/2645 [01:02<03:09, 10.53it/s, training_loss=0.727]\u001b[A\n",
      "Epoch 3:  24%|██▍       | 648/2645 [01:02<03:09, 10.53it/s, training_loss=0.633]\u001b[A\n",
      "Epoch 3:  25%|██▍       | 650/2645 [01:02<03:11, 10.44it/s, training_loss=0.633]\u001b[A\n",
      "Epoch 3:  25%|██▍       | 650/2645 [01:02<03:11, 10.44it/s, training_loss=0.110]\u001b[A\n",
      "Epoch 3:  25%|██▍       | 650/2645 [01:02<03:11, 10.44it/s, training_loss=0.597]\u001b[A\n",
      "Epoch 3:  25%|██▍       | 652/2645 [01:02<03:11, 10.42it/s, training_loss=0.597]\u001b[A\n",
      "Epoch 3:  25%|██▍       | 652/2645 [01:02<03:11, 10.42it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  25%|██▍       | 652/2645 [01:02<03:11, 10.42it/s, training_loss=0.677]\u001b[A\n",
      "Epoch 3:  25%|██▍       | 654/2645 [01:02<03:10, 10.44it/s, training_loss=0.677]\u001b[A\n",
      "Epoch 3:  25%|██▍       | 654/2645 [01:02<03:10, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  25%|██▍       | 654/2645 [01:03<03:10, 10.44it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  25%|██▍       | 656/2645 [01:03<03:10, 10.43it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  25%|██▍       | 656/2645 [01:03<03:10, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  25%|██▍       | 656/2645 [01:03<03:10, 10.43it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  25%|██▍       | 658/2645 [01:03<03:10, 10.43it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  25%|██▍       | 658/2645 [01:03<03:10, 10.43it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  25%|██▍       | 658/2645 [01:03<03:10, 10.43it/s, training_loss=0.636]\u001b[A\n",
      "Epoch 3:  25%|██▍       | 660/2645 [01:03<03:12, 10.33it/s, training_loss=0.636]\u001b[A\n",
      "Epoch 3:  25%|██▍       | 660/2645 [01:03<03:12, 10.33it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  25%|██▍       | 660/2645 [01:03<03:12, 10.33it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  25%|██▌       | 662/2645 [01:03<03:13, 10.27it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  25%|██▌       | 662/2645 [01:03<03:13, 10.27it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  25%|██▌       | 662/2645 [01:03<03:13, 10.27it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  25%|██▌       | 664/2645 [01:03<03:13, 10.22it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  25%|██▌       | 664/2645 [01:03<03:13, 10.22it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  25%|██▌       | 664/2645 [01:04<03:13, 10.22it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  25%|██▌       | 666/2645 [01:04<03:15, 10.11it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  25%|██▌       | 666/2645 [01:04<03:15, 10.11it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  25%|██▌       | 666/2645 [01:04<03:15, 10.11it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  25%|██▌       | 668/2645 [01:04<03:14, 10.16it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  25%|██▌       | 668/2645 [01:04<03:14, 10.16it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  25%|██▌       | 668/2645 [01:04<03:14, 10.16it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  25%|██▌       | 670/2645 [01:04<03:13, 10.21it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  25%|██▌       | 670/2645 [01:04<03:13, 10.21it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 3:  25%|██▌       | 670/2645 [01:04<03:13, 10.21it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  25%|██▌       | 672/2645 [01:04<03:13, 10.22it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  25%|██▌       | 672/2645 [01:04<03:13, 10.22it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 3:  25%|██▌       | 672/2645 [01:04<03:13, 10.22it/s, training_loss=0.610]\u001b[A\n",
      "Epoch 3:  25%|██▌       | 674/2645 [01:04<03:13, 10.18it/s, training_loss=0.610]\u001b[A\n",
      "Epoch 3:  25%|██▌       | 674/2645 [01:04<03:13, 10.18it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  25%|██▌       | 674/2645 [01:04<03:13, 10.18it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 3:  26%|██▌       | 676/2645 [01:04<03:11, 10.26it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 3:  26%|██▌       | 676/2645 [01:05<03:11, 10.26it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  26%|██▌       | 676/2645 [01:05<03:11, 10.26it/s, training_loss=0.538]\u001b[A\n",
      "Epoch 3:  26%|██▌       | 678/2645 [01:05<03:11, 10.28it/s, training_loss=0.538]\u001b[A\n",
      "Epoch 3:  26%|██▌       | 678/2645 [01:05<03:11, 10.28it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  26%|██▌       | 678/2645 [01:05<03:11, 10.28it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  26%|██▌       | 680/2645 [01:05<03:09, 10.37it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  26%|██▌       | 680/2645 [01:05<03:09, 10.37it/s, training_loss=0.328]\u001b[A\n",
      "Epoch 3:  26%|██▌       | 680/2645 [01:05<03:09, 10.37it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  26%|██▌       | 682/2645 [01:05<03:08, 10.39it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  26%|██▌       | 682/2645 [01:05<03:08, 10.39it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  26%|██▌       | 682/2645 [01:05<03:08, 10.39it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  26%|██▌       | 684/2645 [01:05<03:08, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  26%|██▌       | 684/2645 [01:05<03:08, 10.43it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  26%|██▌       | 684/2645 [01:05<03:08, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  26%|██▌       | 686/2645 [01:05<03:07, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  26%|██▌       | 686/2645 [01:06<03:07, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  26%|██▌       | 686/2645 [01:06<03:07, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  26%|██▌       | 688/2645 [01:06<03:06, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  26%|██▌       | 688/2645 [01:06<03:06, 10.47it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  26%|██▌       | 688/2645 [01:06<03:06, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  26%|██▌       | 690/2645 [01:06<03:09, 10.34it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  26%|██▌       | 690/2645 [01:06<03:09, 10.34it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  26%|██▌       | 690/2645 [01:06<03:09, 10.34it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  26%|██▌       | 692/2645 [01:06<03:07, 10.42it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  26%|██▌       | 692/2645 [01:06<03:07, 10.42it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  26%|██▌       | 692/2645 [01:06<03:07, 10.42it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  26%|██▌       | 694/2645 [01:06<03:07, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  26%|██▌       | 694/2645 [01:06<03:07, 10.43it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  26%|██▌       | 694/2645 [01:06<03:07, 10.43it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  26%|██▋       | 696/2645 [01:06<03:06, 10.47it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  26%|██▋       | 696/2645 [01:06<03:06, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  26%|██▋       | 696/2645 [01:07<03:06, 10.47it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  26%|██▋       | 698/2645 [01:07<03:05, 10.48it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  26%|██▋       | 698/2645 [01:07<03:05, 10.48it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  26%|██▋       | 698/2645 [01:07<03:05, 10.48it/s, training_loss=0.793]\u001b[A\n",
      "Epoch 3:  26%|██▋       | 700/2645 [01:07<03:05, 10.46it/s, training_loss=0.793]\u001b[A\n",
      "Epoch 3:  26%|██▋       | 700/2645 [01:07<03:05, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  26%|██▋       | 700/2645 [01:07<03:05, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  27%|██▋       | 702/2645 [01:07<03:04, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  27%|██▋       | 702/2645 [01:07<03:04, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  27%|██▋       | 702/2645 [01:07<03:04, 10.51it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  27%|██▋       | 704/2645 [01:07<03:05, 10.47it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  27%|██▋       | 704/2645 [01:07<03:05, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  27%|██▋       | 704/2645 [01:07<03:05, 10.47it/s, training_loss=0.017]\u001b[A\n",
      "Epoch 3:  27%|██▋       | 706/2645 [01:07<03:05, 10.46it/s, training_loss=0.017]\u001b[A\n",
      "Epoch 3:  27%|██▋       | 706/2645 [01:07<03:05, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  27%|██▋       | 706/2645 [01:08<03:05, 10.46it/s, training_loss=0.938]\u001b[A\n",
      "Epoch 3:  27%|██▋       | 708/2645 [01:08<03:05, 10.47it/s, training_loss=0.938]\u001b[A\n",
      "Epoch 3:  27%|██▋       | 708/2645 [01:08<03:05, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  27%|██▋       | 708/2645 [01:08<03:05, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  27%|██▋       | 710/2645 [01:08<03:04, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  27%|██▋       | 710/2645 [01:08<03:04, 10.50it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  27%|██▋       | 710/2645 [01:08<03:04, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  27%|██▋       | 712/2645 [01:08<03:05, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  27%|██▋       | 712/2645 [01:08<03:05, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  27%|██▋       | 712/2645 [01:08<03:05, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  27%|██▋       | 714/2645 [01:08<03:04, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  27%|██▋       | 714/2645 [01:08<03:04, 10.48it/s, training_loss=0.157]\u001b[A\n",
      "Epoch 3:  27%|██▋       | 714/2645 [01:08<03:04, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  27%|██▋       | 716/2645 [01:08<03:04, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  27%|██▋       | 716/2645 [01:08<03:04, 10.44it/s, training_loss=0.441]\u001b[A\n",
      "Epoch 3:  27%|██▋       | 716/2645 [01:09<03:04, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  27%|██▋       | 718/2645 [01:09<03:06, 10.33it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  27%|██▋       | 718/2645 [01:09<03:06, 10.33it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  27%|██▋       | 718/2645 [01:09<03:06, 10.33it/s, training_loss=0.512]\u001b[A\n",
      "Epoch 3:  27%|██▋       | 720/2645 [01:09<03:06, 10.31it/s, training_loss=0.512]\u001b[A\n",
      "Epoch 3:  27%|██▋       | 720/2645 [01:09<03:06, 10.31it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  27%|██▋       | 720/2645 [01:09<03:06, 10.31it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  27%|██▋       | 722/2645 [01:09<03:05, 10.39it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  27%|██▋       | 722/2645 [01:09<03:05, 10.39it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  27%|██▋       | 722/2645 [01:09<03:05, 10.39it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  27%|██▋       | 724/2645 [01:09<03:03, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  27%|██▋       | 724/2645 [01:09<03:03, 10.45it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  27%|██▋       | 724/2645 [01:09<03:03, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  27%|██▋       | 726/2645 [01:09<03:03, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  27%|██▋       | 726/2645 [01:09<03:03, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  27%|██▋       | 726/2645 [01:09<03:03, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  28%|██▊       | 728/2645 [01:09<03:02, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  28%|██▊       | 728/2645 [01:10<03:02, 10.49it/s, training_loss=0.039]\u001b[A\n",
      "Epoch 3:  28%|██▊       | 728/2645 [01:10<03:02, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  28%|██▊       | 730/2645 [01:10<03:03, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  28%|██▊       | 730/2645 [01:10<03:03, 10.45it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  28%|██▊       | 730/2645 [01:10<03:03, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  28%|██▊       | 732/2645 [01:10<03:02, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  28%|██▊       | 732/2645 [01:10<03:02, 10.46it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  28%|██▊       | 732/2645 [01:10<03:02, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  28%|██▊       | 734/2645 [01:10<03:04, 10.36it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  28%|██▊       | 734/2645 [01:10<03:04, 10.36it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  28%|██▊       | 734/2645 [01:10<03:04, 10.36it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  28%|██▊       | 736/2645 [01:10<03:02, 10.44it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  28%|██▊       | 736/2645 [01:10<03:02, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  28%|██▊       | 736/2645 [01:10<03:02, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  28%|██▊       | 738/2645 [01:10<03:01, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  28%|██▊       | 738/2645 [01:11<03:01, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  28%|██▊       | 738/2645 [01:11<03:01, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  28%|██▊       | 740/2645 [01:11<03:02, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  28%|██▊       | 740/2645 [01:11<03:02, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  28%|██▊       | 740/2645 [01:11<03:02, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  28%|██▊       | 742/2645 [01:11<03:01, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  28%|██▊       | 742/2645 [01:11<03:01, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  28%|██▊       | 742/2645 [01:11<03:01, 10.49it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  28%|██▊       | 744/2645 [01:11<03:00, 10.52it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  28%|██▊       | 744/2645 [01:11<03:00, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  28%|██▊       | 744/2645 [01:11<03:00, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  28%|██▊       | 746/2645 [01:11<03:00, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  28%|██▊       | 746/2645 [01:11<03:00, 10.51it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 3:  28%|██▊       | 746/2645 [01:11<03:00, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  28%|██▊       | 748/2645 [01:11<03:00, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  28%|██▊       | 748/2645 [01:11<03:00, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  28%|██▊       | 748/2645 [01:12<03:00, 10.50it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 3:  28%|██▊       | 750/2645 [01:12<03:00, 10.48it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 3:  28%|██▊       | 750/2645 [01:12<03:00, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  28%|██▊       | 750/2645 [01:12<03:00, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  28%|██▊       | 752/2645 [01:12<03:00, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  28%|██▊       | 752/2645 [01:12<03:00, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  28%|██▊       | 752/2645 [01:12<03:00, 10.49it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 3:  29%|██▊       | 754/2645 [01:12<03:00, 10.49it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 3:  29%|██▊       | 754/2645 [01:12<03:00, 10.49it/s, training_loss=0.036]\u001b[A\n",
      "Epoch 3:  29%|██▊       | 754/2645 [01:12<03:00, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  29%|██▊       | 756/2645 [01:12<03:00, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  29%|██▊       | 756/2645 [01:12<03:00, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  29%|██▊       | 756/2645 [01:12<03:00, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  29%|██▊       | 758/2645 [01:12<02:59, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  29%|██▊       | 758/2645 [01:12<02:59, 10.51it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  29%|██▊       | 758/2645 [01:13<02:59, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  29%|██▊       | 760/2645 [01:13<02:58, 10.53it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  29%|██▊       | 760/2645 [01:13<02:58, 10.53it/s, training_loss=0.731]\u001b[A\n",
      "Epoch 3:  29%|██▊       | 760/2645 [01:13<02:58, 10.53it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  29%|██▉       | 762/2645 [01:13<02:58, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  29%|██▉       | 762/2645 [01:13<02:58, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  29%|██▉       | 762/2645 [01:13<02:58, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  29%|██▉       | 764/2645 [01:13<02:58, 10.53it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  29%|██▉       | 764/2645 [01:13<02:58, 10.53it/s, training_loss=0.031]\u001b[A\n",
      "Epoch 3:  29%|██▉       | 764/2645 [01:13<02:58, 10.53it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  29%|██▉       | 766/2645 [01:13<02:58, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  29%|██▉       | 766/2645 [01:13<02:58, 10.52it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  29%|██▉       | 766/2645 [01:13<02:58, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  29%|██▉       | 768/2645 [01:13<02:57, 10.55it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  29%|██▉       | 768/2645 [01:13<02:57, 10.55it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  29%|██▉       | 768/2645 [01:13<02:57, 10.55it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  29%|██▉       | 770/2645 [01:13<02:58, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  29%|██▉       | 770/2645 [01:14<02:58, 10.52it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  29%|██▉       | 770/2645 [01:14<02:58, 10.52it/s, training_loss=0.651]\u001b[A\n",
      "Epoch 3:  29%|██▉       | 772/2645 [01:14<02:58, 10.49it/s, training_loss=0.651]\u001b[A\n",
      "Epoch 3:  29%|██▉       | 772/2645 [01:14<02:58, 10.49it/s, training_loss=0.010]\u001b[A\n",
      "Epoch 3:  29%|██▉       | 772/2645 [01:14<02:58, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  29%|██▉       | 774/2645 [01:14<02:58, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  29%|██▉       | 774/2645 [01:14<02:58, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  29%|██▉       | 774/2645 [01:14<02:58, 10.46it/s, training_loss=0.396]\u001b[A\n",
      "Epoch 3:  29%|██▉       | 776/2645 [01:14<02:59, 10.42it/s, training_loss=0.396]\u001b[A\n",
      "Epoch 3:  29%|██▉       | 776/2645 [01:14<02:59, 10.42it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  29%|██▉       | 776/2645 [01:14<02:59, 10.42it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  29%|██▉       | 778/2645 [01:14<02:58, 10.43it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  29%|██▉       | 778/2645 [01:14<02:58, 10.43it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  29%|██▉       | 778/2645 [01:14<02:58, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  29%|██▉       | 780/2645 [01:14<02:57, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  29%|██▉       | 780/2645 [01:15<02:57, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  29%|██▉       | 780/2645 [01:15<02:57, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  30%|██▉       | 782/2645 [01:15<02:57, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  30%|██▉       | 782/2645 [01:15<02:57, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  30%|██▉       | 782/2645 [01:15<02:57, 10.48it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 3:  30%|██▉       | 784/2645 [01:15<02:59, 10.36it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 3:  30%|██▉       | 784/2645 [01:15<02:59, 10.36it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  30%|██▉       | 784/2645 [01:15<02:59, 10.36it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  30%|██▉       | 786/2645 [01:15<02:58, 10.41it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  30%|██▉       | 786/2645 [01:15<02:58, 10.41it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  30%|██▉       | 786/2645 [01:15<02:58, 10.41it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  30%|██▉       | 788/2645 [01:15<02:57, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  30%|██▉       | 788/2645 [01:15<02:57, 10.45it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  30%|██▉       | 788/2645 [01:15<02:57, 10.45it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  30%|██▉       | 790/2645 [01:15<02:57, 10.47it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  30%|██▉       | 790/2645 [01:15<02:57, 10.47it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  30%|██▉       | 790/2645 [01:16<02:57, 10.47it/s, training_loss=0.098]\u001b[A\n",
      "Epoch 3:  30%|██▉       | 792/2645 [01:16<02:56, 10.47it/s, training_loss=0.098]\u001b[A\n",
      "Epoch 3:  30%|██▉       | 792/2645 [01:16<02:56, 10.47it/s, training_loss=0.203]\u001b[A\n",
      "Epoch 3:  30%|██▉       | 792/2645 [01:16<02:56, 10.47it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  30%|███       | 794/2645 [01:16<02:57, 10.44it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  30%|███       | 794/2645 [01:16<02:57, 10.44it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  30%|███       | 794/2645 [01:16<02:57, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  30%|███       | 796/2645 [01:16<02:57, 10.42it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  30%|███       | 796/2645 [01:16<02:57, 10.42it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  30%|███       | 796/2645 [01:16<02:57, 10.42it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  30%|███       | 798/2645 [01:16<02:56, 10.46it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  30%|███       | 798/2645 [01:16<02:56, 10.46it/s, training_loss=0.326]\u001b[A\n",
      "Epoch 3:  30%|███       | 798/2645 [01:16<02:56, 10.46it/s, training_loss=0.897]\u001b[A\n",
      "Epoch 3:  30%|███       | 800/2645 [01:16<02:57, 10.41it/s, training_loss=0.897]\u001b[A\n",
      "Epoch 3:  30%|███       | 800/2645 [01:16<02:57, 10.41it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  30%|███       | 800/2645 [01:17<02:57, 10.41it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  30%|███       | 802/2645 [01:17<02:56, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  30%|███       | 802/2645 [01:17<02:56, 10.43it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 3:  30%|███       | 802/2645 [01:17<02:56, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  30%|███       | 804/2645 [01:17<02:56, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  30%|███       | 804/2645 [01:17<02:56, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  30%|███       | 804/2645 [01:17<02:56, 10.44it/s, training_loss=0.543]\u001b[A\n",
      "Epoch 3:  30%|███       | 806/2645 [01:17<02:55, 10.47it/s, training_loss=0.543]\u001b[A\n",
      "Epoch 3:  30%|███       | 806/2645 [01:17<02:55, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  30%|███       | 806/2645 [01:17<02:55, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  31%|███       | 808/2645 [01:17<02:54, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  31%|███       | 808/2645 [01:17<02:54, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  31%|███       | 808/2645 [01:17<02:54, 10.52it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  31%|███       | 810/2645 [01:17<02:54, 10.53it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  31%|███       | 810/2645 [01:17<02:54, 10.53it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 3:  31%|███       | 810/2645 [01:17<02:54, 10.53it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  31%|███       | 812/2645 [01:17<02:54, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  31%|███       | 812/2645 [01:18<02:54, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  31%|███       | 812/2645 [01:18<02:54, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  31%|███       | 814/2645 [01:18<02:54, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  31%|███       | 814/2645 [01:18<02:54, 10.52it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  31%|███       | 814/2645 [01:18<02:54, 10.52it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  31%|███       | 816/2645 [01:18<02:53, 10.53it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  31%|███       | 816/2645 [01:18<02:53, 10.53it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  31%|███       | 816/2645 [01:18<02:53, 10.53it/s, training_loss=0.803]\u001b[A\n",
      "Epoch 3:  31%|███       | 818/2645 [01:18<02:54, 10.50it/s, training_loss=0.803]\u001b[A\n",
      "Epoch 3:  31%|███       | 818/2645 [01:18<02:54, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  31%|███       | 818/2645 [01:18<02:54, 10.50it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 3:  31%|███       | 820/2645 [01:18<02:53, 10.50it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 3:  31%|███       | 820/2645 [01:18<02:53, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  31%|███       | 820/2645 [01:18<02:53, 10.50it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  31%|███       | 822/2645 [01:18<02:53, 10.53it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  31%|███       | 822/2645 [01:19<02:53, 10.53it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  31%|███       | 822/2645 [01:19<02:53, 10.53it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  31%|███       | 824/2645 [01:19<02:52, 10.56it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  31%|███       | 824/2645 [01:19<02:52, 10.56it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  31%|███       | 824/2645 [01:19<02:52, 10.56it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  31%|███       | 826/2645 [01:19<02:52, 10.56it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  31%|███       | 826/2645 [01:19<02:52, 10.56it/s, training_loss=0.494]\u001b[A\n",
      "Epoch 3:  31%|███       | 826/2645 [01:19<02:52, 10.56it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  31%|███▏      | 828/2645 [01:19<02:52, 10.53it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  31%|███▏      | 828/2645 [01:19<02:52, 10.53it/s, training_loss=0.376]\u001b[A\n",
      "Epoch 3:  31%|███▏      | 828/2645 [01:19<02:52, 10.53it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  31%|███▏      | 830/2645 [01:19<02:52, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  31%|███▏      | 830/2645 [01:19<02:52, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  31%|███▏      | 830/2645 [01:19<02:52, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  31%|███▏      | 832/2645 [01:19<02:52, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  31%|███▏      | 832/2645 [01:19<02:52, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  31%|███▏      | 832/2645 [01:20<02:52, 10.52it/s, training_loss=0.920]\u001b[A\n",
      "Epoch 3:  32%|███▏      | 834/2645 [01:20<02:52, 10.52it/s, training_loss=0.920]\u001b[A\n",
      "Epoch 3:  32%|███▏      | 834/2645 [01:20<02:52, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  32%|███▏      | 834/2645 [01:20<02:52, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  32%|███▏      | 836/2645 [01:20<02:51, 10.53it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  32%|███▏      | 836/2645 [01:20<02:51, 10.53it/s, training_loss=0.026]\u001b[A\n",
      "Epoch 3:  32%|███▏      | 836/2645 [01:20<02:51, 10.53it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  32%|███▏      | 838/2645 [01:20<02:51, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  32%|███▏      | 838/2645 [01:20<02:51, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  32%|███▏      | 838/2645 [01:20<02:51, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  32%|███▏      | 840/2645 [01:20<02:51, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  32%|███▏      | 840/2645 [01:20<02:51, 10.52it/s, training_loss=0.948]\u001b[A\n",
      "Epoch 3:  32%|███▏      | 840/2645 [01:20<02:51, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  32%|███▏      | 842/2645 [01:20<02:51, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  32%|███▏      | 842/2645 [01:20<02:51, 10.50it/s, training_loss=0.084]\u001b[A\n",
      "Epoch 3:  32%|███▏      | 842/2645 [01:21<02:51, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  32%|███▏      | 844/2645 [01:21<02:51, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  32%|███▏      | 844/2645 [01:21<02:51, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  32%|███▏      | 844/2645 [01:21<02:51, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  32%|███▏      | 846/2645 [01:21<02:51, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  32%|███▏      | 846/2645 [01:21<02:51, 10.51it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  32%|███▏      | 846/2645 [01:21<02:51, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  32%|███▏      | 848/2645 [01:21<02:52, 10.40it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  32%|███▏      | 848/2645 [01:21<02:52, 10.40it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  32%|███▏      | 848/2645 [01:21<02:52, 10.40it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  32%|███▏      | 850/2645 [01:21<02:51, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  32%|███▏      | 850/2645 [01:21<02:51, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  32%|███▏      | 850/2645 [01:21<02:51, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  32%|███▏      | 852/2645 [01:21<02:51, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  32%|███▏      | 852/2645 [01:21<02:51, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  32%|███▏      | 852/2645 [01:21<02:51, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  32%|███▏      | 854/2645 [01:21<02:50, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  32%|███▏      | 854/2645 [01:22<02:50, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  32%|███▏      | 854/2645 [01:22<02:50, 10.51it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  32%|███▏      | 856/2645 [01:22<02:50, 10.49it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  32%|███▏      | 856/2645 [01:22<02:50, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  32%|███▏      | 856/2645 [01:22<02:50, 10.49it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  32%|███▏      | 858/2645 [01:22<02:49, 10.53it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  32%|███▏      | 858/2645 [01:22<02:49, 10.53it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  32%|███▏      | 858/2645 [01:22<02:49, 10.53it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  33%|███▎      | 860/2645 [01:22<02:49, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  33%|███▎      | 860/2645 [01:22<02:49, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  33%|███▎      | 860/2645 [01:22<02:49, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  33%|███▎      | 862/2645 [01:22<02:49, 10.54it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  33%|███▎      | 862/2645 [01:22<02:49, 10.54it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  33%|███▎      | 862/2645 [01:22<02:49, 10.54it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  33%|███▎      | 864/2645 [01:22<02:48, 10.55it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  33%|███▎      | 864/2645 [01:23<02:48, 10.55it/s, training_loss=0.013]\u001b[A\n",
      "Epoch 3:  33%|███▎      | 864/2645 [01:23<02:48, 10.55it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  33%|███▎      | 866/2645 [01:23<02:49, 10.51it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  33%|███▎      | 866/2645 [01:23<02:49, 10.51it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  33%|███▎      | 866/2645 [01:23<02:49, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  33%|███▎      | 868/2645 [01:23<02:48, 10.54it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  33%|███▎      | 868/2645 [01:23<02:48, 10.54it/s, training_loss=0.391]\u001b[A\n",
      "Epoch 3:  33%|███▎      | 868/2645 [01:23<02:48, 10.54it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 3:  33%|███▎      | 870/2645 [01:23<02:49, 10.50it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 3:  33%|███▎      | 870/2645 [01:23<02:49, 10.50it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  33%|███▎      | 870/2645 [01:23<02:49, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  33%|███▎      | 872/2645 [01:23<02:48, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  33%|███▎      | 872/2645 [01:23<02:48, 10.51it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  33%|███▎      | 872/2645 [01:23<02:48, 10.51it/s, training_loss=0.085]\u001b[A\n",
      "Epoch 3:  33%|███▎      | 874/2645 [01:23<02:48, 10.50it/s, training_loss=0.085]\u001b[A\n",
      "Epoch 3:  33%|███▎      | 874/2645 [01:23<02:48, 10.50it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  33%|███▎      | 874/2645 [01:24<02:48, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  33%|███▎      | 876/2645 [01:24<02:48, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  33%|███▎      | 876/2645 [01:24<02:48, 10.48it/s, training_loss=0.090]\u001b[A\n",
      "Epoch 3:  33%|███▎      | 876/2645 [01:24<02:48, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  33%|███▎      | 878/2645 [01:24<02:48, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  33%|███▎      | 878/2645 [01:24<02:48, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  33%|███▎      | 878/2645 [01:24<02:48, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  33%|███▎      | 880/2645 [01:24<02:47, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  33%|███▎      | 880/2645 [01:24<02:47, 10.51it/s, training_loss=0.041]\u001b[A\n",
      "Epoch 3:  33%|███▎      | 880/2645 [01:24<02:47, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  33%|███▎      | 882/2645 [01:24<02:47, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  33%|███▎      | 882/2645 [01:24<02:47, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  33%|███▎      | 882/2645 [01:24<02:47, 10.49it/s, training_loss=0.014]\u001b[A\n",
      "Epoch 3:  33%|███▎      | 884/2645 [01:24<02:52, 10.18it/s, training_loss=0.014]\u001b[A\n",
      "Epoch 3:  33%|███▎      | 884/2645 [01:24<02:52, 10.18it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  33%|███▎      | 884/2645 [01:25<02:52, 10.18it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  33%|███▎      | 886/2645 [01:25<02:52, 10.21it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  33%|███▎      | 886/2645 [01:25<02:52, 10.21it/s, training_loss=0.269]\u001b[A\n",
      "Epoch 3:  33%|███▎      | 886/2645 [01:25<02:52, 10.21it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  34%|███▎      | 888/2645 [01:25<02:53, 10.14it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  34%|███▎      | 888/2645 [01:25<02:53, 10.14it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  34%|███▎      | 888/2645 [01:25<02:53, 10.14it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  34%|███▎      | 890/2645 [01:25<02:51, 10.22it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  34%|███▎      | 890/2645 [01:25<02:51, 10.22it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  34%|███▎      | 890/2645 [01:25<02:51, 10.22it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  34%|███▎      | 892/2645 [01:25<02:50, 10.28it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  34%|███▎      | 892/2645 [01:25<02:50, 10.28it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  34%|███▎      | 892/2645 [01:25<02:50, 10.28it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  34%|███▍      | 894/2645 [01:25<02:48, 10.36it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  34%|███▍      | 894/2645 [01:25<02:48, 10.36it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  34%|███▍      | 894/2645 [01:26<02:48, 10.36it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  34%|███▍      | 896/2645 [01:26<02:50, 10.25it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  34%|███▍      | 896/2645 [01:26<02:50, 10.25it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  34%|███▍      | 896/2645 [01:26<02:50, 10.25it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  34%|███▍      | 898/2645 [01:26<02:54, 10.03it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  34%|███▍      | 898/2645 [01:26<02:54, 10.03it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  34%|███▍      | 898/2645 [01:26<02:54, 10.03it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  34%|███▍      | 900/2645 [01:26<02:52, 10.10it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  34%|███▍      | 900/2645 [01:26<02:52, 10.10it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  34%|███▍      | 900/2645 [01:26<02:52, 10.10it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  34%|███▍      | 902/2645 [01:26<02:52, 10.10it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  34%|███▍      | 902/2645 [01:26<02:52, 10.10it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  34%|███▍      | 902/2645 [01:26<02:52, 10.10it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  34%|███▍      | 904/2645 [01:26<02:50, 10.20it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  34%|███▍      | 904/2645 [01:26<02:50, 10.20it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  34%|███▍      | 904/2645 [01:27<02:50, 10.20it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  34%|███▍      | 906/2645 [01:27<02:51, 10.17it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  34%|███▍      | 906/2645 [01:27<02:51, 10.17it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  34%|███▍      | 906/2645 [01:27<02:51, 10.17it/s, training_loss=0.407]\u001b[A\n",
      "Epoch 3:  34%|███▍      | 908/2645 [01:27<02:50, 10.21it/s, training_loss=0.407]\u001b[A\n",
      "Epoch 3:  34%|███▍      | 908/2645 [01:27<02:50, 10.21it/s, training_loss=0.879]\u001b[A\n",
      "Epoch 3:  34%|███▍      | 908/2645 [01:27<02:50, 10.21it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  34%|███▍      | 910/2645 [01:27<02:48, 10.28it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  34%|███▍      | 910/2645 [01:27<02:48, 10.28it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  34%|███▍      | 910/2645 [01:27<02:48, 10.28it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  34%|███▍      | 912/2645 [01:27<02:47, 10.32it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  34%|███▍      | 912/2645 [01:27<02:47, 10.32it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  34%|███▍      | 912/2645 [01:27<02:47, 10.32it/s, training_loss=0.905]\u001b[A\n",
      "Epoch 3:  35%|███▍      | 914/2645 [01:27<02:46, 10.37it/s, training_loss=0.905]\u001b[A\n",
      "Epoch 3:  35%|███▍      | 914/2645 [01:27<02:46, 10.37it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  35%|███▍      | 914/2645 [01:27<02:46, 10.37it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  35%|███▍      | 916/2645 [01:27<02:45, 10.44it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  35%|███▍      | 916/2645 [01:28<02:45, 10.44it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  35%|███▍      | 916/2645 [01:28<02:45, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  35%|███▍      | 918/2645 [01:28<02:45, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  35%|███▍      | 918/2645 [01:28<02:45, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  35%|███▍      | 918/2645 [01:28<02:45, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  35%|███▍      | 920/2645 [01:28<02:44, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  35%|███▍      | 920/2645 [01:28<02:44, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  35%|███▍      | 920/2645 [01:28<02:44, 10.46it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  35%|███▍      | 922/2645 [01:28<02:44, 10.45it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  35%|███▍      | 922/2645 [01:28<02:44, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  35%|███▍      | 922/2645 [01:28<02:44, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  35%|███▍      | 924/2645 [01:28<02:44, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  35%|███▍      | 924/2645 [01:28<02:44, 10.49it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  35%|███▍      | 924/2645 [01:28<02:44, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  35%|███▌      | 926/2645 [01:28<02:43, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  35%|███▌      | 926/2645 [01:29<02:43, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  35%|███▌      | 926/2645 [01:29<02:43, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  35%|███▌      | 928/2645 [01:29<02:43, 10.53it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  35%|███▌      | 928/2645 [01:29<02:43, 10.53it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  35%|███▌      | 928/2645 [01:29<02:43, 10.53it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  35%|███▌      | 930/2645 [01:29<02:42, 10.55it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  35%|███▌      | 930/2645 [01:29<02:42, 10.55it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  35%|███▌      | 930/2645 [01:29<02:42, 10.55it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  35%|███▌      | 932/2645 [01:29<02:45, 10.32it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  35%|███▌      | 932/2645 [01:29<02:45, 10.32it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  35%|███▌      | 932/2645 [01:29<02:45, 10.32it/s, training_loss=0.015]\u001b[A\n",
      "Epoch 3:  35%|███▌      | 934/2645 [01:29<02:47, 10.24it/s, training_loss=0.015]\u001b[A\n",
      "Epoch 3:  35%|███▌      | 934/2645 [01:29<02:47, 10.24it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  35%|███▌      | 934/2645 [01:29<02:47, 10.24it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  35%|███▌      | 936/2645 [01:29<02:45, 10.32it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  35%|███▌      | 936/2645 [01:29<02:45, 10.32it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  35%|███▌      | 936/2645 [01:30<02:45, 10.32it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  35%|███▌      | 938/2645 [01:30<02:44, 10.37it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  35%|███▌      | 938/2645 [01:30<02:44, 10.37it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  35%|███▌      | 938/2645 [01:30<02:44, 10.37it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  36%|███▌      | 940/2645 [01:30<02:45, 10.29it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  36%|███▌      | 940/2645 [01:30<02:45, 10.29it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  36%|███▌      | 940/2645 [01:30<02:45, 10.29it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  36%|███▌      | 942/2645 [01:30<02:47, 10.19it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  36%|███▌      | 942/2645 [01:30<02:47, 10.19it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  36%|███▌      | 942/2645 [01:30<02:47, 10.19it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  36%|███▌      | 944/2645 [01:30<02:48, 10.10it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  36%|███▌      | 944/2645 [01:30<02:48, 10.10it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  36%|███▌      | 944/2645 [01:30<02:48, 10.10it/s, training_loss=0.077]\u001b[A\n",
      "Epoch 3:  36%|███▌      | 946/2645 [01:30<02:48, 10.09it/s, training_loss=0.077]\u001b[A\n",
      "Epoch 3:  36%|███▌      | 946/2645 [01:30<02:48, 10.09it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  36%|███▌      | 946/2645 [01:31<02:48, 10.09it/s, training_loss=0.543]\u001b[A\n",
      "Epoch 3:  36%|███▌      | 948/2645 [01:31<02:50,  9.98it/s, training_loss=0.543]\u001b[A\n",
      "Epoch 3:  36%|███▌      | 948/2645 [01:31<02:50,  9.98it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  36%|███▌      | 948/2645 [01:31<02:50,  9.98it/s, training_loss=0.311]\u001b[A\n",
      "Epoch 3:  36%|███▌      | 950/2645 [01:31<02:49,  9.98it/s, training_loss=0.311]\u001b[A\n",
      "Epoch 3:  36%|███▌      | 950/2645 [01:31<02:49,  9.98it/s, training_loss=0.559]\u001b[A\n",
      "Epoch 3:  36%|███▌      | 951/2645 [01:31<02:50,  9.91it/s, training_loss=0.559]\u001b[A\n",
      "Epoch 3:  36%|███▌      | 951/2645 [01:31<02:50,  9.91it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  36%|███▌      | 951/2645 [01:31<02:50,  9.91it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  36%|███▌      | 953/2645 [01:31<02:49,  9.98it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  36%|███▌      | 953/2645 [01:31<02:49,  9.98it/s, training_loss=0.938]\u001b[A\n",
      "Epoch 3:  36%|███▌      | 954/2645 [01:31<02:51,  9.86it/s, training_loss=0.938]\u001b[A\n",
      "Epoch 3:  36%|███▌      | 954/2645 [01:31<02:51,  9.86it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  36%|███▌      | 954/2645 [01:31<02:51,  9.86it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  36%|███▌      | 956/2645 [01:31<02:47, 10.07it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  36%|███▌      | 956/2645 [01:31<02:47, 10.07it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  36%|███▌      | 956/2645 [01:32<02:47, 10.07it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  36%|███▌      | 958/2645 [01:32<02:45, 10.20it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  36%|███▌      | 958/2645 [01:32<02:45, 10.20it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  36%|███▌      | 958/2645 [01:32<02:45, 10.20it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  36%|███▋      | 960/2645 [01:32<02:43, 10.31it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  36%|███▋      | 960/2645 [01:32<02:43, 10.31it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  36%|███▋      | 960/2645 [01:32<02:43, 10.31it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  36%|███▋      | 962/2645 [01:32<02:43, 10.29it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  36%|███▋      | 962/2645 [01:32<02:43, 10.29it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  36%|███▋      | 962/2645 [01:32<02:43, 10.29it/s, training_loss=1.041]\u001b[A\n",
      "Epoch 3:  36%|███▋      | 964/2645 [01:32<02:44, 10.23it/s, training_loss=1.041]\u001b[A\n",
      "Epoch 3:  36%|███▋      | 964/2645 [01:32<02:44, 10.23it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 3:  36%|███▋      | 964/2645 [01:32<02:44, 10.23it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  37%|███▋      | 966/2645 [01:32<02:43, 10.28it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  37%|███▋      | 966/2645 [01:32<02:43, 10.28it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 3:  37%|███▋      | 966/2645 [01:33<02:43, 10.28it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  37%|███▋      | 968/2645 [01:33<02:42, 10.35it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  37%|███▋      | 968/2645 [01:33<02:42, 10.35it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  37%|███▋      | 968/2645 [01:33<02:42, 10.35it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  37%|███▋      | 970/2645 [01:33<02:40, 10.42it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  37%|███▋      | 970/2645 [01:33<02:40, 10.42it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  37%|███▋      | 970/2645 [01:33<02:40, 10.42it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  37%|███▋      | 972/2645 [01:33<02:40, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  37%|███▋      | 972/2645 [01:33<02:40, 10.45it/s, training_loss=0.010]\u001b[A\n",
      "Epoch 3:  37%|███▋      | 972/2645 [01:33<02:40, 10.45it/s, training_loss=0.502]\u001b[A\n",
      "Epoch 3:  37%|███▋      | 974/2645 [01:33<02:40, 10.43it/s, training_loss=0.502]\u001b[A\n",
      "Epoch 3:  37%|███▋      | 974/2645 [01:33<02:40, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  37%|███▋      | 974/2645 [01:33<02:40, 10.43it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  37%|███▋      | 976/2645 [01:33<02:39, 10.48it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  37%|███▋      | 976/2645 [01:33<02:39, 10.48it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  37%|███▋      | 976/2645 [01:33<02:39, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  37%|███▋      | 978/2645 [01:33<02:39, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  37%|███▋      | 978/2645 [01:34<02:39, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  37%|███▋      | 978/2645 [01:34<02:39, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  37%|███▋      | 980/2645 [01:34<02:39, 10.41it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  37%|███▋      | 980/2645 [01:34<02:39, 10.41it/s, training_loss=0.363]\u001b[A\n",
      "Epoch 3:  37%|███▋      | 980/2645 [01:34<02:39, 10.41it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  37%|███▋      | 982/2645 [01:34<02:39, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  37%|███▋      | 982/2645 [01:34<02:39, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  37%|███▋      | 982/2645 [01:34<02:39, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  37%|███▋      | 984/2645 [01:34<02:39, 10.42it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  37%|███▋      | 984/2645 [01:34<02:39, 10.42it/s, training_loss=0.239]\u001b[A\n",
      "Epoch 3:  37%|███▋      | 984/2645 [01:34<02:39, 10.42it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  37%|███▋      | 986/2645 [01:34<02:43, 10.14it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  37%|███▋      | 986/2645 [01:34<02:43, 10.14it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  37%|███▋      | 986/2645 [01:34<02:43, 10.14it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  37%|███▋      | 988/2645 [01:34<02:42, 10.21it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  37%|███▋      | 988/2645 [01:35<02:42, 10.21it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  37%|███▋      | 988/2645 [01:35<02:42, 10.21it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  37%|███▋      | 990/2645 [01:35<02:40, 10.31it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  37%|███▋      | 990/2645 [01:35<02:40, 10.31it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  37%|███▋      | 990/2645 [01:35<02:40, 10.31it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  38%|███▊      | 992/2645 [01:35<02:39, 10.37it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  38%|███▊      | 992/2645 [01:35<02:39, 10.37it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  38%|███▊      | 992/2645 [01:35<02:39, 10.37it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  38%|███▊      | 994/2645 [01:35<02:38, 10.42it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  38%|███▊      | 994/2645 [01:35<02:38, 10.42it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  38%|███▊      | 994/2645 [01:35<02:38, 10.42it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  38%|███▊      | 996/2645 [01:35<02:37, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  38%|███▊      | 996/2645 [01:35<02:37, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  38%|███▊      | 996/2645 [01:35<02:37, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  38%|███▊      | 998/2645 [01:35<02:37, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  38%|███▊      | 998/2645 [01:36<02:37, 10.47it/s, training_loss=0.608]\u001b[A\n",
      "Epoch 3:  38%|███▊      | 998/2645 [01:36<02:37, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  38%|███▊      | 1000/2645 [01:36<02:37, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  38%|███▊      | 1000/2645 [01:36<02:37, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  38%|███▊      | 1000/2645 [01:36<02:37, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  38%|███▊      | 1002/2645 [01:36<02:36, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  38%|███▊      | 1002/2645 [01:36<02:36, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  38%|███▊      | 1002/2645 [01:36<02:36, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  38%|███▊      | 1004/2645 [01:36<02:38, 10.33it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  38%|███▊      | 1004/2645 [01:36<02:38, 10.33it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  38%|███▊      | 1004/2645 [01:36<02:38, 10.33it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  38%|███▊      | 1006/2645 [01:36<02:37, 10.39it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  38%|███▊      | 1006/2645 [01:36<02:37, 10.39it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  38%|███▊      | 1006/2645 [01:36<02:37, 10.39it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  38%|███▊      | 1008/2645 [01:36<02:36, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  38%|███▊      | 1008/2645 [01:36<02:36, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  38%|███▊      | 1008/2645 [01:37<02:36, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  38%|███▊      | 1010/2645 [01:37<02:36, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  38%|███▊      | 1010/2645 [01:37<02:36, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  38%|███▊      | 1010/2645 [01:37<02:36, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  38%|███▊      | 1012/2645 [01:37<02:35, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  38%|███▊      | 1012/2645 [01:37<02:35, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  38%|███▊      | 1012/2645 [01:37<02:35, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  38%|███▊      | 1014/2645 [01:37<02:35, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  38%|███▊      | 1014/2645 [01:37<02:35, 10.48it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  38%|███▊      | 1014/2645 [01:37<02:35, 10.48it/s, training_loss=0.021]\u001b[A\n",
      "Epoch 3:  38%|███▊      | 1016/2645 [01:37<02:35, 10.44it/s, training_loss=0.021]\u001b[A\n",
      "Epoch 3:  38%|███▊      | 1016/2645 [01:37<02:35, 10.44it/s, training_loss=0.368]\u001b[A\n",
      "Epoch 3:  38%|███▊      | 1016/2645 [01:37<02:35, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  38%|███▊      | 1018/2645 [01:37<02:36, 10.41it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  38%|███▊      | 1018/2645 [01:37<02:36, 10.41it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  38%|███▊      | 1018/2645 [01:38<02:36, 10.41it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 3:  39%|███▊      | 1020/2645 [01:38<02:36, 10.40it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 3:  39%|███▊      | 1020/2645 [01:38<02:36, 10.40it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  39%|███▊      | 1020/2645 [01:38<02:36, 10.40it/s, training_loss=0.568]\u001b[A\n",
      "Epoch 3:  39%|███▊      | 1022/2645 [01:38<02:35, 10.41it/s, training_loss=0.568]\u001b[A\n",
      "Epoch 3:  39%|███▊      | 1022/2645 [01:38<02:35, 10.41it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  39%|███▊      | 1022/2645 [01:38<02:35, 10.41it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  39%|███▊      | 1024/2645 [01:38<02:37, 10.31it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  39%|███▊      | 1024/2645 [01:38<02:37, 10.31it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  39%|███▊      | 1024/2645 [01:38<02:37, 10.31it/s, training_loss=0.011]\u001b[A\n",
      "Epoch 3:  39%|███▉      | 1026/2645 [01:38<02:37, 10.29it/s, training_loss=0.011]\u001b[A\n",
      "Epoch 3:  39%|███▉      | 1026/2645 [01:38<02:37, 10.29it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  39%|███▉      | 1026/2645 [01:38<02:37, 10.29it/s, training_loss=0.102]\u001b[A\n",
      "Epoch 3:  39%|███▉      | 1028/2645 [01:38<02:36, 10.33it/s, training_loss=0.102]\u001b[A\n",
      "Epoch 3:  39%|███▉      | 1028/2645 [01:38<02:36, 10.33it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  39%|███▉      | 1028/2645 [01:39<02:36, 10.33it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  39%|███▉      | 1030/2645 [01:39<02:35, 10.40it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  39%|███▉      | 1030/2645 [01:39<02:35, 10.40it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  39%|███▉      | 1030/2645 [01:39<02:35, 10.40it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  39%|███▉      | 1032/2645 [01:39<02:34, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  39%|███▉      | 1032/2645 [01:39<02:34, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  39%|███▉      | 1032/2645 [01:39<02:34, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  39%|███▉      | 1034/2645 [01:39<02:34, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  39%|███▉      | 1034/2645 [01:39<02:34, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  39%|███▉      | 1034/2645 [01:39<02:34, 10.46it/s, training_loss=1.394]\u001b[A\n",
      "Epoch 3:  39%|███▉      | 1036/2645 [01:39<02:34, 10.44it/s, training_loss=1.394]\u001b[A\n",
      "Epoch 3:  39%|███▉      | 1036/2645 [01:39<02:34, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  39%|███▉      | 1036/2645 [01:39<02:34, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  39%|███▉      | 1038/2645 [01:39<02:34, 10.40it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  39%|███▉      | 1038/2645 [01:39<02:34, 10.40it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  39%|███▉      | 1038/2645 [01:39<02:34, 10.40it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  39%|███▉      | 1040/2645 [01:39<02:33, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  39%|███▉      | 1040/2645 [01:40<02:33, 10.43it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 3:  39%|███▉      | 1040/2645 [01:40<02:33, 10.43it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  39%|███▉      | 1042/2645 [01:40<02:36, 10.22it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  39%|███▉      | 1042/2645 [01:40<02:36, 10.22it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  39%|███▉      | 1042/2645 [01:40<02:36, 10.22it/s, training_loss=0.056]\u001b[A\n",
      "Epoch 3:  39%|███▉      | 1044/2645 [01:40<02:35, 10.31it/s, training_loss=0.056]\u001b[A\n",
      "Epoch 3:  39%|███▉      | 1044/2645 [01:40<02:35, 10.31it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  39%|███▉      | 1044/2645 [01:40<02:35, 10.31it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  40%|███▉      | 1046/2645 [01:40<02:33, 10.39it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  40%|███▉      | 1046/2645 [01:40<02:33, 10.39it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  40%|███▉      | 1046/2645 [01:40<02:33, 10.39it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  40%|███▉      | 1048/2645 [01:40<02:32, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  40%|███▉      | 1048/2645 [01:40<02:32, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  40%|███▉      | 1048/2645 [01:40<02:32, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  40%|███▉      | 1050/2645 [01:40<02:31, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  40%|███▉      | 1050/2645 [01:41<02:31, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  40%|███▉      | 1050/2645 [01:41<02:31, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  40%|███▉      | 1052/2645 [01:41<02:31, 10.53it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  40%|███▉      | 1052/2645 [01:41<02:31, 10.53it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  40%|███▉      | 1052/2645 [01:41<02:31, 10.53it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  40%|███▉      | 1054/2645 [01:41<02:31, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  40%|███▉      | 1054/2645 [01:41<02:31, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  40%|███▉      | 1054/2645 [01:41<02:31, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  40%|███▉      | 1056/2645 [01:41<02:30, 10.53it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  40%|███▉      | 1056/2645 [01:41<02:30, 10.53it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  40%|███▉      | 1056/2645 [01:41<02:30, 10.53it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  40%|████      | 1058/2645 [01:41<02:30, 10.53it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  40%|████      | 1058/2645 [01:41<02:30, 10.53it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  40%|████      | 1058/2645 [01:41<02:30, 10.53it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  40%|████      | 1060/2645 [01:41<02:31, 10.49it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  40%|████      | 1060/2645 [01:41<02:31, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  40%|████      | 1060/2645 [01:42<02:31, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  40%|████      | 1062/2645 [01:42<02:30, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  40%|████      | 1062/2645 [01:42<02:30, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  40%|████      | 1062/2645 [01:42<02:30, 10.50it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  40%|████      | 1064/2645 [01:42<02:30, 10.52it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  40%|████      | 1064/2645 [01:42<02:30, 10.52it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  40%|████      | 1064/2645 [01:42<02:30, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  40%|████      | 1066/2645 [01:42<02:30, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  40%|████      | 1066/2645 [01:42<02:30, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  40%|████      | 1066/2645 [01:42<02:30, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  40%|████      | 1068/2645 [01:42<02:29, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  40%|████      | 1068/2645 [01:42<02:29, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  40%|████      | 1068/2645 [01:42<02:29, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  40%|████      | 1070/2645 [01:42<02:29, 10.54it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  40%|████      | 1070/2645 [01:42<02:29, 10.54it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  40%|████      | 1070/2645 [01:43<02:29, 10.54it/s, training_loss=0.606]\u001b[A\n",
      "Epoch 3:  41%|████      | 1072/2645 [01:43<02:29, 10.51it/s, training_loss=0.606]\u001b[A\n",
      "Epoch 3:  41%|████      | 1072/2645 [01:43<02:29, 10.51it/s, training_loss=0.327]\u001b[A\n",
      "Epoch 3:  41%|████      | 1072/2645 [01:43<02:29, 10.51it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  41%|████      | 1074/2645 [01:43<02:29, 10.51it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  41%|████      | 1074/2645 [01:43<02:29, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  41%|████      | 1074/2645 [01:43<02:29, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  41%|████      | 1076/2645 [01:43<02:29, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  41%|████      | 1076/2645 [01:43<02:29, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  41%|████      | 1076/2645 [01:43<02:29, 10.52it/s, training_loss=0.711]\u001b[A\n",
      "Epoch 3:  41%|████      | 1078/2645 [01:43<02:29, 10.47it/s, training_loss=0.711]\u001b[A\n",
      "Epoch 3:  41%|████      | 1078/2645 [01:43<02:29, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  41%|████      | 1078/2645 [01:43<02:29, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  41%|████      | 1080/2645 [01:43<02:29, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  41%|████      | 1080/2645 [01:43<02:29, 10.47it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  41%|████      | 1080/2645 [01:43<02:29, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  41%|████      | 1082/2645 [01:43<02:28, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  41%|████      | 1082/2645 [01:44<02:28, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  41%|████      | 1082/2645 [01:44<02:28, 10.49it/s, training_loss=0.658]\u001b[A\n",
      "Epoch 3:  41%|████      | 1084/2645 [01:44<02:28, 10.48it/s, training_loss=0.658]\u001b[A\n",
      "Epoch 3:  41%|████      | 1084/2645 [01:44<02:28, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  41%|████      | 1084/2645 [01:44<02:28, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  41%|████      | 1086/2645 [01:44<02:29, 10.42it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  41%|████      | 1086/2645 [01:44<02:29, 10.42it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  41%|████      | 1086/2645 [01:44<02:29, 10.42it/s, training_loss=0.909]\u001b[A\n",
      "Epoch 3:  41%|████      | 1088/2645 [01:44<02:29, 10.42it/s, training_loss=0.909]\u001b[A\n",
      "Epoch 3:  41%|████      | 1088/2645 [01:44<02:29, 10.42it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  41%|████      | 1088/2645 [01:44<02:29, 10.42it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  41%|████      | 1090/2645 [01:44<02:28, 10.45it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  41%|████      | 1090/2645 [01:44<02:28, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  41%|████      | 1090/2645 [01:44<02:28, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  41%|████▏     | 1092/2645 [01:44<02:28, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  41%|████▏     | 1092/2645 [01:45<02:28, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  41%|████▏     | 1092/2645 [01:45<02:28, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  41%|████▏     | 1094/2645 [01:45<02:27, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  41%|████▏     | 1094/2645 [01:45<02:27, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  41%|████▏     | 1094/2645 [01:45<02:27, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  41%|████▏     | 1096/2645 [01:45<02:26, 10.54it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  41%|████▏     | 1096/2645 [01:45<02:26, 10.54it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  41%|████▏     | 1096/2645 [01:45<02:26, 10.54it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  42%|████▏     | 1098/2645 [01:45<02:26, 10.56it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  42%|████▏     | 1098/2645 [01:45<02:26, 10.56it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  42%|████▏     | 1098/2645 [01:45<02:26, 10.56it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  42%|████▏     | 1100/2645 [01:45<02:26, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  42%|████▏     | 1100/2645 [01:45<02:26, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  42%|████▏     | 1100/2645 [01:45<02:26, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  42%|████▏     | 1102/2645 [01:45<02:26, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  42%|████▏     | 1102/2645 [01:45<02:26, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  42%|████▏     | 1102/2645 [01:46<02:26, 10.51it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  42%|████▏     | 1104/2645 [01:46<02:26, 10.52it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  42%|████▏     | 1104/2645 [01:46<02:26, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  42%|████▏     | 1104/2645 [01:46<02:26, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  42%|████▏     | 1106/2645 [01:46<02:26, 10.53it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  42%|████▏     | 1106/2645 [01:46<02:26, 10.53it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  42%|████▏     | 1106/2645 [01:46<02:26, 10.53it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  42%|████▏     | 1108/2645 [01:46<02:25, 10.53it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  42%|████▏     | 1108/2645 [01:46<02:25, 10.53it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  42%|████▏     | 1108/2645 [01:46<02:25, 10.53it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  42%|████▏     | 1110/2645 [01:46<02:25, 10.53it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  42%|████▏     | 1110/2645 [01:46<02:25, 10.53it/s, training_loss=0.051]\u001b[A\n",
      "Epoch 3:  42%|████▏     | 1110/2645 [01:46<02:25, 10.53it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  42%|████▏     | 1112/2645 [01:46<02:25, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  42%|████▏     | 1112/2645 [01:46<02:25, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  42%|████▏     | 1112/2645 [01:47<02:25, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  42%|████▏     | 1114/2645 [01:47<02:25, 10.55it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  42%|████▏     | 1114/2645 [01:47<02:25, 10.55it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  42%|████▏     | 1114/2645 [01:47<02:25, 10.55it/s, training_loss=0.348]\u001b[A\n",
      "Epoch 3:  42%|████▏     | 1116/2645 [01:47<02:25, 10.54it/s, training_loss=0.348]\u001b[A\n",
      "Epoch 3:  42%|████▏     | 1116/2645 [01:47<02:25, 10.54it/s, training_loss=0.050]\u001b[A\n",
      "Epoch 3:  42%|████▏     | 1116/2645 [01:47<02:25, 10.54it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  42%|████▏     | 1118/2645 [01:47<02:25, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  42%|████▏     | 1118/2645 [01:47<02:25, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  42%|████▏     | 1118/2645 [01:47<02:25, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  42%|████▏     | 1120/2645 [01:47<02:24, 10.54it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  42%|████▏     | 1120/2645 [01:47<02:24, 10.54it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  42%|████▏     | 1120/2645 [01:47<02:24, 10.54it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  42%|████▏     | 1122/2645 [01:47<02:24, 10.58it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  42%|████▏     | 1122/2645 [01:47<02:24, 10.58it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  42%|████▏     | 1122/2645 [01:47<02:24, 10.58it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  42%|████▏     | 1124/2645 [01:47<02:24, 10.56it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  42%|████▏     | 1124/2645 [01:48<02:24, 10.56it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  42%|████▏     | 1124/2645 [01:48<02:24, 10.56it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  43%|████▎     | 1126/2645 [01:48<02:25, 10.42it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  43%|████▎     | 1126/2645 [01:48<02:25, 10.42it/s, training_loss=0.725]\u001b[A\n",
      "Epoch 3:  43%|████▎     | 1126/2645 [01:48<02:25, 10.42it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  43%|████▎     | 1128/2645 [01:48<02:27, 10.32it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  43%|████▎     | 1128/2645 [01:48<02:27, 10.32it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  43%|████▎     | 1128/2645 [01:48<02:27, 10.32it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  43%|████▎     | 1130/2645 [01:48<02:27, 10.28it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  43%|████▎     | 1130/2645 [01:48<02:27, 10.28it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  43%|████▎     | 1130/2645 [01:48<02:27, 10.28it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 3:  43%|████▎     | 1132/2645 [01:48<02:27, 10.23it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 3:  43%|████▎     | 1132/2645 [01:48<02:27, 10.23it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  43%|████▎     | 1132/2645 [01:48<02:27, 10.23it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  43%|████▎     | 1134/2645 [01:48<02:27, 10.27it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  43%|████▎     | 1134/2645 [01:49<02:27, 10.27it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  43%|████▎     | 1134/2645 [01:49<02:27, 10.27it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  43%|████▎     | 1136/2645 [01:49<02:26, 10.30it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  43%|████▎     | 1136/2645 [01:49<02:26, 10.30it/s, training_loss=0.278]\u001b[A\n",
      "Epoch 3:  43%|████▎     | 1136/2645 [01:49<02:26, 10.30it/s, training_loss=1.286]\u001b[A\n",
      "Epoch 3:  43%|████▎     | 1138/2645 [01:49<02:27, 10.21it/s, training_loss=1.286]\u001b[A\n",
      "Epoch 3:  43%|████▎     | 1138/2645 [01:49<02:27, 10.21it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  43%|████▎     | 1138/2645 [01:49<02:27, 10.21it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  43%|████▎     | 1140/2645 [01:49<02:26, 10.24it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  43%|████▎     | 1140/2645 [01:49<02:26, 10.24it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  43%|████▎     | 1140/2645 [01:49<02:26, 10.24it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  43%|████▎     | 1142/2645 [01:49<02:27, 10.18it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  43%|████▎     | 1142/2645 [01:49<02:27, 10.18it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  43%|████▎     | 1142/2645 [01:49<02:27, 10.18it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  43%|████▎     | 1144/2645 [01:49<02:27, 10.20it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  43%|████▎     | 1144/2645 [01:50<02:27, 10.20it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  43%|████▎     | 1144/2645 [01:50<02:27, 10.20it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  43%|████▎     | 1146/2645 [01:50<02:26, 10.27it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  43%|████▎     | 1146/2645 [01:50<02:26, 10.27it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  43%|████▎     | 1146/2645 [01:50<02:26, 10.27it/s, training_loss=0.031]\u001b[A\n",
      "Epoch 3:  43%|████▎     | 1148/2645 [01:50<02:26, 10.22it/s, training_loss=0.031]\u001b[A\n",
      "Epoch 3:  43%|████▎     | 1148/2645 [01:50<02:26, 10.22it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  43%|████▎     | 1148/2645 [01:50<02:26, 10.22it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  43%|████▎     | 1150/2645 [01:50<02:25, 10.27it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  43%|████▎     | 1150/2645 [01:50<02:25, 10.27it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  43%|████▎     | 1150/2645 [01:50<02:25, 10.27it/s, training_loss=0.120]\u001b[A\n",
      "Epoch 3:  44%|████▎     | 1152/2645 [01:50<02:25, 10.27it/s, training_loss=0.120]\u001b[A\n",
      "Epoch 3:  44%|████▎     | 1152/2645 [01:50<02:25, 10.27it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  44%|████▎     | 1152/2645 [01:50<02:25, 10.27it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  44%|████▎     | 1154/2645 [01:50<02:25, 10.28it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  44%|████▎     | 1154/2645 [01:50<02:25, 10.28it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  44%|████▎     | 1154/2645 [01:51<02:25, 10.28it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  44%|████▎     | 1156/2645 [01:51<02:25, 10.24it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  44%|████▎     | 1156/2645 [01:51<02:25, 10.24it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  44%|████▎     | 1156/2645 [01:51<02:25, 10.24it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  44%|████▍     | 1158/2645 [01:51<02:24, 10.29it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  44%|████▍     | 1158/2645 [01:51<02:24, 10.29it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  44%|████▍     | 1158/2645 [01:51<02:24, 10.29it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  44%|████▍     | 1160/2645 [01:51<02:24, 10.26it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  44%|████▍     | 1160/2645 [01:51<02:24, 10.26it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  44%|████▍     | 1160/2645 [01:51<02:24, 10.26it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  44%|████▍     | 1162/2645 [01:51<02:26, 10.12it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  44%|████▍     | 1162/2645 [01:51<02:26, 10.12it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  44%|████▍     | 1162/2645 [01:51<02:26, 10.12it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  44%|████▍     | 1164/2645 [01:51<02:24, 10.25it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  44%|████▍     | 1164/2645 [01:51<02:24, 10.25it/s, training_loss=0.823]\u001b[A\n",
      "Epoch 3:  44%|████▍     | 1164/2645 [01:52<02:24, 10.25it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  44%|████▍     | 1166/2645 [01:52<02:23, 10.31it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  44%|████▍     | 1166/2645 [01:52<02:23, 10.31it/s, training_loss=1.017]\u001b[A\n",
      "Epoch 3:  44%|████▍     | 1166/2645 [01:52<02:23, 10.31it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  44%|████▍     | 1168/2645 [01:52<02:23, 10.30it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  44%|████▍     | 1168/2645 [01:52<02:23, 10.30it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  44%|████▍     | 1168/2645 [01:52<02:23, 10.30it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  44%|████▍     | 1170/2645 [01:52<02:24, 10.23it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  44%|████▍     | 1170/2645 [01:52<02:24, 10.23it/s, training_loss=0.249]\u001b[A\n",
      "Epoch 3:  44%|████▍     | 1170/2645 [01:52<02:24, 10.23it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  44%|████▍     | 1172/2645 [01:52<02:23, 10.25it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  44%|████▍     | 1172/2645 [01:52<02:23, 10.25it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  44%|████▍     | 1172/2645 [01:52<02:23, 10.25it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  44%|████▍     | 1174/2645 [01:52<02:24, 10.15it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  44%|████▍     | 1174/2645 [01:52<02:24, 10.15it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  44%|████▍     | 1174/2645 [01:53<02:24, 10.15it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  44%|████▍     | 1176/2645 [01:53<02:25, 10.09it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  44%|████▍     | 1176/2645 [01:53<02:25, 10.09it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  44%|████▍     | 1176/2645 [01:53<02:25, 10.09it/s, training_loss=0.912]\u001b[A\n",
      "Epoch 3:  45%|████▍     | 1178/2645 [01:53<02:24, 10.16it/s, training_loss=0.912]\u001b[A\n",
      "Epoch 3:  45%|████▍     | 1178/2645 [01:53<02:24, 10.16it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  45%|████▍     | 1178/2645 [01:53<02:24, 10.16it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  45%|████▍     | 1180/2645 [01:53<02:24, 10.14it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  45%|████▍     | 1180/2645 [01:53<02:24, 10.14it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  45%|████▍     | 1180/2645 [01:53<02:24, 10.14it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  45%|████▍     | 1182/2645 [01:53<02:23, 10.21it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  45%|████▍     | 1182/2645 [01:53<02:23, 10.21it/s, training_loss=0.716]\u001b[A\n",
      "Epoch 3:  45%|████▍     | 1182/2645 [01:53<02:23, 10.21it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 3:  45%|████▍     | 1184/2645 [01:53<02:22, 10.26it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 3:  45%|████▍     | 1184/2645 [01:53<02:22, 10.26it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  45%|████▍     | 1184/2645 [01:54<02:22, 10.26it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  45%|████▍     | 1186/2645 [01:54<02:20, 10.36it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  45%|████▍     | 1186/2645 [01:54<02:20, 10.36it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  45%|████▍     | 1186/2645 [01:54<02:20, 10.36it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  45%|████▍     | 1188/2645 [01:54<02:19, 10.43it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  45%|████▍     | 1188/2645 [01:54<02:19, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  45%|████▍     | 1188/2645 [01:54<02:19, 10.43it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 3:  45%|████▍     | 1190/2645 [01:54<02:19, 10.42it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 3:  45%|████▍     | 1190/2645 [01:54<02:19, 10.42it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  45%|████▍     | 1190/2645 [01:54<02:19, 10.42it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  45%|████▌     | 1192/2645 [01:54<02:20, 10.33it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  45%|████▌     | 1192/2645 [01:54<02:20, 10.33it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  45%|████▌     | 1192/2645 [01:54<02:20, 10.33it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  45%|████▌     | 1194/2645 [01:54<02:20, 10.29it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  45%|████▌     | 1194/2645 [01:54<02:20, 10.29it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  45%|████▌     | 1194/2645 [01:54<02:20, 10.29it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  45%|████▌     | 1196/2645 [01:54<02:21, 10.25it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  45%|████▌     | 1196/2645 [01:55<02:21, 10.25it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  45%|████▌     | 1196/2645 [01:55<02:21, 10.25it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  45%|████▌     | 1198/2645 [01:55<02:21, 10.21it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  45%|████▌     | 1198/2645 [01:55<02:21, 10.21it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  45%|████▌     | 1198/2645 [01:55<02:21, 10.21it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  45%|████▌     | 1200/2645 [01:55<02:21, 10.23it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  45%|████▌     | 1200/2645 [01:55<02:21, 10.23it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  45%|████▌     | 1200/2645 [01:55<02:21, 10.23it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  45%|████▌     | 1202/2645 [01:55<02:20, 10.28it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  45%|████▌     | 1202/2645 [01:55<02:20, 10.28it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  45%|████▌     | 1202/2645 [01:55<02:20, 10.28it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  46%|████▌     | 1204/2645 [01:55<02:20, 10.25it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  46%|████▌     | 1204/2645 [01:55<02:20, 10.25it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  46%|████▌     | 1204/2645 [01:55<02:20, 10.25it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  46%|████▌     | 1206/2645 [01:55<02:22, 10.12it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  46%|████▌     | 1206/2645 [01:56<02:22, 10.12it/s, training_loss=0.815]\u001b[A\n",
      "Epoch 3:  46%|████▌     | 1206/2645 [01:56<02:22, 10.12it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  46%|████▌     | 1208/2645 [01:56<02:23, 10.05it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  46%|████▌     | 1208/2645 [01:56<02:23, 10.05it/s, training_loss=0.124]\u001b[A\n",
      "Epoch 3:  46%|████▌     | 1208/2645 [01:56<02:23, 10.05it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  46%|████▌     | 1210/2645 [01:56<02:21, 10.12it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  46%|████▌     | 1210/2645 [01:56<02:21, 10.12it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  46%|████▌     | 1210/2645 [01:56<02:21, 10.12it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  46%|████▌     | 1212/2645 [01:56<02:20, 10.20it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  46%|████▌     | 1212/2645 [01:56<02:20, 10.20it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  46%|████▌     | 1212/2645 [01:56<02:20, 10.20it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  46%|████▌     | 1214/2645 [01:56<02:20, 10.18it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  46%|████▌     | 1214/2645 [01:56<02:20, 10.18it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  46%|████▌     | 1214/2645 [01:56<02:20, 10.18it/s, training_loss=0.015]\u001b[A\n",
      "Epoch 3:  46%|████▌     | 1216/2645 [01:56<02:21, 10.12it/s, training_loss=0.015]\u001b[A\n",
      "Epoch 3:  46%|████▌     | 1216/2645 [01:57<02:21, 10.12it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  46%|████▌     | 1216/2645 [01:57<02:21, 10.12it/s, training_loss=0.754]\u001b[A\n",
      "Epoch 3:  46%|████▌     | 1218/2645 [01:57<02:21, 10.09it/s, training_loss=0.754]\u001b[A\n",
      "Epoch 3:  46%|████▌     | 1218/2645 [01:57<02:21, 10.09it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  46%|████▌     | 1218/2645 [01:57<02:21, 10.09it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  46%|████▌     | 1220/2645 [01:57<02:20, 10.11it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  46%|████▌     | 1220/2645 [01:57<02:20, 10.11it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  46%|████▌     | 1220/2645 [01:57<02:20, 10.11it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  46%|████▌     | 1222/2645 [01:57<02:21, 10.09it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  46%|████▌     | 1222/2645 [01:57<02:21, 10.09it/s, training_loss=0.993]\u001b[A\n",
      "Epoch 3:  46%|████▌     | 1222/2645 [01:57<02:21, 10.09it/s, training_loss=1.006]\u001b[A\n",
      "Epoch 3:  46%|████▋     | 1224/2645 [01:57<02:22, 10.00it/s, training_loss=1.006]\u001b[A\n",
      "Epoch 3:  46%|████▋     | 1224/2645 [01:57<02:22, 10.00it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  46%|████▋     | 1224/2645 [01:57<02:22, 10.00it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  46%|████▋     | 1226/2645 [01:57<02:22,  9.98it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  46%|████▋     | 1226/2645 [01:58<02:22,  9.98it/s, training_loss=0.024]\u001b[A\n",
      "Epoch 3:  46%|████▋     | 1227/2645 [01:58<02:22,  9.97it/s, training_loss=0.024]\u001b[A\n",
      "Epoch 3:  46%|████▋     | 1227/2645 [01:58<02:22,  9.97it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  46%|████▋     | 1228/2645 [01:58<02:22,  9.96it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  46%|████▋     | 1228/2645 [01:58<02:22,  9.96it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  46%|████▋     | 1228/2645 [01:58<02:22,  9.96it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 3:  47%|████▋     | 1230/2645 [01:58<02:22,  9.92it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 3:  47%|████▋     | 1230/2645 [01:58<02:22,  9.92it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  47%|████▋     | 1230/2645 [01:58<02:22,  9.92it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  47%|████▋     | 1232/2645 [01:58<02:21,  9.96it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  47%|████▋     | 1232/2645 [01:58<02:21,  9.96it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  47%|████▋     | 1233/2645 [01:58<02:21,  9.97it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  47%|████▋     | 1233/2645 [01:58<02:21,  9.97it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  47%|████▋     | 1233/2645 [01:58<02:21,  9.97it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  47%|████▋     | 1235/2645 [01:58<02:21,  9.99it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  47%|████▋     | 1235/2645 [01:58<02:21,  9.99it/s, training_loss=0.457]\u001b[A\n",
      "Epoch 3:  47%|████▋     | 1236/2645 [01:58<02:23,  9.84it/s, training_loss=0.457]\u001b[A\n",
      "Epoch 3:  47%|████▋     | 1236/2645 [01:59<02:23,  9.84it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  47%|████▋     | 1236/2645 [01:59<02:23,  9.84it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  47%|████▋     | 1238/2645 [01:59<02:22,  9.85it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  47%|████▋     | 1238/2645 [01:59<02:22,  9.85it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  47%|████▋     | 1238/2645 [01:59<02:22,  9.85it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  47%|████▋     | 1240/2645 [01:59<02:21,  9.92it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  47%|████▋     | 1240/2645 [01:59<02:21,  9.92it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  47%|████▋     | 1241/2645 [01:59<02:22,  9.87it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  47%|████▋     | 1241/2645 [01:59<02:22,  9.87it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  47%|████▋     | 1241/2645 [01:59<02:22,  9.87it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  47%|████▋     | 1243/2645 [01:59<02:21,  9.90it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  47%|████▋     | 1243/2645 [01:59<02:21,  9.90it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  47%|████▋     | 1243/2645 [01:59<02:21,  9.90it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  47%|████▋     | 1245/2645 [01:59<02:20,  9.97it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  47%|████▋     | 1245/2645 [01:59<02:20,  9.97it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  47%|████▋     | 1245/2645 [02:00<02:20,  9.97it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  47%|████▋     | 1247/2645 [02:00<02:18, 10.06it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  47%|████▋     | 1247/2645 [02:00<02:18, 10.06it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  47%|████▋     | 1247/2645 [02:00<02:18, 10.06it/s, training_loss=1.003]\u001b[A\n",
      "Epoch 3:  47%|████▋     | 1249/2645 [02:00<02:18, 10.07it/s, training_loss=1.003]\u001b[A\n",
      "Epoch 3:  47%|████▋     | 1249/2645 [02:00<02:18, 10.07it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  47%|████▋     | 1249/2645 [02:00<02:18, 10.07it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  47%|████▋     | 1251/2645 [02:00<02:17, 10.13it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  47%|████▋     | 1251/2645 [02:00<02:17, 10.13it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  47%|████▋     | 1251/2645 [02:00<02:17, 10.13it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  47%|████▋     | 1253/2645 [02:00<02:18, 10.07it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  47%|████▋     | 1253/2645 [02:00<02:18, 10.07it/s, training_loss=1.065]\u001b[A\n",
      "Epoch 3:  47%|████▋     | 1253/2645 [02:00<02:18, 10.07it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  47%|████▋     | 1255/2645 [02:00<02:18, 10.02it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  47%|████▋     | 1255/2645 [02:00<02:18, 10.02it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  47%|████▋     | 1255/2645 [02:01<02:18, 10.02it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  48%|████▊     | 1257/2645 [02:01<02:17, 10.06it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  48%|████▊     | 1257/2645 [02:01<02:17, 10.06it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  48%|████▊     | 1257/2645 [02:01<02:17, 10.06it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 3:  48%|████▊     | 1259/2645 [02:01<02:17, 10.07it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 3:  48%|████▊     | 1259/2645 [02:01<02:17, 10.07it/s, training_loss=0.673]\u001b[A\n",
      "Epoch 3:  48%|████▊     | 1259/2645 [02:01<02:17, 10.07it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  48%|████▊     | 1261/2645 [02:01<02:17, 10.06it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  48%|████▊     | 1261/2645 [02:01<02:17, 10.06it/s, training_loss=0.030]\u001b[A\n",
      "Epoch 3:  48%|████▊     | 1261/2645 [02:01<02:17, 10.06it/s, training_loss=0.951]\u001b[A\n",
      "Epoch 3:  48%|████▊     | 1263/2645 [02:01<02:18,  9.98it/s, training_loss=0.951]\u001b[A\n",
      "Epoch 3:  48%|████▊     | 1263/2645 [02:01<02:18,  9.98it/s, training_loss=0.021]\u001b[A\n",
      "Epoch 3:  48%|████▊     | 1264/2645 [02:01<02:18,  9.97it/s, training_loss=0.021]\u001b[A\n",
      "Epoch 3:  48%|████▊     | 1264/2645 [02:01<02:18,  9.97it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  48%|████▊     | 1264/2645 [02:01<02:18,  9.97it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  48%|████▊     | 1266/2645 [02:01<02:16, 10.09it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  48%|████▊     | 1266/2645 [02:02<02:16, 10.09it/s, training_loss=0.059]\u001b[A\n",
      "Epoch 3:  48%|████▊     | 1266/2645 [02:02<02:16, 10.09it/s, training_loss=0.038]\u001b[A\n",
      "Epoch 3:  48%|████▊     | 1268/2645 [02:02<02:16, 10.06it/s, training_loss=0.038]\u001b[A\n",
      "Epoch 3:  48%|████▊     | 1268/2645 [02:02<02:16, 10.06it/s, training_loss=1.512]\u001b[A\n",
      "Epoch 3:  48%|████▊     | 1268/2645 [02:02<02:16, 10.06it/s, training_loss=0.796]\u001b[A\n",
      "Epoch 3:  48%|████▊     | 1270/2645 [02:02<02:17, 10.01it/s, training_loss=0.796]\u001b[A\n",
      "Epoch 3:  48%|████▊     | 1270/2645 [02:02<02:17, 10.01it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  48%|████▊     | 1270/2645 [02:02<02:17, 10.01it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  48%|████▊     | 1272/2645 [02:02<02:16, 10.02it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  48%|████▊     | 1272/2645 [02:02<02:16, 10.02it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  48%|████▊     | 1272/2645 [02:02<02:16, 10.02it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  48%|████▊     | 1274/2645 [02:02<02:16, 10.02it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  48%|████▊     | 1274/2645 [02:02<02:16, 10.02it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  48%|████▊     | 1274/2645 [02:02<02:16, 10.02it/s, training_loss=0.522]\u001b[A\n",
      "Epoch 3:  48%|████▊     | 1276/2645 [02:02<02:17,  9.95it/s, training_loss=0.522]\u001b[A\n",
      "Epoch 3:  48%|████▊     | 1276/2645 [02:03<02:17,  9.95it/s, training_loss=0.093]\u001b[A\n",
      "Epoch 3:  48%|████▊     | 1277/2645 [02:03<02:17,  9.92it/s, training_loss=0.093]\u001b[A\n",
      "Epoch 3:  48%|████▊     | 1277/2645 [02:03<02:17,  9.92it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  48%|████▊     | 1277/2645 [02:03<02:17,  9.92it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  48%|████▊     | 1279/2645 [02:03<02:17,  9.95it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  48%|████▊     | 1279/2645 [02:03<02:17,  9.95it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  48%|████▊     | 1279/2645 [02:03<02:17,  9.95it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  48%|████▊     | 1281/2645 [02:03<02:15, 10.03it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  48%|████▊     | 1281/2645 [02:03<02:15, 10.03it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  48%|████▊     | 1281/2645 [02:03<02:15, 10.03it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  49%|████▊     | 1283/2645 [02:03<02:15, 10.06it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  49%|████▊     | 1283/2645 [02:03<02:15, 10.06it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  49%|████▊     | 1283/2645 [02:03<02:15, 10.06it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  49%|████▊     | 1285/2645 [02:03<02:14, 10.08it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  49%|████▊     | 1285/2645 [02:03<02:14, 10.08it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  49%|████▊     | 1285/2645 [02:04<02:14, 10.08it/s, training_loss=0.881]\u001b[A\n",
      "Epoch 3:  49%|████▊     | 1287/2645 [02:04<02:15, 10.04it/s, training_loss=0.881]\u001b[A\n",
      "Epoch 3:  49%|████▊     | 1287/2645 [02:04<02:15, 10.04it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  49%|████▊     | 1287/2645 [02:04<02:15, 10.04it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  49%|████▊     | 1289/2645 [02:04<02:14, 10.05it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  49%|████▊     | 1289/2645 [02:04<02:14, 10.05it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  49%|████▊     | 1289/2645 [02:04<02:14, 10.05it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  49%|████▉     | 1291/2645 [02:04<02:14, 10.06it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  49%|████▉     | 1291/2645 [02:04<02:14, 10.06it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  49%|████▉     | 1291/2645 [02:04<02:14, 10.06it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  49%|████▉     | 1293/2645 [02:04<02:13, 10.09it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  49%|████▉     | 1293/2645 [02:04<02:13, 10.09it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  49%|████▉     | 1293/2645 [02:04<02:13, 10.09it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  49%|████▉     | 1295/2645 [02:04<02:13, 10.08it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  49%|████▉     | 1295/2645 [02:04<02:13, 10.08it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  49%|████▉     | 1295/2645 [02:05<02:13, 10.08it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  49%|████▉     | 1297/2645 [02:05<02:13, 10.08it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  49%|████▉     | 1297/2645 [02:05<02:13, 10.08it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  49%|████▉     | 1297/2645 [02:05<02:13, 10.08it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  49%|████▉     | 1299/2645 [02:05<02:13, 10.11it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  49%|████▉     | 1299/2645 [02:05<02:13, 10.11it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  49%|████▉     | 1299/2645 [02:05<02:13, 10.11it/s, training_loss=0.039]\u001b[A\n",
      "Epoch 3:  49%|████▉     | 1301/2645 [02:05<02:13, 10.06it/s, training_loss=0.039]\u001b[A\n",
      "Epoch 3:  49%|████▉     | 1301/2645 [02:05<02:13, 10.06it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  49%|████▉     | 1301/2645 [02:05<02:13, 10.06it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  49%|████▉     | 1303/2645 [02:05<02:12, 10.13it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  49%|████▉     | 1303/2645 [02:05<02:12, 10.13it/s, training_loss=0.492]\u001b[A\n",
      "Epoch 3:  49%|████▉     | 1303/2645 [02:05<02:12, 10.13it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  49%|████▉     | 1305/2645 [02:05<02:13, 10.03it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  49%|████▉     | 1305/2645 [02:05<02:13, 10.03it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  49%|████▉     | 1305/2645 [02:06<02:13, 10.03it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  49%|████▉     | 1307/2645 [02:06<02:13, 10.03it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  49%|████▉     | 1307/2645 [02:06<02:13, 10.03it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  49%|████▉     | 1307/2645 [02:06<02:13, 10.03it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  49%|████▉     | 1309/2645 [02:06<02:12, 10.11it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  49%|████▉     | 1309/2645 [02:06<02:12, 10.11it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  49%|████▉     | 1309/2645 [02:06<02:12, 10.11it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 3:  50%|████▉     | 1311/2645 [02:06<02:11, 10.11it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 3:  50%|████▉     | 1311/2645 [02:06<02:11, 10.11it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  50%|████▉     | 1311/2645 [02:06<02:11, 10.11it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  50%|████▉     | 1313/2645 [02:06<02:11, 10.14it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  50%|████▉     | 1313/2645 [02:06<02:11, 10.14it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  50%|████▉     | 1313/2645 [02:06<02:11, 10.14it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  50%|████▉     | 1315/2645 [02:06<02:10, 10.17it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  50%|████▉     | 1315/2645 [02:06<02:10, 10.17it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  50%|████▉     | 1315/2645 [02:07<02:10, 10.17it/s, training_loss=0.721]\u001b[A\n",
      "Epoch 3:  50%|████▉     | 1317/2645 [02:07<02:10, 10.15it/s, training_loss=0.721]\u001b[A\n",
      "Epoch 3:  50%|████▉     | 1317/2645 [02:07<02:10, 10.15it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  50%|████▉     | 1317/2645 [02:07<02:10, 10.15it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  50%|████▉     | 1319/2645 [02:07<02:10, 10.16it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  50%|████▉     | 1319/2645 [02:07<02:10, 10.16it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  50%|████▉     | 1319/2645 [02:07<02:10, 10.16it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  50%|████▉     | 1321/2645 [02:07<02:09, 10.23it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  50%|████▉     | 1321/2645 [02:07<02:09, 10.23it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  50%|████▉     | 1321/2645 [02:07<02:09, 10.23it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  50%|█████     | 1323/2645 [02:07<02:09, 10.24it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  50%|█████     | 1323/2645 [02:07<02:09, 10.24it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  50%|█████     | 1323/2645 [02:07<02:09, 10.24it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  50%|█████     | 1325/2645 [02:07<02:09, 10.17it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  50%|█████     | 1325/2645 [02:07<02:09, 10.17it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  50%|█████     | 1325/2645 [02:08<02:09, 10.17it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  50%|█████     | 1327/2645 [02:08<02:10, 10.10it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  50%|█████     | 1327/2645 [02:08<02:10, 10.10it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  50%|█████     | 1327/2645 [02:08<02:10, 10.10it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  50%|█████     | 1329/2645 [02:08<02:10, 10.12it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  50%|█████     | 1329/2645 [02:08<02:10, 10.12it/s, training_loss=0.381]\u001b[A\n",
      "Epoch 3:  50%|█████     | 1329/2645 [02:08<02:10, 10.12it/s, training_loss=0.097]\u001b[A\n",
      "Epoch 3:  50%|█████     | 1331/2645 [02:08<02:10, 10.11it/s, training_loss=0.097]\u001b[A\n",
      "Epoch 3:  50%|█████     | 1331/2645 [02:08<02:10, 10.11it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  50%|█████     | 1331/2645 [02:08<02:10, 10.11it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  50%|█████     | 1333/2645 [02:08<02:09, 10.14it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  50%|█████     | 1333/2645 [02:08<02:09, 10.14it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  50%|█████     | 1333/2645 [02:08<02:09, 10.14it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  50%|█████     | 1335/2645 [02:08<02:08, 10.16it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  50%|█████     | 1335/2645 [02:08<02:08, 10.16it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  50%|█████     | 1335/2645 [02:08<02:08, 10.16it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  51%|█████     | 1337/2645 [02:08<02:09, 10.07it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  51%|█████     | 1337/2645 [02:09<02:09, 10.07it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  51%|█████     | 1337/2645 [02:09<02:09, 10.07it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  51%|█████     | 1339/2645 [02:09<02:08, 10.14it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  51%|█████     | 1339/2645 [02:09<02:08, 10.14it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  51%|█████     | 1339/2645 [02:09<02:08, 10.14it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  51%|█████     | 1341/2645 [02:09<02:08, 10.12it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  51%|█████     | 1341/2645 [02:09<02:08, 10.12it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 3:  51%|█████     | 1341/2645 [02:09<02:08, 10.12it/s, training_loss=0.727]\u001b[A\n",
      "Epoch 3:  51%|█████     | 1343/2645 [02:09<02:10, 10.01it/s, training_loss=0.727]\u001b[A\n",
      "Epoch 3:  51%|█████     | 1343/2645 [02:09<02:10, 10.01it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  51%|█████     | 1343/2645 [02:09<02:10, 10.01it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  51%|█████     | 1345/2645 [02:09<02:09, 10.03it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  51%|█████     | 1345/2645 [02:09<02:09, 10.03it/s, training_loss=0.056]\u001b[A\n",
      "Epoch 3:  51%|█████     | 1345/2645 [02:09<02:09, 10.03it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  51%|█████     | 1347/2645 [02:09<02:09, 10.00it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  51%|█████     | 1347/2645 [02:10<02:09, 10.00it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  51%|█████     | 1347/2645 [02:10<02:09, 10.00it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  51%|█████     | 1349/2645 [02:10<02:09,  9.98it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  51%|█████     | 1349/2645 [02:10<02:09,  9.98it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  51%|█████     | 1349/2645 [02:10<02:09,  9.98it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  51%|█████     | 1351/2645 [02:10<02:08, 10.05it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  51%|█████     | 1351/2645 [02:10<02:08, 10.05it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  51%|█████     | 1351/2645 [02:10<02:08, 10.05it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  51%|█████     | 1353/2645 [02:10<02:08, 10.07it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  51%|█████     | 1353/2645 [02:10<02:08, 10.07it/s, training_loss=0.047]\u001b[A\n",
      "Epoch 3:  51%|█████     | 1353/2645 [02:10<02:08, 10.07it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  51%|█████     | 1355/2645 [02:10<02:08, 10.03it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  51%|█████     | 1355/2645 [02:10<02:08, 10.03it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  51%|█████     | 1355/2645 [02:10<02:08, 10.03it/s, training_loss=0.105]\u001b[A\n",
      "Epoch 3:  51%|█████▏    | 1357/2645 [02:10<02:07, 10.08it/s, training_loss=0.105]\u001b[A\n",
      "Epoch 3:  51%|█████▏    | 1357/2645 [02:11<02:07, 10.08it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  51%|█████▏    | 1357/2645 [02:11<02:07, 10.08it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  51%|█████▏    | 1359/2645 [02:11<02:06, 10.14it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  51%|█████▏    | 1359/2645 [02:11<02:06, 10.14it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  51%|█████▏    | 1359/2645 [02:11<02:06, 10.14it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  51%|█████▏    | 1361/2645 [02:11<02:08, 10.03it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  51%|█████▏    | 1361/2645 [02:11<02:08, 10.03it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  51%|█████▏    | 1361/2645 [02:11<02:08, 10.03it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  52%|█████▏    | 1363/2645 [02:11<02:06, 10.10it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  52%|█████▏    | 1363/2645 [02:11<02:06, 10.10it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  52%|█████▏    | 1363/2645 [02:11<02:06, 10.10it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  52%|█████▏    | 1365/2645 [02:11<02:06, 10.11it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  52%|█████▏    | 1365/2645 [02:11<02:06, 10.11it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  52%|█████▏    | 1365/2645 [02:11<02:06, 10.11it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  52%|█████▏    | 1367/2645 [02:11<02:07, 10.06it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  52%|█████▏    | 1367/2645 [02:12<02:07, 10.06it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  52%|█████▏    | 1367/2645 [02:12<02:07, 10.06it/s, training_loss=0.153]\u001b[A\n",
      "Epoch 3:  52%|█████▏    | 1369/2645 [02:12<02:07, 10.00it/s, training_loss=0.153]\u001b[A\n",
      "Epoch 3:  52%|█████▏    | 1369/2645 [02:12<02:07, 10.00it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  52%|█████▏    | 1369/2645 [02:12<02:07, 10.00it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  52%|█████▏    | 1371/2645 [02:12<02:07, 10.03it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  52%|█████▏    | 1371/2645 [02:12<02:07, 10.03it/s, training_loss=0.810]\u001b[A\n",
      "Epoch 3:  52%|█████▏    | 1371/2645 [02:12<02:07, 10.03it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  52%|█████▏    | 1373/2645 [02:12<02:07,  9.97it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  52%|█████▏    | 1373/2645 [02:12<02:07,  9.97it/s, training_loss=0.010]\u001b[A\n",
      "Epoch 3:  52%|█████▏    | 1374/2645 [02:12<02:08,  9.88it/s, training_loss=0.010]\u001b[A\n",
      "Epoch 3:  52%|█████▏    | 1374/2645 [02:12<02:08,  9.88it/s, training_loss=0.159]\u001b[A\n",
      "Epoch 3:  52%|█████▏    | 1375/2645 [02:12<02:08,  9.90it/s, training_loss=0.159]\u001b[A\n",
      "Epoch 3:  52%|█████▏    | 1375/2645 [02:12<02:08,  9.90it/s, training_loss=0.656]\u001b[A\n",
      "Epoch 3:  52%|█████▏    | 1376/2645 [02:12<02:07,  9.92it/s, training_loss=0.656]\u001b[A\n",
      "Epoch 3:  52%|█████▏    | 1376/2645 [02:12<02:07,  9.92it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  52%|█████▏    | 1376/2645 [02:13<02:07,  9.92it/s, training_loss=0.681]\u001b[A\n",
      "Epoch 3:  52%|█████▏    | 1378/2645 [02:13<02:07,  9.94it/s, training_loss=0.681]\u001b[A\n",
      "Epoch 3:  52%|█████▏    | 1378/2645 [02:13<02:07,  9.94it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  52%|█████▏    | 1378/2645 [02:13<02:07,  9.94it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  52%|█████▏    | 1380/2645 [02:13<02:06,  9.99it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  52%|█████▏    | 1380/2645 [02:13<02:06,  9.99it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  52%|█████▏    | 1381/2645 [02:13<02:07,  9.90it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  52%|█████▏    | 1381/2645 [02:13<02:07,  9.90it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  52%|█████▏    | 1382/2645 [02:13<02:07,  9.88it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  52%|█████▏    | 1382/2645 [02:13<02:07,  9.88it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  52%|█████▏    | 1382/2645 [02:13<02:07,  9.88it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  52%|█████▏    | 1384/2645 [02:13<02:06,  9.98it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  52%|█████▏    | 1384/2645 [02:13<02:06,  9.98it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  52%|█████▏    | 1384/2645 [02:13<02:06,  9.98it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  52%|█████▏    | 1386/2645 [02:13<02:05, 10.02it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  52%|█████▏    | 1386/2645 [02:13<02:05, 10.02it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  52%|█████▏    | 1386/2645 [02:14<02:05, 10.02it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  52%|█████▏    | 1388/2645 [02:14<02:04, 10.08it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  52%|█████▏    | 1388/2645 [02:14<02:04, 10.08it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  52%|█████▏    | 1388/2645 [02:14<02:04, 10.08it/s, training_loss=0.510]\u001b[A\n",
      "Epoch 3:  53%|█████▎    | 1390/2645 [02:14<02:04, 10.08it/s, training_loss=0.510]\u001b[A\n",
      "Epoch 3:  53%|█████▎    | 1390/2645 [02:14<02:04, 10.08it/s, training_loss=0.121]\u001b[A\n",
      "Epoch 3:  53%|█████▎    | 1390/2645 [02:14<02:04, 10.08it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  53%|█████▎    | 1392/2645 [02:14<02:04, 10.05it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  53%|█████▎    | 1392/2645 [02:14<02:04, 10.05it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  53%|█████▎    | 1392/2645 [02:14<02:04, 10.05it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  53%|█████▎    | 1394/2645 [02:14<02:03, 10.13it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  53%|█████▎    | 1394/2645 [02:14<02:03, 10.13it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  53%|█████▎    | 1394/2645 [02:14<02:03, 10.13it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  53%|█████▎    | 1396/2645 [02:14<02:03, 10.11it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  53%|█████▎    | 1396/2645 [02:14<02:03, 10.11it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  53%|█████▎    | 1396/2645 [02:15<02:03, 10.11it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  53%|█████▎    | 1398/2645 [02:15<02:02, 10.15it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  53%|█████▎    | 1398/2645 [02:15<02:02, 10.15it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  53%|█████▎    | 1398/2645 [02:15<02:02, 10.15it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  53%|█████▎    | 1400/2645 [02:15<02:02, 10.13it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  53%|█████▎    | 1400/2645 [02:15<02:02, 10.13it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  53%|█████▎    | 1400/2645 [02:15<02:02, 10.13it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  53%|█████▎    | 1402/2645 [02:15<02:02, 10.15it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  53%|█████▎    | 1402/2645 [02:15<02:02, 10.15it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  53%|█████▎    | 1402/2645 [02:15<02:02, 10.15it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  53%|█████▎    | 1404/2645 [02:15<02:00, 10.26it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  53%|█████▎    | 1404/2645 [02:15<02:00, 10.26it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  53%|█████▎    | 1404/2645 [02:15<02:00, 10.26it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  53%|█████▎    | 1406/2645 [02:15<01:59, 10.36it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  53%|█████▎    | 1406/2645 [02:15<01:59, 10.36it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  53%|█████▎    | 1406/2645 [02:16<01:59, 10.36it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  53%|█████▎    | 1408/2645 [02:16<01:58, 10.42it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  53%|█████▎    | 1408/2645 [02:16<01:58, 10.42it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  53%|█████▎    | 1408/2645 [02:16<01:58, 10.42it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  53%|█████▎    | 1410/2645 [02:16<01:58, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  53%|█████▎    | 1410/2645 [02:16<01:58, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  53%|█████▎    | 1410/2645 [02:16<01:58, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  53%|█████▎    | 1412/2645 [02:16<01:57, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  53%|█████▎    | 1412/2645 [02:16<01:57, 10.49it/s, training_loss=0.818]\u001b[A\n",
      "Epoch 3:  53%|█████▎    | 1412/2645 [02:16<01:57, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  53%|█████▎    | 1414/2645 [02:16<01:57, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  53%|█████▎    | 1414/2645 [02:16<01:57, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  53%|█████▎    | 1414/2645 [02:16<01:57, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  54%|█████▎    | 1416/2645 [02:16<01:57, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  54%|█████▎    | 1416/2645 [02:16<01:57, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  54%|█████▎    | 1416/2645 [02:16<01:57, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  54%|█████▎    | 1418/2645 [02:16<01:56, 10.54it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  54%|█████▎    | 1418/2645 [02:17<01:56, 10.54it/s, training_loss=1.042]\u001b[A\n",
      "Epoch 3:  54%|█████▎    | 1418/2645 [02:17<01:56, 10.54it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  54%|█████▎    | 1420/2645 [02:17<01:56, 10.54it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  54%|█████▎    | 1420/2645 [02:17<01:56, 10.54it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  54%|█████▎    | 1420/2645 [02:17<01:56, 10.54it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  54%|█████▍    | 1422/2645 [02:17<01:55, 10.56it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  54%|█████▍    | 1422/2645 [02:17<01:55, 10.56it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  54%|█████▍    | 1422/2645 [02:17<01:55, 10.56it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  54%|█████▍    | 1424/2645 [02:17<01:55, 10.58it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  54%|█████▍    | 1424/2645 [02:17<01:55, 10.58it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  54%|█████▍    | 1424/2645 [02:17<01:55, 10.58it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  54%|█████▍    | 1426/2645 [02:17<01:55, 10.59it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  54%|█████▍    | 1426/2645 [02:17<01:55, 10.59it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  54%|█████▍    | 1426/2645 [02:17<01:55, 10.59it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  54%|█████▍    | 1428/2645 [02:17<01:55, 10.58it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  54%|█████▍    | 1428/2645 [02:18<01:55, 10.58it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  54%|█████▍    | 1428/2645 [02:18<01:55, 10.58it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  54%|█████▍    | 1430/2645 [02:18<01:55, 10.56it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  54%|█████▍    | 1430/2645 [02:18<01:55, 10.56it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  54%|█████▍    | 1430/2645 [02:18<01:55, 10.56it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  54%|█████▍    | 1432/2645 [02:18<01:54, 10.58it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  54%|█████▍    | 1432/2645 [02:18<01:54, 10.58it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  54%|█████▍    | 1432/2645 [02:18<01:54, 10.58it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  54%|█████▍    | 1434/2645 [02:18<01:54, 10.58it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  54%|█████▍    | 1434/2645 [02:18<01:54, 10.58it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  54%|█████▍    | 1434/2645 [02:18<01:54, 10.58it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  54%|█████▍    | 1436/2645 [02:18<01:54, 10.57it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  54%|█████▍    | 1436/2645 [02:18<01:54, 10.57it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  54%|█████▍    | 1436/2645 [02:18<01:54, 10.57it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  54%|█████▍    | 1438/2645 [02:18<01:53, 10.60it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  54%|█████▍    | 1438/2645 [02:18<01:53, 10.60it/s, training_loss=0.090]\u001b[A\n",
      "Epoch 3:  54%|█████▍    | 1438/2645 [02:19<01:53, 10.60it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  54%|█████▍    | 1440/2645 [02:19<01:54, 10.55it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  54%|█████▍    | 1440/2645 [02:19<01:54, 10.55it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  54%|█████▍    | 1440/2645 [02:19<01:54, 10.55it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  55%|█████▍    | 1442/2645 [02:19<01:54, 10.53it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  55%|█████▍    | 1442/2645 [02:19<01:54, 10.53it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  55%|█████▍    | 1442/2645 [02:19<01:54, 10.53it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  55%|█████▍    | 1444/2645 [02:19<01:53, 10.55it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  55%|█████▍    | 1444/2645 [02:19<01:53, 10.55it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  55%|█████▍    | 1444/2645 [02:19<01:53, 10.55it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  55%|█████▍    | 1446/2645 [02:19<01:53, 10.53it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  55%|█████▍    | 1446/2645 [02:19<01:53, 10.53it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  55%|█████▍    | 1446/2645 [02:19<01:53, 10.53it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  55%|█████▍    | 1448/2645 [02:19<01:53, 10.54it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  55%|█████▍    | 1448/2645 [02:19<01:53, 10.54it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  55%|█████▍    | 1448/2645 [02:19<01:53, 10.54it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  55%|█████▍    | 1450/2645 [02:20<01:53, 10.56it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  55%|█████▍    | 1450/2645 [02:20<01:53, 10.56it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  55%|█████▍    | 1450/2645 [02:20<01:53, 10.56it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  55%|█████▍    | 1452/2645 [02:20<01:53, 10.55it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  55%|█████▍    | 1452/2645 [02:20<01:53, 10.55it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  55%|█████▍    | 1452/2645 [02:20<01:53, 10.55it/s, training_loss=0.033]\u001b[A\n",
      "Epoch 3:  55%|█████▍    | 1454/2645 [02:20<01:56, 10.25it/s, training_loss=0.033]\u001b[A\n",
      "Epoch 3:  55%|█████▍    | 1454/2645 [02:20<01:56, 10.25it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  55%|█████▍    | 1454/2645 [02:20<01:56, 10.25it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  55%|█████▌    | 1456/2645 [02:20<01:55, 10.30it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  55%|█████▌    | 1456/2645 [02:20<01:55, 10.30it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  55%|█████▌    | 1456/2645 [02:20<01:55, 10.30it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  55%|█████▌    | 1458/2645 [02:20<01:54, 10.36it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  55%|█████▌    | 1458/2645 [02:20<01:54, 10.36it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  55%|█████▌    | 1458/2645 [02:20<01:54, 10.36it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  55%|█████▌    | 1460/2645 [02:20<01:53, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  55%|█████▌    | 1460/2645 [02:21<01:53, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  55%|█████▌    | 1460/2645 [02:21<01:53, 10.43it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 3:  55%|█████▌    | 1462/2645 [02:21<01:53, 10.45it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 3:  55%|█████▌    | 1462/2645 [02:21<01:53, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  55%|█████▌    | 1462/2645 [02:21<01:53, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  55%|█████▌    | 1464/2645 [02:21<01:52, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  55%|█████▌    | 1464/2645 [02:21<01:52, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  55%|█████▌    | 1464/2645 [02:21<01:52, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  55%|█████▌    | 1466/2645 [02:21<01:52, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  55%|█████▌    | 1466/2645 [02:21<01:52, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  55%|█████▌    | 1466/2645 [02:21<01:52, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  56%|█████▌    | 1468/2645 [02:21<01:51, 10.55it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  56%|█████▌    | 1468/2645 [02:21<01:51, 10.55it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  56%|█████▌    | 1468/2645 [02:21<01:51, 10.55it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  56%|█████▌    | 1470/2645 [02:21<01:51, 10.53it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  56%|█████▌    | 1470/2645 [02:22<01:51, 10.53it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  56%|█████▌    | 1470/2645 [02:22<01:51, 10.53it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  56%|█████▌    | 1472/2645 [02:22<01:50, 10.57it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  56%|█████▌    | 1472/2645 [02:22<01:50, 10.57it/s, training_loss=0.032]\u001b[A\n",
      "Epoch 3:  56%|█████▌    | 1472/2645 [02:22<01:50, 10.57it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  56%|█████▌    | 1474/2645 [02:22<01:51, 10.54it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  56%|█████▌    | 1474/2645 [02:22<01:51, 10.54it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  56%|█████▌    | 1474/2645 [02:22<01:51, 10.54it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  56%|█████▌    | 1476/2645 [02:22<01:50, 10.55it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  56%|█████▌    | 1476/2645 [02:22<01:50, 10.55it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  56%|█████▌    | 1476/2645 [02:22<01:50, 10.55it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  56%|█████▌    | 1478/2645 [02:22<01:50, 10.57it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  56%|█████▌    | 1478/2645 [02:22<01:50, 10.57it/s, training_loss=1.001]\u001b[A\n",
      "Epoch 3:  56%|█████▌    | 1478/2645 [02:22<01:50, 10.57it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  56%|█████▌    | 1480/2645 [02:22<01:50, 10.53it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  56%|█████▌    | 1480/2645 [02:22<01:50, 10.53it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  56%|█████▌    | 1480/2645 [02:23<01:50, 10.53it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  56%|█████▌    | 1482/2645 [02:23<01:50, 10.56it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  56%|█████▌    | 1482/2645 [02:23<01:50, 10.56it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  56%|█████▌    | 1482/2645 [02:23<01:50, 10.56it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  56%|█████▌    | 1484/2645 [02:23<01:49, 10.58it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  56%|█████▌    | 1484/2645 [02:23<01:49, 10.58it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  56%|█████▌    | 1484/2645 [02:23<01:49, 10.58it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  56%|█████▌    | 1486/2645 [02:23<01:49, 10.59it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  56%|█████▌    | 1486/2645 [02:23<01:49, 10.59it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  56%|█████▌    | 1486/2645 [02:23<01:49, 10.59it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  56%|█████▋    | 1488/2645 [02:23<01:49, 10.59it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  56%|█████▋    | 1488/2645 [02:23<01:49, 10.59it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  56%|█████▋    | 1488/2645 [02:23<01:49, 10.59it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  56%|█████▋    | 1490/2645 [02:23<01:49, 10.59it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  56%|█████▋    | 1490/2645 [02:23<01:49, 10.59it/s, training_loss=0.041]\u001b[A\n",
      "Epoch 3:  56%|█████▋    | 1490/2645 [02:23<01:49, 10.59it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  56%|█████▋    | 1492/2645 [02:24<01:49, 10.53it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  56%|█████▋    | 1492/2645 [02:24<01:49, 10.53it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  56%|█████▋    | 1492/2645 [02:24<01:49, 10.53it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  56%|█████▋    | 1494/2645 [02:24<01:49, 10.55it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  56%|█████▋    | 1494/2645 [02:24<01:49, 10.55it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  56%|█████▋    | 1494/2645 [02:24<01:49, 10.55it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  57%|█████▋    | 1496/2645 [02:24<01:49, 10.52it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  57%|█████▋    | 1496/2645 [02:24<01:49, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  57%|█████▋    | 1496/2645 [02:24<01:49, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  57%|█████▋    | 1498/2645 [02:24<01:48, 10.53it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  57%|█████▋    | 1498/2645 [02:24<01:48, 10.53it/s, training_loss=0.702]\u001b[A\n",
      "Epoch 3:  57%|█████▋    | 1498/2645 [02:24<01:48, 10.53it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  57%|█████▋    | 1500/2645 [02:24<01:48, 10.55it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  57%|█████▋    | 1500/2645 [02:24<01:48, 10.55it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  57%|█████▋    | 1500/2645 [02:24<01:48, 10.55it/s, training_loss=0.486]\u001b[A\n",
      "Epoch 3:  57%|█████▋    | 1502/2645 [02:24<01:48, 10.53it/s, training_loss=0.486]\u001b[A\n",
      "Epoch 3:  57%|█████▋    | 1502/2645 [02:25<01:48, 10.53it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  57%|█████▋    | 1502/2645 [02:25<01:48, 10.53it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  57%|█████▋    | 1504/2645 [02:25<01:48, 10.54it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  57%|█████▋    | 1504/2645 [02:25<01:48, 10.54it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  57%|█████▋    | 1504/2645 [02:25<01:48, 10.54it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  57%|█████▋    | 1506/2645 [02:25<01:48, 10.53it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  57%|█████▋    | 1506/2645 [02:25<01:48, 10.53it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  57%|█████▋    | 1506/2645 [02:25<01:48, 10.53it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  57%|█████▋    | 1508/2645 [02:25<01:47, 10.54it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  57%|█████▋    | 1508/2645 [02:25<01:47, 10.54it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  57%|█████▋    | 1508/2645 [02:25<01:47, 10.54it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  57%|█████▋    | 1510/2645 [02:25<01:48, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  57%|█████▋    | 1510/2645 [02:25<01:48, 10.49it/s, training_loss=0.941]\u001b[A\n",
      "Epoch 3:  57%|█████▋    | 1510/2645 [02:25<01:48, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  57%|█████▋    | 1512/2645 [02:25<01:48, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  57%|█████▋    | 1512/2645 [02:26<01:48, 10.45it/s, training_loss=1.527]\u001b[A\n",
      "Epoch 3:  57%|█████▋    | 1512/2645 [02:26<01:48, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  57%|█████▋    | 1514/2645 [02:26<01:48, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  57%|█████▋    | 1514/2645 [02:26<01:48, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  57%|█████▋    | 1514/2645 [02:26<01:48, 10.45it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  57%|█████▋    | 1516/2645 [02:26<01:48, 10.45it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  57%|█████▋    | 1516/2645 [02:26<01:48, 10.45it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  57%|█████▋    | 1516/2645 [02:26<01:48, 10.45it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  57%|█████▋    | 1518/2645 [02:26<01:47, 10.48it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  57%|█████▋    | 1518/2645 [02:26<01:47, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  57%|█████▋    | 1518/2645 [02:26<01:47, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  57%|█████▋    | 1520/2645 [02:26<01:46, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  57%|█████▋    | 1520/2645 [02:26<01:46, 10.52it/s, training_loss=0.012]\u001b[A\n",
      "Epoch 3:  57%|█████▋    | 1520/2645 [02:26<01:46, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  58%|█████▊    | 1522/2645 [02:26<01:46, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  58%|█████▊    | 1522/2645 [02:26<01:46, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  58%|█████▊    | 1522/2645 [02:27<01:46, 10.52it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  58%|█████▊    | 1524/2645 [02:27<01:46, 10.54it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  58%|█████▊    | 1524/2645 [02:27<01:46, 10.54it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  58%|█████▊    | 1524/2645 [02:27<01:46, 10.54it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  58%|█████▊    | 1526/2645 [02:27<01:46, 10.54it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  58%|█████▊    | 1526/2645 [02:27<01:46, 10.54it/s, training_loss=0.926]\u001b[A\n",
      "Epoch 3:  58%|█████▊    | 1526/2645 [02:27<01:46, 10.54it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  58%|█████▊    | 1528/2645 [02:27<01:46, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  58%|█████▊    | 1528/2645 [02:27<01:46, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  58%|█████▊    | 1528/2645 [02:27<01:46, 10.50it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  58%|█████▊    | 1530/2645 [02:27<01:46, 10.45it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  58%|█████▊    | 1530/2645 [02:27<01:46, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  58%|█████▊    | 1530/2645 [02:27<01:46, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  58%|█████▊    | 1532/2645 [02:27<01:48, 10.28it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  58%|█████▊    | 1532/2645 [02:27<01:48, 10.28it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  58%|█████▊    | 1532/2645 [02:28<01:48, 10.28it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  58%|█████▊    | 1534/2645 [02:28<01:48, 10.25it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  58%|█████▊    | 1534/2645 [02:28<01:48, 10.25it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  58%|█████▊    | 1534/2645 [02:28<01:48, 10.25it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  58%|█████▊    | 1536/2645 [02:28<01:47, 10.36it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  58%|█████▊    | 1536/2645 [02:28<01:47, 10.36it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  58%|█████▊    | 1536/2645 [02:28<01:47, 10.36it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  58%|█████▊    | 1538/2645 [02:28<01:46, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  58%|█████▊    | 1538/2645 [02:28<01:46, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  58%|█████▊    | 1538/2645 [02:28<01:46, 10.44it/s, training_loss=0.942]\u001b[A\n",
      "Epoch 3:  58%|█████▊    | 1540/2645 [02:28<01:45, 10.45it/s, training_loss=0.942]\u001b[A\n",
      "Epoch 3:  58%|█████▊    | 1540/2645 [02:28<01:45, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  58%|█████▊    | 1540/2645 [02:28<01:45, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  58%|█████▊    | 1542/2645 [02:28<01:45, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  58%|█████▊    | 1542/2645 [02:28<01:45, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  58%|█████▊    | 1542/2645 [02:28<01:45, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  58%|█████▊    | 1544/2645 [02:28<01:44, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  58%|█████▊    | 1544/2645 [02:29<01:44, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  58%|█████▊    | 1544/2645 [02:29<01:44, 10.49it/s, training_loss=0.382]\u001b[A\n",
      "Epoch 3:  58%|█████▊    | 1546/2645 [02:29<01:44, 10.50it/s, training_loss=0.382]\u001b[A\n",
      "Epoch 3:  58%|█████▊    | 1546/2645 [02:29<01:44, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  58%|█████▊    | 1546/2645 [02:29<01:44, 10.50it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  59%|█████▊    | 1548/2645 [02:29<01:44, 10.52it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  59%|█████▊    | 1548/2645 [02:29<01:44, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  59%|█████▊    | 1548/2645 [02:29<01:44, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  59%|█████▊    | 1550/2645 [02:29<01:43, 10.54it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  59%|█████▊    | 1550/2645 [02:29<01:43, 10.54it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  59%|█████▊    | 1550/2645 [02:29<01:43, 10.54it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  59%|█████▊    | 1552/2645 [02:29<01:43, 10.55it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  59%|█████▊    | 1552/2645 [02:29<01:43, 10.55it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  59%|█████▊    | 1552/2645 [02:29<01:43, 10.55it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  59%|█████▉    | 1554/2645 [02:29<01:43, 10.52it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  59%|█████▉    | 1554/2645 [02:30<01:43, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  59%|█████▉    | 1554/2645 [02:30<01:43, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  59%|█████▉    | 1556/2645 [02:30<01:43, 10.54it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  59%|█████▉    | 1556/2645 [02:30<01:43, 10.54it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  59%|█████▉    | 1556/2645 [02:30<01:43, 10.54it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  59%|█████▉    | 1558/2645 [02:30<01:43, 10.54it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  59%|█████▉    | 1558/2645 [02:30<01:43, 10.54it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  59%|█████▉    | 1558/2645 [02:30<01:43, 10.54it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  59%|█████▉    | 1560/2645 [02:30<01:42, 10.57it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  59%|█████▉    | 1560/2645 [02:30<01:42, 10.57it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  59%|█████▉    | 1560/2645 [02:30<01:42, 10.57it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  59%|█████▉    | 1562/2645 [02:30<01:42, 10.57it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  59%|█████▉    | 1562/2645 [02:30<01:42, 10.57it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  59%|█████▉    | 1562/2645 [02:30<01:42, 10.57it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  59%|█████▉    | 1564/2645 [02:30<01:42, 10.55it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  59%|█████▉    | 1564/2645 [02:30<01:42, 10.55it/s, training_loss=0.638]\u001b[A\n",
      "Epoch 3:  59%|█████▉    | 1564/2645 [02:31<01:42, 10.55it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  59%|█████▉    | 1566/2645 [02:31<01:42, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  59%|█████▉    | 1566/2645 [02:31<01:42, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  59%|█████▉    | 1566/2645 [02:31<01:42, 10.51it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  59%|█████▉    | 1568/2645 [02:31<01:42, 10.51it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  59%|█████▉    | 1568/2645 [02:31<01:42, 10.51it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 3:  59%|█████▉    | 1568/2645 [02:31<01:42, 10.51it/s, training_loss=0.699]\u001b[A\n",
      "Epoch 3:  59%|█████▉    | 1570/2645 [02:31<01:42, 10.45it/s, training_loss=0.699]\u001b[A\n",
      "Epoch 3:  59%|█████▉    | 1570/2645 [02:31<01:42, 10.45it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  59%|█████▉    | 1570/2645 [02:31<01:42, 10.45it/s, training_loss=0.011]\u001b[A\n",
      "Epoch 3:  59%|█████▉    | 1572/2645 [02:31<01:43, 10.41it/s, training_loss=0.011]\u001b[A\n",
      "Epoch 3:  59%|█████▉    | 1572/2645 [02:31<01:43, 10.41it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  59%|█████▉    | 1572/2645 [02:31<01:43, 10.41it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  60%|█████▉    | 1574/2645 [02:31<01:42, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  60%|█████▉    | 1574/2645 [02:31<01:42, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  60%|█████▉    | 1574/2645 [02:32<01:42, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  60%|█████▉    | 1576/2645 [02:32<01:41, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  60%|█████▉    | 1576/2645 [02:32<01:41, 10.50it/s, training_loss=0.915]\u001b[A\n",
      "Epoch 3:  60%|█████▉    | 1576/2645 [02:32<01:41, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  60%|█████▉    | 1578/2645 [02:32<01:41, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  60%|█████▉    | 1578/2645 [02:32<01:41, 10.49it/s, training_loss=0.087]\u001b[A\n",
      "Epoch 3:  60%|█████▉    | 1578/2645 [02:32<01:41, 10.49it/s, training_loss=0.141]\u001b[A\n",
      "Epoch 3:  60%|█████▉    | 1580/2645 [02:32<01:41, 10.47it/s, training_loss=0.141]\u001b[A\n",
      "Epoch 3:  60%|█████▉    | 1580/2645 [02:32<01:41, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  60%|█████▉    | 1580/2645 [02:32<01:41, 10.47it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  60%|█████▉    | 1582/2645 [02:32<01:41, 10.50it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  60%|█████▉    | 1582/2645 [02:32<01:41, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  60%|█████▉    | 1582/2645 [02:32<01:41, 10.50it/s, training_loss=0.461]\u001b[A\n",
      "Epoch 3:  60%|█████▉    | 1584/2645 [02:32<01:41, 10.49it/s, training_loss=0.461]\u001b[A\n",
      "Epoch 3:  60%|█████▉    | 1584/2645 [02:32<01:41, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  60%|█████▉    | 1584/2645 [02:32<01:41, 10.49it/s, training_loss=0.029]\u001b[A\n",
      "Epoch 3:  60%|█████▉    | 1586/2645 [02:32<01:40, 10.49it/s, training_loss=0.029]\u001b[A\n",
      "Epoch 3:  60%|█████▉    | 1586/2645 [02:33<01:40, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  60%|█████▉    | 1586/2645 [02:33<01:40, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  60%|██████    | 1588/2645 [02:33<01:42, 10.34it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  60%|██████    | 1588/2645 [02:33<01:42, 10.34it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  60%|██████    | 1588/2645 [02:33<01:42, 10.34it/s, training_loss=0.536]\u001b[A\n",
      "Epoch 3:  60%|██████    | 1590/2645 [02:33<01:43, 10.16it/s, training_loss=0.536]\u001b[A\n",
      "Epoch 3:  60%|██████    | 1590/2645 [02:33<01:43, 10.16it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  60%|██████    | 1590/2645 [02:33<01:43, 10.16it/s, training_loss=0.234]\u001b[A\n",
      "Epoch 3:  60%|██████    | 1592/2645 [02:33<01:44, 10.09it/s, training_loss=0.234]\u001b[A\n",
      "Epoch 3:  60%|██████    | 1592/2645 [02:33<01:44, 10.09it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  60%|██████    | 1592/2645 [02:33<01:44, 10.09it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  60%|██████    | 1594/2645 [02:33<01:44, 10.08it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  60%|██████    | 1594/2645 [02:33<01:44, 10.08it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  60%|██████    | 1594/2645 [02:33<01:44, 10.08it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  60%|██████    | 1596/2645 [02:33<01:43, 10.11it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  60%|██████    | 1596/2645 [02:34<01:43, 10.11it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  60%|██████    | 1596/2645 [02:34<01:43, 10.11it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  60%|██████    | 1598/2645 [02:34<01:43, 10.14it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  60%|██████    | 1598/2645 [02:34<01:43, 10.14it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  60%|██████    | 1598/2645 [02:34<01:43, 10.14it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  60%|██████    | 1600/2645 [02:34<01:43, 10.09it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  60%|██████    | 1600/2645 [02:34<01:43, 10.09it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  60%|██████    | 1600/2645 [02:34<01:43, 10.09it/s, training_loss=0.737]\u001b[A\n",
      "Epoch 3:  61%|██████    | 1602/2645 [02:34<01:44,  9.99it/s, training_loss=0.737]\u001b[A\n",
      "Epoch 3:  61%|██████    | 1602/2645 [02:34<01:44,  9.99it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  61%|██████    | 1602/2645 [02:34<01:44,  9.99it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  61%|██████    | 1604/2645 [02:34<01:43, 10.03it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  61%|██████    | 1604/2645 [02:34<01:43, 10.03it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  61%|██████    | 1604/2645 [02:34<01:43, 10.03it/s, training_loss=0.497]\u001b[A\n",
      "Epoch 3:  61%|██████    | 1606/2645 [02:34<01:44,  9.94it/s, training_loss=0.497]\u001b[A\n",
      "Epoch 3:  61%|██████    | 1606/2645 [02:35<01:44,  9.94it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  61%|██████    | 1606/2645 [02:35<01:44,  9.94it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  61%|██████    | 1608/2645 [02:35<01:44,  9.97it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  61%|██████    | 1608/2645 [02:35<01:44,  9.97it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  61%|██████    | 1609/2645 [02:35<01:43,  9.96it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  61%|██████    | 1609/2645 [02:35<01:43,  9.96it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  61%|██████    | 1610/2645 [02:35<01:43,  9.95it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  61%|██████    | 1610/2645 [02:35<01:43,  9.95it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  61%|██████    | 1611/2645 [02:35<01:43,  9.95it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  61%|██████    | 1611/2645 [02:35<01:43,  9.95it/s, training_loss=0.017]\u001b[A\n",
      "Epoch 3:  61%|██████    | 1612/2645 [02:35<01:44,  9.87it/s, training_loss=0.017]\u001b[A\n",
      "Epoch 3:  61%|██████    | 1612/2645 [02:35<01:44,  9.87it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  61%|██████    | 1612/2645 [02:35<01:44,  9.87it/s, training_loss=0.060]\u001b[A\n",
      "Epoch 3:  61%|██████    | 1614/2645 [02:35<01:44,  9.90it/s, training_loss=0.060]\u001b[A\n",
      "Epoch 3:  61%|██████    | 1614/2645 [02:35<01:44,  9.90it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  61%|██████    | 1614/2645 [02:35<01:44,  9.90it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  61%|██████    | 1616/2645 [02:35<01:42, 10.00it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  61%|██████    | 1616/2645 [02:36<01:42, 10.00it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  61%|██████    | 1616/2645 [02:36<01:42, 10.00it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  61%|██████    | 1618/2645 [02:36<01:42, 10.02it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  61%|██████    | 1618/2645 [02:36<01:42, 10.02it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  61%|██████    | 1618/2645 [02:36<01:42, 10.02it/s, training_loss=0.011]\u001b[A\n",
      "Epoch 3:  61%|██████    | 1620/2645 [02:36<01:42, 10.02it/s, training_loss=0.011]\u001b[A\n",
      "Epoch 3:  61%|██████    | 1620/2645 [02:36<01:42, 10.02it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  61%|██████    | 1620/2645 [02:36<01:42, 10.02it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  61%|██████▏   | 1622/2645 [02:36<01:41, 10.06it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  61%|██████▏   | 1622/2645 [02:36<01:41, 10.06it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  61%|██████▏   | 1622/2645 [02:36<01:41, 10.06it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  61%|██████▏   | 1624/2645 [02:36<01:40, 10.11it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  61%|██████▏   | 1624/2645 [02:36<01:40, 10.11it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  61%|██████▏   | 1624/2645 [02:36<01:40, 10.11it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  61%|██████▏   | 1626/2645 [02:36<01:40, 10.13it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  61%|██████▏   | 1626/2645 [02:37<01:40, 10.13it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  61%|██████▏   | 1626/2645 [02:37<01:40, 10.13it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  62%|██████▏   | 1628/2645 [02:37<01:40, 10.15it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  62%|██████▏   | 1628/2645 [02:37<01:40, 10.15it/s, training_loss=0.193]\u001b[A\n",
      "Epoch 3:  62%|██████▏   | 1628/2645 [02:37<01:40, 10.15it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  62%|██████▏   | 1630/2645 [02:37<01:40, 10.10it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  62%|██████▏   | 1630/2645 [02:37<01:40, 10.10it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  62%|██████▏   | 1630/2645 [02:37<01:40, 10.10it/s, training_loss=0.427]\u001b[A\n",
      "Epoch 3:  62%|██████▏   | 1632/2645 [02:37<01:40, 10.06it/s, training_loss=0.427]\u001b[A\n",
      "Epoch 3:  62%|██████▏   | 1632/2645 [02:37<01:40, 10.06it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  62%|██████▏   | 1632/2645 [02:37<01:40, 10.06it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  62%|██████▏   | 1634/2645 [02:37<01:41,  9.99it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  62%|██████▏   | 1634/2645 [02:37<01:41,  9.99it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  62%|██████▏   | 1634/2645 [02:37<01:41,  9.99it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 3:  62%|██████▏   | 1636/2645 [02:37<01:40, 10.06it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 3:  62%|██████▏   | 1636/2645 [02:38<01:40, 10.06it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  62%|██████▏   | 1636/2645 [02:38<01:40, 10.06it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  62%|██████▏   | 1638/2645 [02:38<01:39, 10.14it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  62%|██████▏   | 1638/2645 [02:38<01:39, 10.14it/s, training_loss=0.488]\u001b[A\n",
      "Epoch 3:  62%|██████▏   | 1638/2645 [02:38<01:39, 10.14it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  62%|██████▏   | 1640/2645 [02:38<01:39, 10.15it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  62%|██████▏   | 1640/2645 [02:38<01:39, 10.15it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  62%|██████▏   | 1640/2645 [02:38<01:39, 10.15it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  62%|██████▏   | 1642/2645 [02:38<01:38, 10.14it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  62%|██████▏   | 1642/2645 [02:38<01:38, 10.14it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  62%|██████▏   | 1642/2645 [02:38<01:38, 10.14it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  62%|██████▏   | 1644/2645 [02:38<01:38, 10.15it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  62%|██████▏   | 1644/2645 [02:38<01:38, 10.15it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  62%|██████▏   | 1644/2645 [02:38<01:38, 10.15it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 3:  62%|██████▏   | 1646/2645 [02:38<01:38, 10.16it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 3:  62%|██████▏   | 1646/2645 [02:39<01:38, 10.16it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  62%|██████▏   | 1646/2645 [02:39<01:38, 10.16it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 3:  62%|██████▏   | 1648/2645 [02:39<01:37, 10.20it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 3:  62%|██████▏   | 1648/2645 [02:39<01:37, 10.20it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  62%|██████▏   | 1648/2645 [02:39<01:37, 10.20it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  62%|██████▏   | 1650/2645 [02:39<01:37, 10.22it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  62%|██████▏   | 1650/2645 [02:39<01:37, 10.22it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  62%|██████▏   | 1650/2645 [02:39<01:37, 10.22it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  62%|██████▏   | 1652/2645 [02:39<01:37, 10.19it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  62%|██████▏   | 1652/2645 [02:39<01:37, 10.19it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  62%|██████▏   | 1652/2645 [02:39<01:37, 10.19it/s, training_loss=0.790]\u001b[A\n",
      "Epoch 3:  63%|██████▎   | 1654/2645 [02:39<01:37, 10.16it/s, training_loss=0.790]\u001b[A\n",
      "Epoch 3:  63%|██████▎   | 1654/2645 [02:39<01:37, 10.16it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  63%|██████▎   | 1654/2645 [02:39<01:37, 10.16it/s, training_loss=0.587]\u001b[A\n",
      "Epoch 3:  63%|██████▎   | 1656/2645 [02:39<01:36, 10.21it/s, training_loss=0.587]\u001b[A\n",
      "Epoch 3:  63%|██████▎   | 1656/2645 [02:40<01:36, 10.21it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  63%|██████▎   | 1656/2645 [02:40<01:36, 10.21it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  63%|██████▎   | 1658/2645 [02:40<01:36, 10.23it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  63%|██████▎   | 1658/2645 [02:40<01:36, 10.23it/s, training_loss=0.273]\u001b[A\n",
      "Epoch 3:  63%|██████▎   | 1658/2645 [02:40<01:36, 10.23it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  63%|██████▎   | 1660/2645 [02:40<01:36, 10.19it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  63%|██████▎   | 1660/2645 [02:40<01:36, 10.19it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  63%|██████▎   | 1660/2645 [02:40<01:36, 10.19it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  63%|██████▎   | 1662/2645 [02:40<01:36, 10.23it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  63%|██████▎   | 1662/2645 [02:40<01:36, 10.23it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 3:  63%|██████▎   | 1662/2645 [02:40<01:36, 10.23it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 3:  63%|██████▎   | 1664/2645 [02:40<01:36, 10.13it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 3:  63%|██████▎   | 1664/2645 [02:40<01:36, 10.13it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  63%|██████▎   | 1664/2645 [02:40<01:36, 10.13it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  63%|██████▎   | 1666/2645 [02:40<01:35, 10.21it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  63%|██████▎   | 1666/2645 [02:40<01:35, 10.21it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  63%|██████▎   | 1666/2645 [02:41<01:35, 10.21it/s, training_loss=0.181]\u001b[A\n",
      "Epoch 3:  63%|██████▎   | 1668/2645 [02:41<01:35, 10.22it/s, training_loss=0.181]\u001b[A\n",
      "Epoch 3:  63%|██████▎   | 1668/2645 [02:41<01:35, 10.22it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 3:  63%|██████▎   | 1668/2645 [02:41<01:35, 10.22it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  63%|██████▎   | 1670/2645 [02:41<01:36, 10.09it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  63%|██████▎   | 1670/2645 [02:41<01:36, 10.09it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  63%|██████▎   | 1670/2645 [02:41<01:36, 10.09it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  63%|██████▎   | 1672/2645 [02:41<01:35, 10.16it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  63%|██████▎   | 1672/2645 [02:41<01:35, 10.16it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  63%|██████▎   | 1672/2645 [02:41<01:35, 10.16it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  63%|██████▎   | 1674/2645 [02:41<01:35, 10.13it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  63%|██████▎   | 1674/2645 [02:41<01:35, 10.13it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  63%|██████▎   | 1674/2645 [02:41<01:35, 10.13it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  63%|██████▎   | 1676/2645 [02:41<01:35, 10.15it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  63%|██████▎   | 1676/2645 [02:41<01:35, 10.15it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 3:  63%|██████▎   | 1676/2645 [02:42<01:35, 10.15it/s, training_loss=0.048]\u001b[A\n",
      "Epoch 3:  63%|██████▎   | 1678/2645 [02:42<01:35, 10.13it/s, training_loss=0.048]\u001b[A\n",
      "Epoch 3:  63%|██████▎   | 1678/2645 [02:42<01:35, 10.13it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  63%|██████▎   | 1678/2645 [02:42<01:35, 10.13it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  64%|██████▎   | 1680/2645 [02:42<01:35, 10.15it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  64%|██████▎   | 1680/2645 [02:42<01:35, 10.15it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  64%|██████▎   | 1680/2645 [02:42<01:35, 10.15it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  64%|██████▎   | 1682/2645 [02:42<01:36,  9.97it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  64%|██████▎   | 1682/2645 [02:42<01:36,  9.97it/s, training_loss=0.718]\u001b[A\n",
      "Epoch 3:  64%|██████▎   | 1683/2645 [02:42<01:36,  9.98it/s, training_loss=0.718]\u001b[A\n",
      "Epoch 3:  64%|██████▎   | 1683/2645 [02:42<01:36,  9.98it/s, training_loss=0.955]\u001b[A\n",
      "Epoch 3:  64%|██████▎   | 1684/2645 [02:42<01:36,  9.97it/s, training_loss=0.955]\u001b[A\n",
      "Epoch 3:  64%|██████▎   | 1684/2645 [02:42<01:36,  9.97it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  64%|██████▎   | 1684/2645 [02:42<01:36,  9.97it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  64%|██████▎   | 1686/2645 [02:42<01:35, 10.09it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  64%|██████▎   | 1686/2645 [02:42<01:35, 10.09it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  64%|██████▎   | 1686/2645 [02:43<01:35, 10.09it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 3:  64%|██████▍   | 1688/2645 [02:43<01:34, 10.14it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 3:  64%|██████▍   | 1688/2645 [02:43<01:34, 10.14it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  64%|██████▍   | 1688/2645 [02:43<01:34, 10.14it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  64%|██████▍   | 1690/2645 [02:43<01:33, 10.17it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  64%|██████▍   | 1690/2645 [02:43<01:33, 10.17it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  64%|██████▍   | 1690/2645 [02:43<01:33, 10.17it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  64%|██████▍   | 1692/2645 [02:43<01:33, 10.22it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  64%|██████▍   | 1692/2645 [02:43<01:33, 10.22it/s, training_loss=0.193]\u001b[A\n",
      "Epoch 3:  64%|██████▍   | 1692/2645 [02:43<01:33, 10.22it/s, training_loss=0.045]\u001b[A\n",
      "Epoch 3:  64%|██████▍   | 1694/2645 [02:43<01:33, 10.15it/s, training_loss=0.045]\u001b[A\n",
      "Epoch 3:  64%|██████▍   | 1694/2645 [02:43<01:33, 10.15it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  64%|██████▍   | 1694/2645 [02:43<01:33, 10.15it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  64%|██████▍   | 1696/2645 [02:43<01:33, 10.14it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  64%|██████▍   | 1696/2645 [02:43<01:33, 10.14it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  64%|██████▍   | 1696/2645 [02:44<01:33, 10.14it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  64%|██████▍   | 1698/2645 [02:44<01:33, 10.16it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  64%|██████▍   | 1698/2645 [02:44<01:33, 10.16it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  64%|██████▍   | 1698/2645 [02:44<01:33, 10.16it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  64%|██████▍   | 1700/2645 [02:44<01:32, 10.22it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  64%|██████▍   | 1700/2645 [02:44<01:32, 10.22it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  64%|██████▍   | 1700/2645 [02:44<01:32, 10.22it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  64%|██████▍   | 1702/2645 [02:44<01:32, 10.21it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  64%|██████▍   | 1702/2645 [02:44<01:32, 10.21it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  64%|██████▍   | 1702/2645 [02:44<01:32, 10.21it/s, training_loss=0.961]\u001b[A\n",
      "Epoch 3:  64%|██████▍   | 1704/2645 [02:44<01:33, 10.07it/s, training_loss=0.961]\u001b[A\n",
      "Epoch 3:  64%|██████▍   | 1704/2645 [02:44<01:33, 10.07it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  64%|██████▍   | 1704/2645 [02:44<01:33, 10.07it/s, training_loss=0.780]\u001b[A\n",
      "Epoch 3:  64%|██████▍   | 1706/2645 [02:44<01:33, 10.03it/s, training_loss=0.780]\u001b[A\n",
      "Epoch 3:  64%|██████▍   | 1706/2645 [02:44<01:33, 10.03it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  64%|██████▍   | 1706/2645 [02:45<01:33, 10.03it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  65%|██████▍   | 1708/2645 [02:45<01:32, 10.11it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  65%|██████▍   | 1708/2645 [02:45<01:32, 10.11it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  65%|██████▍   | 1708/2645 [02:45<01:32, 10.11it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  65%|██████▍   | 1710/2645 [02:45<01:32, 10.13it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  65%|██████▍   | 1710/2645 [02:45<01:32, 10.13it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  65%|██████▍   | 1710/2645 [02:45<01:32, 10.13it/s, training_loss=0.849]\u001b[A\n",
      "Epoch 3:  65%|██████▍   | 1712/2645 [02:45<01:31, 10.16it/s, training_loss=0.849]\u001b[A\n",
      "Epoch 3:  65%|██████▍   | 1712/2645 [02:45<01:31, 10.16it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  65%|██████▍   | 1712/2645 [02:45<01:31, 10.16it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  65%|██████▍   | 1714/2645 [02:45<01:31, 10.16it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  65%|██████▍   | 1714/2645 [02:45<01:31, 10.16it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  65%|██████▍   | 1714/2645 [02:45<01:31, 10.16it/s, training_loss=0.364]\u001b[A\n",
      "Epoch 3:  65%|██████▍   | 1716/2645 [02:45<01:32, 10.03it/s, training_loss=0.364]\u001b[A\n",
      "Epoch 3:  65%|██████▍   | 1716/2645 [02:45<01:32, 10.03it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  65%|██████▍   | 1716/2645 [02:46<01:32, 10.03it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 3:  65%|██████▍   | 1718/2645 [02:46<01:32, 10.00it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 3:  65%|██████▍   | 1718/2645 [02:46<01:32, 10.00it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  65%|██████▍   | 1718/2645 [02:46<01:32, 10.00it/s, training_loss=0.356]\u001b[A\n",
      "Epoch 3:  65%|██████▌   | 1720/2645 [02:46<01:32,  9.98it/s, training_loss=0.356]\u001b[A\n",
      "Epoch 3:  65%|██████▌   | 1720/2645 [02:46<01:32,  9.98it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  65%|██████▌   | 1720/2645 [02:46<01:32,  9.98it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  65%|██████▌   | 1722/2645 [02:46<01:31, 10.10it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  65%|██████▌   | 1722/2645 [02:46<01:31, 10.10it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  65%|██████▌   | 1722/2645 [02:46<01:31, 10.10it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  65%|██████▌   | 1724/2645 [02:46<01:30, 10.17it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  65%|██████▌   | 1724/2645 [02:46<01:30, 10.17it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  65%|██████▌   | 1724/2645 [02:46<01:30, 10.17it/s, training_loss=0.651]\u001b[A\n",
      "Epoch 3:  65%|██████▌   | 1726/2645 [02:46<01:30, 10.16it/s, training_loss=0.651]\u001b[A\n",
      "Epoch 3:  65%|██████▌   | 1726/2645 [02:46<01:30, 10.16it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  65%|██████▌   | 1726/2645 [02:47<01:30, 10.16it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  65%|██████▌   | 1728/2645 [02:47<01:30, 10.17it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  65%|██████▌   | 1728/2645 [02:47<01:30, 10.17it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  65%|██████▌   | 1728/2645 [02:47<01:30, 10.17it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  65%|██████▌   | 1730/2645 [02:47<01:29, 10.17it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  65%|██████▌   | 1730/2645 [02:47<01:29, 10.17it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  65%|██████▌   | 1730/2645 [02:47<01:29, 10.17it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  65%|██████▌   | 1732/2645 [02:47<01:30, 10.11it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  65%|██████▌   | 1732/2645 [02:47<01:30, 10.11it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  65%|██████▌   | 1732/2645 [02:47<01:30, 10.11it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 3:  66%|██████▌   | 1734/2645 [02:47<01:30, 10.04it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 3:  66%|██████▌   | 1734/2645 [02:47<01:30, 10.04it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  66%|██████▌   | 1734/2645 [02:47<01:30, 10.04it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  66%|██████▌   | 1736/2645 [02:47<01:30, 10.03it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  66%|██████▌   | 1736/2645 [02:47<01:30, 10.03it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  66%|██████▌   | 1736/2645 [02:48<01:30, 10.03it/s, training_loss=1.371]\u001b[A\n",
      "Epoch 3:  66%|██████▌   | 1738/2645 [02:48<01:29, 10.09it/s, training_loss=1.371]\u001b[A\n",
      "Epoch 3:  66%|██████▌   | 1738/2645 [02:48<01:29, 10.09it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  66%|██████▌   | 1738/2645 [02:48<01:29, 10.09it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  66%|██████▌   | 1740/2645 [02:48<01:29, 10.11it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  66%|██████▌   | 1740/2645 [02:48<01:29, 10.11it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  66%|██████▌   | 1740/2645 [02:48<01:29, 10.11it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  66%|██████▌   | 1742/2645 [02:48<01:28, 10.15it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  66%|██████▌   | 1742/2645 [02:48<01:28, 10.15it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  66%|██████▌   | 1742/2645 [02:48<01:28, 10.15it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  66%|██████▌   | 1744/2645 [02:48<01:28, 10.13it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  66%|██████▌   | 1744/2645 [02:48<01:28, 10.13it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 3:  66%|██████▌   | 1744/2645 [02:48<01:28, 10.13it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  66%|██████▌   | 1746/2645 [02:48<01:29, 10.07it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  66%|██████▌   | 1746/2645 [02:48<01:29, 10.07it/s, training_loss=0.014]\u001b[A\n",
      "Epoch 3:  66%|██████▌   | 1746/2645 [02:49<01:29, 10.07it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  66%|██████▌   | 1748/2645 [02:49<01:28, 10.10it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  66%|██████▌   | 1748/2645 [02:49<01:28, 10.10it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  66%|██████▌   | 1748/2645 [02:49<01:28, 10.10it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  66%|██████▌   | 1750/2645 [02:49<01:27, 10.21it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  66%|██████▌   | 1750/2645 [02:49<01:27, 10.21it/s, training_loss=0.463]\u001b[A\n",
      "Epoch 3:  66%|██████▌   | 1750/2645 [02:49<01:27, 10.21it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  66%|██████▌   | 1752/2645 [02:49<01:27, 10.22it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  66%|██████▌   | 1752/2645 [02:49<01:27, 10.22it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  66%|██████▌   | 1752/2645 [02:49<01:27, 10.22it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  66%|██████▋   | 1754/2645 [02:49<01:26, 10.30it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  66%|██████▋   | 1754/2645 [02:49<01:26, 10.30it/s, training_loss=0.662]\u001b[A\n",
      "Epoch 3:  66%|██████▋   | 1754/2645 [02:49<01:26, 10.30it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  66%|██████▋   | 1756/2645 [02:49<01:26, 10.32it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  66%|██████▋   | 1756/2645 [02:49<01:26, 10.32it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  66%|██████▋   | 1756/2645 [02:49<01:26, 10.32it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  66%|██████▋   | 1758/2645 [02:49<01:26, 10.25it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  66%|██████▋   | 1758/2645 [02:50<01:26, 10.25it/s, training_loss=1.001]\u001b[A\n",
      "Epoch 3:  66%|██████▋   | 1758/2645 [02:50<01:26, 10.25it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 3:  67%|██████▋   | 1760/2645 [02:50<01:26, 10.22it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 3:  67%|██████▋   | 1760/2645 [02:50<01:26, 10.22it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  67%|██████▋   | 1760/2645 [02:50<01:26, 10.22it/s, training_loss=0.022]\u001b[A\n",
      "Epoch 3:  67%|██████▋   | 1762/2645 [02:50<01:29,  9.89it/s, training_loss=0.022]\u001b[A\n",
      "Epoch 3:  67%|██████▋   | 1762/2645 [02:50<01:29,  9.89it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  67%|██████▋   | 1762/2645 [02:50<01:29,  9.89it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  67%|██████▋   | 1764/2645 [02:50<01:27, 10.03it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  67%|██████▋   | 1764/2645 [02:50<01:27, 10.03it/s, training_loss=0.056]\u001b[A\n",
      "Epoch 3:  67%|██████▋   | 1764/2645 [02:50<01:27, 10.03it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  67%|██████▋   | 1766/2645 [02:50<01:28,  9.97it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  67%|██████▋   | 1766/2645 [02:50<01:28,  9.97it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 3:  67%|██████▋   | 1767/2645 [02:50<01:28,  9.92it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 3:  67%|██████▋   | 1767/2645 [02:50<01:28,  9.92it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  67%|██████▋   | 1767/2645 [02:51<01:28,  9.92it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  67%|██████▋   | 1769/2645 [02:51<01:27, 10.05it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  67%|██████▋   | 1769/2645 [02:51<01:27, 10.05it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  67%|██████▋   | 1769/2645 [02:51<01:27, 10.05it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  67%|██████▋   | 1771/2645 [02:51<01:26, 10.09it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  67%|██████▋   | 1771/2645 [02:51<01:26, 10.09it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  67%|██████▋   | 1771/2645 [02:51<01:26, 10.09it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  67%|██████▋   | 1773/2645 [02:51<01:26, 10.14it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  67%|██████▋   | 1773/2645 [02:51<01:26, 10.14it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  67%|██████▋   | 1773/2645 [02:51<01:26, 10.14it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  67%|██████▋   | 1775/2645 [02:51<01:27,  9.89it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  67%|██████▋   | 1775/2645 [02:51<01:27,  9.89it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  67%|██████▋   | 1776/2645 [02:51<01:30,  9.64it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  67%|██████▋   | 1776/2645 [02:51<01:30,  9.64it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  67%|██████▋   | 1777/2645 [02:51<01:31,  9.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  67%|██████▋   | 1777/2645 [02:52<01:31,  9.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  67%|██████▋   | 1778/2645 [02:52<01:33,  9.29it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  67%|██████▋   | 1778/2645 [02:52<01:33,  9.29it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  67%|██████▋   | 1779/2645 [02:52<01:32,  9.32it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  67%|██████▋   | 1779/2645 [02:52<01:32,  9.32it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  67%|██████▋   | 1780/2645 [02:52<01:33,  9.30it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  67%|██████▋   | 1780/2645 [02:52<01:33,  9.30it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  67%|██████▋   | 1780/2645 [02:52<01:33,  9.30it/s, training_loss=0.804]\u001b[A\n",
      "Epoch 3:  67%|██████▋   | 1782/2645 [02:52<01:30,  9.51it/s, training_loss=0.804]\u001b[A\n",
      "Epoch 3:  67%|██████▋   | 1782/2645 [02:52<01:30,  9.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  67%|██████▋   | 1782/2645 [02:52<01:30,  9.51it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 3:  67%|██████▋   | 1784/2645 [02:52<01:29,  9.60it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 3:  67%|██████▋   | 1784/2645 [02:52<01:29,  9.60it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  67%|██████▋   | 1784/2645 [02:52<01:29,  9.60it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  68%|██████▊   | 1786/2645 [02:52<01:31,  9.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  68%|██████▊   | 1786/2645 [02:52<01:31,  9.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  68%|██████▊   | 1787/2645 [02:52<01:30,  9.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  68%|██████▊   | 1787/2645 [02:53<01:30,  9.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  68%|██████▊   | 1788/2645 [02:53<01:30,  9.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  68%|██████▊   | 1788/2645 [02:53<01:30,  9.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  68%|██████▊   | 1789/2645 [02:53<01:31,  9.34it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  68%|██████▊   | 1789/2645 [02:53<01:31,  9.34it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  68%|██████▊   | 1789/2645 [02:53<01:31,  9.34it/s, training_loss=0.012]\u001b[A\n",
      "Epoch 3:  68%|██████▊   | 1791/2645 [02:53<01:28,  9.63it/s, training_loss=0.012]\u001b[A\n",
      "Epoch 3:  68%|██████▊   | 1791/2645 [02:53<01:28,  9.63it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  68%|██████▊   | 1792/2645 [02:53<01:28,  9.69it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  68%|██████▊   | 1792/2645 [02:53<01:28,  9.69it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  68%|██████▊   | 1792/2645 [02:53<01:28,  9.69it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  68%|██████▊   | 1794/2645 [02:53<01:27,  9.78it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  68%|██████▊   | 1794/2645 [02:53<01:27,  9.78it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  68%|██████▊   | 1795/2645 [02:53<01:27,  9.74it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  68%|██████▊   | 1795/2645 [02:53<01:27,  9.74it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  68%|██████▊   | 1795/2645 [02:53<01:27,  9.74it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  68%|██████▊   | 1797/2645 [02:53<01:26,  9.83it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  68%|██████▊   | 1797/2645 [02:54<01:26,  9.83it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  68%|██████▊   | 1797/2645 [02:54<01:26,  9.83it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  68%|██████▊   | 1799/2645 [02:54<01:24,  9.99it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  68%|██████▊   | 1799/2645 [02:54<01:24,  9.99it/s, training_loss=0.727]\u001b[A\n",
      "Epoch 3:  68%|██████▊   | 1800/2645 [02:54<01:24,  9.97it/s, training_loss=0.727]\u001b[A\n",
      "Epoch 3:  68%|██████▊   | 1800/2645 [02:54<01:24,  9.97it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  68%|██████▊   | 1800/2645 [02:54<01:24,  9.97it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  68%|██████▊   | 1802/2645 [02:54<01:25,  9.88it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  68%|██████▊   | 1802/2645 [02:54<01:25,  9.88it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  68%|██████▊   | 1802/2645 [02:54<01:25,  9.88it/s, training_loss=0.265]\u001b[A\n",
      "Epoch 3:  68%|██████▊   | 1804/2645 [02:54<01:24, 10.01it/s, training_loss=0.265]\u001b[A\n",
      "Epoch 3:  68%|██████▊   | 1804/2645 [02:54<01:24, 10.01it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  68%|██████▊   | 1804/2645 [02:54<01:24, 10.01it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  68%|██████▊   | 1806/2645 [02:54<01:22, 10.12it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  68%|██████▊   | 1806/2645 [02:54<01:22, 10.12it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  68%|██████▊   | 1806/2645 [02:55<01:22, 10.12it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  68%|██████▊   | 1808/2645 [02:55<01:23, 10.04it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  68%|██████▊   | 1808/2645 [02:55<01:23, 10.04it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  68%|██████▊   | 1808/2645 [02:55<01:23, 10.04it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  68%|██████▊   | 1810/2645 [02:55<01:22, 10.17it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  68%|██████▊   | 1810/2645 [02:55<01:22, 10.17it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  68%|██████▊   | 1810/2645 [02:55<01:22, 10.17it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  69%|██████▊   | 1812/2645 [02:55<01:21, 10.27it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  69%|██████▊   | 1812/2645 [02:55<01:21, 10.27it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  69%|██████▊   | 1812/2645 [02:55<01:21, 10.27it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 3:  69%|██████▊   | 1814/2645 [02:55<01:22, 10.04it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 3:  69%|██████▊   | 1814/2645 [02:55<01:22, 10.04it/s, training_loss=0.985]\u001b[A\n",
      "Epoch 3:  69%|██████▊   | 1814/2645 [02:55<01:22, 10.04it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  69%|██████▊   | 1816/2645 [02:55<01:23,  9.90it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  69%|██████▊   | 1816/2645 [02:55<01:23,  9.90it/s, training_loss=0.154]\u001b[A\n",
      "Epoch 3:  69%|██████▊   | 1817/2645 [02:55<01:24,  9.84it/s, training_loss=0.154]\u001b[A\n",
      "Epoch 3:  69%|██████▊   | 1817/2645 [02:56<01:24,  9.84it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  69%|██████▊   | 1818/2645 [02:56<01:28,  9.30it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  69%|██████▊   | 1818/2645 [02:56<01:28,  9.30it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  69%|██████▉   | 1819/2645 [02:56<01:31,  8.99it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  69%|██████▉   | 1819/2645 [02:56<01:31,  8.99it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  69%|██████▉   | 1820/2645 [02:56<01:29,  9.24it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  69%|██████▉   | 1820/2645 [02:56<01:29,  9.24it/s, training_loss=0.391]\u001b[A\n",
      "Epoch 3:  69%|██████▉   | 1820/2645 [02:56<01:29,  9.24it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  69%|██████▉   | 1822/2645 [02:56<01:27,  9.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  69%|██████▉   | 1822/2645 [02:56<01:27,  9.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  69%|██████▉   | 1823/2645 [02:56<01:25,  9.58it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  69%|██████▉   | 1823/2645 [02:56<01:25,  9.58it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  69%|██████▉   | 1824/2645 [02:56<01:24,  9.68it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  69%|██████▉   | 1824/2645 [02:56<01:24,  9.68it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  69%|██████▉   | 1825/2645 [02:56<01:24,  9.73it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  69%|██████▉   | 1825/2645 [02:56<01:24,  9.73it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  69%|██████▉   | 1826/2645 [02:56<01:23,  9.79it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  69%|██████▉   | 1826/2645 [02:57<01:23,  9.79it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  69%|██████▉   | 1827/2645 [02:57<01:23,  9.78it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  69%|██████▉   | 1827/2645 [02:57<01:23,  9.78it/s, training_loss=0.058]\u001b[A\n",
      "Epoch 3:  69%|██████▉   | 1828/2645 [02:57<01:23,  9.76it/s, training_loss=0.058]\u001b[A\n",
      "Epoch 3:  69%|██████▉   | 1828/2645 [02:57<01:23,  9.76it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  69%|██████▉   | 1829/2645 [02:57<01:23,  9.79it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  69%|██████▉   | 1829/2645 [02:57<01:23,  9.79it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  69%|██████▉   | 1830/2645 [02:57<01:22,  9.84it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  69%|██████▉   | 1830/2645 [02:57<01:22,  9.84it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  69%|██████▉   | 1831/2645 [02:57<01:22,  9.87it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  69%|██████▉   | 1831/2645 [02:57<01:22,  9.87it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  69%|██████▉   | 1832/2645 [02:57<01:22,  9.88it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  69%|██████▉   | 1832/2645 [02:57<01:22,  9.88it/s, training_loss=0.018]\u001b[A\n",
      "Epoch 3:  69%|██████▉   | 1833/2645 [02:57<01:22,  9.84it/s, training_loss=0.018]\u001b[A\n",
      "Epoch 3:  69%|██████▉   | 1833/2645 [02:57<01:22,  9.84it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  69%|██████▉   | 1834/2645 [02:57<01:23,  9.76it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  69%|██████▉   | 1834/2645 [02:57<01:23,  9.76it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  69%|██████▉   | 1835/2645 [02:57<01:22,  9.82it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  69%|██████▉   | 1835/2645 [02:57<01:22,  9.82it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  69%|██████▉   | 1836/2645 [02:57<01:22,  9.79it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  69%|██████▉   | 1836/2645 [02:58<01:22,  9.79it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  69%|██████▉   | 1837/2645 [02:58<01:22,  9.84it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  69%|██████▉   | 1837/2645 [02:58<01:22,  9.84it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  69%|██████▉   | 1838/2645 [02:58<01:22,  9.80it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  69%|██████▉   | 1838/2645 [02:58<01:22,  9.80it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  70%|██████▉   | 1839/2645 [02:58<01:24,  9.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  70%|██████▉   | 1839/2645 [02:58<01:24,  9.50it/s, training_loss=0.770]\u001b[A\n",
      "Epoch 3:  70%|██████▉   | 1840/2645 [02:58<01:23,  9.62it/s, training_loss=0.770]\u001b[A\n",
      "Epoch 3:  70%|██████▉   | 1840/2645 [02:58<01:23,  9.62it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  70%|██████▉   | 1840/2645 [02:58<01:23,  9.62it/s, training_loss=0.467]\u001b[A\n",
      "Epoch 3:  70%|██████▉   | 1842/2645 [02:58<01:21,  9.83it/s, training_loss=0.467]\u001b[A\n",
      "Epoch 3:  70%|██████▉   | 1842/2645 [02:58<01:21,  9.83it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  70%|██████▉   | 1842/2645 [02:58<01:21,  9.83it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  70%|██████▉   | 1844/2645 [02:58<01:19, 10.04it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  70%|██████▉   | 1844/2645 [02:58<01:19, 10.04it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  70%|██████▉   | 1844/2645 [02:58<01:19, 10.04it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  70%|██████▉   | 1846/2645 [02:58<01:18, 10.20it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  70%|██████▉   | 1846/2645 [02:59<01:18, 10.20it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  70%|██████▉   | 1846/2645 [02:59<01:18, 10.20it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  70%|██████▉   | 1848/2645 [02:59<01:17, 10.30it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  70%|██████▉   | 1848/2645 [02:59<01:17, 10.30it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  70%|██████▉   | 1848/2645 [02:59<01:17, 10.30it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  70%|██████▉   | 1850/2645 [02:59<01:17, 10.31it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  70%|██████▉   | 1850/2645 [02:59<01:17, 10.31it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  70%|██████▉   | 1850/2645 [02:59<01:17, 10.31it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  70%|███████   | 1852/2645 [02:59<01:16, 10.39it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  70%|███████   | 1852/2645 [02:59<01:16, 10.39it/s, training_loss=0.756]\u001b[A\n",
      "Epoch 3:  70%|███████   | 1852/2645 [02:59<01:16, 10.39it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  70%|███████   | 1854/2645 [02:59<01:16, 10.39it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  70%|███████   | 1854/2645 [02:59<01:16, 10.39it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  70%|███████   | 1854/2645 [02:59<01:16, 10.39it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  70%|███████   | 1856/2645 [02:59<01:16, 10.28it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  70%|███████   | 1856/2645 [02:59<01:16, 10.28it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  70%|███████   | 1856/2645 [03:00<01:16, 10.28it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  70%|███████   | 1858/2645 [03:00<01:16, 10.34it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  70%|███████   | 1858/2645 [03:00<01:16, 10.34it/s, training_loss=0.018]\u001b[A\n",
      "Epoch 3:  70%|███████   | 1858/2645 [03:00<01:16, 10.34it/s, training_loss=0.389]\u001b[A\n",
      "Epoch 3:  70%|███████   | 1860/2645 [03:00<01:15, 10.35it/s, training_loss=0.389]\u001b[A\n",
      "Epoch 3:  70%|███████   | 1860/2645 [03:00<01:15, 10.35it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  70%|███████   | 1860/2645 [03:00<01:15, 10.35it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  70%|███████   | 1862/2645 [03:00<01:15, 10.39it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  70%|███████   | 1862/2645 [03:00<01:15, 10.39it/s, training_loss=0.545]\u001b[A\n",
      "Epoch 3:  70%|███████   | 1862/2645 [03:00<01:15, 10.39it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  70%|███████   | 1864/2645 [03:00<01:14, 10.42it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  70%|███████   | 1864/2645 [03:00<01:14, 10.42it/s, training_loss=0.329]\u001b[A\n",
      "Epoch 3:  70%|███████   | 1864/2645 [03:00<01:14, 10.42it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  71%|███████   | 1866/2645 [03:00<01:15, 10.37it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  71%|███████   | 1866/2645 [03:00<01:15, 10.37it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  71%|███████   | 1866/2645 [03:01<01:15, 10.37it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  71%|███████   | 1868/2645 [03:01<01:14, 10.39it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  71%|███████   | 1868/2645 [03:01<01:14, 10.39it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  71%|███████   | 1868/2645 [03:01<01:14, 10.39it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  71%|███████   | 1870/2645 [03:01<01:14, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  71%|███████   | 1870/2645 [03:01<01:14, 10.45it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  71%|███████   | 1870/2645 [03:01<01:14, 10.45it/s, training_loss=0.384]\u001b[A\n",
      "Epoch 3:  71%|███████   | 1872/2645 [03:01<01:14, 10.41it/s, training_loss=0.384]\u001b[A\n",
      "Epoch 3:  71%|███████   | 1872/2645 [03:01<01:14, 10.41it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  71%|███████   | 1872/2645 [03:01<01:14, 10.41it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  71%|███████   | 1874/2645 [03:01<01:13, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  71%|███████   | 1874/2645 [03:01<01:13, 10.43it/s, training_loss=0.152]\u001b[A\n",
      "Epoch 3:  71%|███████   | 1874/2645 [03:01<01:13, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  71%|███████   | 1876/2645 [03:01<01:13, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  71%|███████   | 1876/2645 [03:01<01:13, 10.44it/s, training_loss=0.348]\u001b[A\n",
      "Epoch 3:  71%|███████   | 1876/2645 [03:01<01:13, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  71%|███████   | 1878/2645 [03:01<01:13, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  71%|███████   | 1878/2645 [03:02<01:13, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  71%|███████   | 1878/2645 [03:02<01:13, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  71%|███████   | 1880/2645 [03:02<01:13, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  71%|███████   | 1880/2645 [03:02<01:13, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  71%|███████   | 1880/2645 [03:02<01:13, 10.45it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 3:  71%|███████   | 1882/2645 [03:02<01:12, 10.47it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 3:  71%|███████   | 1882/2645 [03:02<01:12, 10.47it/s, training_loss=0.461]\u001b[A\n",
      "Epoch 3:  71%|███████   | 1882/2645 [03:02<01:12, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  71%|███████   | 1884/2645 [03:02<01:12, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  71%|███████   | 1884/2645 [03:02<01:12, 10.45it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  71%|███████   | 1884/2645 [03:02<01:12, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  71%|███████▏  | 1886/2645 [03:02<01:12, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  71%|███████▏  | 1886/2645 [03:02<01:12, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  71%|███████▏  | 1886/2645 [03:02<01:12, 10.45it/s, training_loss=0.030]\u001b[A\n",
      "Epoch 3:  71%|███████▏  | 1888/2645 [03:02<01:12, 10.45it/s, training_loss=0.030]\u001b[A\n",
      "Epoch 3:  71%|███████▏  | 1888/2645 [03:03<01:12, 10.45it/s, training_loss=0.645]\u001b[A\n",
      "Epoch 3:  71%|███████▏  | 1888/2645 [03:03<01:12, 10.45it/s, training_loss=0.380]\u001b[A\n",
      "Epoch 3:  71%|███████▏  | 1890/2645 [03:03<01:12, 10.37it/s, training_loss=0.380]\u001b[A\n",
      "Epoch 3:  71%|███████▏  | 1890/2645 [03:03<01:12, 10.37it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  71%|███████▏  | 1890/2645 [03:03<01:12, 10.37it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  72%|███████▏  | 1892/2645 [03:03<01:12, 10.35it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  72%|███████▏  | 1892/2645 [03:03<01:12, 10.35it/s, training_loss=0.030]\u001b[A\n",
      "Epoch 3:  72%|███████▏  | 1892/2645 [03:03<01:12, 10.35it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  72%|███████▏  | 1894/2645 [03:03<01:12, 10.39it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  72%|███████▏  | 1894/2645 [03:03<01:12, 10.39it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  72%|███████▏  | 1894/2645 [03:03<01:12, 10.39it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  72%|███████▏  | 1896/2645 [03:03<01:11, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  72%|███████▏  | 1896/2645 [03:03<01:11, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  72%|███████▏  | 1896/2645 [03:03<01:11, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  72%|███████▏  | 1898/2645 [03:03<01:11, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  72%|███████▏  | 1898/2645 [03:03<01:11, 10.48it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  72%|███████▏  | 1898/2645 [03:04<01:11, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  72%|███████▏  | 1900/2645 [03:04<01:11, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  72%|███████▏  | 1900/2645 [03:04<01:11, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  72%|███████▏  | 1900/2645 [03:04<01:11, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  72%|███████▏  | 1902/2645 [03:04<01:10, 10.53it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  72%|███████▏  | 1902/2645 [03:04<01:10, 10.53it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  72%|███████▏  | 1902/2645 [03:04<01:10, 10.53it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  72%|███████▏  | 1904/2645 [03:04<01:10, 10.48it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  72%|███████▏  | 1904/2645 [03:04<01:10, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  72%|███████▏  | 1904/2645 [03:04<01:10, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  72%|███████▏  | 1906/2645 [03:04<01:10, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  72%|███████▏  | 1906/2645 [03:04<01:10, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  72%|███████▏  | 1906/2645 [03:04<01:10, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  72%|███████▏  | 1908/2645 [03:04<01:10, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  72%|███████▏  | 1908/2645 [03:04<01:10, 10.51it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  72%|███████▏  | 1908/2645 [03:05<01:10, 10.51it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 3:  72%|███████▏  | 1910/2645 [03:05<01:10, 10.47it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 3:  72%|███████▏  | 1910/2645 [03:05<01:10, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  72%|███████▏  | 1910/2645 [03:05<01:10, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  72%|███████▏  | 1912/2645 [03:05<01:10, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  72%|███████▏  | 1912/2645 [03:05<01:10, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  72%|███████▏  | 1912/2645 [03:05<01:10, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  72%|███████▏  | 1914/2645 [03:05<01:09, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  72%|███████▏  | 1914/2645 [03:05<01:09, 10.50it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  72%|███████▏  | 1914/2645 [03:05<01:09, 10.50it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  72%|███████▏  | 1916/2645 [03:05<01:09, 10.48it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  72%|███████▏  | 1916/2645 [03:05<01:09, 10.48it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  72%|███████▏  | 1916/2645 [03:05<01:09, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  73%|███████▎  | 1918/2645 [03:05<01:09, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  73%|███████▎  | 1918/2645 [03:05<01:09, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  73%|███████▎  | 1918/2645 [03:05<01:09, 10.46it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  73%|███████▎  | 1920/2645 [03:06<01:09, 10.48it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  73%|███████▎  | 1920/2645 [03:06<01:09, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  73%|███████▎  | 1920/2645 [03:06<01:09, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  73%|███████▎  | 1922/2645 [03:06<01:09, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  73%|███████▎  | 1922/2645 [03:06<01:09, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  73%|███████▎  | 1922/2645 [03:06<01:09, 10.43it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  73%|███████▎  | 1924/2645 [03:06<01:10, 10.28it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  73%|███████▎  | 1924/2645 [03:06<01:10, 10.28it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  73%|███████▎  | 1924/2645 [03:06<01:10, 10.28it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  73%|███████▎  | 1926/2645 [03:06<01:10, 10.15it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  73%|███████▎  | 1926/2645 [03:06<01:10, 10.15it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  73%|███████▎  | 1926/2645 [03:06<01:10, 10.15it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  73%|███████▎  | 1928/2645 [03:06<01:10, 10.16it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  73%|███████▎  | 1928/2645 [03:06<01:10, 10.16it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  73%|███████▎  | 1928/2645 [03:06<01:10, 10.16it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  73%|███████▎  | 1930/2645 [03:06<01:09, 10.26it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  73%|███████▎  | 1930/2645 [03:07<01:09, 10.26it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  73%|███████▎  | 1930/2645 [03:07<01:09, 10.26it/s, training_loss=0.290]\u001b[A\n",
      "Epoch 3:  73%|███████▎  | 1932/2645 [03:07<01:09, 10.32it/s, training_loss=0.290]\u001b[A\n",
      "Epoch 3:  73%|███████▎  | 1932/2645 [03:07<01:09, 10.32it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  73%|███████▎  | 1932/2645 [03:07<01:09, 10.32it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  73%|███████▎  | 1934/2645 [03:07<01:08, 10.39it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  73%|███████▎  | 1934/2645 [03:07<01:08, 10.39it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  73%|███████▎  | 1934/2645 [03:07<01:08, 10.39it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  73%|███████▎  | 1936/2645 [03:07<01:07, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  73%|███████▎  | 1936/2645 [03:07<01:07, 10.46it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  73%|███████▎  | 1936/2645 [03:07<01:07, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  73%|███████▎  | 1938/2645 [03:07<01:07, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  73%|███████▎  | 1938/2645 [03:07<01:07, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  73%|███████▎  | 1938/2645 [03:07<01:07, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  73%|███████▎  | 1940/2645 [03:07<01:07, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  73%|███████▎  | 1940/2645 [03:08<01:07, 10.44it/s, training_loss=0.174]\u001b[A\n",
      "Epoch 3:  73%|███████▎  | 1940/2645 [03:08<01:07, 10.44it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  73%|███████▎  | 1942/2645 [03:08<01:07, 10.41it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  73%|███████▎  | 1942/2645 [03:08<01:07, 10.41it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  73%|███████▎  | 1942/2645 [03:08<01:07, 10.41it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  73%|███████▎  | 1944/2645 [03:08<01:07, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  73%|███████▎  | 1944/2645 [03:08<01:07, 10.45it/s, training_loss=0.911]\u001b[A\n",
      "Epoch 3:  73%|███████▎  | 1944/2645 [03:08<01:07, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  74%|███████▎  | 1946/2645 [03:08<01:06, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  74%|███████▎  | 1946/2645 [03:08<01:06, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  74%|███████▎  | 1946/2645 [03:08<01:06, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  74%|███████▎  | 1948/2645 [03:08<01:06, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  74%|███████▎  | 1948/2645 [03:08<01:06, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  74%|███████▎  | 1948/2645 [03:08<01:06, 10.48it/s, training_loss=0.155]\u001b[A\n",
      "Epoch 3:  74%|███████▎  | 1950/2645 [03:08<01:06, 10.48it/s, training_loss=0.155]\u001b[A\n",
      "Epoch 3:  74%|███████▎  | 1950/2645 [03:08<01:06, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  74%|███████▎  | 1950/2645 [03:09<01:06, 10.48it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  74%|███████▍  | 1952/2645 [03:09<01:06, 10.36it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  74%|███████▍  | 1952/2645 [03:09<01:06, 10.36it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  74%|███████▍  | 1952/2645 [03:09<01:06, 10.36it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  74%|███████▍  | 1954/2645 [03:09<01:06, 10.37it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  74%|███████▍  | 1954/2645 [03:09<01:06, 10.37it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  74%|███████▍  | 1954/2645 [03:09<01:06, 10.37it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  74%|███████▍  | 1956/2645 [03:09<01:06, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  74%|███████▍  | 1956/2645 [03:09<01:06, 10.43it/s, training_loss=0.172]\u001b[A\n",
      "Epoch 3:  74%|███████▍  | 1956/2645 [03:09<01:06, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  74%|███████▍  | 1958/2645 [03:09<01:05, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  74%|███████▍  | 1958/2645 [03:09<01:05, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  74%|███████▍  | 1958/2645 [03:09<01:05, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  74%|███████▍  | 1960/2645 [03:09<01:05, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  74%|███████▍  | 1960/2645 [03:09<01:05, 10.48it/s, training_loss=0.249]\u001b[A\n",
      "Epoch 3:  74%|███████▍  | 1960/2645 [03:10<01:05, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  74%|███████▍  | 1962/2645 [03:10<01:05, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  74%|███████▍  | 1962/2645 [03:10<01:05, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  74%|███████▍  | 1962/2645 [03:10<01:05, 10.48it/s, training_loss=0.034]\u001b[A\n",
      "Epoch 3:  74%|███████▍  | 1964/2645 [03:10<01:04, 10.48it/s, training_loss=0.034]\u001b[A\n",
      "Epoch 3:  74%|███████▍  | 1964/2645 [03:10<01:04, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  74%|███████▍  | 1964/2645 [03:10<01:04, 10.48it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  74%|███████▍  | 1966/2645 [03:10<01:04, 10.50it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  74%|███████▍  | 1966/2645 [03:10<01:04, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  74%|███████▍  | 1966/2645 [03:10<01:04, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  74%|███████▍  | 1968/2645 [03:10<01:04, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  74%|███████▍  | 1968/2645 [03:10<01:04, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  74%|███████▍  | 1968/2645 [03:10<01:04, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  74%|███████▍  | 1970/2645 [03:10<01:04, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  74%|███████▍  | 1970/2645 [03:10<01:04, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  74%|███████▍  | 1970/2645 [03:10<01:04, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  75%|███████▍  | 1972/2645 [03:10<01:04, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  75%|███████▍  | 1972/2645 [03:11<01:04, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  75%|███████▍  | 1972/2645 [03:11<01:04, 10.48it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 3:  75%|███████▍  | 1974/2645 [03:11<01:04, 10.35it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 3:  75%|███████▍  | 1974/2645 [03:11<01:04, 10.35it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  75%|███████▍  | 1974/2645 [03:11<01:04, 10.35it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  75%|███████▍  | 1976/2645 [03:11<01:04, 10.41it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  75%|███████▍  | 1976/2645 [03:11<01:04, 10.41it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  75%|███████▍  | 1976/2645 [03:11<01:04, 10.41it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  75%|███████▍  | 1978/2645 [03:11<01:03, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  75%|███████▍  | 1978/2645 [03:11<01:03, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  75%|███████▍  | 1978/2645 [03:11<01:03, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  75%|███████▍  | 1980/2645 [03:11<01:03, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  75%|███████▍  | 1980/2645 [03:11<01:03, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  75%|███████▍  | 1980/2645 [03:11<01:03, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  75%|███████▍  | 1982/2645 [03:11<01:03, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  75%|███████▍  | 1982/2645 [03:12<01:03, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  75%|███████▍  | 1982/2645 [03:12<01:03, 10.52it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  75%|███████▌  | 1984/2645 [03:12<01:02, 10.50it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  75%|███████▌  | 1984/2645 [03:12<01:02, 10.50it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  75%|███████▌  | 1984/2645 [03:12<01:02, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  75%|███████▌  | 1986/2645 [03:12<01:03, 10.34it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  75%|███████▌  | 1986/2645 [03:12<01:03, 10.34it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  75%|███████▌  | 1986/2645 [03:12<01:03, 10.34it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  75%|███████▌  | 1988/2645 [03:12<01:03, 10.27it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  75%|███████▌  | 1988/2645 [03:12<01:03, 10.27it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  75%|███████▌  | 1988/2645 [03:12<01:03, 10.27it/s, training_loss=0.075]\u001b[A\n",
      "Epoch 3:  75%|███████▌  | 1990/2645 [03:12<01:04, 10.23it/s, training_loss=0.075]\u001b[A\n",
      "Epoch 3:  75%|███████▌  | 1990/2645 [03:12<01:04, 10.23it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  75%|███████▌  | 1990/2645 [03:12<01:04, 10.23it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  75%|███████▌  | 1992/2645 [03:12<01:03, 10.30it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  75%|███████▌  | 1992/2645 [03:13<01:03, 10.30it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  75%|███████▌  | 1992/2645 [03:13<01:03, 10.30it/s, training_loss=0.564]\u001b[A\n",
      "Epoch 3:  75%|███████▌  | 1994/2645 [03:13<01:03, 10.30it/s, training_loss=0.564]\u001b[A\n",
      "Epoch 3:  75%|███████▌  | 1994/2645 [03:13<01:03, 10.30it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  75%|███████▌  | 1994/2645 [03:13<01:03, 10.30it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  75%|███████▌  | 1996/2645 [03:13<01:02, 10.37it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  75%|███████▌  | 1996/2645 [03:13<01:02, 10.37it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  75%|███████▌  | 1996/2645 [03:13<01:02, 10.37it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  76%|███████▌  | 1998/2645 [03:13<01:02, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  76%|███████▌  | 1998/2645 [03:13<01:02, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  76%|███████▌  | 1998/2645 [03:13<01:02, 10.43it/s, training_loss=0.012]\u001b[A\n",
      "Epoch 3:  76%|███████▌  | 2000/2645 [03:13<01:01, 10.43it/s, training_loss=0.012]\u001b[A\n",
      "Epoch 3:  76%|███████▌  | 2000/2645 [03:13<01:01, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  76%|███████▌  | 2000/2645 [03:13<01:01, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  76%|███████▌  | 2002/2645 [03:13<01:01, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  76%|███████▌  | 2002/2645 [03:13<01:01, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  76%|███████▌  | 2002/2645 [03:14<01:01, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  76%|███████▌  | 2004/2645 [03:14<01:01, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  76%|███████▌  | 2004/2645 [03:14<01:01, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  76%|███████▌  | 2004/2645 [03:14<01:01, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  76%|███████▌  | 2006/2645 [03:14<01:00, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  76%|███████▌  | 2006/2645 [03:14<01:00, 10.51it/s, training_loss=0.771]\u001b[A\n",
      "Epoch 3:  76%|███████▌  | 2006/2645 [03:14<01:00, 10.51it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  76%|███████▌  | 2008/2645 [03:14<01:01, 10.39it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  76%|███████▌  | 2008/2645 [03:14<01:01, 10.39it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  76%|███████▌  | 2008/2645 [03:14<01:01, 10.39it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 3:  76%|███████▌  | 2010/2645 [03:14<01:01, 10.38it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 3:  76%|███████▌  | 2010/2645 [03:14<01:01, 10.38it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  76%|███████▌  | 2010/2645 [03:14<01:01, 10.38it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  76%|███████▌  | 2012/2645 [03:14<01:00, 10.42it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  76%|███████▌  | 2012/2645 [03:14<01:00, 10.42it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  76%|███████▌  | 2012/2645 [03:15<01:00, 10.42it/s, training_loss=0.730]\u001b[A\n",
      "Epoch 3:  76%|███████▌  | 2014/2645 [03:15<01:00, 10.39it/s, training_loss=0.730]\u001b[A\n",
      "Epoch 3:  76%|███████▌  | 2014/2645 [03:15<01:00, 10.39it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  76%|███████▌  | 2014/2645 [03:15<01:00, 10.39it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  76%|███████▌  | 2016/2645 [03:15<01:00, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  76%|███████▌  | 2016/2645 [03:15<01:00, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  76%|███████▌  | 2016/2645 [03:15<01:00, 10.44it/s, training_loss=0.206]\u001b[A\n",
      "Epoch 3:  76%|███████▋  | 2018/2645 [03:15<00:59, 10.46it/s, training_loss=0.206]\u001b[A\n",
      "Epoch 3:  76%|███████▋  | 2018/2645 [03:15<00:59, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  76%|███████▋  | 2018/2645 [03:15<00:59, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  76%|███████▋  | 2020/2645 [03:15<00:59, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  76%|███████▋  | 2020/2645 [03:15<00:59, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  76%|███████▋  | 2020/2645 [03:15<00:59, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  76%|███████▋  | 2022/2645 [03:15<00:59, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  76%|███████▋  | 2022/2645 [03:15<00:59, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  76%|███████▋  | 2022/2645 [03:15<00:59, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  77%|███████▋  | 2024/2645 [03:15<00:58, 10.54it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  77%|███████▋  | 2024/2645 [03:16<00:58, 10.54it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  77%|███████▋  | 2024/2645 [03:16<00:58, 10.54it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  77%|███████▋  | 2026/2645 [03:16<00:58, 10.53it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  77%|███████▋  | 2026/2645 [03:16<00:58, 10.53it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  77%|███████▋  | 2026/2645 [03:16<00:58, 10.53it/s, training_loss=0.853]\u001b[A\n",
      "Epoch 3:  77%|███████▋  | 2028/2645 [03:16<00:58, 10.47it/s, training_loss=0.853]\u001b[A\n",
      "Epoch 3:  77%|███████▋  | 2028/2645 [03:16<00:58, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  77%|███████▋  | 2028/2645 [03:16<00:58, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  77%|███████▋  | 2030/2645 [03:16<00:58, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  77%|███████▋  | 2030/2645 [03:16<00:58, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  77%|███████▋  | 2030/2645 [03:16<00:58, 10.48it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  77%|███████▋  | 2032/2645 [03:16<00:58, 10.49it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  77%|███████▋  | 2032/2645 [03:16<00:58, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  77%|███████▋  | 2032/2645 [03:16<00:58, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  77%|███████▋  | 2034/2645 [03:16<00:58, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  77%|███████▋  | 2034/2645 [03:17<00:58, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  77%|███████▋  | 2034/2645 [03:17<00:58, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  77%|███████▋  | 2036/2645 [03:17<00:57, 10.54it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  77%|███████▋  | 2036/2645 [03:17<00:57, 10.54it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  77%|███████▋  | 2036/2645 [03:17<00:57, 10.54it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 3:  77%|███████▋  | 2038/2645 [03:17<00:57, 10.53it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 3:  77%|███████▋  | 2038/2645 [03:17<00:57, 10.53it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  77%|███████▋  | 2038/2645 [03:17<00:57, 10.53it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  77%|███████▋  | 2040/2645 [03:17<00:57, 10.54it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  77%|███████▋  | 2040/2645 [03:17<00:57, 10.54it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  77%|███████▋  | 2040/2645 [03:17<00:57, 10.54it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  77%|███████▋  | 2042/2645 [03:17<00:57, 10.55it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  77%|███████▋  | 2042/2645 [03:17<00:57, 10.55it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  77%|███████▋  | 2042/2645 [03:17<00:57, 10.55it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  77%|███████▋  | 2044/2645 [03:17<00:56, 10.56it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  77%|███████▋  | 2044/2645 [03:17<00:56, 10.56it/s, training_loss=0.838]\u001b[A\n",
      "Epoch 3:  77%|███████▋  | 2044/2645 [03:18<00:56, 10.56it/s, training_loss=0.374]\u001b[A\n",
      "Epoch 3:  77%|███████▋  | 2046/2645 [03:18<00:57, 10.50it/s, training_loss=0.374]\u001b[A\n",
      "Epoch 3:  77%|███████▋  | 2046/2645 [03:18<00:57, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  77%|███████▋  | 2046/2645 [03:18<00:57, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  77%|███████▋  | 2048/2645 [03:18<00:56, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  77%|███████▋  | 2048/2645 [03:18<00:56, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  77%|███████▋  | 2048/2645 [03:18<00:56, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  78%|███████▊  | 2050/2645 [03:18<00:56, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  78%|███████▊  | 2050/2645 [03:18<00:56, 10.46it/s, training_loss=0.043]\u001b[A\n",
      "Epoch 3:  78%|███████▊  | 2050/2645 [03:18<00:56, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  78%|███████▊  | 2052/2645 [03:18<00:56, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  78%|███████▊  | 2052/2645 [03:18<00:56, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  78%|███████▊  | 2052/2645 [03:18<00:56, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  78%|███████▊  | 2054/2645 [03:18<00:56, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  78%|███████▊  | 2054/2645 [03:18<00:56, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  78%|███████▊  | 2054/2645 [03:19<00:56, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  78%|███████▊  | 2056/2645 [03:19<00:55, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  78%|███████▊  | 2056/2645 [03:19<00:55, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  78%|███████▊  | 2056/2645 [03:19<00:55, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  78%|███████▊  | 2058/2645 [03:19<00:55, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  78%|███████▊  | 2058/2645 [03:19<00:55, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  78%|███████▊  | 2058/2645 [03:19<00:55, 10.48it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 3:  78%|███████▊  | 2060/2645 [03:19<00:55, 10.46it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 3:  78%|███████▊  | 2060/2645 [03:19<00:55, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  78%|███████▊  | 2060/2645 [03:19<00:55, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  78%|███████▊  | 2062/2645 [03:19<00:55, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  78%|███████▊  | 2062/2645 [03:19<00:55, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  78%|███████▊  | 2062/2645 [03:19<00:55, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  78%|███████▊  | 2064/2645 [03:19<00:55, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  78%|███████▊  | 2064/2645 [03:19<00:55, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  78%|███████▊  | 2064/2645 [03:19<00:55, 10.52it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  78%|███████▊  | 2066/2645 [03:19<00:55, 10.51it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  78%|███████▊  | 2066/2645 [03:20<00:55, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  78%|███████▊  | 2066/2645 [03:20<00:55, 10.51it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  78%|███████▊  | 2068/2645 [03:20<00:54, 10.54it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  78%|███████▊  | 2068/2645 [03:20<00:54, 10.54it/s, training_loss=0.668]\u001b[A\n",
      "Epoch 3:  78%|███████▊  | 2068/2645 [03:20<00:54, 10.54it/s, training_loss=0.119]\u001b[A\n",
      "Epoch 3:  78%|███████▊  | 2070/2645 [03:20<00:54, 10.48it/s, training_loss=0.119]\u001b[A\n",
      "Epoch 3:  78%|███████▊  | 2070/2645 [03:20<00:54, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  78%|███████▊  | 2070/2645 [03:20<00:54, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  78%|███████▊  | 2072/2645 [03:20<00:54, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  78%|███████▊  | 2072/2645 [03:20<00:54, 10.52it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  78%|███████▊  | 2072/2645 [03:20<00:54, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  78%|███████▊  | 2074/2645 [03:20<00:54, 10.54it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  78%|███████▊  | 2074/2645 [03:20<00:54, 10.54it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  78%|███████▊  | 2074/2645 [03:20<00:54, 10.54it/s, training_loss=0.519]\u001b[A\n",
      "Epoch 3:  78%|███████▊  | 2076/2645 [03:20<00:54, 10.51it/s, training_loss=0.519]\u001b[A\n",
      "Epoch 3:  78%|███████▊  | 2076/2645 [03:21<00:54, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  78%|███████▊  | 2076/2645 [03:21<00:54, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  79%|███████▊  | 2078/2645 [03:21<00:54, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  79%|███████▊  | 2078/2645 [03:21<00:54, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  79%|███████▊  | 2078/2645 [03:21<00:54, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  79%|███████▊  | 2080/2645 [03:21<00:53, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  79%|███████▊  | 2080/2645 [03:21<00:53, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  79%|███████▊  | 2080/2645 [03:21<00:53, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  79%|███████▊  | 2082/2645 [03:21<00:53, 10.56it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  79%|███████▊  | 2082/2645 [03:21<00:53, 10.56it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  79%|███████▊  | 2082/2645 [03:21<00:53, 10.56it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  79%|███████▉  | 2084/2645 [03:21<00:53, 10.56it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  79%|███████▉  | 2084/2645 [03:21<00:53, 10.56it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  79%|███████▉  | 2084/2645 [03:21<00:53, 10.56it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  79%|███████▉  | 2086/2645 [03:21<00:52, 10.56it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  79%|███████▉  | 2086/2645 [03:21<00:52, 10.56it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  79%|███████▉  | 2086/2645 [03:22<00:52, 10.56it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  79%|███████▉  | 2088/2645 [03:22<00:52, 10.57it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  79%|███████▉  | 2088/2645 [03:22<00:52, 10.57it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  79%|███████▉  | 2088/2645 [03:22<00:52, 10.57it/s, training_loss=0.545]\u001b[A\n",
      "Epoch 3:  79%|███████▉  | 2090/2645 [03:22<00:52, 10.54it/s, training_loss=0.545]\u001b[A\n",
      "Epoch 3:  79%|███████▉  | 2090/2645 [03:22<00:52, 10.54it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  79%|███████▉  | 2090/2645 [03:22<00:52, 10.54it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  79%|███████▉  | 2092/2645 [03:22<00:52, 10.53it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  79%|███████▉  | 2092/2645 [03:22<00:52, 10.53it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  79%|███████▉  | 2092/2645 [03:22<00:52, 10.53it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  79%|███████▉  | 2094/2645 [03:22<00:52, 10.55it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  79%|███████▉  | 2094/2645 [03:22<00:52, 10.55it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  79%|███████▉  | 2094/2645 [03:22<00:52, 10.55it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  79%|███████▉  | 2096/2645 [03:22<00:51, 10.56it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  79%|███████▉  | 2096/2645 [03:22<00:51, 10.56it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  79%|███████▉  | 2096/2645 [03:23<00:51, 10.56it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  79%|███████▉  | 2098/2645 [03:23<00:51, 10.55it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  79%|███████▉  | 2098/2645 [03:23<00:51, 10.55it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  79%|███████▉  | 2098/2645 [03:23<00:51, 10.55it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  79%|███████▉  | 2100/2645 [03:23<00:51, 10.57it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  79%|███████▉  | 2100/2645 [03:23<00:51, 10.57it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  79%|███████▉  | 2100/2645 [03:23<00:51, 10.57it/s, training_loss=0.792]\u001b[A\n",
      "Epoch 3:  79%|███████▉  | 2102/2645 [03:23<00:51, 10.55it/s, training_loss=0.792]\u001b[A\n",
      "Epoch 3:  79%|███████▉  | 2102/2645 [03:23<00:51, 10.55it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  79%|███████▉  | 2102/2645 [03:23<00:51, 10.55it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  80%|███████▉  | 2104/2645 [03:23<00:51, 10.57it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  80%|███████▉  | 2104/2645 [03:23<00:51, 10.57it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  80%|███████▉  | 2104/2645 [03:23<00:51, 10.57it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  80%|███████▉  | 2106/2645 [03:23<00:50, 10.58it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  80%|███████▉  | 2106/2645 [03:23<00:50, 10.58it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  80%|███████▉  | 2106/2645 [03:23<00:50, 10.58it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  80%|███████▉  | 2108/2645 [03:23<00:50, 10.59it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  80%|███████▉  | 2108/2645 [03:24<00:50, 10.59it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  80%|███████▉  | 2108/2645 [03:24<00:50, 10.59it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  80%|███████▉  | 2110/2645 [03:24<00:50, 10.60it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  80%|███████▉  | 2110/2645 [03:24<00:50, 10.60it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  80%|███████▉  | 2110/2645 [03:24<00:50, 10.60it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  80%|███████▉  | 2112/2645 [03:24<00:50, 10.56it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  80%|███████▉  | 2112/2645 [03:24<00:50, 10.56it/s, training_loss=0.364]\u001b[A\n",
      "Epoch 3:  80%|███████▉  | 2112/2645 [03:24<00:50, 10.56it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  80%|███████▉  | 2114/2645 [03:24<00:50, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  80%|███████▉  | 2114/2645 [03:24<00:50, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  80%|███████▉  | 2114/2645 [03:24<00:50, 10.48it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  80%|████████  | 2116/2645 [03:24<00:50, 10.44it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  80%|████████  | 2116/2645 [03:24<00:50, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  80%|████████  | 2116/2645 [03:24<00:50, 10.44it/s, training_loss=0.360]\u001b[A\n",
      "Epoch 3:  80%|████████  | 2118/2645 [03:24<00:50, 10.45it/s, training_loss=0.360]\u001b[A\n",
      "Epoch 3:  80%|████████  | 2118/2645 [03:25<00:50, 10.45it/s, training_loss=0.897]\u001b[A\n",
      "Epoch 3:  80%|████████  | 2118/2645 [03:25<00:50, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  80%|████████  | 2120/2645 [03:25<00:50, 10.41it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  80%|████████  | 2120/2645 [03:25<00:50, 10.41it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  80%|████████  | 2120/2645 [03:25<00:50, 10.41it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  80%|████████  | 2122/2645 [03:25<00:50, 10.30it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  80%|████████  | 2122/2645 [03:25<00:50, 10.30it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  80%|████████  | 2122/2645 [03:25<00:50, 10.30it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  80%|████████  | 2124/2645 [03:25<00:50, 10.38it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  80%|████████  | 2124/2645 [03:25<00:50, 10.38it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  80%|████████  | 2124/2645 [03:25<00:50, 10.38it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  80%|████████  | 2126/2645 [03:25<00:49, 10.42it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  80%|████████  | 2126/2645 [03:25<00:49, 10.42it/s, training_loss=0.022]\u001b[A\n",
      "Epoch 3:  80%|████████  | 2126/2645 [03:25<00:49, 10.42it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  80%|████████  | 2128/2645 [03:25<00:49, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  80%|████████  | 2128/2645 [03:25<00:49, 10.43it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  80%|████████  | 2128/2645 [03:26<00:49, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  81%|████████  | 2130/2645 [03:26<00:49, 10.34it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  81%|████████  | 2130/2645 [03:26<00:49, 10.34it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  81%|████████  | 2130/2645 [03:26<00:49, 10.34it/s, training_loss=0.011]\u001b[A\n",
      "Epoch 3:  81%|████████  | 2132/2645 [03:26<00:49, 10.31it/s, training_loss=0.011]\u001b[A\n",
      "Epoch 3:  81%|████████  | 2132/2645 [03:26<00:49, 10.31it/s, training_loss=0.962]\u001b[A\n",
      "Epoch 3:  81%|████████  | 2132/2645 [03:26<00:49, 10.31it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  81%|████████  | 2134/2645 [03:26<00:50, 10.16it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  81%|████████  | 2134/2645 [03:26<00:50, 10.16it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  81%|████████  | 2134/2645 [03:26<00:50, 10.16it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  81%|████████  | 2136/2645 [03:26<00:50, 10.15it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  81%|████████  | 2136/2645 [03:26<00:50, 10.15it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  81%|████████  | 2136/2645 [03:26<00:50, 10.15it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  81%|████████  | 2138/2645 [03:26<00:49, 10.26it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  81%|████████  | 2138/2645 [03:26<00:49, 10.26it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  81%|████████  | 2138/2645 [03:27<00:49, 10.26it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  81%|████████  | 2140/2645 [03:27<00:49, 10.28it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  81%|████████  | 2140/2645 [03:27<00:49, 10.28it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  81%|████████  | 2140/2645 [03:27<00:49, 10.28it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  81%|████████  | 2142/2645 [03:27<00:49, 10.24it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  81%|████████  | 2142/2645 [03:27<00:49, 10.24it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  81%|████████  | 2142/2645 [03:27<00:49, 10.24it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  81%|████████  | 2144/2645 [03:27<00:48, 10.29it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  81%|████████  | 2144/2645 [03:27<00:48, 10.29it/s, training_loss=0.468]\u001b[A\n",
      "Epoch 3:  81%|████████  | 2144/2645 [03:27<00:48, 10.29it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  81%|████████  | 2146/2645 [03:27<00:48, 10.20it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  81%|████████  | 2146/2645 [03:27<00:48, 10.20it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  81%|████████  | 2146/2645 [03:27<00:48, 10.20it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  81%|████████  | 2148/2645 [03:27<00:48, 10.19it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  81%|████████  | 2148/2645 [03:27<00:48, 10.19it/s, training_loss=0.094]\u001b[A\n",
      "Epoch 3:  81%|████████  | 2148/2645 [03:28<00:48, 10.19it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  81%|████████▏ | 2150/2645 [03:28<00:48, 10.19it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  81%|████████▏ | 2150/2645 [03:28<00:48, 10.19it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  81%|████████▏ | 2150/2645 [03:28<00:48, 10.19it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  81%|████████▏ | 2152/2645 [03:28<00:48, 10.19it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  81%|████████▏ | 2152/2645 [03:28<00:48, 10.19it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  81%|████████▏ | 2152/2645 [03:28<00:48, 10.19it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  81%|████████▏ | 2154/2645 [03:28<00:48, 10.17it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  81%|████████▏ | 2154/2645 [03:28<00:48, 10.17it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  81%|████████▏ | 2154/2645 [03:28<00:48, 10.17it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  82%|████████▏ | 2156/2645 [03:28<00:48, 10.19it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  82%|████████▏ | 2156/2645 [03:28<00:48, 10.19it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  82%|████████▏ | 2156/2645 [03:28<00:48, 10.19it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  82%|████████▏ | 2158/2645 [03:28<00:47, 10.26it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  82%|████████▏ | 2158/2645 [03:28<00:47, 10.26it/s, training_loss=0.873]\u001b[A\n",
      "Epoch 3:  82%|████████▏ | 2158/2645 [03:29<00:47, 10.26it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  82%|████████▏ | 2160/2645 [03:29<00:47, 10.31it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  82%|████████▏ | 2160/2645 [03:29<00:47, 10.31it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  82%|████████▏ | 2160/2645 [03:29<00:47, 10.31it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  82%|████████▏ | 2162/2645 [03:29<00:46, 10.40it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  82%|████████▏ | 2162/2645 [03:29<00:46, 10.40it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  82%|████████▏ | 2162/2645 [03:29<00:46, 10.40it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  82%|████████▏ | 2164/2645 [03:29<00:45, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  82%|████████▏ | 2164/2645 [03:29<00:45, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  82%|████████▏ | 2164/2645 [03:29<00:45, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  82%|████████▏ | 2166/2645 [03:29<00:45, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  82%|████████▏ | 2166/2645 [03:29<00:45, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  82%|████████▏ | 2166/2645 [03:29<00:45, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  82%|████████▏ | 2168/2645 [03:29<00:45, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  82%|████████▏ | 2168/2645 [03:29<00:45, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  82%|████████▏ | 2168/2645 [03:29<00:45, 10.48it/s, training_loss=0.712]\u001b[A\n",
      "Epoch 3:  82%|████████▏ | 2170/2645 [03:29<00:45, 10.48it/s, training_loss=0.712]\u001b[A\n",
      "Epoch 3:  82%|████████▏ | 2170/2645 [03:30<00:45, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  82%|████████▏ | 2170/2645 [03:30<00:45, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  82%|████████▏ | 2172/2645 [03:30<00:45, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  82%|████████▏ | 2172/2645 [03:30<00:45, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  82%|████████▏ | 2172/2645 [03:30<00:45, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  82%|████████▏ | 2174/2645 [03:30<00:44, 10.53it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  82%|████████▏ | 2174/2645 [03:30<00:44, 10.53it/s, training_loss=0.990]\u001b[A\n",
      "Epoch 3:  82%|████████▏ | 2174/2645 [03:30<00:44, 10.53it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  82%|████████▏ | 2176/2645 [03:30<00:44, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  82%|████████▏ | 2176/2645 [03:30<00:44, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  82%|████████▏ | 2176/2645 [03:30<00:44, 10.49it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  82%|████████▏ | 2178/2645 [03:30<00:44, 10.48it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  82%|████████▏ | 2178/2645 [03:30<00:44, 10.48it/s, training_loss=0.982]\u001b[A\n",
      "Epoch 3:  82%|████████▏ | 2178/2645 [03:30<00:44, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  82%|████████▏ | 2180/2645 [03:30<00:44, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  82%|████████▏ | 2180/2645 [03:31<00:44, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  82%|████████▏ | 2180/2645 [03:31<00:44, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  82%|████████▏ | 2182/2645 [03:31<00:44, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  82%|████████▏ | 2182/2645 [03:31<00:44, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  82%|████████▏ | 2182/2645 [03:31<00:44, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  83%|████████▎ | 2184/2645 [03:31<00:43, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  83%|████████▎ | 2184/2645 [03:31<00:43, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  83%|████████▎ | 2184/2645 [03:31<00:43, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  83%|████████▎ | 2186/2645 [03:31<00:43, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  83%|████████▎ | 2186/2645 [03:31<00:43, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  83%|████████▎ | 2186/2645 [03:31<00:43, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  83%|████████▎ | 2188/2645 [03:31<00:43, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  83%|████████▎ | 2188/2645 [03:31<00:43, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  83%|████████▎ | 2188/2645 [03:31<00:43, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  83%|████████▎ | 2190/2645 [03:31<00:43, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  83%|████████▎ | 2190/2645 [03:31<00:43, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  83%|████████▎ | 2190/2645 [03:32<00:43, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  83%|████████▎ | 2192/2645 [03:32<00:43, 10.53it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  83%|████████▎ | 2192/2645 [03:32<00:43, 10.53it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  83%|████████▎ | 2192/2645 [03:32<00:43, 10.53it/s, training_loss=0.676]\u001b[A\n",
      "Epoch 3:  83%|████████▎ | 2194/2645 [03:32<00:42, 10.52it/s, training_loss=0.676]\u001b[A\n",
      "Epoch 3:  83%|████████▎ | 2194/2645 [03:32<00:42, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  83%|████████▎ | 2194/2645 [03:32<00:42, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  83%|████████▎ | 2196/2645 [03:32<00:42, 10.53it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  83%|████████▎ | 2196/2645 [03:32<00:42, 10.53it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  83%|████████▎ | 2196/2645 [03:32<00:42, 10.53it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  83%|████████▎ | 2198/2645 [03:32<00:42, 10.54it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  83%|████████▎ | 2198/2645 [03:32<00:42, 10.54it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  83%|████████▎ | 2198/2645 [03:32<00:42, 10.54it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 3:  83%|████████▎ | 2200/2645 [03:32<00:42, 10.52it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 3:  83%|████████▎ | 2200/2645 [03:32<00:42, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  83%|████████▎ | 2200/2645 [03:33<00:42, 10.52it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  83%|████████▎ | 2202/2645 [03:33<00:42, 10.50it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  83%|████████▎ | 2202/2645 [03:33<00:42, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  83%|████████▎ | 2202/2645 [03:33<00:42, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  83%|████████▎ | 2204/2645 [03:33<00:41, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  83%|████████▎ | 2204/2645 [03:33<00:41, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  83%|████████▎ | 2204/2645 [03:33<00:41, 10.51it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  83%|████████▎ | 2206/2645 [03:33<00:41, 10.48it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  83%|████████▎ | 2206/2645 [03:33<00:41, 10.48it/s, training_loss=0.481]\u001b[A\n",
      "Epoch 3:  83%|████████▎ | 2206/2645 [03:33<00:41, 10.48it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  83%|████████▎ | 2208/2645 [03:33<00:41, 10.48it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  83%|████████▎ | 2208/2645 [03:33<00:41, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  83%|████████▎ | 2208/2645 [03:33<00:41, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  84%|████████▎ | 2210/2645 [03:33<00:41, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  84%|████████▎ | 2210/2645 [03:33<00:41, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  84%|████████▎ | 2210/2645 [03:33<00:41, 10.51it/s, training_loss=0.190]\u001b[A\n",
      "Epoch 3:  84%|████████▎ | 2212/2645 [03:33<00:41, 10.50it/s, training_loss=0.190]\u001b[A\n",
      "Epoch 3:  84%|████████▎ | 2212/2645 [03:34<00:41, 10.50it/s, training_loss=0.089]\u001b[A\n",
      "Epoch 3:  84%|████████▎ | 2212/2645 [03:34<00:41, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  84%|████████▎ | 2214/2645 [03:34<00:41, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  84%|████████▎ | 2214/2645 [03:34<00:41, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  84%|████████▎ | 2214/2645 [03:34<00:41, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  84%|████████▍ | 2216/2645 [03:34<00:40, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  84%|████████▍ | 2216/2645 [03:34<00:40, 10.52it/s, training_loss=0.193]\u001b[A\n",
      "Epoch 3:  84%|████████▍ | 2216/2645 [03:34<00:40, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  84%|████████▍ | 2218/2645 [03:34<00:40, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  84%|████████▍ | 2218/2645 [03:34<00:40, 10.48it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  84%|████████▍ | 2218/2645 [03:34<00:40, 10.48it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  84%|████████▍ | 2220/2645 [03:34<00:40, 10.50it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  84%|████████▍ | 2220/2645 [03:34<00:40, 10.50it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  84%|████████▍ | 2220/2645 [03:34<00:40, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  84%|████████▍ | 2222/2645 [03:34<00:40, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  84%|████████▍ | 2222/2645 [03:35<00:40, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  84%|████████▍ | 2222/2645 [03:35<00:40, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  84%|████████▍ | 2224/2645 [03:35<00:40, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  84%|████████▍ | 2224/2645 [03:35<00:40, 10.45it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  84%|████████▍ | 2224/2645 [03:35<00:40, 10.45it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  84%|████████▍ | 2226/2645 [03:35<00:40, 10.29it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  84%|████████▍ | 2226/2645 [03:35<00:40, 10.29it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  84%|████████▍ | 2226/2645 [03:35<00:40, 10.29it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  84%|████████▍ | 2228/2645 [03:35<00:40, 10.35it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  84%|████████▍ | 2228/2645 [03:35<00:40, 10.35it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  84%|████████▍ | 2228/2645 [03:35<00:40, 10.35it/s, training_loss=0.142]\u001b[A\n",
      "Epoch 3:  84%|████████▍ | 2230/2645 [03:35<00:40, 10.34it/s, training_loss=0.142]\u001b[A\n",
      "Epoch 3:  84%|████████▍ | 2230/2645 [03:35<00:40, 10.34it/s, training_loss=0.081]\u001b[A\n",
      "Epoch 3:  84%|████████▍ | 2230/2645 [03:35<00:40, 10.34it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  84%|████████▍ | 2232/2645 [03:35<00:39, 10.36it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  84%|████████▍ | 2232/2645 [03:35<00:39, 10.36it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  84%|████████▍ | 2232/2645 [03:36<00:39, 10.36it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  84%|████████▍ | 2234/2645 [03:36<00:39, 10.42it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  84%|████████▍ | 2234/2645 [03:36<00:39, 10.42it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  84%|████████▍ | 2234/2645 [03:36<00:39, 10.42it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  85%|████████▍ | 2236/2645 [03:36<00:39, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  85%|████████▍ | 2236/2645 [03:36<00:39, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  85%|████████▍ | 2236/2645 [03:36<00:39, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  85%|████████▍ | 2238/2645 [03:36<00:38, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  85%|████████▍ | 2238/2645 [03:36<00:38, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  85%|████████▍ | 2238/2645 [03:36<00:38, 10.49it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  85%|████████▍ | 2240/2645 [03:36<00:38, 10.50it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  85%|████████▍ | 2240/2645 [03:36<00:38, 10.50it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 3:  85%|████████▍ | 2240/2645 [03:36<00:38, 10.50it/s, training_loss=0.644]\u001b[A\n",
      "Epoch 3:  85%|████████▍ | 2242/2645 [03:36<00:39, 10.24it/s, training_loss=0.644]\u001b[A\n",
      "Epoch 3:  85%|████████▍ | 2242/2645 [03:36<00:39, 10.24it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  85%|████████▍ | 2242/2645 [03:37<00:39, 10.24it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  85%|████████▍ | 2244/2645 [03:37<00:38, 10.29it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  85%|████████▍ | 2244/2645 [03:37<00:38, 10.29it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  85%|████████▍ | 2244/2645 [03:37<00:38, 10.29it/s, training_loss=0.546]\u001b[A\n",
      "Epoch 3:  85%|████████▍ | 2246/2645 [03:37<00:39, 10.23it/s, training_loss=0.546]\u001b[A\n",
      "Epoch 3:  85%|████████▍ | 2246/2645 [03:37<00:39, 10.23it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  85%|████████▍ | 2246/2645 [03:37<00:39, 10.23it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  85%|████████▍ | 2248/2645 [03:37<00:39, 10.02it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  85%|████████▍ | 2248/2645 [03:37<00:39, 10.02it/s, training_loss=0.743]\u001b[A\n",
      "Epoch 3:  85%|████████▍ | 2248/2645 [03:37<00:39, 10.02it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  85%|████████▌ | 2250/2645 [03:37<00:39,  9.98it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  85%|████████▌ | 2250/2645 [03:37<00:39,  9.98it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  85%|████████▌ | 2250/2645 [03:37<00:39,  9.98it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  85%|████████▌ | 2252/2645 [03:37<00:39, 10.04it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  85%|████████▌ | 2252/2645 [03:37<00:39, 10.04it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  85%|████████▌ | 2252/2645 [03:38<00:39, 10.04it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  85%|████████▌ | 2254/2645 [03:38<00:39,  9.85it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  85%|████████▌ | 2254/2645 [03:38<00:39,  9.85it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  85%|████████▌ | 2254/2645 [03:38<00:39,  9.85it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  85%|████████▌ | 2256/2645 [03:38<00:39,  9.97it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  85%|████████▌ | 2256/2645 [03:38<00:39,  9.97it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  85%|████████▌ | 2257/2645 [03:38<00:38,  9.97it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  85%|████████▌ | 2257/2645 [03:38<00:38,  9.97it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  85%|████████▌ | 2258/2645 [03:38<00:39,  9.91it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  85%|████████▌ | 2258/2645 [03:38<00:39,  9.91it/s, training_loss=0.508]\u001b[A\n",
      "Epoch 3:  85%|████████▌ | 2259/2645 [03:38<00:39,  9.87it/s, training_loss=0.508]\u001b[A\n",
      "Epoch 3:  85%|████████▌ | 2259/2645 [03:38<00:39,  9.87it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  85%|████████▌ | 2259/2645 [03:38<00:39,  9.87it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  85%|████████▌ | 2261/2645 [03:38<00:38,  9.93it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  85%|████████▌ | 2261/2645 [03:38<00:38,  9.93it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  86%|████████▌ | 2262/2645 [03:38<00:38,  9.89it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  86%|████████▌ | 2262/2645 [03:38<00:38,  9.89it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  86%|████████▌ | 2262/2645 [03:39<00:38,  9.89it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  86%|████████▌ | 2264/2645 [03:39<00:38,  9.99it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  86%|████████▌ | 2264/2645 [03:39<00:38,  9.99it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  86%|████████▌ | 2264/2645 [03:39<00:38,  9.99it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  86%|████████▌ | 2266/2645 [03:39<00:37, 10.05it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  86%|████████▌ | 2266/2645 [03:39<00:37, 10.05it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  86%|████████▌ | 2266/2645 [03:39<00:37, 10.05it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 3:  86%|████████▌ | 2268/2645 [03:39<00:37, 10.01it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 3:  86%|████████▌ | 2268/2645 [03:39<00:37, 10.01it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  86%|████████▌ | 2268/2645 [03:39<00:37, 10.01it/s, training_loss=0.012]\u001b[A\n",
      "Epoch 3:  86%|████████▌ | 2270/2645 [03:39<00:37,  9.99it/s, training_loss=0.012]\u001b[A\n",
      "Epoch 3:  86%|████████▌ | 2270/2645 [03:39<00:37,  9.99it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  86%|████████▌ | 2271/2645 [03:39<00:37,  9.98it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  86%|████████▌ | 2271/2645 [03:39<00:37,  9.98it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  86%|████████▌ | 2272/2645 [03:39<00:37,  9.92it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  86%|████████▌ | 2272/2645 [03:39<00:37,  9.92it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  86%|████████▌ | 2272/2645 [03:40<00:37,  9.92it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  86%|████████▌ | 2274/2645 [03:40<00:37,  9.99it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  86%|████████▌ | 2274/2645 [03:40<00:37,  9.99it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  86%|████████▌ | 2274/2645 [03:40<00:37,  9.99it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  86%|████████▌ | 2276/2645 [03:40<00:36, 10.07it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  86%|████████▌ | 2276/2645 [03:40<00:36, 10.07it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  86%|████████▌ | 2276/2645 [03:40<00:36, 10.07it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  86%|████████▌ | 2278/2645 [03:40<00:36, 10.02it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  86%|████████▌ | 2278/2645 [03:40<00:36, 10.02it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  86%|████████▌ | 2278/2645 [03:40<00:36, 10.02it/s, training_loss=0.575]\u001b[A\n",
      "Epoch 3:  86%|████████▌ | 2280/2645 [03:40<00:36, 10.03it/s, training_loss=0.575]\u001b[A\n",
      "Epoch 3:  86%|████████▌ | 2280/2645 [03:40<00:36, 10.03it/s, training_loss=0.039]\u001b[A\n",
      "Epoch 3:  86%|████████▌ | 2280/2645 [03:40<00:36, 10.03it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  86%|████████▋ | 2282/2645 [03:40<00:36,  9.96it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  86%|████████▋ | 2282/2645 [03:40<00:36,  9.96it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  86%|████████▋ | 2283/2645 [03:40<00:36,  9.95it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  86%|████████▋ | 2283/2645 [03:41<00:36,  9.95it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  86%|████████▋ | 2284/2645 [03:41<00:36,  9.95it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  86%|████████▋ | 2284/2645 [03:41<00:36,  9.95it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  86%|████████▋ | 2285/2645 [03:41<00:36,  9.95it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  86%|████████▋ | 2285/2645 [03:41<00:36,  9.95it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  86%|████████▋ | 2286/2645 [03:41<00:36,  9.94it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  86%|████████▋ | 2286/2645 [03:41<00:36,  9.94it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  86%|████████▋ | 2287/2645 [03:41<00:36,  9.90it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  86%|████████▋ | 2287/2645 [03:41<00:36,  9.90it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  86%|████████▋ | 2287/2645 [03:41<00:36,  9.90it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  87%|████████▋ | 2289/2645 [03:41<00:35,  9.97it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  87%|████████▋ | 2289/2645 [03:41<00:35,  9.97it/s, training_loss=0.082]\u001b[A\n",
      "Epoch 3:  87%|████████▋ | 2290/2645 [03:41<00:35,  9.92it/s, training_loss=0.082]\u001b[A\n",
      "Epoch 3:  87%|████████▋ | 2290/2645 [03:41<00:35,  9.92it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  87%|████████▋ | 2291/2645 [03:41<00:35,  9.90it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  87%|████████▋ | 2291/2645 [03:41<00:35,  9.90it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  87%|████████▋ | 2292/2645 [03:41<00:35,  9.83it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  87%|████████▋ | 2292/2645 [03:41<00:35,  9.83it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  87%|████████▋ | 2292/2645 [03:42<00:35,  9.83it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  87%|████████▋ | 2294/2645 [03:42<00:35,  9.89it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  87%|████████▋ | 2294/2645 [03:42<00:35,  9.89it/s, training_loss=0.629]\u001b[A\n",
      "Epoch 3:  87%|████████▋ | 2295/2645 [03:42<00:35,  9.77it/s, training_loss=0.629]\u001b[A\n",
      "Epoch 3:  87%|████████▋ | 2295/2645 [03:42<00:35,  9.77it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  87%|████████▋ | 2295/2645 [03:42<00:35,  9.77it/s, training_loss=0.847]\u001b[A\n",
      "Epoch 3:  87%|████████▋ | 2297/2645 [03:42<00:35,  9.83it/s, training_loss=0.847]\u001b[A\n",
      "Epoch 3:  87%|████████▋ | 2297/2645 [03:42<00:35,  9.83it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  87%|████████▋ | 2297/2645 [03:42<00:35,  9.83it/s, training_loss=0.489]\u001b[A\n",
      "Epoch 3:  87%|████████▋ | 2299/2645 [03:42<00:34,  9.89it/s, training_loss=0.489]\u001b[A\n",
      "Epoch 3:  87%|████████▋ | 2299/2645 [03:42<00:34,  9.89it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  87%|████████▋ | 2300/2645 [03:42<00:35,  9.86it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  87%|████████▋ | 2300/2645 [03:42<00:35,  9.86it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  87%|████████▋ | 2300/2645 [03:42<00:35,  9.86it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  87%|████████▋ | 2302/2645 [03:42<00:34,  9.96it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  87%|████████▋ | 2302/2645 [03:42<00:34,  9.96it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  87%|████████▋ | 2302/2645 [03:43<00:34,  9.96it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  87%|████████▋ | 2304/2645 [03:43<00:34, 10.02it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  87%|████████▋ | 2304/2645 [03:43<00:34, 10.02it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  87%|████████▋ | 2304/2645 [03:43<00:34, 10.02it/s, training_loss=0.247]\u001b[A\n",
      "Epoch 3:  87%|████████▋ | 2306/2645 [03:43<00:33, 10.02it/s, training_loss=0.247]\u001b[A\n",
      "Epoch 3:  87%|████████▋ | 2306/2645 [03:43<00:33, 10.02it/s, training_loss=0.744]\u001b[A\n",
      "Epoch 3:  87%|████████▋ | 2306/2645 [03:43<00:33, 10.02it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  87%|████████▋ | 2308/2645 [03:43<00:33,  9.97it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  87%|████████▋ | 2308/2645 [03:43<00:33,  9.97it/s, training_loss=0.933]\u001b[A\n",
      "Epoch 3:  87%|████████▋ | 2309/2645 [03:43<00:33,  9.88it/s, training_loss=0.933]\u001b[A\n",
      "Epoch 3:  87%|████████▋ | 2309/2645 [03:43<00:33,  9.88it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  87%|████████▋ | 2309/2645 [03:43<00:33,  9.88it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  87%|████████▋ | 2311/2645 [03:43<00:33,  9.95it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  87%|████████▋ | 2311/2645 [03:43<00:33,  9.95it/s, training_loss=0.043]\u001b[A\n",
      "Epoch 3:  87%|████████▋ | 2312/2645 [03:43<00:33,  9.82it/s, training_loss=0.043]\u001b[A\n",
      "Epoch 3:  87%|████████▋ | 2312/2645 [03:43<00:33,  9.82it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  87%|████████▋ | 2312/2645 [03:44<00:33,  9.82it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  87%|████████▋ | 2314/2645 [03:44<00:33,  9.88it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  87%|████████▋ | 2314/2645 [03:44<00:33,  9.88it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  87%|████████▋ | 2314/2645 [03:44<00:33,  9.88it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  88%|████████▊ | 2316/2645 [03:44<00:32,  9.99it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  88%|████████▊ | 2316/2645 [03:44<00:32,  9.99it/s, training_loss=0.411]\u001b[A\n",
      "Epoch 3:  88%|████████▊ | 2317/2645 [03:44<00:32,  9.95it/s, training_loss=0.411]\u001b[A\n",
      "Epoch 3:  88%|████████▊ | 2317/2645 [03:44<00:32,  9.95it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  88%|████████▊ | 2317/2645 [03:44<00:32,  9.95it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  88%|████████▊ | 2319/2645 [03:44<00:32, 10.00it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  88%|████████▊ | 2319/2645 [03:44<00:32, 10.00it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  88%|████████▊ | 2319/2645 [03:44<00:32, 10.00it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  88%|████████▊ | 2321/2645 [03:44<00:32, 10.05it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  88%|████████▊ | 2321/2645 [03:44<00:32, 10.05it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  88%|████████▊ | 2321/2645 [03:44<00:32, 10.05it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  88%|████████▊ | 2323/2645 [03:44<00:32, 10.06it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  88%|████████▊ | 2323/2645 [03:45<00:32, 10.06it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  88%|████████▊ | 2323/2645 [03:45<00:32, 10.06it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  88%|████████▊ | 2325/2645 [03:45<00:31, 10.07it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  88%|████████▊ | 2325/2645 [03:45<00:31, 10.07it/s, training_loss=0.681]\u001b[A\n",
      "Epoch 3:  88%|████████▊ | 2325/2645 [03:45<00:31, 10.07it/s, training_loss=0.560]\u001b[A\n",
      "Epoch 3:  88%|████████▊ | 2327/2645 [03:45<00:31, 10.00it/s, training_loss=0.560]\u001b[A\n",
      "Epoch 3:  88%|████████▊ | 2327/2645 [03:45<00:31, 10.00it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  88%|████████▊ | 2327/2645 [03:45<00:31, 10.00it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  88%|████████▊ | 2329/2645 [03:45<00:32,  9.79it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  88%|████████▊ | 2329/2645 [03:45<00:32,  9.79it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  88%|████████▊ | 2329/2645 [03:45<00:32,  9.79it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  88%|████████▊ | 2331/2645 [03:45<00:31,  9.91it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  88%|████████▊ | 2331/2645 [03:45<00:31,  9.91it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  88%|████████▊ | 2332/2645 [03:45<00:31,  9.87it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  88%|████████▊ | 2332/2645 [03:45<00:31,  9.87it/s, training_loss=0.510]\u001b[A\n",
      "Epoch 3:  88%|████████▊ | 2333/2645 [03:45<00:31,  9.86it/s, training_loss=0.510]\u001b[A\n",
      "Epoch 3:  88%|████████▊ | 2333/2645 [03:46<00:31,  9.86it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  88%|████████▊ | 2333/2645 [03:46<00:31,  9.86it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  88%|████████▊ | 2335/2645 [03:46<00:31,  9.72it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  88%|████████▊ | 2335/2645 [03:46<00:31,  9.72it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  88%|████████▊ | 2335/2645 [03:46<00:31,  9.72it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  88%|████████▊ | 2337/2645 [03:46<00:31,  9.82it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  88%|████████▊ | 2337/2645 [03:46<00:31,  9.82it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  88%|████████▊ | 2337/2645 [03:46<00:31,  9.82it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  88%|████████▊ | 2339/2645 [03:46<00:31,  9.85it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  88%|████████▊ | 2339/2645 [03:46<00:31,  9.85it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  88%|████████▊ | 2340/2645 [03:46<00:31,  9.81it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  88%|████████▊ | 2340/2645 [03:46<00:31,  9.81it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 3:  89%|████████▊ | 2341/2645 [03:46<00:30,  9.81it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 3:  89%|████████▊ | 2341/2645 [03:46<00:30,  9.81it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  89%|████████▊ | 2341/2645 [03:46<00:30,  9.81it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 3:  89%|████████▊ | 2343/2645 [03:47<00:30,  9.85it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 3:  89%|████████▊ | 2343/2645 [03:47<00:30,  9.85it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  89%|████████▊ | 2343/2645 [03:47<00:30,  9.85it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  89%|████████▊ | 2345/2645 [03:47<00:30,  9.91it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  89%|████████▊ | 2345/2645 [03:47<00:30,  9.91it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  89%|████████▊ | 2345/2645 [03:47<00:30,  9.91it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 3:  89%|████████▊ | 2347/2645 [03:47<00:30,  9.91it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 3:  89%|████████▊ | 2347/2645 [03:47<00:30,  9.91it/s, training_loss=0.326]\u001b[A\n",
      "Epoch 3:  89%|████████▉ | 2348/2645 [03:47<00:30,  9.89it/s, training_loss=0.326]\u001b[A\n",
      "Epoch 3:  89%|████████▉ | 2348/2645 [03:47<00:30,  9.89it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  89%|████████▉ | 2349/2645 [03:47<00:29,  9.91it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  89%|████████▉ | 2349/2645 [03:47<00:29,  9.91it/s, training_loss=0.611]\u001b[A\n",
      "Epoch 3:  89%|████████▉ | 2350/2645 [03:47<00:29,  9.88it/s, training_loss=0.611]\u001b[A\n",
      "Epoch 3:  89%|████████▉ | 2350/2645 [03:47<00:29,  9.88it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  89%|████████▉ | 2350/2645 [03:47<00:29,  9.88it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  89%|████████▉ | 2352/2645 [03:47<00:29,  9.91it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  89%|████████▉ | 2352/2645 [03:48<00:29,  9.91it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  89%|████████▉ | 2352/2645 [03:48<00:29,  9.91it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  89%|████████▉ | 2354/2645 [03:48<00:29,  9.93it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  89%|████████▉ | 2354/2645 [03:48<00:29,  9.93it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  89%|████████▉ | 2354/2645 [03:48<00:29,  9.93it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  89%|████████▉ | 2356/2645 [03:48<00:29,  9.95it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  89%|████████▉ | 2356/2645 [03:48<00:29,  9.95it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  89%|████████▉ | 2357/2645 [03:48<00:29,  9.75it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  89%|████████▉ | 2357/2645 [03:48<00:29,  9.75it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  89%|████████▉ | 2357/2645 [03:48<00:29,  9.75it/s, training_loss=0.126]\u001b[A\n",
      "Epoch 3:  89%|████████▉ | 2359/2645 [03:48<00:29,  9.85it/s, training_loss=0.126]\u001b[A\n",
      "Epoch 3:  89%|████████▉ | 2359/2645 [03:48<00:29,  9.85it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  89%|████████▉ | 2359/2645 [03:48<00:29,  9.85it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  89%|████████▉ | 2361/2645 [03:48<00:28,  9.90it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  89%|████████▉ | 2361/2645 [03:48<00:28,  9.90it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  89%|████████▉ | 2362/2645 [03:48<00:28,  9.93it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  89%|████████▉ | 2362/2645 [03:49<00:28,  9.93it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  89%|████████▉ | 2363/2645 [03:49<00:28,  9.92it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  89%|████████▉ | 2363/2645 [03:49<00:28,  9.92it/s, training_loss=0.559]\u001b[A\n",
      "Epoch 3:  89%|████████▉ | 2364/2645 [03:49<00:28,  9.86it/s, training_loss=0.559]\u001b[A\n",
      "Epoch 3:  89%|████████▉ | 2364/2645 [03:49<00:28,  9.86it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  89%|████████▉ | 2364/2645 [03:49<00:28,  9.86it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  89%|████████▉ | 2366/2645 [03:49<00:28,  9.90it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  89%|████████▉ | 2366/2645 [03:49<00:28,  9.90it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  89%|████████▉ | 2367/2645 [03:49<00:28,  9.93it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  89%|████████▉ | 2367/2645 [03:49<00:28,  9.93it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  90%|████████▉ | 2368/2645 [03:49<00:28,  9.89it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  90%|████████▉ | 2368/2645 [03:49<00:28,  9.89it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  90%|████████▉ | 2368/2645 [03:49<00:28,  9.89it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  90%|████████▉ | 2370/2645 [03:49<00:27,  9.90it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  90%|████████▉ | 2370/2645 [03:49<00:27,  9.90it/s, training_loss=0.261]\u001b[A\n",
      "Epoch 3:  90%|████████▉ | 2371/2645 [03:49<00:27,  9.90it/s, training_loss=0.261]\u001b[A\n",
      "Epoch 3:  90%|████████▉ | 2371/2645 [03:49<00:27,  9.90it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  90%|████████▉ | 2371/2645 [03:50<00:27,  9.90it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  90%|████████▉ | 2373/2645 [03:50<00:27,  9.94it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  90%|████████▉ | 2373/2645 [03:50<00:27,  9.94it/s, training_loss=0.803]\u001b[A\n",
      "Epoch 3:  90%|████████▉ | 2374/2645 [03:50<00:27,  9.81it/s, training_loss=0.803]\u001b[A\n",
      "Epoch 3:  90%|████████▉ | 2374/2645 [03:50<00:27,  9.81it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  90%|████████▉ | 2374/2645 [03:50<00:27,  9.81it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  90%|████████▉ | 2376/2645 [03:50<00:27,  9.89it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  90%|████████▉ | 2376/2645 [03:50<00:27,  9.89it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  90%|████████▉ | 2376/2645 [03:50<00:27,  9.89it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 3:  90%|████████▉ | 2378/2645 [03:50<00:27,  9.88it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 3:  90%|████████▉ | 2378/2645 [03:50<00:27,  9.88it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  90%|████████▉ | 2379/2645 [03:50<00:26,  9.91it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  90%|████████▉ | 2379/2645 [03:50<00:26,  9.91it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  90%|████████▉ | 2379/2645 [03:50<00:26,  9.91it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  90%|█████████ | 2381/2645 [03:50<00:26,  9.98it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  90%|█████████ | 2381/2645 [03:50<00:26,  9.98it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  90%|█████████ | 2382/2645 [03:50<00:26,  9.90it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  90%|█████████ | 2382/2645 [03:51<00:26,  9.90it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  90%|█████████ | 2383/2645 [03:51<00:26,  9.82it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  90%|█████████ | 2383/2645 [03:51<00:26,  9.82it/s, training_loss=0.678]\u001b[A\n",
      "Epoch 3:  90%|█████████ | 2384/2645 [03:51<00:26,  9.82it/s, training_loss=0.678]\u001b[A\n",
      "Epoch 3:  90%|█████████ | 2384/2645 [03:51<00:26,  9.82it/s, training_loss=0.079]\u001b[A\n",
      "Epoch 3:  90%|█████████ | 2385/2645 [03:51<00:26,  9.85it/s, training_loss=0.079]\u001b[A\n",
      "Epoch 3:  90%|█████████ | 2385/2645 [03:51<00:26,  9.85it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  90%|█████████ | 2386/2645 [03:51<00:26,  9.89it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  90%|█████████ | 2386/2645 [03:51<00:26,  9.89it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  90%|█████████ | 2386/2645 [03:51<00:26,  9.89it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  90%|█████████ | 2388/2645 [03:51<00:25,  9.95it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  90%|█████████ | 2388/2645 [03:51<00:25,  9.95it/s, training_loss=0.202]\u001b[A\n",
      "Epoch 3:  90%|█████████ | 2389/2645 [03:51<00:26,  9.83it/s, training_loss=0.202]\u001b[A\n",
      "Epoch 3:  90%|█████████ | 2389/2645 [03:51<00:26,  9.83it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  90%|█████████ | 2389/2645 [03:51<00:26,  9.83it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  90%|█████████ | 2391/2645 [03:51<00:25,  9.87it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  90%|█████████ | 2391/2645 [03:51<00:25,  9.87it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  90%|█████████ | 2391/2645 [03:52<00:25,  9.87it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  90%|█████████ | 2393/2645 [03:52<00:25,  9.94it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  90%|█████████ | 2393/2645 [03:52<00:25,  9.94it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  91%|█████████ | 2394/2645 [03:52<00:25,  9.72it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  91%|█████████ | 2394/2645 [03:52<00:25,  9.72it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  91%|█████████ | 2394/2645 [03:52<00:25,  9.72it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 3:  91%|█████████ | 2396/2645 [03:52<00:25,  9.83it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 3:  91%|█████████ | 2396/2645 [03:52<00:25,  9.83it/s, training_loss=0.092]\u001b[A\n",
      "Epoch 3:  91%|█████████ | 2397/2645 [03:52<00:25,  9.85it/s, training_loss=0.092]\u001b[A\n",
      "Epoch 3:  91%|█████████ | 2397/2645 [03:52<00:25,  9.85it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  91%|█████████ | 2397/2645 [03:52<00:25,  9.85it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  91%|█████████ | 2399/2645 [03:52<00:24,  9.91it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  91%|█████████ | 2399/2645 [03:52<00:24,  9.91it/s, training_loss=0.542]\u001b[A\n",
      "Epoch 3:  91%|█████████ | 2400/2645 [03:52<00:24,  9.87it/s, training_loss=0.542]\u001b[A\n",
      "Epoch 3:  91%|█████████ | 2400/2645 [03:52<00:24,  9.87it/s, training_loss=0.096]\u001b[A\n",
      "Epoch 3:  91%|█████████ | 2401/2645 [03:52<00:24,  9.87it/s, training_loss=0.096]\u001b[A\n",
      "Epoch 3:  91%|█████████ | 2401/2645 [03:52<00:24,  9.87it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  91%|█████████ | 2401/2645 [03:53<00:24,  9.87it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  91%|█████████ | 2403/2645 [03:53<00:24,  9.93it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  91%|█████████ | 2403/2645 [03:53<00:24,  9.93it/s, training_loss=0.031]\u001b[A\n",
      "Epoch 3:  91%|█████████ | 2404/2645 [03:53<00:24,  9.72it/s, training_loss=0.031]\u001b[A\n",
      "Epoch 3:  91%|█████████ | 2404/2645 [03:53<00:24,  9.72it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  91%|█████████ | 2405/2645 [03:53<00:24,  9.70it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  91%|█████████ | 2405/2645 [03:53<00:24,  9.70it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  91%|█████████ | 2406/2645 [03:53<00:24,  9.76it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  91%|█████████ | 2406/2645 [03:53<00:24,  9.76it/s, training_loss=0.413]\u001b[A\n",
      "Epoch 3:  91%|█████████ | 2407/2645 [03:53<00:24,  9.70it/s, training_loss=0.413]\u001b[A\n",
      "Epoch 3:  91%|█████████ | 2407/2645 [03:53<00:24,  9.70it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  91%|█████████ | 2407/2645 [03:53<00:24,  9.70it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  91%|█████████ | 2409/2645 [03:53<00:23,  9.89it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  91%|█████████ | 2409/2645 [03:53<00:23,  9.89it/s, training_loss=0.403]\u001b[A\n",
      "Epoch 3:  91%|█████████ | 2409/2645 [03:53<00:23,  9.89it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  91%|█████████ | 2411/2645 [03:53<00:23, 10.05it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  91%|█████████ | 2411/2645 [03:53<00:23, 10.05it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  91%|█████████ | 2411/2645 [03:54<00:23, 10.05it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  91%|█████████ | 2413/2645 [03:54<00:22, 10.19it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  91%|█████████ | 2413/2645 [03:54<00:22, 10.19it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  91%|█████████ | 2413/2645 [03:54<00:22, 10.19it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  91%|█████████▏| 2415/2645 [03:54<00:22, 10.18it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  91%|█████████▏| 2415/2645 [03:54<00:22, 10.18it/s, training_loss=0.339]\u001b[A\n",
      "Epoch 3:  91%|█████████▏| 2415/2645 [03:54<00:22, 10.18it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  91%|█████████▏| 2417/2645 [03:54<00:22, 10.08it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  91%|█████████▏| 2417/2645 [03:54<00:22, 10.08it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  91%|█████████▏| 2417/2645 [03:54<00:22, 10.08it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  91%|█████████▏| 2419/2645 [03:54<00:22, 10.14it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  91%|█████████▏| 2419/2645 [03:54<00:22, 10.14it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  91%|█████████▏| 2419/2645 [03:54<00:22, 10.14it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 2421/2645 [03:54<00:21, 10.27it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 2421/2645 [03:54<00:21, 10.27it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 2421/2645 [03:55<00:21, 10.27it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 2423/2645 [03:55<00:21, 10.34it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 2423/2645 [03:55<00:21, 10.34it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 2423/2645 [03:55<00:21, 10.34it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 2425/2645 [03:55<00:21, 10.41it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 2425/2645 [03:55<00:21, 10.41it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 2425/2645 [03:55<00:21, 10.41it/s, training_loss=0.109]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 2427/2645 [03:55<00:20, 10.41it/s, training_loss=0.109]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 2427/2645 [03:55<00:20, 10.41it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 2427/2645 [03:55<00:20, 10.41it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 2429/2645 [03:55<00:20, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 2429/2645 [03:55<00:20, 10.44it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 2429/2645 [03:55<00:20, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 2431/2645 [03:55<00:20, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 2431/2645 [03:55<00:20, 10.46it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 2431/2645 [03:55<00:20, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 2433/2645 [03:55<00:20, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 2433/2645 [03:56<00:20, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 2433/2645 [03:56<00:20, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 2435/2645 [03:56<00:19, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 2435/2645 [03:56<00:19, 10.52it/s, training_loss=0.024]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 2435/2645 [03:56<00:19, 10.52it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 2437/2645 [03:56<00:19, 10.44it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 2437/2645 [03:56<00:19, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 2437/2645 [03:56<00:19, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 2439/2645 [03:56<00:19, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 2439/2645 [03:56<00:19, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 2439/2645 [03:56<00:19, 10.48it/s, training_loss=0.738]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 2441/2645 [03:56<00:19, 10.47it/s, training_loss=0.738]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 2441/2645 [03:56<00:19, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 2441/2645 [03:56<00:19, 10.47it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 2443/2645 [03:56<00:19, 10.50it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 2443/2645 [03:57<00:19, 10.50it/s, training_loss=0.844]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 2443/2645 [03:57<00:19, 10.50it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 2445/2645 [03:57<00:19, 10.47it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 2445/2645 [03:57<00:19, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 2445/2645 [03:57<00:19, 10.47it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  93%|█████████▎| 2447/2645 [03:57<00:18, 10.49it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  93%|█████████▎| 2447/2645 [03:57<00:18, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  93%|█████████▎| 2447/2645 [03:57<00:18, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  93%|█████████▎| 2449/2645 [03:57<00:18, 10.53it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  93%|█████████▎| 2449/2645 [03:57<00:18, 10.53it/s, training_loss=0.155]\u001b[A\n",
      "Epoch 3:  93%|█████████▎| 2449/2645 [03:57<00:18, 10.53it/s, training_loss=0.022]\u001b[A\n",
      "Epoch 3:  93%|█████████▎| 2451/2645 [03:57<00:18, 10.47it/s, training_loss=0.022]\u001b[A\n",
      "Epoch 3:  93%|█████████▎| 2451/2645 [03:57<00:18, 10.47it/s, training_loss=0.759]\u001b[A\n",
      "Epoch 3:  93%|█████████▎| 2451/2645 [03:57<00:18, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  93%|█████████▎| 2453/2645 [03:57<00:18, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  93%|█████████▎| 2453/2645 [03:57<00:18, 10.46it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  93%|█████████▎| 2453/2645 [03:58<00:18, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  93%|█████████▎| 2455/2645 [03:58<00:18, 10.26it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  93%|█████████▎| 2455/2645 [03:58<00:18, 10.26it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  93%|█████████▎| 2455/2645 [03:58<00:18, 10.26it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  93%|█████████▎| 2457/2645 [03:58<00:18, 10.35it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  93%|█████████▎| 2457/2645 [03:58<00:18, 10.35it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  93%|█████████▎| 2457/2645 [03:58<00:18, 10.35it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  93%|█████████▎| 2459/2645 [03:58<00:17, 10.40it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  93%|█████████▎| 2459/2645 [03:58<00:17, 10.40it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  93%|█████████▎| 2459/2645 [03:58<00:17, 10.40it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  93%|█████████▎| 2461/2645 [03:58<00:17, 10.39it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  93%|█████████▎| 2461/2645 [03:58<00:17, 10.39it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  93%|█████████▎| 2461/2645 [03:58<00:17, 10.39it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  93%|█████████▎| 2463/2645 [03:58<00:17, 10.42it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  93%|█████████▎| 2463/2645 [03:58<00:17, 10.42it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  93%|█████████▎| 2463/2645 [03:59<00:17, 10.42it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  93%|█████████▎| 2465/2645 [03:59<00:17, 10.39it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  93%|█████████▎| 2465/2645 [03:59<00:17, 10.39it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  93%|█████████▎| 2465/2645 [03:59<00:17, 10.39it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  93%|█████████▎| 2467/2645 [03:59<00:17, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  93%|█████████▎| 2467/2645 [03:59<00:17, 10.43it/s, training_loss=0.418]\u001b[A\n",
      "Epoch 3:  93%|█████████▎| 2467/2645 [03:59<00:17, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  93%|█████████▎| 2469/2645 [03:59<00:16, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  93%|█████████▎| 2469/2645 [03:59<00:16, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  93%|█████████▎| 2469/2645 [03:59<00:16, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  93%|█████████▎| 2471/2645 [03:59<00:16, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  93%|█████████▎| 2471/2645 [03:59<00:16, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  93%|█████████▎| 2471/2645 [03:59<00:16, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  93%|█████████▎| 2473/2645 [03:59<00:16, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  93%|█████████▎| 2473/2645 [03:59<00:16, 10.44it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  93%|█████████▎| 2473/2645 [03:59<00:16, 10.44it/s, training_loss=0.343]\u001b[A\n",
      "Epoch 3:  94%|█████████▎| 2475/2645 [03:59<00:16, 10.46it/s, training_loss=0.343]\u001b[A\n",
      "Epoch 3:  94%|█████████▎| 2475/2645 [04:00<00:16, 10.46it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  94%|█████████▎| 2475/2645 [04:00<00:16, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  94%|█████████▎| 2477/2645 [04:00<00:16, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  94%|█████████▎| 2477/2645 [04:00<00:16, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  94%|█████████▎| 2477/2645 [04:00<00:16, 10.45it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  94%|█████████▎| 2479/2645 [04:00<00:15, 10.48it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  94%|█████████▎| 2479/2645 [04:00<00:15, 10.48it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  94%|█████████▎| 2479/2645 [04:00<00:15, 10.48it/s, training_loss=0.357]\u001b[A\n",
      "Epoch 3:  94%|█████████▍| 2481/2645 [04:00<00:15, 10.41it/s, training_loss=0.357]\u001b[A\n",
      "Epoch 3:  94%|█████████▍| 2481/2645 [04:00<00:15, 10.41it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  94%|█████████▍| 2481/2645 [04:00<00:15, 10.41it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  94%|█████████▍| 2483/2645 [04:00<00:15, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  94%|█████████▍| 2483/2645 [04:00<00:15, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  94%|█████████▍| 2483/2645 [04:00<00:15, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  94%|█████████▍| 2485/2645 [04:00<00:15, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  94%|█████████▍| 2485/2645 [04:01<00:15, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  94%|█████████▍| 2485/2645 [04:01<00:15, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  94%|█████████▍| 2487/2645 [04:01<00:15, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  94%|█████████▍| 2487/2645 [04:01<00:15, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  94%|█████████▍| 2487/2645 [04:01<00:15, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  94%|█████████▍| 2489/2645 [04:01<00:14, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  94%|█████████▍| 2489/2645 [04:01<00:14, 10.52it/s, training_loss=0.068]\u001b[A\n",
      "Epoch 3:  94%|█████████▍| 2489/2645 [04:01<00:14, 10.52it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  94%|█████████▍| 2491/2645 [04:01<00:14, 10.47it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  94%|█████████▍| 2491/2645 [04:01<00:14, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  94%|█████████▍| 2491/2645 [04:01<00:14, 10.47it/s, training_loss=0.191]\u001b[A\n",
      "Epoch 3:  94%|█████████▍| 2493/2645 [04:01<00:14, 10.44it/s, training_loss=0.191]\u001b[A\n",
      "Epoch 3:  94%|█████████▍| 2493/2645 [04:01<00:14, 10.44it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  94%|█████████▍| 2493/2645 [04:01<00:14, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  94%|█████████▍| 2495/2645 [04:01<00:14, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  94%|█████████▍| 2495/2645 [04:01<00:14, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  94%|█████████▍| 2495/2645 [04:02<00:14, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  94%|█████████▍| 2497/2645 [04:02<00:14, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  94%|█████████▍| 2497/2645 [04:02<00:14, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  94%|█████████▍| 2497/2645 [04:02<00:14, 10.51it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  94%|█████████▍| 2499/2645 [04:02<00:13, 10.50it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  94%|█████████▍| 2499/2645 [04:02<00:13, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  94%|█████████▍| 2499/2645 [04:02<00:13, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  95%|█████████▍| 2501/2645 [04:02<00:13, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  95%|█████████▍| 2501/2645 [04:02<00:13, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  95%|█████████▍| 2501/2645 [04:02<00:13, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  95%|█████████▍| 2503/2645 [04:02<00:13, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  95%|█████████▍| 2503/2645 [04:02<00:13, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  95%|█████████▍| 2503/2645 [04:02<00:13, 10.50it/s, training_loss=0.240]\u001b[A\n",
      "Epoch 3:  95%|█████████▍| 2505/2645 [04:02<00:13, 10.49it/s, training_loss=0.240]\u001b[A\n",
      "Epoch 3:  95%|█████████▍| 2505/2645 [04:02<00:13, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  95%|█████████▍| 2505/2645 [04:03<00:13, 10.49it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  95%|█████████▍| 2507/2645 [04:03<00:13, 10.54it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  95%|█████████▍| 2507/2645 [04:03<00:13, 10.54it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  95%|█████████▍| 2507/2645 [04:03<00:13, 10.54it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  95%|█████████▍| 2509/2645 [04:03<00:12, 10.56it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  95%|█████████▍| 2509/2645 [04:03<00:12, 10.56it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  95%|█████████▍| 2509/2645 [04:03<00:12, 10.56it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  95%|█████████▍| 2511/2645 [04:03<00:12, 10.35it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  95%|█████████▍| 2511/2645 [04:03<00:12, 10.35it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  95%|█████████▍| 2511/2645 [04:03<00:12, 10.35it/s, training_loss=1.025]\u001b[A\n",
      "Epoch 3:  95%|█████████▌| 2513/2645 [04:03<00:12, 10.16it/s, training_loss=1.025]\u001b[A\n",
      "Epoch 3:  95%|█████████▌| 2513/2645 [04:03<00:12, 10.16it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  95%|█████████▌| 2513/2645 [04:03<00:12, 10.16it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  95%|█████████▌| 2515/2645 [04:03<00:12, 10.28it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  95%|█████████▌| 2515/2645 [04:03<00:12, 10.28it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  95%|█████████▌| 2515/2645 [04:04<00:12, 10.28it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  95%|█████████▌| 2517/2645 [04:04<00:12, 10.39it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  95%|█████████▌| 2517/2645 [04:04<00:12, 10.39it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  95%|█████████▌| 2517/2645 [04:04<00:12, 10.39it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  95%|█████████▌| 2519/2645 [04:04<00:12, 10.44it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  95%|█████████▌| 2519/2645 [04:04<00:12, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  95%|█████████▌| 2519/2645 [04:04<00:12, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  95%|█████████▌| 2521/2645 [04:04<00:11, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  95%|█████████▌| 2521/2645 [04:04<00:11, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  95%|█████████▌| 2521/2645 [04:04<00:11, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  95%|█████████▌| 2523/2645 [04:04<00:11, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  95%|█████████▌| 2523/2645 [04:04<00:11, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  95%|█████████▌| 2523/2645 [04:04<00:11, 10.50it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  95%|█████████▌| 2525/2645 [04:04<00:11, 10.52it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  95%|█████████▌| 2525/2645 [04:04<00:11, 10.52it/s, training_loss=0.949]\u001b[A\n",
      "Epoch 3:  95%|█████████▌| 2525/2645 [04:04<00:11, 10.52it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  96%|█████████▌| 2527/2645 [04:04<00:11, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  96%|█████████▌| 2527/2645 [04:05<00:11, 10.51it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  96%|█████████▌| 2527/2645 [04:05<00:11, 10.51it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  96%|█████████▌| 2529/2645 [04:05<00:10, 10.55it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  96%|█████████▌| 2529/2645 [04:05<00:10, 10.55it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  96%|█████████▌| 2529/2645 [04:05<00:10, 10.55it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  96%|█████████▌| 2531/2645 [04:05<00:10, 10.57it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  96%|█████████▌| 2531/2645 [04:05<00:10, 10.57it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  96%|█████████▌| 2531/2645 [04:05<00:10, 10.57it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  96%|█████████▌| 2533/2645 [04:05<00:10, 10.60it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  96%|█████████▌| 2533/2645 [04:05<00:10, 10.60it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  96%|█████████▌| 2533/2645 [04:05<00:10, 10.60it/s, training_loss=1.586]\u001b[A\n",
      "Epoch 3:  96%|█████████▌| 2535/2645 [04:05<00:10, 10.58it/s, training_loss=1.586]\u001b[A\n",
      "Epoch 3:  96%|█████████▌| 2535/2645 [04:05<00:10, 10.58it/s, training_loss=0.318]\u001b[A\n",
      "Epoch 3:  96%|█████████▌| 2535/2645 [04:05<00:10, 10.58it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  96%|█████████▌| 2537/2645 [04:05<00:10, 10.57it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  96%|█████████▌| 2537/2645 [04:05<00:10, 10.57it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  96%|█████████▌| 2537/2645 [04:06<00:10, 10.57it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  96%|█████████▌| 2539/2645 [04:06<00:09, 10.60it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  96%|█████████▌| 2539/2645 [04:06<00:09, 10.60it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  96%|█████████▌| 2539/2645 [04:06<00:09, 10.60it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  96%|█████████▌| 2541/2645 [04:06<00:09, 10.61it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  96%|█████████▌| 2541/2645 [04:06<00:09, 10.61it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  96%|█████████▌| 2541/2645 [04:06<00:09, 10.61it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  96%|█████████▌| 2543/2645 [04:06<00:09, 10.54it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  96%|█████████▌| 2543/2645 [04:06<00:09, 10.54it/s, training_loss=0.924]\u001b[A\n",
      "Epoch 3:  96%|█████████▌| 2543/2645 [04:06<00:09, 10.54it/s, training_loss=0.851]\u001b[A\n",
      "Epoch 3:  96%|█████████▌| 2545/2645 [04:06<00:09, 10.30it/s, training_loss=0.851]\u001b[A\n",
      "Epoch 3:  96%|█████████▌| 2545/2645 [04:06<00:09, 10.30it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  96%|█████████▌| 2545/2645 [04:06<00:09, 10.30it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  96%|█████████▋| 2547/2645 [04:06<00:09, 10.34it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  96%|█████████▋| 2547/2645 [04:06<00:09, 10.34it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  96%|█████████▋| 2547/2645 [04:07<00:09, 10.34it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  96%|█████████▋| 2549/2645 [04:07<00:09, 10.25it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  96%|█████████▋| 2549/2645 [04:07<00:09, 10.25it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  96%|█████████▋| 2549/2645 [04:07<00:09, 10.25it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  96%|█████████▋| 2551/2645 [04:07<00:09, 10.29it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  96%|█████████▋| 2551/2645 [04:07<00:09, 10.29it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  96%|█████████▋| 2551/2645 [04:07<00:09, 10.29it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 2553/2645 [04:07<00:08, 10.23it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 2553/2645 [04:07<00:08, 10.23it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 2553/2645 [04:07<00:08, 10.23it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 2555/2645 [04:07<00:08, 10.11it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 2555/2645 [04:07<00:08, 10.11it/s, training_loss=0.205]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 2555/2645 [04:07<00:08, 10.11it/s, training_loss=0.876]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 2557/2645 [04:07<00:08, 10.02it/s, training_loss=0.876]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 2557/2645 [04:07<00:08, 10.02it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 2557/2645 [04:08<00:08, 10.02it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 2559/2645 [04:08<00:08, 10.02it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 2559/2645 [04:08<00:08, 10.02it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 2559/2645 [04:08<00:08, 10.02it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 2561/2645 [04:08<00:08, 10.08it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 2561/2645 [04:08<00:08, 10.08it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 2561/2645 [04:08<00:08, 10.08it/s, training_loss=0.158]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 2563/2645 [04:08<00:08, 10.07it/s, training_loss=0.158]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 2563/2645 [04:08<00:08, 10.07it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 2563/2645 [04:08<00:08, 10.07it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 2565/2645 [04:08<00:07, 10.04it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 2565/2645 [04:08<00:07, 10.04it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 2565/2645 [04:08<00:07, 10.04it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 2567/2645 [04:08<00:07, 10.10it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 2567/2645 [04:08<00:07, 10.10it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 2567/2645 [04:09<00:07, 10.10it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 2569/2645 [04:09<00:07, 10.10it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 2569/2645 [04:09<00:07, 10.10it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 2569/2645 [04:09<00:07, 10.10it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 2571/2645 [04:09<00:07, 10.15it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 2571/2645 [04:09<00:07, 10.15it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 2571/2645 [04:09<00:07, 10.15it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 2573/2645 [04:09<00:07, 10.16it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 2573/2645 [04:09<00:07, 10.16it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 2573/2645 [04:09<00:07, 10.16it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 2575/2645 [04:09<00:06, 10.14it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 2575/2645 [04:09<00:06, 10.14it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 2575/2645 [04:09<00:06, 10.14it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 2577/2645 [04:09<00:06, 10.13it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 2577/2645 [04:09<00:06, 10.13it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 2577/2645 [04:10<00:06, 10.13it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 2579/2645 [04:10<00:06, 10.09it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 2579/2645 [04:10<00:06, 10.09it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 2579/2645 [04:10<00:06, 10.09it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 2581/2645 [04:10<00:06, 10.14it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 2581/2645 [04:10<00:06, 10.14it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 2581/2645 [04:10<00:06, 10.14it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 2583/2645 [04:10<00:06, 10.16it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 2583/2645 [04:10<00:06, 10.16it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 2583/2645 [04:10<00:06, 10.16it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 2585/2645 [04:10<00:05, 10.15it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 2585/2645 [04:10<00:05, 10.15it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 2585/2645 [04:10<00:05, 10.15it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 2587/2645 [04:10<00:05, 10.23it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 2587/2645 [04:10<00:05, 10.23it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 2587/2645 [04:11<00:05, 10.23it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 2589/2645 [04:11<00:05, 10.27it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 2589/2645 [04:11<00:05, 10.27it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 2589/2645 [04:11<00:05, 10.27it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 2591/2645 [04:11<00:05, 10.34it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 2591/2645 [04:11<00:05, 10.34it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 2591/2645 [04:11<00:05, 10.34it/s, training_loss=0.026]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 2593/2645 [04:11<00:05, 10.38it/s, training_loss=0.026]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 2593/2645 [04:11<00:05, 10.38it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 2593/2645 [04:11<00:05, 10.38it/s, training_loss=0.103]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 2595/2645 [04:11<00:04, 10.34it/s, training_loss=0.103]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 2595/2645 [04:11<00:04, 10.34it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 2595/2645 [04:11<00:04, 10.34it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 2597/2645 [04:11<00:04, 10.41it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 2597/2645 [04:11<00:04, 10.41it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 2597/2645 [04:11<00:04, 10.41it/s, training_loss=0.265]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 2599/2645 [04:11<00:04, 10.42it/s, training_loss=0.265]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 2599/2645 [04:12<00:04, 10.42it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 2599/2645 [04:12<00:04, 10.42it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 2601/2645 [04:12<00:04, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 2601/2645 [04:12<00:04, 10.45it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 2601/2645 [04:12<00:04, 10.45it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 2603/2645 [04:12<00:04, 10.45it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 2603/2645 [04:12<00:04, 10.45it/s, training_loss=0.304]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 2603/2645 [04:12<00:04, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 2605/2645 [04:12<00:03, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 2605/2645 [04:12<00:03, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 2605/2645 [04:12<00:03, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  99%|█████████▊| 2607/2645 [04:12<00:03, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  99%|█████████▊| 2607/2645 [04:12<00:03, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  99%|█████████▊| 2607/2645 [04:12<00:03, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  99%|█████████▊| 2609/2645 [04:12<00:03, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  99%|█████████▊| 2609/2645 [04:13<00:03, 10.50it/s, training_loss=0.896]\u001b[A\n",
      "Epoch 3:  99%|█████████▊| 2609/2645 [04:13<00:03, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  99%|█████████▊| 2611/2645 [04:13<00:03, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  99%|█████████▊| 2611/2645 [04:13<00:03, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  99%|█████████▊| 2611/2645 [04:13<00:03, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  99%|█████████▉| 2613/2645 [04:13<00:03, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  99%|█████████▉| 2613/2645 [04:13<00:03, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  99%|█████████▉| 2613/2645 [04:13<00:03, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  99%|█████████▉| 2615/2645 [04:13<00:02, 10.53it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  99%|█████████▉| 2615/2645 [04:13<00:02, 10.53it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  99%|█████████▉| 2615/2645 [04:13<00:02, 10.53it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  99%|█████████▉| 2617/2645 [04:13<00:02, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  99%|█████████▉| 2617/2645 [04:13<00:02, 10.50it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  99%|█████████▉| 2617/2645 [04:13<00:02, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  99%|█████████▉| 2619/2645 [04:13<00:02, 10.53it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  99%|█████████▉| 2619/2645 [04:13<00:02, 10.53it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  99%|█████████▉| 2619/2645 [04:14<00:02, 10.53it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  99%|█████████▉| 2621/2645 [04:14<00:02, 10.55it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  99%|█████████▉| 2621/2645 [04:14<00:02, 10.55it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  99%|█████████▉| 2621/2645 [04:14<00:02, 10.55it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  99%|█████████▉| 2623/2645 [04:14<00:02, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  99%|█████████▉| 2623/2645 [04:14<00:02, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  99%|█████████▉| 2623/2645 [04:14<00:02, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  99%|█████████▉| 2625/2645 [04:14<00:01, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  99%|█████████▉| 2625/2645 [04:14<00:01, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  99%|█████████▉| 2625/2645 [04:14<00:01, 10.44it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  99%|█████████▉| 2627/2645 [04:14<00:01, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  99%|█████████▉| 2627/2645 [04:14<00:01, 10.43it/s, training_loss=0.033]\u001b[A\n",
      "Epoch 3:  99%|█████████▉| 2627/2645 [04:14<00:01, 10.43it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  99%|█████████▉| 2629/2645 [04:14<00:01, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  99%|█████████▉| 2629/2645 [04:14<00:01, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  99%|█████████▉| 2629/2645 [04:15<00:01, 10.45it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  99%|█████████▉| 2631/2645 [04:15<00:01, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  99%|█████████▉| 2631/2645 [04:15<00:01, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  99%|█████████▉| 2631/2645 [04:15<00:01, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3: 100%|█████████▉| 2633/2645 [04:15<00:01, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3: 100%|█████████▉| 2633/2645 [04:15<00:01, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3: 100%|█████████▉| 2633/2645 [04:15<00:01, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3: 100%|█████████▉| 2635/2645 [04:15<00:00, 10.48it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3: 100%|█████████▉| 2635/2645 [04:15<00:00, 10.48it/s, training_loss=0.101]\u001b[A\n",
      "Epoch 3: 100%|█████████▉| 2635/2645 [04:15<00:00, 10.48it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3: 100%|█████████▉| 2637/2645 [04:15<00:00, 10.46it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3: 100%|█████████▉| 2637/2645 [04:15<00:00, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3: 100%|█████████▉| 2637/2645 [04:15<00:00, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3: 100%|█████████▉| 2639/2645 [04:15<00:00, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3: 100%|█████████▉| 2639/2645 [04:15<00:00, 10.47it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3: 100%|█████████▉| 2639/2645 [04:15<00:00, 10.47it/s, training_loss=0.507]\u001b[A\n",
      "Epoch 3: 100%|█████████▉| 2641/2645 [04:15<00:00, 10.46it/s, training_loss=0.507]\u001b[A\n",
      "Epoch 3: 100%|█████████▉| 2641/2645 [04:16<00:00, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3: 100%|█████████▉| 2641/2645 [04:16<00:00, 10.46it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3: 100%|█████████▉| 2643/2645 [04:16<00:00, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3: 100%|█████████▉| 2643/2645 [04:16<00:00, 10.50it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 3: 100%|█████████▉| 2643/2645 [04:16<00:00, 10.50it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 3: 100%|██████████| 2645/2645 [04:16<00:00, 10.83it/s, training_loss=0.001]\u001b[A\n",
      " 67%|██████▋   | 2/3 [13:46<04:45, 285.44s/it]                                   \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3\n",
      "Training loss: 0.19787852873831274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [14:12<00:00, 284.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 1.1813626895421234\n",
      "F1 Score (Weighted): 0.8173750923067524\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "seed_val = 17\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "def evaluate(dataloader_val):\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    loss_val_total = 0\n",
    "    predictions, true_vals = [], []\n",
    "    \n",
    "    for batch in dataloader_val:\n",
    "        \n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        \n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2],\n",
    "                 }\n",
    "\n",
    "        with torch.no_grad():        \n",
    "            outputs = model(**inputs)\n",
    "            \n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "        loss_val_total += loss.item()\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = inputs['labels'].cpu().numpy()\n",
    "        predictions.append(logits)\n",
    "        true_vals.append(label_ids)\n",
    "    \n",
    "    loss_val_avg = loss_val_total/len(dataloader_val) \n",
    "    \n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    true_vals = np.concatenate(true_vals, axis=0)\n",
    "            \n",
    "    return loss_val_avg, predictions, true_vals\n",
    "    \n",
    "for epoch in tqdm(range(1, NUM_EPOCHS+1)):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    loss_train_total = 0\n",
    "\n",
    "    progress_bar = tqdm(dataloader_train, desc='Epoch {:1d}'.format(epoch), leave=False, disable=False)\n",
    "    for batch in progress_bar:\n",
    "\n",
    "        model.zero_grad()\n",
    "        \n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        \n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2],\n",
    "                 }       \n",
    "\n",
    "        outputs = model(**inputs)\n",
    "        \n",
    "        loss = outputs[0]\n",
    "        loss_train_total += loss.item()\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})\n",
    "         \n",
    "        \n",
    "    #torch.save(model.state_dict(), f'model/finetuned_BERT_epoch_{epoch}.model')\n",
    "        \n",
    "    tqdm.write(f'\\nEpoch {epoch}')\n",
    "    \n",
    "    loss_train_avg = loss_train_total/len(dataloader_train)            \n",
    "    tqdm.write(f'Training loss: {loss_train_avg}')\n",
    "    \n",
    "    val_loss, predictions, true_vals = evaluate(dataloader_validation)\n",
    "    val_f1 = f1_score_func(predictions, true_vals)\n",
    "    tqdm.write(f'Validation loss: {val_loss}')\n",
    "    tqdm.write(f'F1 Score (Weighted): {val_f1}')\n",
    "torch.save(model.state_dict(), './model/online.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
    "                                                      num_labels=len(class_names),\n",
    "                                                      output_attentions=False,\n",
    "                                                      output_hidden_states=False)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "model.load_state_dict(torch.load('./model/online.pt', map_location=torch.device('cpu')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, predictions, true_vals = evaluate(dataloader_validation)\n",
    "accuracy_per_class(predictions, true_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(\"uwu! good morning Zusty Lemons\", return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(**inputs.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = outputs[0].argmax().cpu().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'joy'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
