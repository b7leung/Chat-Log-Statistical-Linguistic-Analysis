{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T17:04:57.160065Z",
     "start_time": "2021-05-11T17:04:57.150755Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T17:04:59.598265Z",
     "start_time": "2021-05-11T17:04:57.999036Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pprint\n",
    "import glob\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "add_paths = ['..', 'style_transfer_paraphrase', 'style_transfer_paraphrase/style_paraphrase']\n",
    "for add_path in add_paths: \n",
    "    if add_path not in sys.path: sys.path.append(add_path)\n",
    "        \n",
    "from style_paraphrase.inference_utils import GPT2Generator\n",
    "import data_preprocessing\n",
    "\n",
    "# prep work:\n",
    "# conda env create --file /home/svcl-oowl/brandon/misc/dockerfiles/A40_para.yaml\n",
    "# conda activate A40_para\n",
    "#? export ROBERTA_LARGE=/home/svcl-oowl/brandon/classes/ECE_229/project/ece_229_group_9_nlp_suite/nlp_suite/chatbot/style_transfer_paraphrase/fairseq/weights/roberta.large\n",
    "\n",
    "\n",
    "# pip install transformers\n",
    "# cd /home/svcl-oowl/brandon/classes/ECE_229/project/chatbot/fairseq\n",
    "# pip install --editable .\n",
    "# cd /home/svcl-oowl/brandon/classes/ECE_229/project/chatbot/fairseq/weights\n",
    "# export ROBERTA_LARGE=$PWD/roberta.large\n",
    "# cd /home/svcl-oowl/brandon/classes/ECE_229/project/chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T21:31:38.391783Z",
     "start_time": "2021-05-05T21:28:48.226949Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "paraphraser_model_dir = os.path.join(\"style_transfer_paraphrase/models\", \"paraphraser_gpt2_large\")\n",
    "#inverse_paraphraser_model_dir = os.path.join(\"style_transfer_paraphrase/models\", \"bible\")\n",
    "inverse_paraphraser_model_dir = \"style_transfer_paraphrase/style_paraphrase/saved_models/298954459172700181_muffins/checkpoint-9294\"\n",
    "\n",
    "# 6795\n",
    "with torch.cuda.device(0):\n",
    "    model = GPT2Generator(inverse_paraphraser_model_dir)\n",
    "    #paraphraser = GPT2Generator(paraphraser_model_dir, upper_length=\"same_5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T21:42:23.503878Z",
     "start_time": "2021-05-05T21:42:22.859506Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "top_p_paraphrase = 0.0 # 0.0\n",
    "top_p_style = 0.7 # 0.7\n",
    "use_paraphraser = False\n",
    "\n",
    "#input_text = \"I should have created all the animals first.\"\n",
    "#input_text = \"Hey, how was your day?\"\n",
    "#input_text = \"That's really nice of you.\"\n",
    "#input_text = \"My name is sarah.\"\n",
    "#input_text = \"Do you have any pets?\"\n",
    "#input_text = \"I have a pet cat.\"\n",
    "#input_text = \"I love cats, they're so cute.\"\n",
    "input_text = \"What other hobbies do you have?\"\n",
    "\n",
    "print([input_text])\n",
    "with torch.cuda.device(0):\n",
    "    with torch.no_grad():\n",
    "        if use_paraphraser:\n",
    "            output_paraphrase = paraphraser.generate_batch([input_text], top_p=top_p_paraphrase)[0]\n",
    "        else:\n",
    "            output_paraphrase = [input_text]\n",
    "        print(output_paraphrase)\n",
    "\n",
    "        transferred_output = model.generate_batch(output_paraphrase, top_p=top_p_style)[0]\n",
    "        print(transferred_output)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T17:05:01.706013Z",
     "start_time": "2021-05-11T17:05:01.673149Z"
    }
   },
   "outputs": [],
   "source": [
    "# preps based on instructions from https://github.com/martiansideofthemoon/style-transfer-paraphrase#custom-datasets\n",
    "\n",
    "def prep_discord_data_for_style_transfer(user, user_messages, output_dir, dev_ratio=0.10, test_ratio=0.02):\n",
    "    user_output_dir = os.path.join(output_dir, user)\n",
    "    os.makedirs(user_output_dir, exist_ok=True)\n",
    "    \n",
    "    # partitioning user messages\n",
    "    user_messages = random.sample(user_messages, len(user_messages))\n",
    "    train_messages, dev_messages, test_messages = np.split(user_messages, [int(len(user_messages)*(1-test_ratio-dev_ratio)), int(len(user_messages)*(1-test_ratio))])\n",
    "    partitions_info = {\"train\":{\"data_file\": \"train.txt\", \"label_file\": \"train.label\", \"num_messages\":0, \"messages\":train_messages},\n",
    "                      \"dev\":{\"data_file\": \"dev.txt\", \"label_file\": \"dev.label\", \"num_messages\":0, \"messages\":dev_messages},\n",
    "                      \"test\":{\"data_file\": \"test.txt\", \"label_file\": \"test.label\", \"num_messages\":0, \"messages\":test_messages}}\n",
    "\n",
    "    for partition in partitions_info:\n",
    "        data_file = partitions_info[partition][\"data_file\"]\n",
    "        label_file = partitions_info[partition][\"label_file\"]\n",
    "        num_messages = partitions_info[partition][\"num_messages\"]\n",
    "        messages = partitions_info[partition][\"messages\"]\n",
    "    \n",
    "        with open(os.path.join(user_output_dir, data_file), \"w\") as f:\n",
    "            for msg in messages:\n",
    "                try:\n",
    "                    f.write(\"{}\\n\".format(msg))\n",
    "                    num_messages += 1\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "        with open(os.path.join(user_output_dir, label_file), \"w\") as f:\n",
    "            for i in range(num_messages):\n",
    "                f.write(\"{}\\n\".format(user))\n",
    "\n",
    "    cmd = \"cd style_transfer_paraphrase\"\n",
    "    print(cmd)\n",
    "    print(\"\")\n",
    "                \n",
    "    # convert plaintext to BPE\n",
    "    cmd = \"python datasets/dataset2bpe.py --dataset {}\".format('/'.join(user_output_dir.split('/')[1:]))\n",
    "    print(cmd)\n",
    "    print(\"\")\n",
    "    \n",
    "    # convert BPE to binaries # can reduce\n",
    "    cmd = \"datasets/bpe2binary.sh {}\".format('/'.join(user_output_dir.split('/')[1:]))\n",
    "    print(cmd)\n",
    "    print(\"\")\n",
    "                                             \n",
    "    cmd = \"cp datasets/{}-bin/dict.txt datasets/{}\".format(user, user)\n",
    "    print(cmd)\n",
    "    print(\"\")\n",
    "\n",
    "    # paraphrase the dataset\n",
    "    cmd = \"python datasets/paraphrase_splits.py --dataset {} --model_dir {}\".format('/'.join(user_output_dir.split('/')[1:]), \"models/paraphraser_gpt2_large\" )\n",
    "    print(cmd)\n",
    "    print(\"\")\n",
    "    \n",
    "    # fine tune inverse paraphraser (run in style_transfer_paraphrase)\n",
    "    cmd = \"\"\"python style_paraphrase/run_lm_finetuning.py \\\n",
    "    --output_dir=style_paraphrase/saved_models/{} \\\n",
    "    --model_type=gpt2 \\\n",
    "    --model_name_or_path=gpt2-large \\\n",
    "    --data_dir=datasets/{} \\\n",
    "    --do_train \\\n",
    "    --save_steps 1000 \\\n",
    "    --evaluate_during_training \\\n",
    "    --logging_steps 400 \\\n",
    "    --save_total_limit -1 \\\n",
    "    --num_train_epochs 3 \\\n",
    "    --gradient_accumulation_steps 1 \\\n",
    "    --per_gpu_train_batch_size 16 \\\n",
    "    --job_id {} \\\n",
    "    --learning_rate 5e-5 \\\n",
    "    --prefix_input_type paraphrase_250 \\\n",
    "    --global_dense_feature_list none \\\n",
    "    --specific_style_train -1 \\\n",
    "    --optimizer adam\"\"\".format(user, user, user)\n",
    "    print(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T17:05:09.846298Z",
     "start_time": "2021-05-11T17:05:04.590258Z"
    }
   },
   "outputs": [],
   "source": [
    "channel_id = \"689963458967765003\"\n",
    "discord_data_dir = \"../../discord_dataset/discord-v3-detox-antispam\"\n",
    "user_name = \"NoPoint\"\n",
    "\n",
    "chat_log_paths = glob.glob(os.path.join(discord_data_dir, \"*{}*\".format(channel_id)))\n",
    "channel_messages, message_counts = data_preprocessing.process_discord_data(chat_log_paths, 3)\n",
    "user_messages = channel_messages[user_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T17:05:13.469801Z",
     "start_time": "2021-05-11T17:05:13.078423Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cd style_transfer_paraphrase\n",
      "\n",
      "python datasets/dataset2bpe.py --dataset datasets/NoPoint\n",
      "\n",
      "datasets/bpe2binary.sh datasets/NoPoint\n",
      "\n",
      "cp datasets/NoPoint-bin/dict.txt datasets/NoPoint\n",
      "\n",
      "python datasets/paraphrase_splits.py --dataset datasets/NoPoint --model_dir models/paraphraser_gpt2_large\n",
      "\n",
      "python style_paraphrase/run_lm_finetuning.py     --output_dir=style_paraphrase/saved_models/NoPoint     --model_type=gpt2     --model_name_or_path=gpt2-large     --data_dir=datasets/NoPoint     --do_train     --save_steps 1000     --evaluate_during_training     --logging_steps 400     --save_total_limit -1     --num_train_epochs 3     --gradient_accumulation_steps 1     --per_gpu_train_batch_size 16     --job_id NoPoint     --learning_rate 5e-5     --prefix_input_type paraphrase_250     --global_dense_feature_list none     --specific_style_train -1     --optimizer adam\n"
     ]
    }
   ],
   "source": [
    "prep_discord_data_for_style_transfer(user_name, user_messages, \"style_transfer_paraphrase/datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:standard] *",
   "language": "python",
   "name": "conda-env-standard-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
