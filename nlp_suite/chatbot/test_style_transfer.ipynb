{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T21:28:38.962983Z",
     "start_time": "2021-05-05T21:28:38.914030Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T21:28:48.136856Z",
     "start_time": "2021-05-05T21:28:39.535361Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "import sys\n",
    "add_paths = ['style_transfer_paraphrase', 'style_transfer_paraphrase/style_paraphrase'\n",
    "            ]\n",
    "for add_path in add_paths: \n",
    "    if add_path not in sys.path: sys.path.append(add_path) \n",
    "from style_paraphrase.inference_utils import GPT2Generator\n",
    "import data_preprocessing\n",
    "\n",
    "# pip install transformers\n",
    "# cd /home/svcl-oowl/brandon/classes/ECE_229/project/chatbot/fairseq\n",
    "# pip install --editable .\n",
    "# cd /home/svcl-oowl/brandon/classes/ECE_229/project/chatbot/fairseq/weights\n",
    "# export ROBERTA_LARGE=$PWD/roberta.large\n",
    "# cd /home/svcl-oowl/brandon/classes/ECE_229/project/chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T21:31:38.391783Z",
     "start_time": "2021-05-05T21:28:48.226949Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "paraphraser_model_dir = os.path.join(\"style_transfer_paraphrase/models\", \"paraphraser_gpt2_large\")\n",
    "#inverse_paraphraser_model_dir = os.path.join(\"style_transfer_paraphrase/models\", \"bible\")\n",
    "inverse_paraphraser_model_dir = \"style_transfer_paraphrase/style_paraphrase/saved_models/298954459172700181_muffins/checkpoint-9294\"\n",
    "\n",
    "# 6795\n",
    "with torch.cuda.device(0):\n",
    "    model = GPT2Generator(inverse_paraphraser_model_dir)\n",
    "    #paraphraser = GPT2Generator(paraphraser_model_dir, upper_length=\"same_5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T21:42:23.503878Z",
     "start_time": "2021-05-05T21:42:22.859506Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['What other hobbies do you have?']\n",
      "['What other hobbies do you have?']\n",
      "['What other hobbies are you into?']\n"
     ]
    }
   ],
   "source": [
    "top_p_paraphrase = 0.0 # 0.0\n",
    "top_p_style = 0.7 # 0.7\n",
    "use_paraphraser = False\n",
    "\n",
    "#input_text = \"I should have created all the animals first.\"\n",
    "#input_text = \"Hey, how was your day?\"\n",
    "#input_text = \"That's really nice of you.\"\n",
    "#input_text = \"My name is sarah.\"\n",
    "#input_text = \"Do you have any pets?\"\n",
    "#input_text = \"I have a pet cat.\"\n",
    "#input_text = \"I love cats, they're so cute.\"\n",
    "input_text = \"What other hobbies do you have?\"\n",
    "\n",
    "print([input_text])\n",
    "with torch.cuda.device(0):\n",
    "    with torch.no_grad():\n",
    "        if use_paraphraser:\n",
    "            output_paraphrase = paraphraser.generate_batch([input_text], top_p=top_p_paraphrase)[0]\n",
    "        else:\n",
    "            output_paraphrase = [input_text]\n",
    "        print(output_paraphrase)\n",
    "\n",
    "        transferred_output = model.generate_batch(output_paraphrase, top_p=top_p_style)[0]\n",
    "        print(transferred_output)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T01:17:15.676482Z",
     "start_time": "2021-05-05T01:17:15.660753Z"
    }
   },
   "outputs": [],
   "source": [
    "# preps based on instructions from https://github.com/martiansideofthemoon/style-transfer-paraphrase#custom-datasets\n",
    "\n",
    "def prep_discord_data_for_style_transfer(channel_dict, output_dir):\n",
    "    for user in channel_dict:\n",
    "        print(user)\n",
    "        user_output_dir = os.path.join(output_dir, user)\n",
    "        os.makedirs(user_output_dir, exist_ok=True)\n",
    "        \n",
    "        for data_file in [\"train.txt\", \"dev.txt\", \"test.txt\"]:\n",
    "            num_msgs = 0\n",
    "            with open(os.path.join(user_output_dir, data_file), \"w\") as f:\n",
    "                for msg in channel_dict[user]:\n",
    "                    try:\n",
    "                        f.write(\"{}\\n\".format(msg))\n",
    "                        num_msgs += 1\n",
    "                    except:\n",
    "                        pass\n",
    "        \n",
    "        for label_file in [\"train.label\", \"dev.label\", \"test.label\"]:\n",
    "            with open(os.path.join(user_output_dir, label_file), \"w\") as f:\n",
    "                for i in range(num_msgs):\n",
    "                    f.write(\"{}\\n\".format(user))\n",
    "        \n",
    "        # convert plaintext to BPE\n",
    "        cmd = \"python style_transfer_paraphrase/datasets/dataset2bpe.py --dataset {}\".format(user_output_dir)\n",
    "        print(cmd)\n",
    "        print(\"\")\n",
    "        \n",
    "        # convert BPE to binaries\n",
    "        cmd = \"style_transfer_paraphrase/datasets/bpe2binary.sh {}\".format(user_output_dir)\n",
    "        print(cmd)\n",
    "        print(\"\")\n",
    "        \n",
    "        # paraphrase the dataset\n",
    "        cmd = \"cd /home/svcl-oowl/brandon/classes/ECE_229/project/chatbot/style_transfer_paraphrase && python datasets/paraphrase_splits.py --dataset {} --model_dir {}\".format('/'.join(user_output_dir.split('/')[1:]), \"models/paraphraser_gpt2_large\" )\n",
    "        print(cmd)\n",
    "        print(\"\")\n",
    "\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T01:17:19.763878Z",
     "start_time": "2021-05-05T01:17:17.866376Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['muffins', 12391], ['LenKagamine', 11978], ['Sezzy', 11083], ['Dich', 9058], ['Fabrin', 9001], ['GR88', 8337], ['Victoria', 7341], ['DanniKawai', 7322], ['Neysa', 6949], ['Stalker', 6860]]\n"
     ]
    }
   ],
   "source": [
    "channel = \"298954459172700181\"\n",
    "#channel = \"390037306230177803\"\n",
    "discord_data_dir = \"../data/test_data_small\"\n",
    "\n",
    "channel_messages, message_counts = data_preprocessing.process_discord_data(discord_data_dir, channel, 3)\n",
    "print(message_counts[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T01:17:24.717826Z",
     "start_time": "2021-05-05T01:17:24.457254Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['muffins', 'LenKagamine', 'Sezzy', 'Dich', 'Fabrin', 'GR88', 'Victoria', 'DanniKawai', 'Neysa', 'Stalker', 'Mkie', 'TPetraT', 'ScytheOfTheUnholy', 'iza', 'boredmuziekmaster', 'BlackCadillac', 'hafts', 'Cliffu', 'SmallFan', 'skrr', 'Lou', 'AiOhto', 'CPBBAE', 'DimitriosPagourtzis', 'yodad', 'Exynos', 'LucidCapture', 'Erkis', 'Sylvbutold', 'panic', 'LucasPhelma', 'Dx8pi', 'soul', 'Cinder', 'akame.', 'ImmortaL', 'kan2', 'silent', 'CCChesterC', 'Jess', 'Dabbu', 'Marlene', 'LordofHollows', 'WhiteBoy', 'Dr.Senpips', 'AdrYuu', 'Aiz']\n",
      "298954459172700181_muffins\n",
      "python style_transfer_paraphrase/datasets/dataset2bpe.py --dataset style_transfer_paraphrase/datasets/298954459172700181_muffins\n",
      "\n",
      "style_transfer_paraphrase/datasets/bpe2binary.sh style_transfer_paraphrase/datasets/298954459172700181_muffins\n",
      "\n",
      "cd /home/svcl-oowl/brandon/classes/ECE_229/project/chatbot/style_transfer_paraphrase && python datasets/paraphrase_splits.py --dataset datasets/298954459172700181_muffins --model_dir models/paraphraser_gpt2_large\n",
      "\n"
     ]
    }
   ],
   "source": [
    "valid_users = [user[0] for user in message_counts if user[1]>1000]\n",
    "print(valid_users)\n",
    "style_transfer_msgs = {\"{}_{}\".format(channel, user):channel_messages[user] for user in valid_users}\n",
    "\n",
    "prep_discord_data_for_style_transfer(style_transfer_msgs, \"style_transfer_paraphrase/datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T17:54:56.472217Z",
     "start_time": "2021-05-05T17:54:56.459014Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cd /home/svcl-oowl/brandon/classes/ECE_229/project/chatbot/style_transfer_paraphrase\n",
      "style_paraphrase/examples/298954459172700181_muffins/run_finetune_298954459172700181_muffins.sh\n",
      "style_paraphrase/examples/298954459172700181_muffins/run_finetune_298954459172700181_muffins_0.sh\n",
      "style_paraphrase/examples/298954459172700181_muffins/run_finetune_298954459172700181_muffins_1.sh\n"
     ]
    }
   ],
   "source": [
    "cmd = \"cd /home/svcl-oowl/brandon/classes/ECE_229/project/chatbot/style_transfer_paraphrase\" \n",
    "print(cmd)\n",
    "cmd = \"style_paraphrase/examples/298954459172700181_muffins/run_finetune_298954459172700181_muffins.sh\"\n",
    "print(cmd)\n",
    "cmd = \"style_paraphrase/examples/298954459172700181_muffins/run_finetune_298954459172700181_muffins_0.sh\"\n",
    "print(cmd)\n",
    "cmd = \"style_paraphrase/examples/298954459172700181_muffins/run_finetune_298954459172700181_muffins_1.sh\"\n",
    "print(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:standard] *",
   "language": "python",
   "name": "conda-env-standard-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
